[
    {
        "commit": "https://github.com/apache/pig/commit/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7",
        "file": [
            {
                "patch": "@@ -92,9 +92,11 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n-PIG-5386: Pig local mode with bundled Hadoop broken\n+PIG-5375: NullPointerException for multi-level self unions with Tez UnionOptimizer (knoguchi)\n \n-PIG-5387: Test failures on JRE 11\n+PIG-5386: Pig local mode with bundled Hadoop broken (nkollar)\n+\n+PIG-5387: Test failures on JRE 11 (nkollar)\n \n PIG-5383: OrcStorage fails when \"bytearray\" represents unknown type (knoguchi)\n ",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/CHANGES.txt",
                "status": "modified",
                "changes": 6,
                "deletions": 2,
                "sha": "2922cdc8b06315c8d3fd28fbc917e0450e6e978c",
                "blob_url": "https://github.com/apache/pig/blob/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7"
            },
            {
                "patch": "@@ -289,18 +289,16 @@ public void visitTezOp(TezOperator tezOp) throws VisitorException {\n                 if (storeVertexGroupOps[i] != null) {\n                     continue;\n                 }\n-            }\n-            if (existingVertexGroup != null) {\n-                storeVertexGroupOps[i] = existingVertexGroup;\n-                existingVertexGroup.getVertexGroupMembers().remove(unionOp.getOperatorKey());\n-                existingVertexGroup.getVertexGroupMembers().addAll(unionOp.getUnionMembers());\n-                existingVertexGroup.getVertexGroupInfo().removeInput(unionOp.getOperatorKey());\n-            } else {\n                 storeVertexGroupOps[i] = new TezOperator(OperatorKey.genOpKey(scope));\n                 storeVertexGroupOps[i].setVertexGroupInfo(new VertexGroupInfo(unionStoreOutputs.get(i)));\n                 storeVertexGroupOps[i].getVertexGroupInfo().setSFile(unionStoreOutputs.get(i).getSFile());\n                 storeVertexGroupOps[i].setVertexGroupMembers(new ArrayList<OperatorKey>(unionOp.getUnionMembers()));\n                 tezPlan.add(storeVertexGroupOps[i]);\n+            } else {\n+                storeVertexGroupOps[i] = existingVertexGroup;\n+                existingVertexGroup.getVertexGroupMembers().remove(unionOp.getOperatorKey());\n+                existingVertexGroup.getVertexGroupMembers().addAll(unionOp.getUnionMembers());\n+                existingVertexGroup.getVertexGroupInfo().removeInput(unionOp.getOperatorKey());\n             }\n         }\n \n@@ -320,19 +318,36 @@ public void visitTezOp(TezOperator tezOp) throws VisitorException {\n         TezOperator[] outputVertexGroupOps = new TezOperator[unionOutputKeys.size()];\n         String[] newOutputKeys = new String[unionOutputKeys.size()];\n         for (int i=0; i < outputVertexGroupOps.length; i++) {\n-            for (int j = 0; j < i; j++) {\n-                if (unionOutputKeys.get(i).equals(unionOutputKeys.get(j))) {\n-                    outputVertexGroupOps[i] = outputVertexGroupOps[j];\n-                    break;\n+            TezOperator existingVertexGroup = null;\n+            if (successors != null) {\n+                for (TezOperator succ : successors) {\n+                    if (succ.isVertexGroup()\n+                        && unionOutputKeys.get(i).equals(succ.getVertexGroupInfo().getOutput()) ) {\n+                        existingVertexGroup = succ;\n+                        break;\n+                    }\n                 }\n             }\n-            if (outputVertexGroupOps[i] != null) {\n-                continue;\n+            if (existingVertexGroup == null) {\n+                for (int j = 0; j < i; j++) {\n+                    if (unionOutputKeys.get(i).equals(unionOutputKeys.get(j))) {\n+                        outputVertexGroupOps[i] = outputVertexGroupOps[j];\n+                        break;\n+                    }\n+                }\n+                if (outputVertexGroupOps[i] != null) {\n+                    continue;\n+                }\n+                outputVertexGroupOps[i] = new TezOperator(OperatorKey.genOpKey(scope));\n+                outputVertexGroupOps[i].setVertexGroupInfo(new VertexGroupInfo());\n+                outputVertexGroupOps[i].getVertexGroupInfo().setOutput(unionOutputKeys.get(i));\n+                outputVertexGroupOps[i].setVertexGroupMembers(new ArrayList<OperatorKey>(unionOp.getUnionMembers()));\n+            } else {\n+                outputVertexGroupOps[i] = existingVertexGroup;\n+                existingVertexGroup.getVertexGroupMembers().remove(unionOp.getOperatorKey());\n+                existingVertexGroup.getVertexGroupMembers().addAll(unionOp.getUnionMembers());\n+                existingVertexGroup.getVertexGroupInfo().removeInput(unionOp.getOperatorKey());\n             }\n-            outputVertexGroupOps[i] = new TezOperator(OperatorKey.genOpKey(scope));\n-            outputVertexGroupOps[i].setVertexGroupInfo(new VertexGroupInfo());\n-            outputVertexGroupOps[i].getVertexGroupInfo().setOutput(unionOutputKeys.get(i));\n-            outputVertexGroupOps[i].setVertexGroupMembers(new ArrayList<OperatorKey>(unionOp.getUnionMembers()));\n             newOutputKeys[i] = outputVertexGroupOps[i].getOperatorKey().toString();\n             tezPlan.add(outputVertexGroupOps[i]);\n         }\n@@ -619,18 +634,6 @@ private void connectVertexGroupsToSuccessors(TezOperator unionOp,\n         // Connect to outputVertexGroupOps\n         for (Entry<OperatorKey, TezEdgeDescriptor> entry : unionOp.outEdges.entrySet()) {\n             TezOperator succOp = tezPlan.getOperator(entry.getKey());\n-            // Case of union followed by union.\n-            // unionOp.outEdges will not point to vertex group, but to its output.\n-            // So find the vertex group if there is one.\n-            TezOperator succOpVertexGroup = null;\n-            for (TezOperator succ : successors) {\n-                if (succ.isVertexGroup()\n-                        && succOp.getOperatorKey().toString()\n-                                .equals(succ.getVertexGroupInfo().getOutput())) {\n-                    succOpVertexGroup = succ;\n-                    break;\n-                }\n-            }\n             TezEdgeDescriptor edge = entry.getValue();\n             // Edge cannot be one to one as it will get input from two or\n             // more union predecessors. Change it to SCATTER_GATHER\n@@ -641,26 +644,14 @@ private void connectVertexGroupsToSuccessors(TezOperator unionOp,\n                 edge.inputClassName = UnorderedKVInput.class.getName();\n             }\n             TezOperator vertexGroupOp = outputVertexGroupOps[unionOutputKeys.indexOf(entry.getKey().toString())];\n-            for (OperatorKey predKey : vertexGroupOp.getVertexGroupMembers()) {\n+            for (OperatorKey predKey : unionOp.getUnionMembers()) {\n                 TezOperator pred = tezPlan.getOperator(predKey);\n                 // Keep the output edge directly to successor\n                 // Don't need to keep output edge for vertexgroup\n                 pred.outEdges.put(entry.getKey(), edge);\n                 succOp.inEdges.put(predKey, edge);\n-                if (succOpVertexGroup != null) {\n-                    succOpVertexGroup.getVertexGroupMembers().add(predKey);\n-                    succOpVertexGroup.getVertexGroupInfo().addInput(predKey);\n-                    // Connect directly to the successor vertex group\n-                    tezPlan.disconnect(pred, vertexGroupOp);\n-                    tezPlan.connect(pred, succOpVertexGroup);\n-                }\n             }\n-            if (succOpVertexGroup != null) {\n-                succOpVertexGroup.getVertexGroupMembers().remove(unionOp.getOperatorKey());\n-                succOpVertexGroup.getVertexGroupInfo().removeInput(unionOp.getOperatorKey());\n-                //Discard the new vertex group created\n-                tezPlan.remove(vertexGroupOp);\n-            } else {\n+            if(!tezPlan.pathExists(vertexGroupOp, succOp)) {\n                 tezPlan.connect(vertexGroupOp, succOp);\n             }\n         }",
                "additions": 34,
                "raw_url": "https://github.com/apache/pig/raw/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "status": "modified",
                "changes": 77,
                "deletions": 43,
                "sha": "6ea5a8b09d49ea688760962d0bf00f5d99988c14",
                "blob_url": "https://github.com/apache/pig/blob/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java?ref=c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7"
            },
            {
                "patch": "@@ -773,6 +773,19 @@ u3 = UNION ONSCHEMA e, f;\n SPLIT u3 INTO t if age > 75, u OTHERWISE;\r\n v = JOIN t BY name LEFT, c BY votername;\r\n store v into ':OUTPATH:';\\,\r\n+            },\r\n+            {\r\n+            # PIG-5375. multi-level Unions with splits\r\n+            'num' => 15,\r\n+            'pig' => q\\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age:int, gpa);\r\n+b= load ':INPATH:/singlefile/studentnulltab10k' as (name, age:int, gpa);\r\n+c= load ':INPATH:/singlefile/studentnulltab10k' as (name, age:int, gpa);\r\n+a_and_b = UNION ONSCHEMA a, b;\r\n+SPLIT a_and_b INTO a_and_b2 IF age < 30, a_and_b3 OTHERWISE;\r\n+a_and_b_and_c = UNION ONSCHEMA c, a_and_b;\r\n+v = UNION ONSCHEMA a_and_b_and_c, a_and_b2, a_and_b3;\r\n+v2 = GROUP v by *;\r\n+store v2 into ':OUTPATH:';\\,\r\n             }\r\n             ] # end of tests\r\n         },\r",
                "additions": 13,
                "raw_url": "https://github.com/apache/pig/raw/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/e2e/pig/tests/multiquery.conf",
                "status": "modified",
                "changes": 13,
                "deletions": 0,
                "sha": "b470d373527758df96abc50d6bc6fa8c36039ef8",
                "blob_url": "https://github.com/apache/pig/blob/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/e2e/pig/tests/multiquery.conf",
                "filename": "test/e2e/pig/tests/multiquery.conf",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/e2e/pig/tests/multiquery.conf?ref=c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7"
            },
            {
                "patch": "@@ -34,13 +34,13 @@ e: Split - scope-61\n     |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-17\n Tez vertex scope-37\n # Plan on vertex\n-e: Split - scope-66\n+e: Split - scope-65\n |   |\n-|   e: Store(file:///tmp/pigoutput1:org.apache.pig.builtin.PigStorage) - scope-67\t->\t scope-29\n+|   e: Store(file:///tmp/pigoutput1:org.apache.pig.builtin.PigStorage) - scope-66\t->\t scope-29\n |   |\n-|   f: Local Rearrange[tuple]{int}(false) - scope-68\t->\t scope-53\n+|   f: Local Rearrange[tuple]{int}(false) - scope-67\t->\t scope-53\n |   |   |\n-|   |   Project[int][0] - scope-69\n+|   |   Project[int][0] - scope-68\n |\n |---a: New For Each(false,false)[bag] - scope-7\n     |   |\n@@ -55,13 +55,13 @@ e: Split - scope-66\n     |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0\n Tez vertex scope-38\n # Plan on vertex\n-e: Split - scope-70\n+e: Split - scope-69\n |   |\n-|   e: Store(file:///tmp/pigoutput1:org.apache.pig.builtin.PigStorage) - scope-71\t->\t scope-29\n+|   e: Store(file:///tmp/pigoutput1:org.apache.pig.builtin.PigStorage) - scope-70\t->\t scope-29\n |   |\n-|   f: Local Rearrange[tuple]{int}(false) - scope-72\t->\t scope-53\n+|   f: Local Rearrange[tuple]{int}(false) - scope-71\t->\t scope-53\n |   |   |\n-|   |   Project[int][0] - scope-73\n+|   |   Project[int][0] - scope-72\n |\n |---c: New For Each(false,false)[bag] - scope-15\n     |   |",
                "additions": 8,
                "raw_url": "https://github.com/apache/pig/raw/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "status": "modified",
                "changes": 16,
                "deletions": 8,
                "sha": "db95b77ac884d0d275e39fa617d79522eba5faa0",
                "blob_url": "https://github.com/apache/pig/blob/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld?ref=c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7"
            },
            {
                "patch": "@@ -27,77 +27,77 @@ d: Local Rearrange[tuple]{chararray}(false) - scope-29\t->\t scope-84\n     |---c: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-18\n Tez vertex scope-74\n # Plan on vertex\n-1-3: Split - scope-166\n+1-3: Split - scope-165\n |   |\n-|   d: Local Rearrange[tuple]{chararray}(false) - scope-171\t->\t scope-84\n+|   d: Local Rearrange[tuple]{chararray}(false) - scope-170\t->\t scope-84\n |   |   |\n-|   |   Project[chararray][0] - scope-172\n+|   |   Project[chararray][0] - scope-171\n |   |\n-|   |---r: Filter[bag] - scope-167\n+|   |---r: Filter[bag] - scope-166\n |       |   |\n-|       |   Not Equal To[boolean] - scope-170\n+|       |   Not Equal To[boolean] - scope-169\n |       |   |\n-|       |   |---Project[chararray][0] - scope-168\n+|       |   |---Project[chararray][0] - scope-167\n |       |   |\n-|       |   |---Constant() - scope-169\n+|       |   |---Constant() - scope-168\n |   |\n-|   u2: Split - scope-181\n+|   u2: Split - scope-180\n |   |   |\n-|   |   POValueOutputTez - scope-191\t->\t [scope-104]\n+|   |   POValueOutputTez - scope-190\t->\t [scope-104]\n |   |   |\n-|   |   |---v: Limit - scope-190\n+|   |   |---v: Limit - scope-189\n |   |       |\n-|   |       |---t: Filter[bag] - scope-186\n+|   |       |---t: Filter[bag] - scope-185\n |   |           |   |\n-|   |           |   Not Equal To[boolean] - scope-189\n+|   |           |   Not Equal To[boolean] - scope-188\n |   |           |   |\n-|   |           |   |---Project[chararray][0] - scope-187\n+|   |           |   |---Project[chararray][0] - scope-186\n |   |           |   |\n-|   |           |   |---Constant() - scope-188\n+|   |           |   |---Constant() - scope-187\n |   |           |\n-|   |           |---e: Filter[bag] - scope-182\n+|   |           |---e: Filter[bag] - scope-181\n |   |               |   |\n-|   |               |   Equal To[boolean] - scope-185\n+|   |               |   Equal To[boolean] - scope-184\n |   |               |   |\n-|   |               |   |---Project[chararray][0] - scope-183\n+|   |               |   |---Project[chararray][0] - scope-182\n |   |               |   |\n-|   |               |   |---Constant() - scope-184\n+|   |               |   |---Constant() - scope-183\n |   |   |\n-|   |   POValueOutputTez - scope-201\t->\t [scope-104]\n+|   |   POValueOutputTez - scope-200\t->\t [scope-104]\n |   |   |\n-|   |   |---v: Limit - scope-200\n+|   |   |---v: Limit - scope-199\n |   |       |\n-|   |       |---t: Filter[bag] - scope-196\n+|   |       |---t: Filter[bag] - scope-195\n |   |           |   |\n-|   |           |   Not Equal To[boolean] - scope-199\n+|   |           |   Not Equal To[boolean] - scope-198\n |   |           |   |\n-|   |           |   |---Project[chararray][0] - scope-197\n+|   |           |   |---Project[chararray][0] - scope-196\n |   |           |   |\n-|   |           |   |---Constant() - scope-198\n+|   |           |   |---Constant() - scope-197\n |   |           |\n-|   |           |---f: Filter[bag] - scope-192\n+|   |           |---f: Filter[bag] - scope-191\n |   |               |   |\n-|   |               |   Equal To[boolean] - scope-195\n+|   |               |   Equal To[boolean] - scope-194\n |   |               |   |\n-|   |               |   |---Project[chararray][0] - scope-193\n+|   |               |   |---Project[chararray][0] - scope-192\n |   |               |   |\n-|   |               |   |---Constant(m) - scope-194\n+|   |               |   |---Constant(m) - scope-193\n |   |\n-|   |---u2: New For Each(false,false)[bag] - scope-180\n+|   |---u2: New For Each(false,false)[bag] - scope-179\n |       |   |\n-|       |   Project[chararray][0] - scope-178\n+|       |   Project[chararray][0] - scope-177\n |       |   |\n-|       |   Constant(DummyVal) - scope-179\n+|       |   Constant(DummyVal) - scope-178\n |       |\n-|       |---s: Filter[bag] - scope-173\n+|       |---s: Filter[bag] - scope-172\n |           |   |\n-|           |   Not[boolean] - scope-177\n+|           |   Not[boolean] - scope-176\n |           |   |\n-|           |   |---Not Equal To[boolean] - scope-176\n+|           |   |---Not Equal To[boolean] - scope-175\n |           |       |\n-|           |       |---Project[chararray][0] - scope-174\n+|           |       |---Project[chararray][0] - scope-173\n |           |       |\n-|           |       |---Constant() - scope-175\n+|           |       |---Constant() - scope-174\n |\n |---a: New For Each(false)[bag] - scope-6\n     |   |\n@@ -108,77 +108,77 @@ Tez vertex scope-74\n     |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-2\n Tez vertex scope-75\n # Plan on vertex\n-1-3: Split - scope-202\n+1-3: Split - scope-201\n |   |\n-|   d: Local Rearrange[tuple]{chararray}(false) - scope-207\t->\t scope-84\n+|   d: Local Rearrange[tuple]{chararray}(false) - scope-206\t->\t scope-84\n |   |   |\n-|   |   Project[chararray][0] - scope-208\n+|   |   Project[chararray][0] - scope-207\n |   |\n-|   |---r: Filter[bag] - scope-203\n+|   |---r: Filter[bag] - scope-202\n |       |   |\n-|       |   Not Equal To[boolean] - scope-206\n+|       |   Not Equal To[boolean] - scope-205\n |       |   |\n-|       |   |---Project[chararray][0] - scope-204\n+|       |   |---Project[chararray][0] - scope-203\n |       |   |\n-|       |   |---Constant() - scope-205\n+|       |   |---Constant() - scope-204\n |   |\n-|   u2: Split - scope-217\n+|   u2: Split - scope-216\n |   |   |\n-|   |   POValueOutputTez - scope-227\t->\t [scope-104]\n+|   |   POValueOutputTez - scope-226\t->\t [scope-104]\n |   |   |\n-|   |   |---v: Limit - scope-226\n+|   |   |---v: Limit - scope-225\n |   |       |\n-|   |       |---t: Filter[bag] - scope-222\n+|   |       |---t: Filter[bag] - scope-221\n |   |           |   |\n-|   |           |   Not Equal To[boolean] - scope-225\n+|   |           |   Not Equal To[boolean] - scope-224\n |   |           |   |\n-|   |           |   |---Project[chararray][0] - scope-223\n+|   |           |   |---Project[chararray][0] - scope-222\n |   |           |   |\n-|   |           |   |---Constant() - scope-224\n+|   |           |   |---Constant() - scope-223\n |   |           |\n-|   |           |---e: Filter[bag] - scope-218\n+|   |           |---e: Filter[bag] - scope-217\n |   |               |   |\n-|   |               |   Equal To[boolean] - scope-221\n+|   |               |   Equal To[boolean] - scope-220\n |   |               |   |\n-|   |               |   |---Project[chararray][0] - scope-219\n+|   |               |   |---Project[chararray][0] - scope-218\n |   |               |   |\n-|   |               |   |---Constant() - scope-220\n+|   |               |   |---Constant() - scope-219\n |   |   |\n-|   |   POValueOutputTez - scope-237\t->\t [scope-104]\n+|   |   POValueOutputTez - scope-236\t->\t [scope-104]\n |   |   |\n-|   |   |---v: Limit - scope-236\n+|   |   |---v: Limit - scope-235\n |   |       |\n-|   |       |---t: Filter[bag] - scope-232\n+|   |       |---t: Filter[bag] - scope-231\n |   |           |   |\n-|   |           |   Not Equal To[boolean] - scope-235\n+|   |           |   Not Equal To[boolean] - scope-234\n |   |           |   |\n-|   |           |   |---Project[chararray][0] - scope-233\n+|   |           |   |---Project[chararray][0] - scope-232\n |   |           |   |\n-|   |           |   |---Constant() - scope-234\n+|   |           |   |---Constant() - scope-233\n |   |           |\n-|   |           |---f: Filter[bag] - scope-228\n+|   |           |---f: Filter[bag] - scope-227\n |   |               |   |\n-|   |               |   Equal To[boolean] - scope-231\n+|   |               |   Equal To[boolean] - scope-230\n |   |               |   |\n-|   |               |   |---Project[chararray][0] - scope-229\n+|   |               |   |---Project[chararray][0] - scope-228\n |   |               |   |\n-|   |               |   |---Constant(m) - scope-230\n+|   |               |   |---Constant(m) - scope-229\n |   |\n-|   |---u2: New For Each(false,false)[bag] - scope-216\n+|   |---u2: New For Each(false,false)[bag] - scope-215\n |       |   |\n-|       |   Project[chararray][0] - scope-214\n+|       |   Project[chararray][0] - scope-213\n |       |   |\n-|       |   Constant(DummyVal) - scope-215\n+|       |   Constant(DummyVal) - scope-214\n |       |\n-|       |---s: Filter[bag] - scope-209\n+|       |---s: Filter[bag] - scope-208\n |           |   |\n-|           |   Not[boolean] - scope-213\n+|           |   Not[boolean] - scope-212\n |           |   |\n-|           |   |---Not Equal To[boolean] - scope-212\n+|           |   |---Not Equal To[boolean] - scope-211\n |           |       |\n-|           |       |---Project[chararray][0] - scope-210\n+|           |       |---Project[chararray][0] - scope-209\n |           |       |\n-|           |       |---Constant() - scope-211\n+|           |       |---Constant() - scope-210\n |\n |---b: New For Each(false)[bag] - scope-11\n     |   |\n@@ -254,7 +254,7 @@ u2: Split - scope-122\n         |   |---Constant({()}) - scope-35\n         |\n         |---d: Package(Packager)[tuple]{chararray} - scope-26\n-Tez vertex group scope-121\t<-\t [scope-84, scope-84, scope-76, scope-74, scope-75]\t->\t scope-104\n+Tez vertex group scope-121\t<-\t [scope-84, scope-84, scope-74, scope-74, scope-75, scope-75]\t->\t scope-104\n # No plan on vertex group\n Tez vertex scope-104\n # Plan on vertex",
                "additions": 73,
                "raw_url": "https://github.com/apache/pig/raw/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-21.gld",
                "status": "modified",
                "changes": 146,
                "deletions": 73,
                "sha": "27bced27e34e7d533b0aa0ba5d6ada8323f8b6f7",
                "blob_url": "https://github.com/apache/pig/blob/c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-21.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-21.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-21.gld?ref=c8ac87c2516e9d4e446fdb9d1cc4a04ccaacebb7"
            }
        ],
        "bug_id": "pig_1",
        "parent": "https://github.com/apache/pig/commit/61cb452177c63ff49bc843a5a3555072be914079",
        "message": "PIG-5375: NullPointerException for multi-level self unions with Tez UnionOptimizer (knoguchi)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1862504 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/01b7a50657b46d346f0a8f472c92fdba72819a24",
        "file": [
            {
                "patch": "@@ -87,6 +87,7 @@ PIG-5251: Bump joda-time to 2.9.9 (dbist13 via rohini)\n OPTIMIZATIONS\n  \n BUG FIXES\n+PIG-5372: SAMPLE/RANDOM(udf) before skewed join failing with NPE (knoguchi)\n \n PIG-5374: Use CircularFifoBuffer in InterRecordReader (szita)\n ",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/01b7a50657b46d346f0a8f472c92fdba72819a24/CHANGES.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "ceba83de46d545efee0e2147fb16796ef78f5cfe",
                "blob_url": "https://github.com/apache/pig/blob/01b7a50657b46d346f0a8f472c92fdba72819a24/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=01b7a50657b46d346f0a8f472c92fdba72819a24"
            },
            {
                "patch": "@@ -112,8 +112,6 @@ public int getPartition(PigNullableWritable wrappedKey, Writable value, int numP\n     @Override\n     public void setConf(Configuration job) {\n         conf = job;\n-        PigMapReduce.sJobConfInternal.set(conf);\n-        PigMapReduce.sJobConf = conf;\n     }\n \n     @Override",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/01b7a50657b46d346f0a8f472c92fdba72819a24/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java",
                "status": "modified",
                "changes": 2,
                "deletions": 2,
                "sha": "1209989808511324633db5a30f7da6cae5d4adb2",
                "blob_url": "https://github.com/apache/pig/blob/01b7a50657b46d346f0a8f472c92fdba72819a24/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java?ref=01b7a50657b46d346f0a8f472c92fdba72819a24"
            },
            {
                "patch": "@@ -93,10 +93,10 @@\n             conf.set(\"yarn.resourcemanager.principal\", mapConf.get(\"yarn.resourcemanager.principal\"));\n         }\n \n-        if (PigMapReduce.sJobConfInternal.get().get(\"fs.file.impl\")!=null)\n-            conf.set(\"fs.file.impl\", PigMapReduce.sJobConfInternal.get().get(\"fs.file.impl\"));\n-        if (PigMapReduce.sJobConfInternal.get().get(\"fs.hdfs.impl\")!=null)\n-            conf.set(\"fs.hdfs.impl\", PigMapReduce.sJobConfInternal.get().get(\"fs.hdfs.impl\"));\n+        if (mapConf.get(\"fs.file.impl\")!=null)\n+            conf.set(\"fs.file.impl\", mapConf.get(\"fs.file.impl\"));\n+        if (mapConf.get(\"fs.hdfs.impl\")!=null)\n+            conf.set(\"fs.hdfs.impl\", mapConf.get(\"fs.hdfs.impl\"));\n \n         copyTmpFileConfigurationValues(PigMapReduce.sJobConfInternal.get(), conf);\n ",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/01b7a50657b46d346f0a8f472c92fdba72819a24/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java",
                "status": "modified",
                "changes": 8,
                "deletions": 4,
                "sha": "ec931f6507bcc7a2da1ca54806512225bf677237",
                "blob_url": "https://github.com/apache/pig/blob/01b7a50657b46d346f0a8f472c92fdba72819a24/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java?ref=01b7a50657b46d346f0a8f472c92fdba72819a24"
            },
            {
                "patch": "@@ -207,7 +207,6 @@ public void testSkewedJoinMapLeftEmpty() throws IOException{\n         assertEquals(0, count);\n     }\n \n-\n     @Test\n     public void testSkewedJoinWithGroup() throws IOException{\n         pigServer.registerQuery(\"A = LOAD '\" + INPUT_FILE1 + \"' as (id, name, n);\");\n@@ -354,7 +353,7 @@ public void testSkewedJoinNullKeys() throws IOException {\n         try {\n             DataBag dbfrj = BagFactory.getInstance().newDefaultBag();\n             {\n-                pigServer.registerQuery(\"C = join A by id, B by id using 'skewed';\");\n+                pigServer.registerQuery(\"C = join A by id, B by id using 'skewed' parallel 2;\");\n                 Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n \n                 while(iter.hasNext()) {\n@@ -375,23 +374,23 @@ public void testSkewedJoinOuter() throws IOException {\n         pigServer.registerQuery(\"B = LOAD '\" + INPUT_FILE5 + \"' as (id,name);\");\n         DataBag dbfrj = BagFactory.getInstance().newDefaultBag();\n         {\n-            pigServer.registerQuery(\"C = join A by id left, B by id using 'skewed';\");\n+            pigServer.registerQuery(\"C = join A by id left, B by id using 'skewed' parallel 2;\");\n             Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n \n             while(iter.hasNext()) {\n                 dbfrj.add(iter.next());\n             }\n         }\n         {\n-            pigServer.registerQuery(\"C = join A by id right, B by id using 'skewed';\");\n+            pigServer.registerQuery(\"C = join A by id right, B by id using 'skewed' parallel 2;\");\n             Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n \n             while(iter.hasNext()) {\n                 dbfrj.add(iter.next());\n             }\n         }\n         {\n-            pigServer.registerQuery(\"C = join A by id full, B by id using 'skewed';\");\n+            pigServer.registerQuery(\"C = join A by id full, B by id using 'skewed' parallel 2;\");\n             Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n \n             while(iter.hasNext()) {\n@@ -413,7 +412,7 @@ public void testSkewedJoinOneValue() throws IOException {\n \n         DataBag dbfrj = BagFactory.getInstance().newDefaultBag(), dbrj = BagFactory.getInstance().newDefaultBag();\n         {\n-            pigServer.registerQuery(\"E = join C by id, D by id using 'skewed';\");\n+            pigServer.registerQuery(\"E = join C by id, D by id using 'skewed' parallel 2;\");\n             Iterator<Tuple> iter = pigServer.openIterator(\"E\");\n \n             while(iter.hasNext()) {\n@@ -487,7 +486,7 @@ public void testSkewedJoinEmptyInput() throws IOException {\n         pigServer.registerQuery(\"a = load 'left.dat' as (nums:chararray);\");\n         pigServer.registerQuery(\"b = load 'right.dat' as (number:chararray,text:chararray);\");\n         pigServer.registerQuery(\"c = filter a by nums == '7';\");\n-        pigServer.registerQuery(\"d = join c by nums LEFT OUTER, b by number USING 'skewed';\");\n+        pigServer.registerQuery(\"d = join c by nums LEFT OUTER, b by number USING 'skewed' parallel 2;\");\n \n         Iterator<Tuple> iter = pigServer.openIterator(\"d\");\n \n@@ -515,7 +514,7 @@ public void testRecursiveFileListing() throws IOException {\n \n         pigServer.registerQuery(\"a = load 'foo' as (nums:chararray);\");\n         pigServer.registerQuery(\"b = load 'foo' as (nums:chararray);\");\n-        pigServer.registerQuery(\"d = join a by nums, b by nums USING 'skewed';\");\n+        pigServer.registerQuery(\"d = join a by nums, b by nums USING 'skewed' parallel 2;\");\n \n         Iterator<Tuple> iter = pigServer.openIterator(\"d\");\n         int count = 0;\n@@ -569,7 +568,7 @@ public void testNonExistingInputPathInSkewJoin() throws Exception {\n           \"exists = LOAD '\" + INPUT_FILE2 + \"' AS (a:long, x:chararray);\" +\n           \"missing = LOAD '/non/existing/directory' AS (a:long);\" +\n           \"missing = FOREACH ( GROUP missing BY a ) GENERATE $0 AS a, COUNT_STAR($1);\" +\n-          \"joined = JOIN exists BY a, missing BY a USING 'skewed';\";\n+          \"joined = JOIN exists BY a, missing BY a USING 'skewed' parallel 2;\";\n \n         String logFile = Util.createTempFileDelOnExit(\"tmp\", \".log\").getAbsolutePath();\n         Logger logger = Logger.getLogger(\"org.apache.pig\");\n@@ -619,4 +618,34 @@ public void testNonExistingInputPathInSkewJoin() throws Exception {\n         }\n     }\n \n+    // PIG-5372\n+    @Test\n+    public void testSkewedJoinWithRANDOMudf() throws IOException{\n+        pigServer.registerQuery(\"A = LOAD '\" + INPUT_FILE1 + \"' as (id, name, n);\");\n+        pigServer.registerQuery(\"B = LOAD '\" + INPUT_FILE2 + \"' as (id, name);\");\n+        pigServer.registerQuery(\"A2 = FOREACH A GENERATE id, RANDOM() as randnum;\");\n+\n+        DataBag dbfrj = BagFactory.getInstance().newDefaultBag(), dbshj = BagFactory.getInstance().newDefaultBag();\n+        {\n+            pigServer.registerQuery(\"D = join A2 by id, B by id using 'skewed' parallel 2;\");\n+            Iterator<Tuple> iter = pigServer.openIterator(\"D\");\n+\n+            while(iter.hasNext()) {\n+                dbfrj.add(iter.next());\n+            }\n+        }\n+        {\n+            pigServer.registerQuery(\"D = join A2 by id, B by id;\");\n+            Iterator<Tuple> iter = pigServer.openIterator(\"D\");\n+\n+            while(iter.hasNext()) {\n+                dbshj.add(iter.next());\n+            }\n+        }\n+        assertTrue(dbfrj.size()>0);\n+        assertTrue(dbshj.size()>0);\n+        assertEquals(dbfrj.size(), dbshj.size());\n+    }\n+\n+\n }",
                "additions": 38,
                "raw_url": "https://github.com/apache/pig/raw/01b7a50657b46d346f0a8f472c92fdba72819a24/test/org/apache/pig/test/TestSkewedJoin.java",
                "status": "modified",
                "changes": 47,
                "deletions": 9,
                "sha": "e1ad73cb04d95b21b1ce7bcc64ce420188ed522d",
                "blob_url": "https://github.com/apache/pig/blob/01b7a50657b46d346f0a8f472c92fdba72819a24/test/org/apache/pig/test/TestSkewedJoin.java",
                "filename": "test/org/apache/pig/test/TestSkewedJoin.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestSkewedJoin.java?ref=01b7a50657b46d346f0a8f472c92fdba72819a24"
            }
        ],
        "bug_id": "pig_2",
        "parent": "https://github.com/apache/pig/commit/8cecd74b7f64f7e964ea7164637da1011e1ab92f",
        "message": "PIG-5372: SAMPLE/RANDOM(udf) before skewed join failing with NPE (knoguchi)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1852183 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/518b5d0a958f22b35e108e609ada523fee3f6a69",
        "file": [
            {
                "patch": "@@ -52,6 +52,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-5307: NPE in TezOperDependencyParallelismEstimator (rohini)\n+\n PIG-5272: BagToTuple output schema is incorrect (juen1jp via rohini)\n \n PIG-5271: StackOverflowError when compiling in Tez mode (with union and replicated join) (knoguchi)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/518b5d0a958f22b35e108e609ada523fee3f6a69/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "99df4cb76dcc3a25ded7b8e722b77e601f7223d7",
                "blob_url": "https://github.com/apache/pig/blob/518b5d0a958f22b35e108e609ada523fee3f6a69/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=518b5d0a958f22b35e108e609ada523fee3f6a69"
            },
            {
                "patch": "@@ -217,7 +217,7 @@ public TezParallelismFactorVisitor(TezOperator tezOp, TezOperator successor) {\n         public void visitFilter(POFilter fl) throws VisitorException {\n             if (fl.getPlan().size()==1 && fl.getPlan().getRoots().get(0) instanceof ConstantExpression) {\n                 ConstantExpression cons = (ConstantExpression)fl.getPlan().getRoots().get(0);\n-                if (cons.getValue().equals(Boolean.TRUE)) {\n+                if (Boolean.TRUE.equals(cons.getValue())) {\n                     // skip all true condition\n                     return;\n                 }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/518b5d0a958f22b35e108e609ada523fee3f6a69/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/TezOperDependencyParallelismEstimator.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "b4223db592fdb0ac2f1e1553db56ce9771595f0f",
                "blob_url": "https://github.com/apache/pig/blob/518b5d0a958f22b35e108e609ada523fee3f6a69/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/TezOperDependencyParallelismEstimator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/TezOperDependencyParallelismEstimator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/TezOperDependencyParallelismEstimator.java?ref=518b5d0a958f22b35e108e609ada523fee3f6a69"
            }
        ],
        "bug_id": "pig_3",
        "parent": "https://github.com/apache/pig/commit/e07bcade84ff174680a754f607e5b39c4c003fb7",
        "message": "PIG-5307: NPE in TezOperDependencyParallelismEstimator (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1810606 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/6204838ade23ada51456df328e2eb226c6e61683",
        "file": [
            {
                "patch": "@@ -69,6 +69,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4733: Avoid NullPointerException in JVMReuseImpl for builtin classes (rohini)\n+\n PIG-4722: [Pig on Tez] NPE while running Combiner (rohini)\n \n PIG-4730: [Pig on Tez] Total parallelism estimation does not account load parallelism (rohini)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "1c27e7e05342aa56bcd8c9e7e685eb3787c65f26",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -22,12 +22,34 @@\n \n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner;\n+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n+import org.apache.pig.classification.InterfaceAudience;\n+import org.apache.pig.classification.InterfaceStability;\n+import org.apache.pig.impl.PigContext;\n+import org.apache.pig.impl.util.SpillableMemoryManager;\n+import org.apache.pig.impl.util.UDFContext;\n+import org.apache.pig.tools.pigstats.PigStatusReporter;\n \n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n public class JVMReuseImpl {\n \n     private static Log LOG = LogFactory.getLog(JVMReuseImpl.class);\n \n     public void cleanupStaticData() {\n+\n+        // Calling Pig builtin ones directly without reflection for optimization\n+        // and to reduce probability of NPE in PIG-4418\n+        SpillableMemoryManager.staticDataCleanup();\n+        PhysicalOperator.staticDataCleanup();\n+        PigContext.staticDataCleanup();\n+        UDFContext.staticDataCleanup();\n+        PigGenericMapReduce.staticDataCleanup();\n+        PigStatusReporter.staticDataCleanup();\n+        PigCombiner.Combine.staticDataCleanup();\n+\n         String className = null;\n         String msg = null;\n         List<Method> staticCleanupMethods = JVMReuseManager.getInstance()\n@@ -45,15 +67,16 @@ public void cleanupStaticData() {\n                 m.invoke(null);\n                 msg = null;\n             } catch (Exception e) {\n-                LOG.error(\"Exception while calling static methods:\" + getMethodNames() + \". \" + msg, e);\n+                LOG.error(\"Exception while calling static methods:\"\n+                        + getMethodNames(staticCleanupMethods) + \". \" + msg, e);\n                 throw new RuntimeException(\"Error while \" + msg, e);\n             }\n         }\n     }\n \n-    private String getMethodNames() {\n+    private String getMethodNames(List<Method> staticCleanupMethods) {\n         StringBuilder sb = new StringBuilder();\n-        for (Method m : JVMReuseManager.getInstance().getStaticDataCleanupMethods()) {\n+        for (Method m : staticCleanupMethods) {\n             if (m == null) {\n                 sb.append(\"null,\");\n             } else {",
                "additions": 26,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/JVMReuseImpl.java",
                "status": "modified",
                "changes": 29,
                "deletions": 3,
                "sha": "087853ebfcc37ad4cd1bccc207b611d734cf3704",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/JVMReuseImpl.java",
                "filename": "src/org/apache/pig/JVMReuseImpl.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/JVMReuseImpl.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -27,9 +27,7 @@\n import org.apache.hadoop.io.Writable;\n import org.apache.hadoop.mapreduce.Reducer;\n import org.apache.log4j.PropertyConfigurator;\n-import org.apache.pig.JVMReuseManager;\n import org.apache.pig.PigException;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.HDataType;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;\n@@ -76,11 +74,7 @@\n         PigContext pigContext = null;\n         private volatile boolean initialized = false;\n \n-        static {\n-            JVMReuseManager.getInstance().registerForStaticDataCleanup(Combine.class);\n-        }\n-\n-        @StaticDataCleanup\n+        //@StaticDataCleanup\n         public static void staticDataCleanup() {\n             firstTime = true;\n         }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java",
                "status": "modified",
                "changes": 8,
                "deletions": 7,
                "sha": "76ea41cc9a37bd985f0ae75e2b384d6e01eb5fe4",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -30,10 +30,8 @@\n import org.apache.hadoop.mapred.jobcontrol.Job;\n import org.apache.hadoop.mapreduce.JobContext;\n import org.apache.hadoop.mapreduce.Reducer;\n-import org.apache.pig.JVMReuseManager;\n import org.apache.pig.PigConstants;\n import org.apache.pig.PigException;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.HDataType;\n import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;\n@@ -103,11 +101,7 @@\n \n     public static ThreadLocal<Configuration> sJobConfInternal = new ThreadLocal<Configuration>();\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(PigGenericMapReduce.class);\n-    }\n-\n-    @StaticDataCleanup\n+    //@StaticDataCleanup\n     public static void staticDataCleanup() {\n         sJobContext = null;\n         sJobConf = null;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "status": "modified",
                "changes": 8,
                "deletions": 7,
                "sha": "b22a9238a1990eafad5c69c592c536db25034160",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -24,8 +24,6 @@\n \n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n-import org.apache.pig.JVMReuseManager;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n@@ -122,10 +120,6 @@\n \n     private List<OriginalLocation> originalLocations =  new ArrayList<OriginalLocation>();\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(PhysicalOperator.class);\n-    }\n-\n     public PhysicalOperator(OperatorKey k) {\n         this(k, -1, null);\n     }\n@@ -458,7 +452,7 @@ public static void setReporter(PigProgressable reporter) {\n         PhysicalOperator.reporter.set(reporter);\n     }\n \n-    @StaticDataCleanup\n+    //@StaticDataCleanup\n     public static void staticDataCleanup() {\n         reporter = new ThreadLocal<PigProgressable>();\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "status": "modified",
                "changes": 8,
                "deletions": 7,
                "sha": "65df3cc3e86f12077bc7cd2daffa0458f6492126",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -162,7 +162,6 @@ public void handleEvents(List<Event> processorEvents) {\n \n     @Override\n     public void close() throws Exception {\n-\n         execPlan = null;\n         fileOutputs = null;\n         leaf = null;",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/tez/runtime/PigProcessor.java",
                "status": "modified",
                "changes": 1,
                "deletions": 1,
                "sha": "7d8e1c1db965411c93ae67981397ebbf8e39fb03",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/backend/hadoop/executionengine/tez/runtime/PigProcessor.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/runtime/PigProcessor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/runtime/PigProcessor.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -22,9 +22,7 @@\n \n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n-import org.apache.pig.JVMReuseManager;\n import org.apache.pig.PigConfiguration;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce;\n import org.apache.pig.data.BagFactory;\n@@ -45,16 +43,6 @@\n     private static boolean initialized = false;\n     private static boolean useDefaultBag = false;\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(Distinct.class);\n-    }\n-\n-    @StaticDataCleanup\n-    public static void staticDataCleanup() {\n-        initialized = false;\n-        useDefaultBag = false;\n-    }\n-\n     @Override\n     public DataBag exec(Tuple input) throws IOException {\n         return getDistinct(input);",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/builtin/Distinct.java",
                "status": "modified",
                "changes": 12,
                "deletions": 12,
                "sha": "f95e303c52ce041a36614d06024299268f711805",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/builtin/Distinct.java",
                "filename": "src/org/apache/pig/builtin/Distinct.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/Distinct.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -52,9 +52,7 @@\n import org.apache.pig.ExecType;\n import org.apache.pig.ExecTypeProvider;\n import org.apache.pig.FuncSpec;\n-import org.apache.pig.JVMReuseManager;\n import org.apache.pig.PigException;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.datastorage.DataStorage;\n import org.apache.pig.backend.datastorage.DataStorageException;\n import org.apache.pig.backend.datastorage.ElementDescriptor;\n@@ -171,11 +169,7 @@\n     // List of paths skipped for automatic shipping\n     List<String> skippedShipPaths = new ArrayList<String>();\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(PigContext.class);\n-    }\n-\n-    @StaticDataCleanup\n+    //@StaticDataCleanup\n     public static void staticDataCleanup() {\n         packageImportList.set(null);\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/PigContext.java",
                "status": "modified",
                "changes": 8,
                "deletions": 7,
                "sha": "064bb5b913d0a8633d4e75b1d43b9d4086bee295",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/PigContext.java",
                "filename": "src/org/apache/pig/impl/PigContext.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/PigContext.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -36,8 +36,6 @@\n \n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n-import org.apache.pig.JVMReuseManager;\n-import org.apache.pig.StaticDataCleanup;\n \n /**\n  * This class Tracks the tenured pool and a list of Spillable objects. When memory gets low, this\n@@ -93,12 +91,8 @@\n \n     private static final SpillableMemoryManager manager = new SpillableMemoryManager();\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(SpillableMemoryManager.class);\n-    }\n-\n-    @StaticDataCleanup\n-    public static void cleanupStaticData() {\n+    //@StaticDataCleanup\n+    public static void staticDataCleanup() {\n         manager.spillables.clear();\n         manager.accumulatedFreeSize = 0L;\n     }",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/util/SpillableMemoryManager.java",
                "status": "modified",
                "changes": 10,
                "deletions": 8,
                "sha": "433b8d7657261bc2c2fdbe7c526673df113388c9",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/util/SpillableMemoryManager.java",
                "filename": "src/org/apache/pig/impl/util/SpillableMemoryManager.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/util/SpillableMemoryManager.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -26,8 +26,6 @@\n import java.util.Properties;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.pig.JVMReuseManager;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRConfiguration;\n \n public class UDFContext {\n@@ -46,10 +44,6 @@ public UDFContext initialValue() {\n         }\n     };\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(UDFContext.class);\n-    }\n-\n     private UDFContext() {\n         udfConfs = new HashMap<UDFContextKey, Properties>();\n     }\n@@ -71,8 +65,8 @@ public static void setUdfContext(UDFContext udfContext) {\n     /*\n      *  internal pig use only - should NOT be called from user code\n      */\n-    @StaticDataCleanup\n-    public static void cleanupStaticData() {\n+    //@StaticDataCleanup\n+    public static void staticDataCleanup() {\n         tss = new ThreadLocal<UDFContext>() {\n             @Override\n             public UDFContext initialValue() {",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/util/UDFContext.java",
                "status": "modified",
                "changes": 10,
                "deletions": 8,
                "sha": "1f63798158a59c3c444b40716a9c4e5d5afcaf3a",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/impl/util/UDFContext.java",
                "filename": "src/org/apache/pig/impl/util/UDFContext.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/util/UDFContext.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            },
            {
                "patch": "@@ -21,8 +21,6 @@\n import org.apache.hadoop.mapreduce.Counter;\n import org.apache.hadoop.mapreduce.StatusReporter;\n import org.apache.hadoop.util.Progressable;\n-import org.apache.pig.JVMReuseManager;\n-import org.apache.pig.StaticDataCleanup;\n import org.apache.pig.backend.hadoop.executionengine.TaskContext;\n import org.apache.pig.classification.InterfaceAudience;\n import org.apache.pig.classification.InterfaceStability;\n@@ -35,11 +33,7 @@\n \n     private TaskContext<?> context = null;\n \n-    static {\n-        JVMReuseManager.getInstance().registerForStaticDataCleanup(PigStatusReporter.class);\n-    }\n-\n-    @StaticDataCleanup\n+    //@StaticDataCleanup\n     public static void staticDataCleanup() {\n         reporter = null;\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/tools/pigstats/PigStatusReporter.java",
                "status": "modified",
                "changes": 8,
                "deletions": 7,
                "sha": "5396535301b0e90dc5d3be2064cfe0bdf488bf6a",
                "blob_url": "https://github.com/apache/pig/blob/6204838ade23ada51456df328e2eb226c6e61683/src/org/apache/pig/tools/pigstats/PigStatusReporter.java",
                "filename": "src/org/apache/pig/tools/pigstats/PigStatusReporter.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/tools/pigstats/PigStatusReporter.java?ref=6204838ade23ada51456df328e2eb226c6e61683"
            }
        ],
        "bug_id": "pig_4",
        "parent": "https://github.com/apache/pig/commit/348d0839580ff7b0e647c326012580bfd00ed906",
        "message": "PIG-4733: Avoid NullPointerException in JVMReuseImpl for builtin classes (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1714257 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/6da826cf82711b141922ccd565c4339eca695cad",
        "file": [
            {
                "patch": "@@ -76,6 +76,8 @@ PIG-4333: Split BigData tests into multiple groups (rohini)\n  \n BUG FIXES\n \n+PIG-4418: NullPointerException in JVMReuseImpl (rohini)\n+\n PIG-4562: Typo in DataType.toDateTime (daijy)\n \n PIG-4559: Fix several new tez e2e test failures (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6da826cf82711b141922ccd565c4339eca695cad/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "295e4acd50994f09772ce60b1c4b4a7da3b9ef73",
                "blob_url": "https://github.com/apache/pig/blob/6da826cf82711b141922ccd565c4339eca695cad/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=6da826cf82711b141922ccd565c4339eca695cad"
            },
            {
                "patch": "@@ -28,23 +28,42 @@\n     private static Log LOG = LogFactory.getLog(JVMReuseImpl.class);\n \n     public void cleanupStaticData() {\n+        String className = null;\n+        String msg = null;\n         List<Method> staticCleanupMethods = JVMReuseManager.getInstance()\n                 .getStaticDataCleanupMethods();\n         for (Method m : staticCleanupMethods) {\n             try {\n-                String msg = \"Invoking method \" + m.getName() + \" in class \"\n-                        + m.getDeclaringClass().getName() + \" for static data cleanup\";\n-                if (m.getDeclaringClass().getName().startsWith(\"org.apache.pig\")) {\n+                className = m.getDeclaringClass() == null ? \"anonymous\" : m.getDeclaringClass().getName();\n+                msg = \"Invoking method \" + m.getName() + \" in class \"\n+                        + className + \" for static data cleanup\";\n+                if (className.startsWith(\"org.apache.pig\")) {\n                     LOG.debug(msg);\n                 } else {\n                     LOG.info(msg);\n                 }\n                 m.invoke(null);\n+                msg = null;\n             } catch (Exception e) {\n-                throw new RuntimeException(\"Error while invoking method \"\n-                        + m.getName() + \" in class \" + m.getDeclaringClass().getName()\n-                        + \" for static data cleanup\", e);\n+                LOG.error(\"Exception while calling static methods:\" + getMethodNames() + \". \" + msg, e);\n+                throw new RuntimeException(\"Error while \" + msg, e);\n             }\n         }\n     }\n+\n+    private String getMethodNames() {\n+        StringBuilder sb = new StringBuilder();\n+        for (Method m : JVMReuseManager.getInstance().getStaticDataCleanupMethods()) {\n+            if (m == null) {\n+                sb.append(\"null,\");\n+            } else {\n+                sb.append(m.getDeclaringClass() == null ? \"anonymous\" : m.getDeclaringClass().getName());\n+                sb.append(\".\").append(m.getName()).append(\",\");\n+            }\n+        }\n+        if (sb.length() > 1) {\n+            sb.deleteCharAt(sb.length() - 1);\n+        }\n+        return sb.toString();\n+    }\n }",
                "additions": 25,
                "raw_url": "https://github.com/apache/pig/raw/6da826cf82711b141922ccd565c4339eca695cad/src/org/apache/pig/JVMReuseImpl.java",
                "status": "modified",
                "changes": 31,
                "deletions": 6,
                "sha": "d71251291cc5493cf6a19366b46bdf7fc49c98e5",
                "blob_url": "https://github.com/apache/pig/blob/6da826cf82711b141922ccd565c4339eca695cad/src/org/apache/pig/JVMReuseImpl.java",
                "filename": "src/org/apache/pig/JVMReuseImpl.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/JVMReuseImpl.java?ref=6da826cf82711b141922ccd565c4339eca695cad"
            }
        ],
        "bug_id": "pig_5",
        "parent": "https://github.com/apache/pig/commit/16d2e31af63fd3e48b9be04e603122c56f20c7ae",
        "message": "PIG-4418: NullPointerException in JVMReuseImpl (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1681163 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/534562153a9658ff7ca9c156af9c61060e9077fb",
        "file": [
            {
                "patch": "@@ -76,6 +76,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3726: Ranking empty records leads to NullPointerException (jarcec via daijy)\n+\n PIG-3652: Pigmix parser (PigPerformanceLoader) deletes chars during parsing (keren3000 via daijy)\n \n PIG-3722: Udf deserialization for registered classes fails in local_mode (aniket486)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/534562153a9658ff7ca9c156af9c61060e9077fb/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "1f471a653621fb355a288a335a59eef08ad9c8d1",
                "blob_url": "https://github.com/apache/pig/blob/534562153a9658ff7ca9c156af9c61060e9077fb/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=534562153a9658ff7ca9c156af9c61060e9077fb"
            },
            {
                "patch": "@@ -110,6 +110,7 @@\n import org.apache.pig.impl.util.Pair;\n import org.apache.pig.impl.util.UDFContext;\n import org.apache.pig.impl.util.Utils;\n+import org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil;\n import org.apache.pig.tools.pigstats.mapreduce.MRScriptState;\n \n /**\n@@ -375,7 +376,24 @@ private void saveCounters(Job job, String operationID) {\n \n         try {\n             counters = HadoopShims.getCounters(job);\n-            groupCounters = counters.getGroup(getGroupName(counters.getGroupNames()));\n+\n+            String groupName = getGroupName(counters.getGroupNames());\n+            // In case that the counter group was not find, we need to find\n+            // out why. Only acceptable state is that the relation has been\n+            // empty.\n+            if (groupName == null) {\n+                Counter outputRecords =\n+                    counters.getGroup(MRPigStatsUtil.TASK_COUNTER_GROUP)\n+                    .getCounterForName(MRPigStatsUtil.MAP_OUTPUT_RECORDS);\n+\n+                if(outputRecords.getCounter() == 0) {\n+                    globalCounters.put(operationID, new ArrayList<Pair<String, Long>>());\n+                    return;\n+                } else {\n+                  throw new RuntimeException(\"Did not found RANK counter group for operationId: \" + operationID);\n+                }\n+            }\n+            groupCounters = counters.getGroup(groupName);\n \n             Iterator<Counter> it = groupCounters.iterator();\n             HashMap<Integer,Long> counterList = new HashMap<Integer, Long>();",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/534562153a9658ff7ca9c156af9c61060e9077fb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "status": "modified",
                "changes": 20,
                "deletions": 1,
                "sha": "0cbcbed1c06d7210b12c573f9bbeb3bccfe05469",
                "blob_url": "https://github.com/apache/pig/blob/534562153a9658ff7ca9c156af9c61060e9077fb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java?ref=534562153a9658ff7ca9c156af9c61060e9077fb"
            },
            {
                "patch": "@@ -52,6 +52,7 @@ public void setUp() throws Exception {\n             pigServer = new PigServer(\"local\");\n \n             data = resetData(pigServer);\n+            data.set(\"empty\");\n             data.set(\n                     \"testcascade\",\n                     tuple(3,2,3),\n@@ -142,6 +143,19 @@ public void testRankCascade() throws IOException {\n         verifyExpected(data.get(\"result\"), expected);\n     }\n \n+    // See PIG-3726\n+    @Test\n+    public void testRankEmptyRelation() throws Exception {\n+      String query = \"DATA = LOAD 'empty' USING mock.Storage();\"\n+        + \"A = rank DATA;\"\n+        + \"store A into 'empty_result' using mock.Storage();\";\n+\n+      Util.registerMultiLineQuery(pigServer, query);\n+\n+      Set<Tuple> expected = ImmutableSet.of();\n+      verifyExpected(data.get(\"empty_result\"), expected);\n+    }\n+\n     public void verifyExpected(List<Tuple> out, Set<Tuple> expected) {\n         for (Tuple tup : out) {\n             assertTrue(expected + \" contains \" + tup, expected.contains(tup));",
                "additions": 14,
                "raw_url": "https://github.com/apache/pig/raw/534562153a9658ff7ca9c156af9c61060e9077fb/test/org/apache/pig/test/TestRank3.java",
                "status": "modified",
                "changes": 14,
                "deletions": 0,
                "sha": "e73d11558bfdb63cd0e8a60c54469f35ea899505",
                "blob_url": "https://github.com/apache/pig/blob/534562153a9658ff7ca9c156af9c61060e9077fb/test/org/apache/pig/test/TestRank3.java",
                "filename": "test/org/apache/pig/test/TestRank3.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestRank3.java?ref=534562153a9658ff7ca9c156af9c61060e9077fb"
            }
        ],
        "bug_id": "pig_6",
        "parent": "https://github.com/apache/pig/commit/2f041a0855785bb86190c464632a9c980d14c782",
        "message": "PIG-3726: Ranking empty records leads to NullPointerException\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1563200 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/42cbf31fd86ae599c93c3d8f671671954acde1e2",
        "file": [
            {
                "patch": "@@ -156,6 +156,8 @@ PIG-2228: support partial aggregation in map task (thejas)\n \n BUG FIXES\n \n+PIG-2275: NullPointerException from ILLUSTRATE (daijy)\n+\n PIG-2119: DuplicateForEachColumnRewrite makes assumptions about the position of LOGGenerate in the plan (daijy)\n \n PIG-2290: TOBAG wraps tuple parameters in another tuple (ryan.hoegg via thejas)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/42cbf31fd86ae599c93c3d8f671671954acde1e2/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "05469d7ae0699800243103b1b9a01ed7e009aeff",
                "blob_url": "https://github.com/apache/pig/blob/42cbf31fd86ae599c93c3d8f671671954acde1e2/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=42cbf31fd86ae599c93c3d8f671671954acde1e2"
            },
            {
                "patch": "@@ -55,7 +55,7 @@ public void setOperandType(byte operandType) {\n     @Override\n     public Tuple illustratorMarkup(Object in, Object out, int eqClassIndex) {\n         if(illustrator != null) {\n-\n+            illustrator.setSubExpResult(eqClassIndex == 0);\n         }\n         return null;\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/42cbf31fd86ae599c93c3d8f671671954acde1e2/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "ab2bdb0933d0e61911464aa1e1b293703234a913",
                "blob_url": "https://github.com/apache/pig/blob/42cbf31fd86ae599c93c3d8f671671954acde1e2/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java?ref=42cbf31fd86ae599c93c3d8f671671954acde1e2"
            },
            {
                "patch": "@@ -61,6 +61,7 @@\n import org.apache.pig.newplan.logical.expression.LessThanEqualExpression;\n import org.apache.pig.newplan.logical.relational.LOLoad;\n import org.apache.pig.newplan.logical.relational.LogicalPlan;\n+import org.apache.pig.newplan.logical.expression.IsNullExpression;\n import org.apache.pig.newplan.logical.expression.ModExpression;\n import org.apache.pig.newplan.logical.expression.LogicalExpression;\n import org.apache.pig.newplan.logical.expression.MultiplyExpression;\n@@ -69,6 +70,7 @@\n import org.apache.pig.newplan.logical.expression.OrExpression;\n import org.apache.pig.newplan.logical.expression.ProjectExpression;\n import org.apache.pig.newplan.logical.expression.RegexExpression;\n+import org.apache.pig.newplan.logical.expression.UserFuncExpression;\n import org.apache.pig.newplan.logical.relational.LOSort;\n import org.apache.pig.newplan.logical.relational.LOSplit;\n import org.apache.pig.newplan.logical.relational.LOStore;\n@@ -510,10 +512,10 @@ public void visit(LOFilter filter) throws FrontendException {\n         } catch (Exception e) {\n             log\n                     .error(\"Error visiting Load during Augmentation phase of Example Generator! \"\n-                            + e.getMessage());\n+                            + e.getMessage(), e);\n             throw new FrontendException(\n                     \"Error visiting Load during Augmentation phase of Example Generator! \"\n-                            + e.getMessage());\n+                            + e.getMessage(), e);\n         }\n     }\n \n@@ -946,6 +948,12 @@ void GenerateMatchingTupleHelper(Tuple t, Operator pred,\n                     invert);\n         else if (pred instanceof NotExpression)\n             GenerateMatchingTupleHelper(t, (NotExpression) pred, invert);\n+        else if (pred instanceof IsNullExpression)\n+            GenerateMatchingTupleHelper(t, (IsNullExpression) pred, invert);\n+        else if (pred instanceof UserFuncExpression)\n+            // Don't know how to generate input tuple for UDF, return null\n+            // to suppress the generation \n+            t = null;\n         else\n             throw new FrontendException(\"Unknown operator in filter predicate\");\n     }\n@@ -1151,6 +1159,15 @@ void GenerateMatchingTupleHelper(Tuple t, NotExpression op, boolean invert)\n         GenerateMatchingTupleHelper(t, input, !invert);\n \n     }\n+    \n+    void GenerateMatchingTupleHelper(Tuple t, IsNullExpression op, boolean invert)\n+            throws FrontendException, ExecException {\n+        byte type = op.getExpression().getType();\n+        if (!invert)\n+            t.set(0, null);\n+        else\n+            t.set(0, generateData(type, \"0\"));\n+    }\n \n     Object GetUnequalValue(Object v) {\n         byte type = DataType.findType(v);",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/42cbf31fd86ae599c93c3d8f671671954acde1e2/src/org/apache/pig/pen/AugmentBaseDataVisitor.java",
                "status": "modified",
                "changes": 21,
                "deletions": 2,
                "sha": "84e58cf636d91809a6e1c2d186b46cd0524bfd6a",
                "blob_url": "https://github.com/apache/pig/blob/42cbf31fd86ae599c93c3d8f671671954acde1e2/src/org/apache/pig/pen/AugmentBaseDataVisitor.java",
                "filename": "src/org/apache/pig/pen/AugmentBaseDataVisitor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/pen/AugmentBaseDataVisitor.java?ref=42cbf31fd86ae599c93c3d8f671671954acde1e2"
            },
            {
                "patch": "@@ -361,4 +361,33 @@ public void testLimit() throws Exception {\n \n         assertTrue(derivedData != null);\n     }\n+    \n+    //see PIG-2275\n+    @Test\n+    public void testFilterWithIsNull() throws ExecException, IOException {\n+        PigServer pigServer = new PigServer(pigContext);\n+\n+        pigServer.registerQuery(\"A = load \" + A\n+                + \" using PigStorage() as (x : int, y : int);\");\n+        pigServer.registerQuery(\"B = filter A by x is not null;\");\n+\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"B\");\n+\n+        assertTrue(derivedData != null);\n+    }\n+    \n+    @Test\n+    public void testFilterWithUDF() throws ExecException, IOException {\n+        PigServer pigServer = new PigServer(pigContext);\n+\n+        pigServer.registerQuery(\"A = load \" + A\n+                + \" using PigStorage() as (x : int, y : int);\");\n+        pigServer.registerQuery(\"B = group A by x;\");\n+        pigServer.registerQuery(\"C = filter B by NOT IsEmpty(A.y);\");\n+\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"C\");\n+\n+        assertTrue(derivedData != null);\n+    }\n+\n }",
                "additions": 29,
                "raw_url": "https://github.com/apache/pig/raw/42cbf31fd86ae599c93c3d8f671671954acde1e2/test/org/apache/pig/test/TestExampleGenerator.java",
                "status": "modified",
                "changes": 29,
                "deletions": 0,
                "sha": "d10bbca4168078d9652c7d429d4718b84eed0141",
                "blob_url": "https://github.com/apache/pig/blob/42cbf31fd86ae599c93c3d8f671671954acde1e2/test/org/apache/pig/test/TestExampleGenerator.java",
                "filename": "test/org/apache/pig/test/TestExampleGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestExampleGenerator.java?ref=42cbf31fd86ae599c93c3d8f671671954acde1e2"
            }
        ],
        "bug_id": "pig_7",
        "parent": "https://github.com/apache/pig/commit/dfbf11db6dc642aafa8a49241d490ba4e0811e09",
        "message": "PIG-2275: NullPointerException from ILLUSTRATE\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1196483 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/c74e6279680daec10d15e9777953013ea9567dbb",
        "file": [
            {
                "patch": "@@ -111,6 +111,8 @@ PIG-2011: Speed up TestTypedMap.java (dvryaboy)\n \n BUG FIXES\n \n+PIG-2185: NullPointerException while Accessing Empty Bag in FOREACH { FILTER } (daijy)\n+\n PIG-2227: Wrong jars copied into lib directory in e2e tests when invoked from top level (gates)\n \n PIG-2219: Pig tests fail if ${user.home}/pigtest/conf does not already exist (cwsteinbach via gates)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/c74e6279680daec10d15e9777953013ea9567dbb/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "f95d7dbdbcbdd674ce6b5f80368ec69ce041bc25",
                "blob_url": "https://github.com/apache/pig/blob/c74e6279680daec10d15e9777953013ea9567dbb/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c74e6279680daec10d15e9777953013ea9567dbb"
            },
            {
                "patch": "@@ -444,15 +444,19 @@ public Result getNext(Tuple t) throws ExecException {\n             }\n \n             if(overloaded){\n-                DataBag retBag = (DataBag)ret;\n-                bagIterator = retBag.iterator();\n-                if(bagIterator.hasNext()){\n-                    processingBagOfTuples = true;\n-                    res.result = bagIterator.next();\n-                }\n-                // If the bag contains no tuple, set the returnStatus to STATUS_EOP\n-                if (!processingBagOfTuples)\n+                if (ret!=null) {\n+                    DataBag retBag = (DataBag)ret;\n+                    bagIterator = retBag.iterator();\n+                    if(bagIterator.hasNext()){\n+                        processingBagOfTuples = true;\n+                        res.result = bagIterator.next();\n+                    }\n+                    // If the bag contains no tuple, set the returnStatus to STATUS_EOP\n+                    if (!processingBagOfTuples)\n+                        res.returnStatus = POStatus.STATUS_EOP;\n+                } else {\n                     res.returnStatus = POStatus.STATUS_EOP;\n+                }\n             }\n             else {\n                 res.result = (Tuple)ret;",
                "additions": 12,
                "raw_url": "https://github.com/apache/pig/raw/c74e6279680daec10d15e9777953013ea9567dbb/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java",
                "status": "modified",
                "changes": 20,
                "deletions": 8,
                "sha": "826b4b2f299b98694b523af4d79940840dd28011",
                "blob_url": "https://github.com/apache/pig/blob/c74e6279680daec10d15e9777953013ea9567dbb/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java?ref=c74e6279680daec10d15e9777953013ea9567dbb"
            },
            {
                "patch": "@@ -1585,4 +1585,34 @@ public void testUnionOnSchemaUidGeneration() throws Exception{\n         Assert.assertFalse(iter.hasNext());\n         \n     }\n+    \n+    // See PIG-2185\n+    @Test\n+    public void testProjectEmptyBag() throws Exception{\n+        String[] input = {\n+                \"{(12)}\",\n+                \"{(23)}\",\n+                \"\"\n+        };\n+        \n+        Util.createInputFile(cluster, \"table_testProjectEmptyBag\", input);\n+        \n+        pigServer.registerQuery(\"A = load 'table_testProjectEmptyBag' as (bg:bag{});\");\n+        pigServer.registerQuery(\"B = FOREACH A { x = FILTER bg BY $0 == '12'; GENERATE x; };\");\n+\n+        Iterator<Tuple> iter = pigServer.openIterator(\"B\");\n+        \n+        Tuple t = iter.next();\n+        Assert.assertTrue(t.toString().equals(\"({(12)})\"));\n+        \n+        t = iter.next();\n+        Assert.assertTrue(t.toString().equals(\"({})\"));\n+        \n+        Assert.assertTrue(iter.hasNext());\n+        \n+        t = iter.next();\n+        Assert.assertTrue(t.toString().equals(\"({})\"));\n+        \n+        Assert.assertFalse(iter.hasNext());\n+    }\n }",
                "additions": 30,
                "raw_url": "https://github.com/apache/pig/raw/c74e6279680daec10d15e9777953013ea9567dbb/test/org/apache/pig/test/TestEvalPipeline2.java",
                "status": "modified",
                "changes": 30,
                "deletions": 0,
                "sha": "0b7b391bf01f9569c1f0b1029b0a763d507a61c8",
                "blob_url": "https://github.com/apache/pig/blob/c74e6279680daec10d15e9777953013ea9567dbb/test/org/apache/pig/test/TestEvalPipeline2.java",
                "filename": "test/org/apache/pig/test/TestEvalPipeline2.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestEvalPipeline2.java?ref=c74e6279680daec10d15e9777953013ea9567dbb"
            }
        ],
        "bug_id": "pig_8",
        "parent": "https://github.com/apache/pig/commit/75faa4177a2f8cbbf6668dc8a37b9992a4f51eb6",
        "message": "PIG-2185: NullPointerException while Accessing Empty Bag in FOREACH { FILTER }\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1159791 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/66c24d35689d78e23c9af99dbd33490fd8a1d7d1",
        "file": [
            {
                "patch": "@@ -62,6 +62,8 @@ PIG-2011: Speed up TestTypedMap.java (dvryaboy)\n \n BUG FIXES\n \n+PIG-2110: NullPointerException in piggybank.evaluation.util.apachelogparser.SearchTermExtractor (dale_jin via daijy)\n+\n PIG-2144: ClassCastException when using IsEmpty(DIFF()) (thejas)\n \n PIG-2139: LogicalExpressionSimplifier optimizer rule should check if udf is",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "39c44262fdefcdf9bfb6b957579da8880e4d3434",
                "blob_url": "https://github.com/apache/pig/blob/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=66c24d35689d78e23c9af99dbd33490fd8a1d7d1"
            },
            {
                "patch": "@@ -167,6 +167,7 @@ public String exec(Tuple input) throws IOException {\n       if (HOSTS.containsKey(host) || host.contains(\"google.co\")\n           || host.contains(\"search.yahoo\")) {\n         String queryString = urlObject.getQuery();\n+        if (queryString == null) { return null; }\n         TERM_MATCHER.reset(queryString);\n         if (TERM_MATCHER.find()) {\n           String terms = TERM_MATCHER.group(1);",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/util/apachelogparser/SearchTermExtractor.java",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "b555dd5f100e16cee23ebee767dcda4c0901a894",
                "blob_url": "https://github.com/apache/pig/blob/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/util/apachelogparser/SearchTermExtractor.java",
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/util/apachelogparser/SearchTermExtractor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/util/apachelogparser/SearchTermExtractor.java?ref=66c24d35689d78e23c9af99dbd33490fd8a1d7d1"
            },
            {
                "patch": "@@ -26,6 +26,7 @@\n public class TestSearchTermExtractor extends TestCase {\n     private static HashMap<String, String> tests = new HashMap<String, String>();\n     static {\n+        tests.put(\"http://www.google.com/search\", null);\n         tests.put(\"http://www.google.com/search?hl=en&q=a+simple+test&btnG=Google+Search\", \"a simple test\");\n         tests.put(\"http://www.google.co.uk/search?hl=en&q=a+simple+test&btnG=Google+Search&meta=\", \"a simple test\");\n         tests.put(\"http://www.google.co.jp/search?hl=ja&q=a+simple+test&btnG=Google+%E6%A4%9C%E7%B4%A2&lr=\", \"a simple test\");",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/evaluation/util/apachelogparser/TestSearchTermExtractor.java",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "fc94875041ff2a3d31584c367946a992314166ac",
                "blob_url": "https://github.com/apache/pig/blob/66c24d35689d78e23c9af99dbd33490fd8a1d7d1/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/evaluation/util/apachelogparser/TestSearchTermExtractor.java",
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/evaluation/util/apachelogparser/TestSearchTermExtractor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/evaluation/util/apachelogparser/TestSearchTermExtractor.java?ref=66c24d35689d78e23c9af99dbd33490fd8a1d7d1"
            }
        ],
        "bug_id": "pig_9",
        "parent": "https://github.com/apache/pig/commit/620fe36c7cd31b0ab6087f0acf7951a199918d1e",
        "message": "PIG-2110: NullPointerException in piggybank.evaluation.util.apachelogparser.SearchTermExtractor\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1143623 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/5578536b231fb96386ad21b8eda5bbf460f27ff6",
        "file": [
            {
                "patch": "@@ -147,6 +147,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-1697: NullPointerException if log4j.properties is Used (laukik via daijy)\n+\n PIG-1929:Type checker failed to catch invalid type comparison (thejas)\n \n PIG-1928: Type Checking, incorrect error message (thejas)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/5578536b231fb96386ad21b8eda5bbf460f27ff6/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "77fb3e89d34d01330db966acd8d80beac1217d87",
                "blob_url": "https://github.com/apache/pig/blob/5578536b231fb96386ad21b8eda5bbf460f27ff6/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=5578536b231fb96386ad21b8eda5bbf460f27ff6"
            },
            {
                "patch": "@@ -660,6 +660,9 @@ private static void configureLog4J(Properties properties, PigContext pigContext)\n \n     PropertyConfigurator.configure(props);\n     logLevel = Logger.getLogger(\"org.apache.pig\").getLevel();\n+    if (logLevel==null) {\n+    \tlogLevel = Logger.getLogger(\"org.apache.pig\").getEffectiveLevel();\n+    }\n     Properties backendProps = pigContext.getLog4jProperties();\n     backendProps.setProperty(\"log4j.logger.org.apache.pig\", logLevel.toString());\n     pigContext.setLog4jProperties(backendProps);",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/5578536b231fb96386ad21b8eda5bbf460f27ff6/src/org/apache/pig/Main.java",
                "status": "modified",
                "changes": 3,
                "deletions": 0,
                "sha": "384e12fe0a001c40d9aa983d4dbdfd70991284b8",
                "blob_url": "https://github.com/apache/pig/blob/5578536b231fb96386ad21b8eda5bbf460f27ff6/src/org/apache/pig/Main.java",
                "filename": "src/org/apache/pig/Main.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/Main.java?ref=5578536b231fb96386ad21b8eda5bbf460f27ff6"
            }
        ],
        "bug_id": "pig_10",
        "parent": "https://github.com/apache/pig/commit/aee28271d3a30d91a15dc83480ed7508f0a3e437",
        "message": "PIG-1697: NullPointerException if log4j.properties is Used\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1092782 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/94d92e17670e89db3bc53168b08b26527e98dd68",
        "file": [
            {
                "patch": "@@ -55,6 +55,8 @@ manner (rding via pradeepkth)\n \n IMPROVEMENTS\n \n+PIG-1233: NullPointerException in AVG  (ankur via olgan)\n+\n PIG-1218: Use distributed cache to store samples (rding via pradeepkth)\n \n PIG-1226: suuport for additional jar files (thejas via olgan)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "7ab01f162dd8e2d4a24549b6f889d613bf08089a",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -306,7 +306,7 @@ public void cleanup() {\n     @Override\n     public Double getValue() {\n         Double avg = null;\n-        if (intermediateCount > 0) {\n+        if (intermediateCount != null && intermediateCount > 0) {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/AVG.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "f6c8892e731882f2e3b09edaa05ec3f05fa5cb09",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/AVG.java",
                "filename": "src/org/apache/pig/builtin/AVG.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AVG.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -277,7 +277,7 @@ public void cleanup() {\n     @Override\n     public Double getValue() {\n         Double avg = null;\n-        if (intermediateCount > 0) {\n+        if (intermediateCount != null && intermediateCount > 0) {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/DoubleAvg.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "e5273e17a64b601d654470d39590b7d4c01fded6",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/DoubleAvg.java",
                "filename": "src/org/apache/pig/builtin/DoubleAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/DoubleAvg.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -274,7 +274,7 @@ public void cleanup() {\n     @Override\n     public Double getValue() {\n         Double avg = null;\n-        if (intermediateCount > 0) {\n+        if (intermediateCount != null && intermediateCount > 0) {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/FloatAvg.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "ad0b74fd180772142d86acf02549994b45e44af8",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/FloatAvg.java",
                "filename": "src/org/apache/pig/builtin/FloatAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/FloatAvg.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -279,7 +279,7 @@ public void cleanup() {\n     @Override\n     public Double getValue() {\n         Double avg = null;\n-        if (intermediateCount > 0) {\n+        if (intermediateCount != null && intermediateCount > 0) {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/IntAvg.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "ae3c51a3166436fb9fb729edea185684415b39df",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/IntAvg.java",
                "filename": "src/org/apache/pig/builtin/IntAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/IntAvg.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -274,7 +274,7 @@ public void cleanup() {\n     @Override\n     public Double getValue() {\n         Double avg = null;\n-        if (intermediateCount > 0) {\n+        if (intermediateCount != null && intermediateCount > 0) {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/LongAvg.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "b3fe33c3b7dae8db3950e602d924e133d8adc300",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/src/org/apache/pig/builtin/LongAvg.java",
                "filename": "src/org/apache/pig/builtin/LongAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/LongAvg.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            },
            {
                "patch": "@@ -43,6 +43,9 @@ public TestAccumulator() throws ExecException, IOException{\n         pigServer.getPigContext().getProperties().setProperty(\"pig.accumulative.batchsize\", \"2\");     \n         pigServer.getPigContext().getProperties().setProperty(\"pig.exec.batchsize\", \"2\");\n         pigServer.getPigContext().getProperties().setProperty(\"pig.exec.nocombiner\", \"true\");\n+        // reducing the number of retry attempts to speed up test completion\n+        pigServer.getPigContext().getProperties().setProperty(\"mapred.map.max.attempts\",\"1\");\n+        pigServer.getPigContext().getProperties().setProperty(\"mapred.reduce.max.attempts\",\"1\");\n     }\n     \n     @Before\n@@ -86,6 +89,8 @@ private void createFiles() throws IOException {\n         w.println(\"200\\t3.1\");\n         w.println(\"100\\t5.0\");\n         w.println(\"300\\t3.3\");\n+        w.println(\"400\\t\");\n+        w.println(\"400\\t\");\n         w.close();   \n         \n         Util.copyFromLocalToCluster(cluster, INPUT_FILE3, INPUT_FILE3);\n@@ -407,23 +412,62 @@ public void testAccumWithSort() throws IOException{\n         }                                   \n     }\n     \n+    public void testAccumWithBuildinAvg() throws IOException {\n+      HashMap<Integer, Double> expected = new HashMap<Integer, Double>();\n+      expected.put(100, 3.0);\n+      expected.put(200, 2.1);\n+      expected.put(300, 3.3);\n+      expected.put(400, null);\n+      // Test all the averages for correct behaviour with null values\n+      String[] types = { \"double\", \"float\", \"int\", \"long\" };\n+      for (int i = 0; i < types.length; i++) {\n+        if (i > 1) { // adjust decimal error for non real types\n+          expected.put(200, 2.0);\n+          expected.put(300, 3.0);\n+        }\n+        pigServer.registerQuery(\"A = load '\" + INPUT_FILE3 + \"' as (id:int, v:\"\n+            + types[i] + \");\");\n+        pigServer.registerQuery(\"C = group A by id;\");\n+        pigServer.registerQuery(\"D = foreach C generate group, AVG(A.v);\");\n+        Iterator<Tuple> iter = pigServer.openIterator(\"D\");\n+\n+        while (iter.hasNext()) {\n+          Tuple t = iter.next();\n+          Double v = expected.get((Integer) t.get(0));\n+          if (v != null) {\n+            assertEquals(v.doubleValue(), ((Number) t.get(1)).doubleValue(),\n+                0.0001);\n+          } else {\n+            assertEquals(null, t.get(1));\n+          }\n+        }\n+      }\n+    }\n+    \n     public void testAccumWithBuildin() throws IOException{\n         pigServer.registerQuery(\"A = load '\" + INPUT_FILE3 + \"' as (id:int, v:double);\");\n         pigServer.registerQuery(\"C = group A by id;\");\n-        pigServer.registerQuery(\"D = foreach C generate group, SUM(A.v), AVG(A.v), COUNT(A.v), MIN(A.v), MAX(A.v);\");       \n+        // moving AVG accumulator test to separate test case\n+        pigServer.registerQuery(\"D = foreach C generate group, SUM(A.v), COUNT(A.v), MIN(A.v), MAX(A.v);\");       \n \n         HashMap<Integer, Double[]> expected = new HashMap<Integer, Double[]>();\n-        expected.put(100, new Double[]{15.0,3.0,5.0,1.0,5.0});\n-        expected.put(200, new Double[]{6.3,2.1,3.0,1.1,3.1});\n-        expected.put(300, new Double[]{3.3,3.3,1.0,3.3,3.3});\n+        expected.put(100, new Double[]{15.0, 5.0, 1.0, 5.0});\n+        expected.put(200, new Double[]{6.3, 3.0, 1.1, 3.1});\n+        expected.put(300, new Double[]{3.3, 1.0, 3.3, 3.3});\n+        expected.put(400, new Double[] { null, 0.0, null, null });\n                   \n         Iterator<Tuple> iter = pigServer.openIterator(\"D\");\n         \n         while(iter.hasNext()) {\n             Tuple t = iter.next();\n             Double[] v = expected.get((Integer)t.get(0));\n             for(int i=0; i<v.length; i++) {\n-                assertEquals(v[i].doubleValue(), ((Number)t.get(i+1)).doubleValue(), 0.0001);\n+              if (v[i] != null) {\n+                assertEquals(v[i].doubleValue(), ((Number) t.get(i + 1))\n+                    .doubleValue(), 0.0001);\n+              } else {\n+                assertEquals(null, t.get(i + 1));\n+              }\n             }            \n         }    \n     }",
                "additions": 49,
                "raw_url": "https://github.com/apache/pig/raw/94d92e17670e89db3bc53168b08b26527e98dd68/test/org/apache/pig/test/TestAccumulator.java",
                "status": "modified",
                "changes": 54,
                "deletions": 5,
                "sha": "839e144a3d6e0661e6b41112c0d5fd5d24a16d17",
                "blob_url": "https://github.com/apache/pig/blob/94d92e17670e89db3bc53168b08b26527e98dd68/test/org/apache/pig/test/TestAccumulator.java",
                "filename": "test/org/apache/pig/test/TestAccumulator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestAccumulator.java?ref=94d92e17670e89db3bc53168b08b26527e98dd68"
            }
        ],
        "bug_id": "pig_11",
        "parent": "https://github.com/apache/pig/commit/abe0b6237eee0ca3e6129a176e2c7c4b8dcea081",
        "message": "PIG-1233: NullPointerException in AVG  (ankur via olgan)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@912057 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/ff393ebd343e52111969e8c832824e375ea2e939",
        "file": [
            {
                "patch": "@@ -822,7 +822,8 @@ public boolean pruneColumns(List<Pair<Integer, Integer>> columns)\n                     errCode, PigException.BUG);\n         }\n \n-        for (Pair<Integer, Integer> column : columns) {\n+        for (int i=columns.size()-1;i>=0;i--) {\n+            Pair<Integer, Integer> column = columns.get(i);\n             if (column.first < 0 || column.first > predecessors.size()) {\n                 int errCode = 2191;\n                 throw new FrontendException(\"No input \" + column.first",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOCogroup.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "6b47b465e2054eba98f4a973f891cecb8dbcc9c1",
                "blob_url": "https://github.com/apache/pig/blob/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOCogroup.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOCogroup.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOCogroup.java?ref=ff393ebd343e52111969e8c832824e375ea2e939"
            },
            {
                "patch": "@@ -268,7 +268,8 @@ public boolean pruneColumns(List<Pair<Integer, Integer>> columns)\n                     .warn(\"Cannot prune columns in filter, no schema information found\");\n             return false;\n         }\n-        for (Pair<Integer, Integer> column : columns) {\n+        for (int i=columns.size()-1;i>=0;i--) {\n+            Pair<Integer, Integer> column = columns.get(i);\n             if (column.first != 0) {\n                 int errCode = 2191;\n                 throw new FrontendException(",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOFilter.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "3b26e1cced364f2f6f60736cddf0538221661a9c",
                "blob_url": "https://github.com/apache/pig/blob/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOFilter.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOFilter.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOFilter.java?ref=ff393ebd343e52111969e8c832824e375ea2e939"
            },
            {
                "patch": "@@ -385,7 +385,8 @@ public boolean pruneColumns(List<Pair<Integer, Integer>> columns)\n         if (predecessors == null)\n             return false;\n \n-        for (Pair<Integer, Integer> column : columns) {\n+        for (int i=columns.size()-1;i>=0;i--) {\n+            Pair<Integer, Integer> column = columns.get(i);\n             if (column.first != 0) {\n                 int errCode = 2191;\n                 throw new FrontendException(",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOSort.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "adf75e36421c28894053521920e08efd2514c22b",
                "blob_url": "https://github.com/apache/pig/blob/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOSort.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOSort.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOSort.java?ref=ff393ebd343e52111969e8c832824e375ea2e939"
            },
            {
                "patch": "@@ -283,7 +283,8 @@ public boolean pruneColumns(List<Pair<Integer, Integer>> columns)\n             return false;\n         }\n \n-        for (Pair<Integer, Integer> column : columns) {\n+        for (int i=columns.size()-1;i>=0;i--) {\n+            Pair<Integer, Integer> column = columns.get(i);\n             if (column.first != 0) {\n                 int errCode = 2191;\n                 throw new FrontendException(",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOSplitOutput.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "15612e00ef79aee50024db8934f338d4ce5c53b3",
                "blob_url": "https://github.com/apache/pig/blob/ff393ebd343e52111969e8c832824e375ea2e939/src/org/apache/pig/impl/logicalLayer/LOSplitOutput.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOSplitOutput.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOSplitOutput.java?ref=ff393ebd343e52111969e8c832824e375ea2e939"
            },
            {
                "patch": "@@ -1566,5 +1566,94 @@ public void testJoin4() throws Exception {\n         \n         assertTrue(checkLogFileMessage(new String[]{\"No column pruned for A\", \n                 \"No map keys pruned for A\", \"Columns pruned for B: $0, $1\", \"No map keys pruned for B\"}));\n-     }\n+    }\n+    \n+    @Test\n+    public void testFilter4() throws Exception {\n+        pigServer.registerQuery(\"A = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (a0, a1, a2:int);\");\n+        pigServer.registerQuery(\"B = filter A by a2==3;\");\n+        pigServer.registerQuery(\"C = foreach B generate $2;\");\n+        \n+        Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n+        \n+        assertTrue(iter.hasNext());\n+        Tuple t = iter.next();\n+        assertTrue(t.toString().equals(\"(3)\"));\n+        \n+        assertFalse(iter.hasNext());\n+        \n+        assertTrue(checkLogFileMessage(new String[]{\"Columns pruned for A: $0, $1\", \n+                \"No map keys pruned for A\"}));\n+    }\n+    \n+    @Test\n+    public void testSplit3() throws Exception {\n+        pigServer.registerQuery(\"A = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (a0, a1, a2:int);\");\n+        pigServer.registerQuery(\"split A into B if a2==3, C if a2<3;\");\n+        pigServer.registerQuery(\"C = foreach B generate $2;\");\n+        \n+        Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n+        \n+        assertTrue(iter.hasNext());\n+        Tuple t = iter.next();\n+        assertTrue(t.toString().equals(\"(3)\"));\n+        \n+        assertFalse(iter.hasNext());\n+        \n+        assertTrue(checkLogFileMessage(new String[]{\"Columns pruned for A: $0, $1\", \n+                \"No map keys pruned for A\"}));\n+    }\n+    \n+    @Test\n+    public void testOrderBy3() throws Exception {\n+        pigServer.registerQuery(\"A = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (a0, a1, a2);\");\n+        pigServer.registerQuery(\"B = order A by a2;\");\n+        pigServer.registerQuery(\"C = foreach B generate a2;\");\n+        Iterator<Tuple> iter = pigServer.openIterator(\"C\");\n+        \n+        assertTrue(iter.hasNext());\n+        Tuple t = iter.next();\n+        \n+        assertTrue(t.size()==1);\n+        assertTrue(t.toString().equals(\"(2)\"));\n+        \n+        assertTrue(iter.hasNext());\n+        t = iter.next();\n+        \n+        assertTrue(t.size()==1);\n+        assertTrue(t.toString().equals(\"(3)\"));\n+\n+        assertFalse(iter.hasNext());\n+        \n+        assertTrue(checkLogFileMessage(new String[]{\"Columns pruned for A: $0, $1\", \n+            \"No map keys pruned for A\"}));\n+    }\n+    \n+    @Test\n+    public void testCogroup9() throws Exception {\n+        pigServer.registerQuery(\"A = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (a0, a1, a2);\");\n+        pigServer.registerQuery(\"B = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (b0, b1, b2);\");\n+        pigServer.registerQuery(\"C = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (c0, c1, c2);\");\n+        pigServer.registerQuery(\"D = cogroup A by a2, B by b2, C by c2;\");\n+        pigServer.registerQuery(\"E = foreach D generate $1, $2;\");\n+        Iterator<Tuple> iter = pigServer.openIterator(\"E\");\n+        \n+        assertTrue(iter.hasNext());\n+        Tuple t = iter.next();\n+        \n+        assertTrue(t.size()==2);\n+        assertTrue(t.toString().equals(\"({(2,5,2)},{(2,5,2)})\"));\n+        \n+        assertTrue(iter.hasNext());\n+        t = iter.next();\n+        \n+        assertTrue(t.size()==2);\n+        assertTrue(t.toString().equals(\"({(1,2,3)},{(1,2,3)})\"));\n+\n+        assertFalse(iter.hasNext());\n+        \n+        assertTrue(checkLogFileMessage(new String[]{\"Columns pruned for C: $0, $1\", \n+            \"No map keys pruned for C\"}));\n+    }\n+\n }",
                "additions": 90,
                "raw_url": "https://github.com/apache/pig/raw/ff393ebd343e52111969e8c832824e375ea2e939/test/org/apache/pig/test/TestPruneColumn.java",
                "status": "modified",
                "changes": 91,
                "deletions": 1,
                "sha": "cc07991c1870b92445ffabbbd7220995265ed8ab",
                "blob_url": "https://github.com/apache/pig/blob/ff393ebd343e52111969e8c832824e375ea2e939/test/org/apache/pig/test/TestPruneColumn.java",
                "filename": "test/org/apache/pig/test/TestPruneColumn.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPruneColumn.java?ref=ff393ebd343e52111969e8c832824e375ea2e939"
            }
        ],
        "bug_id": "pig_12",
        "parent": "https://github.com/apache/pig/commit/32de59fdb89c07dc49eef22b815e1298c6806a01",
        "message": "PIG-1142: Got NullPointerException merge join with pruning\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@889755 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/c85fe4b0408b4dbea254924aaae20188cebf976b",
        "file": [
            {
                "patch": "@@ -269,6 +269,8 @@ PIG-1133: UDFContext should be made available to LoadFunc.bindTo (daijy)\n \n PIG-1132: Column Pruner issues in dealing with unprunable loader (daijy)\n \n+PIG-1142: Got NullPointerException merge join with pruning (daijy)\n+\n Release 0.5.0\n \n INCOMPATIBLE CHANGES",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/c85fe4b0408b4dbea254924aaae20188cebf976b/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "3870fc31e4ad8bbdca7da355e43776f7c1cee6c6",
                "blob_url": "https://github.com/apache/pig/blob/c85fe4b0408b4dbea254924aaae20188cebf976b/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c85fe4b0408b4dbea254924aaae20188cebf976b"
            },
            {
                "patch": "@@ -617,7 +617,8 @@ public boolean pruneColumns(List<Pair<Integer, Integer>> columns)\n                     errCode, PigException.BUG);\n         }\n \n-        for (Pair<Integer, Integer> column : columns) {\n+        for (int i=columns.size()-1;i>=0;i--) {\n+            Pair<Integer, Integer> column = columns.get(i);\n             if (column.first < 0 || column.first > predecessors.size()) {\n                 int errCode = 2191;\n                 throw new FrontendException(\"No input \" + column.first",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/c85fe4b0408b4dbea254924aaae20188cebf976b/src/org/apache/pig/impl/logicalLayer/LOJoin.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "78a59cc99b2709695f95c860a662c084078b07ab",
                "blob_url": "https://github.com/apache/pig/blob/c85fe4b0408b4dbea254924aaae20188cebf976b/src/org/apache/pig/impl/logicalLayer/LOJoin.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOJoin.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOJoin.java?ref=c85fe4b0408b4dbea254924aaae20188cebf976b"
            },
            {
                "patch": "@@ -1539,5 +1539,32 @@ public void testSharedSchemaObject() throws Exception {\n         \n         assertTrue(checkLogFileMessage(new String[]{\"Columns pruned for A: $0, $2\", \n                 \"No map keys pruned for A\"}));\n-     } \n+    }\n+    \n+    // See PIG-1142\n+    @Test\n+    public void testJoin4() throws Exception {\n+        pigServer.registerQuery(\"A = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (a0, a1, a2);\");\n+        pigServer.registerQuery(\"B = load '\"+ Util.generateURI(tmpFile1.toString()) + \"' AS (b0, b1, b2);\");\n+        pigServer.registerQuery(\"C = join A by a2, B by b2;\");\n+        pigServer.registerQuery(\"D = foreach C generate $0,  $1,  $2;\");\n+        \n+        Iterator<Tuple> iter = pigServer.openIterator(\"D\");\n+        Collection<String> results = new HashSet<String>();\n+        results.add(\"(1,2,3)\");\n+        results.add(\"(2,5,2)\");\n+        \n+        assertTrue(iter.hasNext());\n+        Tuple t = iter.next();\n+        assertTrue(results.contains(t.toString()));\n+        \n+        assertTrue(iter.hasNext());\n+        t = iter.next();\n+        assertTrue(results.contains(t.toString()));\n+        \n+        assertFalse(iter.hasNext());\n+        \n+        assertTrue(checkLogFileMessage(new String[]{\"No column pruned for A\", \n+                \"No map keys pruned for A\", \"Columns pruned for B: $0, $1\", \"No map keys pruned for B\"}));\n+     }\n }",
                "additions": 28,
                "raw_url": "https://github.com/apache/pig/raw/c85fe4b0408b4dbea254924aaae20188cebf976b/test/org/apache/pig/test/TestPruneColumn.java",
                "status": "modified",
                "changes": 29,
                "deletions": 1,
                "sha": "67804a6b3b8241755df7477ce54b55a72da039e5",
                "blob_url": "https://github.com/apache/pig/blob/c85fe4b0408b4dbea254924aaae20188cebf976b/test/org/apache/pig/test/TestPruneColumn.java",
                "filename": "test/org/apache/pig/test/TestPruneColumn.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPruneColumn.java?ref=c85fe4b0408b4dbea254924aaae20188cebf976b"
            }
        ],
        "bug_id": "pig_13",
        "parent": "https://github.com/apache/pig/commit/464a9751d5169ee28158fc18ca895aee69043502",
        "message": "PIG-1142: Got NullPointerException merge join with pruning\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@889346 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f",
        "file": [
            {
                "patch": "@@ -42,6 +42,9 @@ PIG-4333: Split BigData tests into multiple groups (rohini)\n  \n BUG FIXES\n \n+PIG-4376: NullPointerException accessing a field of an invalid bag from a nested foreach\n+ (kspringborn via daijy)\n+\n PIG-4355: Piggybank: XPath cant handle namespace in xpath, nor can it return more than one match\n  (cavanaug via daijy)\n ",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/CHANGES.txt",
                "status": "modified",
                "changes": 3,
                "deletions": 0,
                "sha": "c7d78f53dba55e3256689145b01389e2d2932b5b",
                "blob_url": "https://github.com/apache/pig/blob/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c60f06635e7807a0e7f5d37ece17e5c94ba75e8f"
            },
            {
                "patch": "@@ -206,7 +206,7 @@ public String toString() {\n             \t    throw new FrontendException(\"Index \"+rawColumn + \" out of range in schema:\" + schema.toString(false), 1127);\n             \t}\n                 columns.add( (Integer)rawColumn );\n-            } else {\n+            } else if (schema!=null) {\n                 int pos = schema.getFieldPosition((String)rawColumn);\n                 if( pos != -1) {\n                     columns.add( pos );",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/src/org/apache/pig/newplan/logical/expression/DereferenceExpression.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "89ebe14f4163ccb20de3e5733e761eae8fade213",
                "blob_url": "https://github.com/apache/pig/blob/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/src/org/apache/pig/newplan/logical/expression/DereferenceExpression.java",
                "filename": "src/org/apache/pig/newplan/logical/expression/DereferenceExpression.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/expression/DereferenceExpression.java?ref=c60f06635e7807a0e7f5d37ece17e5c94ba75e8f"
            },
            {
                "patch": "@@ -159,6 +159,22 @@ public void testNegative5() throws RecognitionException, ParsingFailureException\n         Assert.fail( \"Query should fail to validate.\" );\n     }\n \n+    @Test\n+    public void testInvalidNestedProjection() throws Exception {\n+        String query = \"A = load 'x' as (field);\" +\n+                       \"B = foreach A {\" +\n+                       \"  C = LIMIT invalidName 1;\" +\n+                       \"  generate C.foo;\" +\n+                       \"};\";\n+        try {\n+            validate( query );\n+        } catch(PlanValidationException ex) {\n+            System.out.println(ex.getMessage());\n+            return;\n+        }\n+        Assert.fail( \"Query should fail to validate.\" );\n+    }\n+\n     private LogicalPlan validate(String query) throws RecognitionException, ParsingFailureException, IOException {\n         LogicalPlan plan = ParserTestingUtils.generateLogicalPlan( query );\n         ColumnAliasConversionVisitor visitor = new ColumnAliasConversionVisitor( plan );",
                "additions": 16,
                "raw_url": "https://github.com/apache/pig/raw/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/test/org/apache/pig/parser/TestColumnAliasConversion.java",
                "status": "modified",
                "changes": 16,
                "deletions": 0,
                "sha": "291a81c69ca1ee2363c43d96ef33e802187bfe2b",
                "blob_url": "https://github.com/apache/pig/blob/c60f06635e7807a0e7f5d37ece17e5c94ba75e8f/test/org/apache/pig/parser/TestColumnAliasConversion.java",
                "filename": "test/org/apache/pig/parser/TestColumnAliasConversion.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/parser/TestColumnAliasConversion.java?ref=c60f06635e7807a0e7f5d37ece17e5c94ba75e8f"
            }
        ],
        "bug_id": "pig_14",
        "parent": "https://github.com/apache/pig/commit/2c6116f1bc230baf8a14b368704d3a7a22ebf280",
        "message": "PIG-4376: NullPointerException accessing a field of an invalid bag from a nested foreach\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1652257 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/dc54571be938015c2d1b00694c845101a8404127",
        "file": [
            {
                "patch": "@@ -40,6 +40,8 @@ OPTIMIZATIONS\n \u00a0\n BUG FIXES\n \n+PIG-4967: NPE in PigJobControl.run() when job status is null (water via daijy)\n+\n PIG-4972: StreamingIO_1 fail on perl 5.22 (daijy)\n \n PIG-4933: TestDataBagAccess.testBagConstantFlatten1/TestLogicalPlanBuilder.testQuery90 broken after PIG-2315 (knoguchi)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/dc54571be938015c2d1b00694c845101a8404127/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "9c75f6d49ae35b3b8ed8cd8559a3bce55d210f76",
                "blob_url": "https://github.com/apache/pig/blob/dc54571be938015c2d1b00694c845101a8404127/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=dc54571be938015c2d1b00694c845101a8404127"
            },
            {
                "patch": "@@ -179,7 +179,18 @@ public void run() {\n           }\n           while(it.hasNext()) {\n             ControlledJob j = it.next();\n-            log.debug(\"Checking state of job \"+j);\n+\n+            // TODO: Need to re-visit the following try...catch\n+            // when Pig picks up a Hadoop release with MAPREDUCE-6762 applied\n+            // as its dependency.\n+            try {\n+              log.debug(\"Checking state of job \" + j);\n+            } catch(NullPointerException npe) {\n+              log.warn(\"Failed to get job name \" +\n+                \"when checking state of job. \" +\n+                \"Check if job status is null.\", npe);\n+            }\n+\n             switch(checkState(j)) {\n             case SUCCESS:\n               getJobs(successfulJobs).add(j);",
                "additions": 12,
                "raw_url": "https://github.com/apache/pig/raw/dc54571be938015c2d1b00694c845101a8404127/shims/src/hadoop23/org/apache/pig/backend/hadoop23/PigJobControl.java",
                "status": "modified",
                "changes": 13,
                "deletions": 1,
                "sha": "6439611ae1b983266a9832bd54e653862bdc9564",
                "blob_url": "https://github.com/apache/pig/blob/dc54571be938015c2d1b00694c845101a8404127/shims/src/hadoop23/org/apache/pig/backend/hadoop23/PigJobControl.java",
                "filename": "shims/src/hadoop23/org/apache/pig/backend/hadoop23/PigJobControl.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop23/org/apache/pig/backend/hadoop23/PigJobControl.java?ref=dc54571be938015c2d1b00694c845101a8404127"
            }
        ],
        "bug_id": "pig_15",
        "parent": "https://github.com/apache/pig/commit/2babe53b41bf374701851f53e97e27883a8b1bc9",
        "message": "PIG-4967: NPE in PigJobControl.run() when job status is null\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1758708 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/c840e0297d7134b62fc7b2d88887a2842b03c928",
        "file": [
            {
                "patch": "@@ -133,6 +133,8 @@ PIG-3882: Multiquery off mode execution is not done in batch and very inefficien\n  \n BUG FIXES\n \n+PIG-3940: NullPointerException writing .pig_header for field with null name in JsonMetadata.java (mrflip via cheolsoo)\n+\n PIG-3944: PigNullableWritable toString method throws NPE on null value (mauzhang via cheolsoo)\n \n PIG-3936: DBStorage fails on storing nulls for non varchar columns (jeremykarn via cheolsoo) ",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/c840e0297d7134b62fc7b2d88887a2842b03c928/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "944ccc39ffd87b293f96fd196e668a0601b311cc",
                "blob_url": "https://github.com/apache/pig/blob/c840e0297d7134b62fc7b2d88887a2842b03c928/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c840e0297d7134b62fc7b2d88887a2842b03c928"
            },
            {
                "patch": "@@ -122,9 +122,7 @@ public JsonMetadata(String schemaFileName, String headerFileName, String statFil\n \n                     if (descriptor instanceof HFile) {\n                         Path descriptorPath = ((HPath) descriptor).getPath();\n-                        String fileName = descriptorPath.getName();\n                         Path parent = descriptorPath.getParent();\n-                        String parentName = parent.toString();\n                         container = new HDirectory((HDataStorage)storage,parent);\n                     } else { // descriptor instanceof HDirectory\n                         container = (HDirectory)descriptor;\n@@ -314,10 +312,11 @@ public void storeSchema(ResourceSchema schema, String location, Job job) throws\n                 OutputStream os = headerFilePath.create();\n                 try {\n                     String[] names = schema.fieldNames();\n-\n+                    String fn;\n                     for (int i=0; i < names.length; i++) {\n-                        os.write(names[i].getBytes(\"UTF-8\"));\n-                        if (i <names.length-1) {\n+                        fn = ( (names[i] == null) ? (\"$\"+i) : names[i] );\n+                        os.write(fn.getBytes(\"UTF-8\"));\n+                        if (i < names.length-1) {\n                             os.write(fieldDel);\n                         } else {\n                             os.write(recordDel);",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/c840e0297d7134b62fc7b2d88887a2842b03c928/src/org/apache/pig/builtin/JsonMetadata.java",
                "status": "modified",
                "changes": 9,
                "deletions": 5,
                "sha": "08a6f5dfdefa1147d27a250b75e064237e9284c8",
                "blob_url": "https://github.com/apache/pig/blob/c840e0297d7134b62fc7b2d88887a2842b03c928/src/org/apache/pig/builtin/JsonMetadata.java",
                "filename": "src/org/apache/pig/builtin/JsonMetadata.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/JsonMetadata.java?ref=c840e0297d7134b62fc7b2d88887a2842b03c928"
            },
            {
                "patch": "@@ -438,9 +438,7 @@ public void testByteArrayConversion() throws IOException {\n         Iterator<Tuple> sessions = pig.openIterator(\"Sessions\");\n         while (sessions.hasNext()) {\n             System.out.println(sessions.next());\n-}\n-\n-\n+        }\n     }\n \n     // See PIG-1993\n@@ -471,6 +469,24 @@ public void testColumnPrune() throws IOException {\n         Assert.assertFalse(sessions.hasNext());\n     }\n \n+    @Test\n+    public void testPigStorageSchemaHeader() throws Exception {\n+        pigContext.connect();\n+        String query = \"a = LOAD '\" + datadir + \"originput' using PigStorage(',') \" +\n+                \"as (foo:chararray, bar:int);\";\n+        pig.registerQuery(query);\n+        pig.registerQuery(\"a2 = FOREACH a GENERATE *, 1;\"); // adds a field with a null schema name\n+        pig.registerQuery(\"STORE a2 into '\" + datadir + \"nout' using PigStorage('\\\\t', '-schema');\");\n+\n+        String outPath = FileLocalizer.fullPath(datadir + \"nout/.pig_header\",\n+                pig.getPigContext());\n+        Assert.assertTrue(FileLocalizer.fileExists(outPath,\n+                pig.getPigContext()));\n+\n+        String[] header = Util.readOutput(pig.getPigContext(), outPath);\n+        Assert.assertArrayEquals(\"Headers are not the same.\", new String[] {\"foo\\tbar\\t$2\"}, header);\n+    }\n+\n     @Test\n     public void testPigStorageSchemaHeaderDelimiter() throws Exception {\n         pigContext.connect();",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/c840e0297d7134b62fc7b2d88887a2842b03c928/test/org/apache/pig/test/TestPigStorage.java",
                "status": "modified",
                "changes": 22,
                "deletions": 3,
                "sha": "f958a5a0742cf15b62b6a9b96bf24741b82e12ca",
                "blob_url": "https://github.com/apache/pig/blob/c840e0297d7134b62fc7b2d88887a2842b03c928/test/org/apache/pig/test/TestPigStorage.java",
                "filename": "test/org/apache/pig/test/TestPigStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigStorage.java?ref=c840e0297d7134b62fc7b2d88887a2842b03c928"
            }
        ],
        "bug_id": "pig_16",
        "parent": "https://github.com/apache/pig/commit/01276f04024d2e0d16f31fddef3faf54cdb18d10",
        "message": "PIG-3940: NullPointerException writing .pig_header for field with null name in JsonMetadata.java (mrflip via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1596063 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca",
        "file": [
            {
                "patch": "@@ -32,6 +32,7 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3469: Skewed join can cause unrecoverable NullPointerException when one of its inputs is missing (Jarek Jarcec Cecho  via xuefuz)\n \n Release 0.12.0 (unreleased changes)\n ",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/CHANGES.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "7c18229e1c63510992075a143985983445fbaad9",
                "blob_url": "https://github.com/apache/pig/blob/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca"
            },
            {
                "patch": "@@ -864,7 +864,7 @@ public void adjustNumReducers(MROperPlan plan, MapReduceOper mro,\n             org.apache.hadoop.mapreduce.Job nwJob) throws IOException {\n         int jobParallelism = calculateRuntimeReducers(mro, nwJob);\n \n-        if (mro.isSampler()) {\n+        if (mro.isSampler() && plan.getSuccessors(mro) != null) {\n             // We need to calculate the final number of reducers of the next job (order-by or skew-join)\n             // to generate the quantfile.\n             MapReduceOper nextMro = plan.getSuccessors(mro).get(0);",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "80777768dc81b42909b3e64203e898d3a129bc72",
                "blob_url": "https://github.com/apache/pig/blob/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java?ref=9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca"
            },
            {
                "patch": "@@ -601,6 +601,25 @@ public void testRegisterRemoteScript() throws Throwable {\n         assertFalse(iter.hasNext());\n     }\n \n+    // PIG-3469\n+    @Test\n+    public void testNonExistingSecondDirectoryInSkewJoin() throws Exception {\n+        String script =\n+          \"exists = LOAD 'test/org/apache/pig/test/data/InputFiles/jsTst1.txt' AS (x:chararray, a:long);\" +\n+          \"missing = LOAD '/non/existing/directory' AS (a:long);\" +\n+          \"missing = FOREACH ( GROUP missing BY a ) GENERATE $0 AS a, COUNT_STAR($1);\" +\n+          \"joined = JOIN exists BY a, missing BY a USING 'skewed';\" +\n+          \"STORE joined INTO '/tmp/test_out.tsv';\";\n+\n+        PigServer pig = new PigServer(ExecType.LOCAL);\n+        // Execution of the script should fail, but without throwing any exceptions (such as NPE)\n+        try {\n+            pig.registerScript(new ByteArrayInputStream(script.getBytes(\"UTF-8\")));\n+        } catch(Exception ex) {\n+            fail(\"Unexpected exception: \" + ex);\n+        }\n+    }\n+\n     @Test\n     public void testParamSubstitution() throws Exception{\n         // using params map",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/test/org/apache/pig/test/TestPigServer.java",
                "status": "modified",
                "changes": 19,
                "deletions": 0,
                "sha": "483fa48d475ff9c12c342c9a3d0ca4863c616cf2",
                "blob_url": "https://github.com/apache/pig/blob/9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca/test/org/apache/pig/test/TestPigServer.java",
                "filename": "test/org/apache/pig/test/TestPigServer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigServer.java?ref=9e49a7e9f9ae2fd1dd5f9f831391a2457d2e13ca"
            }
        ],
        "bug_id": "pig_17",
        "parent": "https://github.com/apache/pig/commit/158d4b4ae53423d61211dbc2af7ebe4c935a4a9a",
        "message": "PIG-3469: Skewed join can cause unrecoverable NullPointerException when one of its inputs is missing (Jarek Jarcec Cecho  via xuefuz)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1529011 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/5de019a0785911c2881dc816a2d616a10327938f",
        "file": [
            {
                "patch": "@@ -99,6 +99,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4832: Fix TestPrumeColumn NPE failure (kellyzly via daijy)\n+\n PIG-4833 TestBuiltin.testURIWithCurlyBrace in TEZ failing after PIG-4819 (knoguchi)\n \n PIG-4819: RANDOM() udf can lead to missing or redundant records (knoguchi)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/5de019a0785911c2881dc816a2d616a10327938f/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "433cf0dc5055c9017e32d24516f928c1fbec59e1",
                "blob_url": "https://github.com/apache/pig/blob/5de019a0785911c2881dc816a2d616a10327938f/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=5de019a0785911c2881dc816a2d616a10327938f"
            },
            {
                "patch": "@@ -247,9 +247,11 @@ public Schema getSchema() {\n \n \n     public StoreFuncInterface getStoreFunc() {\n-        if(storer == null){\n-            storer = (StoreFuncInterface)PigContext.instantiateFuncFromSpec(sFile.getFuncSpec());\n+        if (storer == null) {\n+            storer = (StoreFuncInterface) PigContext.instantiateFuncFromSpec(sFile.getFuncSpec());\n             storer.setStoreFuncUDFContextSignature(signature);\n+        }\n+        if (sDecorator == null) {\n             // Init the Decorator we use for writing Tuples\n             setStoreFuncDecorator(new StoreFuncDecorator(storer, signature));\n         }",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/5de019a0785911c2881dc816a2d616a10327938f/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java",
                "status": "modified",
                "changes": 6,
                "deletions": 2,
                "sha": "e0e0bc2d657c5cf6ac63175ef2f2351f97c2c090",
                "blob_url": "https://github.com/apache/pig/blob/5de019a0785911c2881dc816a2d616a10327938f/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java?ref=5de019a0785911c2881dc816a2d616a10327938f"
            }
        ],
        "bug_id": "pig_18",
        "parent": "https://github.com/apache/pig/commit/9562f478075624f15889f95b266296d6f607618e",
        "message": "PIG-4832: Fix TestPrumeColumn NPE failure\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1736096 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/d2b7e212a2fcb7b989198923e9e76ee49ebf850d",
        "file": [
            {
                "patch": "@@ -155,6 +155,8 @@ OPTIMIZATIONS\n \n BUG FIXES\n \n+PIG-5064: NPE in TestScriptUDF#testPythonBuiltinModuleImport1 when JAVA_HOME is not set (water via daijy)\n+\n PIG-5048: HiveUDTF fail if it is the first expression in projection (nkollar via daijy)\n \n PIG-4951: Rename PIG_ATS_ENABLED constant (szita via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/d2b7e212a2fcb7b989198923e9e76ee49ebf850d/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "196539f5a46e3d304fcee18aa5994ff7c988885d",
                "blob_url": "https://github.com/apache/pig/blob/d2b7e212a2fcb7b989198923e9e76ee49ebf850d/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=d2b7e212a2fcb7b989198923e9e76ee49ebf850d"
            },
            {
                "patch": "@@ -247,7 +247,11 @@ public void testPythonBuiltinModuleImport1() throws Exception {\n         Assert.assertTrue(t.get(0).toString().equals(System.getenv(input[0])));\n         Assert.assertTrue(iter.hasNext());\n         t = iter.next();\n-        Assert.assertTrue(t.get(0).toString().equals(System.getenv(input[1])));\n+        if (System.getenv(input[1]) != null) {  // JAVA_HOME is set, t.get(0) is not null\n+            Assert.assertTrue(t.get(0).toString().equals(System.getenv(input[1])));\n+        } else {  // JAVA_HOME is not set, t.get(0) is null\n+            Assert.assertNull(t.get(0));\n+        }\n         Assert.assertFalse(iter.hasNext());\n     }\n ",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/d2b7e212a2fcb7b989198923e9e76ee49ebf850d/test/org/apache/pig/test/TestScriptUDF.java",
                "status": "modified",
                "changes": 6,
                "deletions": 1,
                "sha": "8dc5818d3f574a77588e387a6abb87ea63a869cd",
                "blob_url": "https://github.com/apache/pig/blob/d2b7e212a2fcb7b989198923e9e76ee49ebf850d/test/org/apache/pig/test/TestScriptUDF.java",
                "filename": "test/org/apache/pig/test/TestScriptUDF.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestScriptUDF.java?ref=d2b7e212a2fcb7b989198923e9e76ee49ebf850d"
            }
        ],
        "bug_id": "pig_19",
        "parent": "https://github.com/apache/pig/commit/b6f197003cb7e74ee47e278e40ad62e7be654300",
        "message": "PIG-5064: NPE in TestScriptUDF#testPythonBuiltinModuleImport1 when JAVA_HOME is not set\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1770733 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/348d0839580ff7b0e647c326012580bfd00ed906",
        "file": [
            {
                "patch": "@@ -69,6 +69,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4722: [Pig on Tez] NPE while running Combiner (rohini)\n+\n PIG-4730: [Pig on Tez] Total parallelism estimation does not account load parallelism (rohini)\n \n PIG-4689: CSV Writes incorrect header if two CSV files are created in one script (nielsbasjes via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/348d0839580ff7b0e647c326012580bfd00ed906/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "54b5ead7dfe8408efc26e35e3bdb67841df2d19d",
                "blob_url": "https://github.com/apache/pig/blob/348d0839580ff7b0e647c326012580bfd00ed906/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=348d0839580ff7b0e647c326012580bfd00ed906"
            },
            {
                "patch": "@@ -299,8 +299,9 @@ public Result processInput() throws ExecException {\n             }\n \n             // Should be removed once the model is clear\n-            if (getReporter() != null) {\n-                getReporter().progress();\n+            PigProgressable progRep = getReporter();\n+            if (progRep != null) {\n+                progRep.progress();\n             }\n \n             if (!isInputAttached()) {",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/348d0839580ff7b0e647c326012580bfd00ed906/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "status": "modified",
                "changes": 5,
                "deletions": 2,
                "sha": "164b75fc8dfc2aa00b8f2e85f200183c5ad15e81",
                "blob_url": "https://github.com/apache/pig/blob/348d0839580ff7b0e647c326012580bfd00ed906/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java?ref=348d0839580ff7b0e647c326012580bfd00ed906"
            }
        ],
        "bug_id": "pig_20",
        "parent": "https://github.com/apache/pig/commit/27d4ee118de18acaf267d459cf90192bad7d047f",
        "message": "PIG-4722: [Pig on Tez] NPE while running Combiner (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1714256 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/a44b85a0ab941cdd1d2d7f6e457303aef1e57501",
        "file": [
            {
                "patch": "@@ -47,6 +47,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4635: NPE while running pig script in tez mode (daijy)\n+\n PIG-4683: Nested order is broken after PIG-3591 in some cases (daijy)\n \n PIG-4679: Performance degradation due to InputSizeReducerEstimator since PIG-3754 (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "1085ffaa11a5d01c36c7e90f3ee0ae8032ff6b2a",
                "blob_url": "https://github.com/apache/pig/blob/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=a44b85a0ab941cdd1d2d7f6e457303aef1e57501"
            },
            {
                "patch": "@@ -189,6 +189,7 @@\n     private transient VertexGroupInfo vertexGroupInfo;\n     // Mapping of OperatorKey of POStore OperatorKey to vertexGroup TezOperator\n     private Map<OperatorKey, OperatorKey> vertexGroupStores = null;\n+    private boolean isVertexGroup = false;\n \n     public static class LoaderInfo implements Serializable {\n         private List<POLoad> loads = null;\n@@ -487,7 +488,7 @@ public void setVertexGroupMembers(List<OperatorKey> vertexGroupMembers) {\n     // Union is the only operator that uses alias vertex (VertexGroup) now. But\n     // more operators could be added to the list in the future.\n     public boolean isVertexGroup() {\n-        return vertexGroupInfo != null;\n+        return isVertexGroup;\n     }\n \n     public VertexGroupInfo getVertexGroupInfo() {\n@@ -496,6 +497,7 @@ public VertexGroupInfo getVertexGroupInfo() {\n \n     public void setVertexGroupInfo(VertexGroupInfo vertexGroup) {\n         this.vertexGroupInfo = vertexGroup;\n+        this.isVertexGroup = true;\n     }\n \n     public void addVertexGroupStore(OperatorKey storeKey, OperatorKey vertexGroupKey) {",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "52764ab09991369c716aea647a9526ef05c9e73b",
                "blob_url": "https://github.com/apache/pig/blob/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java?ref=a44b85a0ab941cdd1d2d7f6e457303aef1e57501"
            },
            {
                "patch": "@@ -55,9 +55,13 @@ public void setVerbose(boolean verbose) {\n     public void visitTezOp(TezOperator tezOper) throws VisitorException {\n         if (tezOper.isVertexGroup()) {\n             VertexGroupInfo info = tezOper.getVertexGroupInfo();\n-            mStream.println(\"Tez vertex group \"\n-                    + tezOper.getOperatorKey().toString() + \"\\t<-\\t \"\n-                    + info.getInputs() + \"\\t->\\t \" + info.getOutput());\n+            mStream.print(\"Tez vertex group \"\n+                    + tezOper.getOperatorKey().toString());\n+            if (info!=null) {\n+                mStream.println(\"\\t<-\\t \" + info.getInputs() + \"\\t->\\t \" + info.getOutput());\n+            } else {\n+                mStream.println();\n+            }\n             mStream.println(\"# No plan on vertex group\");\n         } else {\n             mStream.println(\"Tez vertex \" + tezOper.getOperatorKey().toString());",
                "additions": 7,
                "raw_url": "https://github.com/apache/pig/raw/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezPrinter.java",
                "status": "modified",
                "changes": 10,
                "deletions": 3,
                "sha": "ce5d98176d0546575aa1ef0bca323f9673210091",
                "blob_url": "https://github.com/apache/pig/blob/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezPrinter.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezPrinter.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezPrinter.java?ref=a44b85a0ab941cdd1d2d7f6e457303aef1e57501"
            },
            {
                "patch": "@@ -26,6 +26,7 @@\n import java.io.IOException;\n import java.io.PrintWriter;\n import java.io.StringWriter;\n+import java.util.Arrays;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Random;\n@@ -248,4 +249,37 @@ public void testJoinWithDifferentDepth2() throws IOException{\n             Util.removeLogAppender(PigGraceShuffleVertexManager.class, \"testJoinWithDifferentDepth2\");\n         }\n     }\n+\n+    @Test\n+    // See PIG-4635 for a NPE in TezOperDependencyParallelismEstimator\n+    public void testJoinWithUnion() throws IOException{\n+        NodeIdGenerator.reset();\n+        PigServer.resetScope();\n+        StringWriter writer = new StringWriter();\n+        Util.createLogAppender(\"testJoinWithUnion\", writer, PigGraceShuffleVertexManager.class);\n+        try {\n+            // DAG: 29 -> 32 -> 41 \\\n+            //                       -> 70 (vertex group) -> 61\n+            //      42 -> 45 -> 54 /\n+            pigServer.registerQuery(\"A = load '\" + INPUT_DIR + \"/\" + INPUT_FILE2 + \"' as (name:chararray, gender:chararray);\");\n+            pigServer.registerQuery(\"B = distinct A;\");\n+            pigServer.registerQuery(\"C = group B by name;\");\n+            pigServer.registerQuery(\"D = load '\" + INPUT_DIR + \"/\" + INPUT_FILE2 + \"' as (name:chararray, gender:chararray);\");\n+            pigServer.registerQuery(\"E = distinct D;\");\n+            pigServer.registerQuery(\"F = group E by name;\");\n+            pigServer.registerQuery(\"G = union C, F;\");\n+            pigServer.registerQuery(\"H = distinct G;\");\n+            Iterator<Tuple> iter = pigServer.openIterator(\"H\");\n+            int count = 0;\n+            while (iter.hasNext()) {\n+                iter.next();\n+                count++;\n+            }\n+            assertEquals(count, 20);\n+            assertTrue(writer.toString().contains(\"time to set parallelism for scope-41\"));\n+            assertTrue(writer.toString().contains(\"time to set parallelism for scope-54\"));\n+        } finally {\n+            Util.removeLogAppender(PigGraceShuffleVertexManager.class, \"testJoinWithUnion\");\n+        }\n+    }\n }",
                "additions": 34,
                "raw_url": "https://github.com/apache/pig/raw/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/test/org/apache/pig/tez/TestTezGraceParallelism.java",
                "status": "modified",
                "changes": 34,
                "deletions": 0,
                "sha": "cf8d19c55fa2de818f3776675c4f0b9951336872",
                "blob_url": "https://github.com/apache/pig/blob/a44b85a0ab941cdd1d2d7f6e457303aef1e57501/test/org/apache/pig/tez/TestTezGraceParallelism.java",
                "filename": "test/org/apache/pig/tez/TestTezGraceParallelism.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/tez/TestTezGraceParallelism.java?ref=a44b85a0ab941cdd1d2d7f6e457303aef1e57501"
            }
        ],
        "bug_id": "pig_21",
        "parent": "https://github.com/apache/pig/commit/8f273342fdd3e8c4292f2460d07b99978a2be5c6",
        "message": "PIG-4635: NPE while running pig script in tez mode\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1705335 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0",
        "file": [
            {
                "patch": "@@ -58,6 +58,8 @@ PIG-4333: Split BigData tests into multiple groups (rohini)\n  \n BUG FIXES\n \n+PIG-4497: [Pig on Tez] NPE for null scalar (rohini)\n+\n PIG-4493: Pig on Tez gives wrong results if Union is followed by Split (rohini)\n \n PIG-4491: Streaming Python Bytearray Bugs (jeremykarn via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "47c0d77b1714a463fb55a5aaf9776bd59d31eb54",
                "blob_url": "https://github.com/apache/pig/blob/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=8d7d90161e41654a03b73624e5bfe6f1e68ddaf0"
            },
            {
                "patch": "@@ -100,6 +100,9 @@ public void attachInputs(Map<String, LogicalInput> inputs,\n \n     @Override\n     public Object exec(Tuple input) throws IOException {\n+        if (t == null) {\n+            return null;\n+        }\n         int pos = (Integer) input.get(0);\n         Object obj = t.get(pos);\n         return obj;",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/udf/ReadScalarsTez.java",
                "status": "modified",
                "changes": 3,
                "deletions": 0,
                "sha": "df04f2f476b8824cd836f4e2a04badb7542ded2b",
                "blob_url": "https://github.com/apache/pig/blob/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/udf/ReadScalarsTez.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/udf/ReadScalarsTez.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/udf/ReadScalarsTez.java?ref=8d7d90161e41654a03b73624e5bfe6f1e68ddaf0"
            },
            {
                "patch": "@@ -25,8 +25,10 @@\n import java.io.File;\n import java.io.IOException;\n import java.util.Iterator;\n+import java.util.List;\n \n import org.apache.pig.PigServer;\n+import org.apache.pig.builtin.mock.Storage;\n import org.apache.pig.data.BagFactory;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n@@ -556,4 +558,24 @@ public void testScalarWithNoProjection() throws Exception{\n         );\n     }\n \n+    @Test\n+    public void testScalarNullValue() throws Exception{\n+        Storage.Data data = Storage.resetData(pigServer);\n+        data.set(\"input\", Storage.tuple(\"a\", 1), Storage.tuple(\"b\", 2));\n+\n+        pigServer.setBatchOn();\n+        pigServer.registerQuery(\"A = load 'input' using mock.Storage() as (a:chararray, b:int);\");\n+        pigServer.registerQuery(\"B = FILTER A by a == 'c';\");\n+        pigServer.registerQuery(\"C = FOREACH A generate a, b + B.b;\");\n+        pigServer.registerQuery(\"store C into 'output' using mock.Storage();\");\n+\n+        pigServer.executeBatch();\n+\n+        List<Tuple> actualResults = data.get(\"output\");\n+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(\n+                new String[] {\"('a', null)\", \"('b', null)\"});\n+        Util.checkQueryOutputsAfterSort(actualResults.iterator(), expectedResults);\n+\n+    }\n+\n }",
                "additions": 22,
                "raw_url": "https://github.com/apache/pig/raw/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/test/org/apache/pig/test/TestScalarAliasesLocal.java",
                "status": "modified",
                "changes": 22,
                "deletions": 0,
                "sha": "7c88219bb90faf5fc7aaee92ac57ad74917ef65f",
                "blob_url": "https://github.com/apache/pig/blob/8d7d90161e41654a03b73624e5bfe6f1e68ddaf0/test/org/apache/pig/test/TestScalarAliasesLocal.java",
                "filename": "test/org/apache/pig/test/TestScalarAliasesLocal.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestScalarAliasesLocal.java?ref=8d7d90161e41654a03b73624e5bfe6f1e68ddaf0"
            }
        ],
        "bug_id": "pig_22",
        "parent": "https://github.com/apache/pig/commit/9b7af31b09099f9954729cddbdf71519ab8b1621",
        "message": "PIG-4497: [Pig on Tez] NPE for null scalar (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1671155 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/6e19aa5c51829f525149c5ef6de69395599deacb",
        "file": [
            {
                "patch": "@@ -127,6 +127,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4873: InputSplit.getLocations return null and result a NPE in Pig (daijy)\n+\n PIG-4895: User UDFs relying on mapreduce.job.maps broken in Tez (rohini)\n \n PIG-4883: MapKeyType of splitter was set wrongly in specific multiquery case (kellyzly via rohini)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6e19aa5c51829f525149c5ef6de69395599deacb/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "5d917b0533962ce629770571128ad9920ba996d9",
                "blob_url": "https://github.com/apache/pig/blob/6e19aa5c51829f525149c5ef6de69395599deacb/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=6e19aa5c51829f525149c5ef6de69395599deacb"
            },
            {
                "patch": "@@ -463,9 +463,11 @@ public String toString() {\n             for (int i = 0; i < wrappedSplits.length; i++) {\n                 st.append(\"Input split[\"+i+\"]:\\n   Length = \"+ wrappedSplits[i].getLength()+\"\\n   ClassName: \" +\n                     wrappedSplits[i].getClass().getName() + \"\\n   Locations:\\n\");\n-                for (String location :  wrappedSplits[i].getLocations())\n-                    st.append(\"    \"+location+\"\\n\");\n-                st.append(\"\\n-----------------------\\n\");\n+                if (wrappedSplits[i]!=null && wrappedSplits[i].getLocations()!=null) {\n+                    for (String location :  wrappedSplits[i].getLocations())\n+                        st.append(\"    \"+location+\"\\n\");\n+                    st.append(\"\\n-----------------------\\n\");\n+                }\n           }\n         } catch (IOException e) {\n           return null;",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/6e19aa5c51829f525149c5ef6de69395599deacb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "status": "modified",
                "changes": 8,
                "deletions": 3,
                "sha": "e866b28c1bcdadcb5c0201d80c9648868dd6b3ca",
                "blob_url": "https://github.com/apache/pig/blob/6e19aa5c51829f525149c5ef6de69395599deacb/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigSplit.java?ref=6e19aa5c51829f525149c5ef6de69395599deacb"
            }
        ],
        "bug_id": "pig_23",
        "parent": "https://github.com/apache/pig/commit/a58d3088c37a153fe565f0b9dd7cb208e6c5ac56",
        "message": "PIG-4873: InputSplit.getLocations return null and result a NPE in Pig\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1744313 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/fbda3661b25d640233ff3ddcf0e69832170c11b4",
        "file": [
            {
                "patch": "@@ -119,6 +119,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4880: Overlapping of parameter substitution names inside&outside a macro fails with NPE (knoguchi)\n+\n PIG-4881: TestBuiltin.testUniqueID failing on hadoop-1.x (knoguchi)\n \n PIG-4888: Line number off when reporting syntax error inside a macro (knoguchi)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/fbda3661b25d640233ff3ddcf0e69832170c11b4/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "cfc219cb85e38587a9bbbdb6fc4326271ca98d2b",
                "blob_url": "https://github.com/apache/pig/blob/fbda3661b25d640233ff3ddcf0e69832170c11b4/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=fbda3661b25d640233ff3ddcf0e69832170c11b4"
            },
            {
                "patch": "@@ -168,14 +168,9 @@ private String substituteParams(String[] inputs, String[] outputs,\n \n             Map<String, String> paramVal = pc.getParamVal();\n             for (Map.Entry<String, String> e : pigContext.getParamVal().entrySet()) {\n-                if (paramVal.containsKey(e.getKey())) {\n-                    throw new ParserException(\n-                        \"Macro contains argument or return value \" + e.getKey() + \" which conflicts \" +\n-                        \"with a Pig parameter of the same name.\"\n-                    );\n-                } else {\n-                    paramVal.put(e.getKey(), e.getValue());\n-                }\n+                // overwrite=false since macro parameters should have precedence\n+                // over commandline parameters (if keys overlap)\n+                pc.processOrdLine(e.getKey(), e.getValue(), false);\n             }\n             \n             ParameterSubstitutionPreprocessor psp = new ParameterSubstitutionPreprocessor(pc);",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/fbda3661b25d640233ff3ddcf0e69832170c11b4/src/org/apache/pig/parser/PigMacro.java",
                "status": "modified",
                "changes": 11,
                "deletions": 8,
                "sha": "1f84af48c5346690b461a1f1a65f576f43bf6cbd",
                "blob_url": "https://github.com/apache/pig/blob/fbda3661b25d640233ff3ddcf0e69832170c11b4/src/org/apache/pig/parser/PigMacro.java",
                "filename": "src/org/apache/pig/parser/PigMacro.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/parser/PigMacro.java?ref=fbda3661b25d640233ff3ddcf0e69832170c11b4"
            },
            {
                "patch": "@@ -2280,6 +2280,135 @@ public void testNestedImport() throws Exception {\n         verify(script, expected);\n     }\n \n+    // When  declare-in-macro, macro param and command-line param contain the\n+    // same name, last declare wins\n+    @Test\n+    public void testParamOverLap1() throws Exception {\n+        String macro =\n+            \"DEFINE mygroupby(REL, key, number) RETURNS G {\\n\" +\n+            \"    %declare number 333;\\n\"  +\n+            \"    $G = GROUP $REL by $key parallel $number;\\n\" +\n+            \"};\";\n+        createFile(\"my_macro.pig\", macro);\n+\n+        String script =\n+            \"%declare number 111;\\n\" +\n+            \"IMPORT 'my_macro.pig';\\n\" +\n+            \"data = LOAD '1234.txt' USING PigStorage() AS (i: int);\\n\" +\n+            \"result = mygroupby(data, i, 222);\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\";\n+\n+        String expected =\n+            \"data = LOAD '1234.txt' USING PigStorage() AS i:int;\\n\" +\n+            \"result = GROUP data by (i) parallel 333;\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\\n\";\n+\n+        verify(script, expected);\n+    }\n+\n+    // When  default-in-macro, macro param and command-line param contain the\n+    // same name, then default should be ignored and macro param to be taken\n+    @Test\n+    public void testParamOverLap2() throws Exception {\n+        String macro =\n+            \"DEFINE mygroupby(REL, key, number) RETURNS G {\\n\" +\n+            \"    %default number 333;\\n\"  +\n+            \"    $G = GROUP $REL by $key parallel $number;\\n\" +\n+            \"};\";\n+        createFile(\"my_macro.pig\", macro);\n+\n+        String script =\n+            \"%declare number 111;\\n\" +\n+            \"IMPORT 'my_macro.pig';\\n\" +\n+            \"data = LOAD '1234.txt' USING PigStorage() AS (i: int);\\n\" +\n+            \"result = mygroupby(data, i, 222);\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\";\n+\n+        String expected =\n+            \"data = LOAD '1234.txt' USING PigStorage() AS i:int;\\n\" +\n+            \"result = GROUP data by (i) parallel 222;\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\\n\";\n+\n+        verify(script, expected);\n+    }\n+\n+    // Overlapping of  macro param and command-line param used to be disallowed.\n+    // Now, simply taking the macro param when this happens\n+    @Test\n+    public void testParamOverLap3() throws Exception {\n+        String macro =\n+            \"DEFINE mygroupby(REL, key, number) RETURNS G {\\n\" +\n+            \"    $G = GROUP $REL by $key parallel $number;\\n\" +\n+            \"};\";\n+        createFile(\"my_macro.pig\", macro);\n+\n+        String script =\n+            \"%default number 111;\\n\" +\n+            \"IMPORT 'my_macro.pig';\\n\" +\n+            \"data = LOAD '1234.txt' USING PigStorage() AS (i: int);\\n\" +\n+            \"result = mygroupby(data, i, 222);\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\";\n+\n+        String expected =\n+            \"data = LOAD '1234.txt' USING PigStorage() AS i:int;\\n\" +\n+            \"result = GROUP data by (i) parallel 222;\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\\n\";\n+\n+        verify(script, expected);\n+    }\n+\n+    // Testing inline declare and commandline param overlap.\n+    // testParamOverLap1 should cover this case as well but creating a specific\n+    // case since this pair used to fail with NPE\n+    @Test\n+    public void testParamOverLap4() throws Exception {\n+        String macro =\n+            \"DEFINE mygroupby(REL, key) RETURNS G {\\n\" +\n+            \"    %declare number 333;\\n\"  +\n+            \"    $G = GROUP $REL by $key parallel $number;\\n\" +\n+            \"};\";\n+        createFile(\"my_macro.pig\", macro);\n+\n+        String script =\n+            \"%default number 111;\\n\" +\n+            \"IMPORT 'my_macro.pig';\\n\" +\n+            \"data = LOAD '1234.txt' USING PigStorage() AS (i: int);\\n\" +\n+            \"result = mygroupby(data, i);\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\";\n+\n+        String expected =\n+            \"data = LOAD '1234.txt' USING PigStorage() AS i:int;\\n\" +\n+            \"result = GROUP data by (i) parallel 333;\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\\n\";\n+\n+        verify(script, expected);\n+    }\n+\n+    // default-in-macro should yield to command-line param\n+    @Test\n+    public void testParamOverLap5() throws Exception {\n+        String macro =\n+            \"DEFINE mygroupby(REL, key) RETURNS G {\\n\" +\n+            \"    %default number 333;\\n\"  +\n+            \"    $G = GROUP $REL by $key parallel $number;\\n\" +\n+            \"};\";\n+        createFile(\"my_macro.pig\", macro);\n+\n+        String script =\n+            \"%declare number 111;\\n\" +\n+            \"IMPORT 'my_macro.pig';\\n\" +\n+            \"data = LOAD '1234.txt' USING PigStorage() AS (i: int);\\n\" +\n+            \"result = mygroupby(data, i);\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\";\n+\n+        String expected =\n+            \"data = LOAD '1234.txt' USING PigStorage() AS i:int;\\n\" +\n+            \"result = GROUP data by (i) parallel 111;\\n\" +\n+            \"STORE result INTO 'test.out' USING PigStorage();\\n\";\n+\n+        verify(script, expected);\n+    }\n+\n     //-------------------------------------------------------------------------\n     \n     private void testMacro(String content) throws Exception {",
                "additions": 129,
                "raw_url": "https://github.com/apache/pig/raw/fbda3661b25d640233ff3ddcf0e69832170c11b4/test/org/apache/pig/test/TestMacroExpansion.java",
                "status": "modified",
                "changes": 129,
                "deletions": 0,
                "sha": "0328b072166536e02a0568b574f3cdfe36f9ad49",
                "blob_url": "https://github.com/apache/pig/blob/fbda3661b25d640233ff3ddcf0e69832170c11b4/test/org/apache/pig/test/TestMacroExpansion.java",
                "filename": "test/org/apache/pig/test/TestMacroExpansion.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestMacroExpansion.java?ref=fbda3661b25d640233ff3ddcf0e69832170c11b4"
            }
        ],
        "bug_id": "pig_24",
        "parent": "https://github.com/apache/pig/commit/8cc8c06ac886613f3c695209d92bf584576ad887",
        "message": "PIG-4880: Overlapping of parameter substitution names inside&outside a macro fails with NPE (knoguchi)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1743527 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9",
        "file": [
            {
                "patch": "@@ -26,8 +26,8 @@\n \n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;\n+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigHadoopLogger;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n@@ -149,15 +149,14 @@ protected void execute(LogicalExpression op) throws FrontendException {\n                     PhysicalOperator root = expPhysicalPlan.getLeaves().get(0);\n                     try {\n                         UDFContext.getUDFContext().addJobConf(ConfigurationUtil.toConfiguration(pc.getProperties(), true));\n-                        Result ret= root.getNext(root.getResultType());\n-                        if (ret.result != null) {\n-                            val = ret.result;\n-                            valSet = true;\n-                        }\n+                        PigHadoopLogger pigHadoopLogger = PigHadoopLogger.getInstance();\n+                        PhysicalOperator.setPigLogger(pigHadoopLogger);\n+                        val = root.getNext(root.getResultType()).result;\n                         UDFContext.getUDFContext().addJobConf(null);\n                     } catch (ExecException e) {\n                         throw new FrontendException(e);\n                     }\n+                    valSet = true;\n                 } else if (op instanceof UserFuncExpression) {\n                     // If solo UDF, calculate UDF\n                     UserFuncExpression udf = (UserFuncExpression)op;",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "status": "modified",
                "changes": 11,
                "deletions": 6,
                "sha": "860fa474ea59bf6126a37d46740fc9d6d3df0f06",
                "blob_url": "https://github.com/apache/pig/blob/5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "filename": "src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java?ref=5a9b9ebdf1554898bd3a3d59d6571f20cbc692b9"
            }
        ],
        "bug_id": "pig_25",
        "parent": "https://github.com/apache/pig/commit/f919fc3b742dae415a59539ab3abd08c6b8a0400",
        "message": "PIG-4169: NPE in ConstantCalculator\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1625205 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/779945ca83b00b13835184b8da25548cd5e0e0c7",
        "file": [
            {
                "patch": "@@ -70,6 +70,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4169: NPE in ConstantCalculator (cheolsoo)\n+\n PIG-4161: check for latest Hive snapshot dependencies (daijy)\n \n PIG-4102: Adding e2e tests and several improvements for Orc predicate pushdown (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/779945ca83b00b13835184b8da25548cd5e0e0c7/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "234073e4fd15efb3ec54f8e6b265b3f6811d607d",
                "blob_url": "https://github.com/apache/pig/blob/779945ca83b00b13835184b8da25548cd5e0e0c7/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=779945ca83b00b13835184b8da25548cd5e0e0c7"
            },
            {
                "patch": "@@ -27,6 +27,7 @@\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n@@ -148,12 +149,15 @@ protected void execute(LogicalExpression op) throws FrontendException {\n                     PhysicalOperator root = expPhysicalPlan.getLeaves().get(0);\n                     try {\n                         UDFContext.getUDFContext().addJobConf(ConfigurationUtil.toConfiguration(pc.getProperties(), true));\n-                        val = root.getNext(root.getResultType()).result;\n+                        Result ret= root.getNext(root.getResultType());\n+                        if (ret.result != null) {\n+                            val = ret.result;\n+                            valSet = true;\n+                        }\n                         UDFContext.getUDFContext().addJobConf(null);\n                     } catch (ExecException e) {\n                         throw new FrontendException(e);\n                     }\n-                    valSet = true;\n                 } else if (op instanceof UserFuncExpression) {\n                     // If solo UDF, calculate UDF\n                     UserFuncExpression udf = (UserFuncExpression)op;",
                "additions": 6,
                "raw_url": "https://github.com/apache/pig/raw/779945ca83b00b13835184b8da25548cd5e0e0c7/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "status": "modified",
                "changes": 8,
                "deletions": 2,
                "sha": "761781c1e3ab01b84316b45a7c23d6c873592ee8",
                "blob_url": "https://github.com/apache/pig/blob/779945ca83b00b13835184b8da25548cd5e0e0c7/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "filename": "src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/rules/ConstantCalculator.java?ref=779945ca83b00b13835184b8da25548cd5e0e0c7"
            }
        ],
        "bug_id": "pig_26",
        "parent": "https://github.com/apache/pig/commit/484de09de12b17bed1d76fef8958f38163822e0c",
        "message": "PIG-4169: NPE in ConstantCalculator (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1624611 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/6567cc0704041f2b7b1f6fa9f7e264a568fd5975",
        "file": [
            {
                "patch": "@@ -70,6 +70,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4156: [PATCH] fix NPE when running scripts stored on hdfs:// (acoliver via daijy)\n+\n PIG-4159: TestGroupConstParallelTez and TestJobSubmissionTez should be excluded in Hadoop 20 unit tests (cheolsoo)\n \n PIG-4154: ScriptState#setScript(File) does not close resources (lars_francke via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6567cc0704041f2b7b1f6fa9f7e264a568fd5975/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "4f8376b59e9bd16905750bb3f2fcc43735300546",
                "blob_url": "https://github.com/apache/pig/blob/6567cc0704041f2b7b1f6fa9f7e264a568fd5975/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=6567cc0704041f2b7b1f6fa9f7e264a568fd5975"
            },
            {
                "patch": "@@ -800,7 +800,8 @@ public static FetchFileRet fetchFile(Properties properties, String filePath) thr\n                 && uri.getScheme() == null )||\n                 // For Windows local files\n                 (uri.getScheme() == null && uri.getPath().matches(\"^/[A-Za-z]:.*\")) ||\n-                uri.getScheme().equals(\"local\") ) {\n+                (uri.getScheme() != null && uri.getScheme().equals(\"local\")) \n+            ) {\n             srcFs = localFs;\n         } else {\n             srcFs = path.getFileSystem(conf);",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/6567cc0704041f2b7b1f6fa9f7e264a568fd5975/src/org/apache/pig/impl/io/FileLocalizer.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "2ffa4ebed3fa4a22065c28334e0f3361f1b4e03f",
                "blob_url": "https://github.com/apache/pig/blob/6567cc0704041f2b7b1f6fa9f7e264a568fd5975/src/org/apache/pig/impl/io/FileLocalizer.java",
                "filename": "src/org/apache/pig/impl/io/FileLocalizer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/io/FileLocalizer.java?ref=6567cc0704041f2b7b1f6fa9f7e264a568fd5975"
            }
        ],
        "bug_id": "pig_27",
        "parent": "https://github.com/apache/pig/commit/0fb27a9a7a5cb7fdd277db66b647e09f319bef32",
        "message": "PIG-4156: [PATCH] fix NPE when running scripts stored on hdfs://\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1623608 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/20eac9b2672f80eb24502a176a9df2024ba70fbe",
        "file": [
            {
                "patch": "@@ -193,6 +193,8 @@ PIG-3882: Multiquery off mode execution is not done in batch and very inefficien\n  \n BUG FIXES\n \n+PIG-4017: NPE thrown from JobControlCompiler.shipToHdfs (cheolsoo)\n+\n PIG-3997: Issue on Pig docs: Testing and Diagnostics (zjffdu via cheolsoo)\n \n PIG-3998: Documentation fix: invalid page links, wrong Groovy udf example (lbendig via cheolsoo)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/20eac9b2672f80eb24502a176a9df2024ba70fbe/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "dba86c9ade6aa95d040f79ba8e05a19186f49384",
                "blob_url": "https://github.com/apache/pig/blob/20eac9b2672f80eb24502a176a9df2024ba70fbe/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=20eac9b2672f80eb24502a176a9df2024ba70fbe"
            },
            {
                "patch": "@@ -1687,7 +1687,9 @@ private static Path shipToHDFS(\n         } finally {\n             org.apache.commons.io.IOUtils.closeQuietly(is);\n             // IOUtils should not close stream to HDFS quietly\n-            os.close();\n+            if (os != null) {\n+                os.close();\n+            }\n         }\n         return dst;\n     }",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/20eac9b2672f80eb24502a176a9df2024ba70fbe/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "37341ce948d89c3b66d7a4860e5ba83a98d3c4a8",
                "blob_url": "https://github.com/apache/pig/blob/20eac9b2672f80eb24502a176a9df2024ba70fbe/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java?ref=20eac9b2672f80eb24502a176a9df2024ba70fbe"
            }
        ],
        "bug_id": "pig_28",
        "parent": "https://github.com/apache/pig/commit/63efe61aa797cb65b470019b2a6beb6c74826e61",
        "message": "PIG-4017: NPE thrown from JobControlCompiler.shipToHdfs (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1603315 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/23dc5ce42e783a32fd5713de05e9e330cc429731",
        "file": [
            {
                "patch": "@@ -99,6 +99,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3806: PigServer constructor throws NPE after PIG-3765 (aniket486)\n+\n PIG-3801: Auto local mode does not call storeSchema (aniket486)\n \n PIG-3754: InputSizeReducerEstimator.getTotalInputFileSize reports incorrect size (aniket486)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/23dc5ce42e783a32fd5713de05e9e330cc429731/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "70b6d59884318e7be39758c61b14231baeb4a70c",
                "blob_url": "https://github.com/apache/pig/blob/23dc5ce42e783a32fd5713de05e9e330cc429731/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=23dc5ce42e783a32fd5713de05e9e330cc429731"
            },
            {
                "patch": "@@ -233,6 +233,8 @@ public PigServer(PigContext context, boolean connect) throws ExecException {\n         if (connect) {\n             pigContext.connect();\n         }\n+        \n+        this.filter = new BlackAndWhitelistFilter(this);\n \n         addJarsFromProperties();\n         markPredeployedJarsFromProperties();\n@@ -244,8 +246,6 @@ public PigServer(PigContext context, boolean connect) throws ExecException {\n         if (ScriptState.get() == null) {\n             ScriptState.start(pigContext.getExecutionEngine().instantiateScriptState());\n         }\n-\n-        this.filter = new BlackAndWhitelistFilter(this);\n     }\n \n     private void addJarsFromProperties() throws ExecException {",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/23dc5ce42e783a32fd5713de05e9e330cc429731/src/org/apache/pig/PigServer.java",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "54515206ca52220ccb68faf19ff54c6a034d2255",
                "blob_url": "https://github.com/apache/pig/blob/23dc5ce42e783a32fd5713de05e9e330cc429731/src/org/apache/pig/PigServer.java",
                "filename": "src/org/apache/pig/PigServer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/PigServer.java?ref=23dc5ce42e783a32fd5713de05e9e330cc429731"
            }
        ],
        "bug_id": "pig_29",
        "parent": "https://github.com/apache/pig/commit/c2aedcc66486ddc721a32dc4984547f049aa5541",
        "message": "PIG-3806: PigServer constructor throws NPE after PIG-3765 (aniket486)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1576549 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/18c844e6e3254586d4b5ba9840c054c66c513adc",
        "file": [
            {
                "patch": "@@ -77,6 +77,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4774: Fix NPE in SUM,AVG,MIN,MAX UDFs for null bag input (rohini)\n+\n PIG-4757: Job stats on successfully read/output records wrong with multiple inputs/outputs (rohini)\n \n PIG-4769: UnionOptimizer hits errors when merging vertex group into split (rohini)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "92003cd62079ad44d3b712e1e4cf2fb6904d63a1",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -27,14 +27,14 @@\n import org.apache.pig.EvalFunc;\n import org.apache.pig.FuncSpec;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataByteArray;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n@@ -79,14 +79,17 @@ public Double exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -230,7 +233,7 @@ static protected Double sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n ",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AVG.java",
                "status": "modified",
                "changes": 7,
                "deletions": 2,
                "sha": "f14dce1086bb89b43cc07306b64899621d176c42",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AVG.java",
                "filename": "src/org/apache/pig/builtin/AVG.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AVG.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -18,8 +18,8 @@\n package org.apache.pig.builtin;\n \n import java.io.IOException;\n-import java.util.Iterator;\n import java.math.BigDecimal;\n+import java.util.Iterator;\n \n import org.apache.pig.Accumulator;\n import org.apache.pig.PigException;\n@@ -88,7 +88,7 @@ protected static BigDecimal doTupleWork(Tuple input, KnownOpProvider opProvider)\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         BigDecimal sofar = AlgebraicBigDecimalMathBase.getSeed(opProvider.getOp());",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicBigDecimalMathBase.java",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "e16221096d7e5f4d4e5060bcc0bbe22b57614c5e",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicBigDecimalMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicBigDecimalMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicBigDecimalMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -18,8 +18,8 @@\n package org.apache.pig.builtin;\n \n import java.io.IOException;\n-import java.util.Iterator;\n import java.math.BigInteger;\n+import java.util.Iterator;\n \n import org.apache.pig.Accumulator;\n import org.apache.pig.PigException;\n@@ -88,7 +88,7 @@ protected static BigInteger doTupleWork(Tuple input, KnownOpProvider opProvider)\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         BigInteger sofar = AlgebraicBigIntegerMathBase.getSeed(opProvider.getOp());",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicBigIntegerMathBase.java",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "7b9be4a6e3e87c1896c072cca5cbc06238e8e0e2",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicBigIntegerMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicBigIntegerMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicBigIntegerMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -67,7 +67,7 @@ protected static Double doTupleWork(Tuple input, KnownOpProvider opProvider, byt\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         double sofar = AlgebraicByteArrayMathBase.getSeed(opProvider.getOp());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicByteArrayMathBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "b6e694dba74d1c5cc8ccfd97b1b41a7b2fc33589",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicByteArrayMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicByteArrayMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicByteArrayMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -64,7 +64,7 @@ protected static Double doTupleWork(Tuple input, KnownOpProvider opProvider) thr\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         double sofar = AlgebraicDoubleMathBase.getSeed(opProvider.getOp());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicDoubleMathBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "b6dc77c6c18138de51b235d8c539f15052e00fb9",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicDoubleMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicDoubleMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicDoubleMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -64,7 +64,7 @@ protected static Float doTupleWork(Tuple input, KnownOpProvider opProvider) thro\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         Float sofar = AlgebraicFloatMathBase.getSeed(opProvider.getOp());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicFloatMathBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "7e360cc57b77760b29edaed93132e23e9fd1b121",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicFloatMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicFloatMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicFloatMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -64,7 +64,7 @@ protected static Integer doTupleWork(Tuple input, KnownOpProvider opProvider) th\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         int sofar = AlgebraicIntMathBase.getSeed(opProvider.getOp());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicIntMathBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "4b58f9d241e2d79eaa527aefe639863eb7718f3b",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicIntMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicIntMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicIntMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -64,7 +64,7 @@ protected static Long doTupleWork(Tuple input, KnownOpProvider opProvider) throw\n         DataBag values = (DataBag)input.get(0);\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n         Long sofar = AlgebraicLongMathBase.getSeed(opProvider.getOp());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicLongMathBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "38674b25345a0d3352653ad191839ad5561c036d",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/AlgebraicLongMathBase.java",
                "filename": "src/org/apache/pig/builtin/AlgebraicLongMathBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/AlgebraicLongMathBase.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -18,20 +18,20 @@\n package org.apache.pig.builtin;\n \n import java.io.IOException;\n-import java.util.Iterator;\n import java.math.BigDecimal;\n import java.math.MathContext;\n+import java.util.Iterator;\n \n import org.apache.pig.Accumulator;\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n@@ -61,14 +61,17 @@ public BigDecimal exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -199,7 +202,7 @@ static protected BigDecimal sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n ",
                "additions": 6,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/BigDecimalAvg.java",
                "status": "modified",
                "changes": 9,
                "deletions": 3,
                "sha": "f9452aef3105b49d9401966d62d4da301ec36590",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/BigDecimalAvg.java",
                "filename": "src/org/apache/pig/builtin/BigDecimalAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/BigDecimalAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -18,21 +18,21 @@\n package org.apache.pig.builtin;\n \n import java.io.IOException;\n-import java.util.Iterator;\n import java.math.BigDecimal;\n import java.math.BigInteger;\n import java.math.MathContext;\n+import java.util.Iterator;\n \n import org.apache.pig.Accumulator;\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n@@ -62,14 +62,17 @@ public BigDecimal exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -201,7 +204,7 @@ static protected BigInteger sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if (values.size() == 0) {\n+        if (values == null || values.size() == 0) {\n             return null;\n         }\n ",
                "additions": 6,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/BigIntegerAvg.java",
                "status": "modified",
                "changes": 9,
                "deletions": 3,
                "sha": "a388adb83dca6fecf92c343ade401952738209c9",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/BigIntegerAvg.java",
                "filename": "src/org/apache/pig/builtin/BigIntegerAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/BigIntegerAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -20,8 +20,6 @@\n import java.io.IOException;\n import java.util.Iterator;\n \n-import org.joda.time.DateTime;\n-\n import org.apache.pig.Accumulator;\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n@@ -32,6 +30,7 @@\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n+import org.joda.time.DateTime;\n \n /**\n  * This method should never be used directly, use {@link MAX}.\n@@ -47,14 +46,17 @@ public DateTime exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -120,7 +122,7 @@ static protected DateTime max(Tuple input) throws ExecException {\n \n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -153,7 +155,7 @@ static protected DateTime max(Tuple input) throws ExecException {\n \n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.DATETIME)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.DATETIME));\n     }\n \n ",
                "additions": 6,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DateTimeMax.java",
                "status": "modified",
                "changes": 10,
                "deletions": 4,
                "sha": "ce08bc4aab9abc097951304c7435f2068b22332c",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DateTimeMax.java",
                "filename": "src/org/apache/pig/builtin/DateTimeMax.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/DateTimeMax.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -20,8 +20,6 @@\n import java.io.IOException;\n import java.util.Iterator;\n \n-import org.joda.time.DateTime;\n-\n import org.apache.pig.Accumulator;\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n@@ -32,6 +30,7 @@\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n+import org.joda.time.DateTime;\n \n /**\n  * This method should never be used directly, use {@link MAX}.\n@@ -47,14 +46,17 @@ public DateTime exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -120,7 +122,7 @@ static protected DateTime min(Tuple input) throws ExecException {\n \n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n ",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DateTimeMin.java",
                "status": "modified",
                "changes": 8,
                "deletions": 3,
                "sha": "20739e1a8fd0b4783c357aee7240ddb14e722afa",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DateTimeMin.java",
                "filename": "src/org/apache/pig/builtin/DateTimeMin.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/DateTimeMin.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -18,28 +18,25 @@\n package org.apache.pig.builtin;\n \n import java.io.IOException;\n-import java.util.HashMap;\n import java.util.Iterator;\n \n import org.apache.pig.Accumulator;\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n-import org.apache.pig.FuncSpec;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n-import org.apache.pig.impl.logicalLayer.FrontendException;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n  * This method should never be used directly, use {@link AVG}.\n  */\n public class DoubleAvg extends EvalFunc<Double> implements Algebraic, Accumulator<Double> {\n-    \n+\n     private static TupleFactory mTupleFactory = TupleFactory.getInstance();\n \n     @Override\n@@ -56,21 +53,24 @@ public Double exec(Tuple input) throws IOException {\n             Double avg = null;\n             if (count > 0)\n                 avg = new Double(sum / count);\n-    \n+\n             return avg;\n         } catch (ExecException ee) {\n             throw ee;\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -91,7 +91,7 @@ public Tuple exec(Tuple input) throws IOException {\n                 t.set(0, d);\n                 if (d != null){\n                     t.set(1, 1L);\n-                }else{    \n+                } else {\n                     t.set(1, 0L);\n                 }\n                 return t;\n@@ -100,9 +100,9 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n-                \n+\n         }\n     }\n \n@@ -117,7 +117,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);            \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -145,7 +145,7 @@ public Double exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);            \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -166,7 +166,7 @@ static protected Tuple combine(DataBag values) throws ExecException {\n             Tuple t = it.next();\n             Double d = (Double)t.get(0);\n             // we count nulls in avg as contributing 0\n-            // a departure from SQL for performance of \n+            // a departure from SQL for performance of\n             // COUNT() which implemented by just inspecting\n             // size of the bag\n             if(d == null) {\n@@ -200,9 +200,9 @@ static protected long count(Tuple input) throws ExecException {\n \n     static protected Double sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n-        \n+\n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -228,17 +228,17 @@ static protected Double sum(Tuple input) throws ExecException, IOException {\n             return null;\n         }\n     }\n-    \n+\n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE));\n     }\n-    \n+\n     /* Accumulator interface */\n-    \n+\n     private Double intermediateSum = null;\n     private Double intermediateCount = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -251,7 +251,7 @@ public void accumulate(Tuple b) throws IOException {\n                 intermediateSum = 0.0;\n                 intermediateCount = 0.0;\n             }\n-            \n+\n             double count = (Long)count(b);\n \n             if (count > 0) {\n@@ -263,9 +263,9 @@ public void accumulate(Tuple b) throws IOException {\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n-    }        \n+    }\n \n     @Override\n     public void cleanup() {\n@@ -280,5 +280,5 @@ public Double getValue() {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;\n-    }    \n+    }\n }",
                "additions": 23,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DoubleAvg.java",
                "status": "modified",
                "changes": 46,
                "deletions": 23,
                "sha": "8ae937ca542c56955fae215f0ffb54693a2456b4",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/DoubleAvg.java",
                "filename": "src/org/apache/pig/builtin/DoubleAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/DoubleAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -24,19 +24,19 @@\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n  * This method should never be used directly, use {@link AVG}.\n  */\n public class FloatAvg extends EvalFunc<Double> implements Algebraic, Accumulator<Double> {\n-    \n+\n     private static TupleFactory mTupleFactory = TupleFactory.getInstance();\n \n     @Override\n@@ -53,21 +53,24 @@ public Double exec(Tuple input) throws IOException {\n             Double avg = null;\n             if (count > 0)\n                 avg = new Double(sum / count);\n-    \n+\n             return avg;\n         } catch (ExecException ee) {\n             throw ee;\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -96,9 +99,9 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n-                \n+\n         }\n     }\n \n@@ -113,7 +116,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -141,7 +144,7 @@ public Double exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -162,7 +165,7 @@ static protected Tuple combine(DataBag values) throws ExecException {\n             Tuple t = it.next();\n             Double d = (Double)t.get(0);\n             // we count nulls in avg as contributing 0\n-            // a departure from SQL for performance of \n+            // a departure from SQL for performance of\n             // COUNT() which implemented by just inspecting\n             // size of the bag\n             if(d == null) {\n@@ -199,7 +202,7 @@ static protected Double sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -225,17 +228,17 @@ static protected Double sum(Tuple input) throws ExecException, IOException {\n             return null;\n         }\n     }\n-    \n+\n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE));\n     }\n-    \n+\n     /* Accumulator interface */\n \n     private Double intermediateSum = null;\n     private Double intermediateCount = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -248,9 +251,9 @@ public void accumulate(Tuple b) throws IOException {\n                 intermediateSum = 0.0;\n                 intermediateCount = 0.0;\n             }\n-            \n+\n             double count = (Long)count(b);\n-            \n+\n             if (count > 0) {\n                 intermediateCount += count;\n                 intermediateSum += sum;\n@@ -260,9 +263,9 @@ public void accumulate(Tuple b) throws IOException {\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n-    }        \n+    }\n \n     @Override\n     public void cleanup() {\n@@ -277,6 +280,6 @@ public Double getValue() {\n             avg = new Double(intermediateSum / intermediateCount);\n         }\n         return avg;\n-    }    \n+    }\n \n }",
                "additions": 21,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/FloatAvg.java",
                "status": "modified",
                "changes": 39,
                "deletions": 18,
                "sha": "ddf0b127798ff9090f10ff3fdc59997a085d916d",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/FloatAvg.java",
                "filename": "src/org/apache/pig/builtin/FloatAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/FloatAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -24,19 +24,19 @@\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n  * This method should never be used directly, use {@link AVG}.\n  */\n public class IntAvg extends EvalFunc<Double> implements Algebraic, Accumulator<Double> {\n-    \n+\n     private static TupleFactory mTupleFactory = TupleFactory.getInstance();\n \n     @Override\n@@ -53,29 +53,32 @@ public Double exec(Tuple input) throws IOException {\n             Double avg = null;\n             if (count > 0)\n                 avg = new Double(sum / count);\n-    \n+\n             return avg;\n         } catch (ExecException ee) {\n             throw ee;\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n \n     static public class Initial extends EvalFunc<Tuple> {\n         @Override\n         public Tuple exec(Tuple input) throws IOException {\n-            \n+\n             try {\n                 Tuple t = mTupleFactory.newTuple(2);\n                 // input is a bag with one tuple containing\n@@ -97,9 +100,9 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n-                \n+\n         }\n     }\n \n@@ -114,7 +117,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -142,7 +145,7 @@ public Double exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -163,7 +166,7 @@ static protected Tuple combine(DataBag values) throws ExecException {\n             Tuple t = it.next();\n             Long l = (Long)t.get(0);\n             // we count nulls in avg as contributing 0\n-            // a departure from SQL for performance of \n+            // a departure from SQL for performance of\n             // COUNT() which implemented by just inspecting\n             // size of the bag\n             if(l == null) {\n@@ -200,7 +203,7 @@ static protected Long sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -211,7 +214,7 @@ static protected Long sum(Tuple input) throws ExecException, IOException {\n             try {\n                 Integer i = (Integer)(t.get(0));\n                 // we count nulls in avg as contributing 0\n-                // a departure from SQL for performance of \n+                // a departure from SQL for performance of\n                 // COUNT() which implemented by just inspecting\n                 // size of the bag\n                 if (i == null) continue;\n@@ -230,17 +233,17 @@ static protected Long sum(Tuple input) throws ExecException, IOException {\n             return null;\n         }\n     }\n-    \n+\n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE));\n     }\n \n     /* Accumulator interface */\n \n     private Long intermediateSum = null;\n     private Double intermediateCount = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -253,7 +256,7 @@ public void accumulate(Tuple b) throws IOException {\n                 intermediateSum = 0L;\n                 intermediateCount = 0.0;\n             }\n-            \n+\n             double count = (Long)count(b);\n \n             if (count > 0) {\n@@ -265,9 +268,9 @@ public void accumulate(Tuple b) throws IOException {\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n-    }        \n+    }\n \n     @Override\n     public void cleanup() {",
                "additions": 20,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/IntAvg.java",
                "status": "modified",
                "changes": 37,
                "deletions": 17,
                "sha": "7e224c6e33a484f01958cc982192d1276443387e",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/IntAvg.java",
                "filename": "src/org/apache/pig/builtin/IntAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/IntAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -24,19 +24,19 @@\n import org.apache.pig.Algebraic;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigException;\n+import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n import org.apache.pig.data.TupleFactory;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n-import org.apache.pig.backend.executionengine.ExecException;\n \n \n /**\n  * This method should never be used directly, use {@link AVG}.\n  */\n public class LongAvg extends EvalFunc<Double> implements Algebraic, Accumulator<Double> {\n-    \n+\n     private static TupleFactory mTupleFactory = TupleFactory.getInstance();\n \n     @Override\n@@ -53,21 +53,24 @@ public Double exec(Tuple input) throws IOException {\n             Double avg = null;\n             if (count > 0)\n                 avg = new Double(sum / count);\n-    \n+\n             return avg;\n         } catch (ExecException ee) {\n             throw ee;\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -96,9 +99,9 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n-                \n+\n         }\n     }\n \n@@ -113,7 +116,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -141,7 +144,7 @@ public Double exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -162,7 +165,7 @@ static protected Tuple combine(DataBag values) throws ExecException {\n             Tuple t = it.next();\n             Long l = (Long)t.get(0);\n             // we count nulls in avg as contributing 0\n-            // a departure from SQL for performance of \n+            // a departure from SQL for performance of\n             // COUNT() which implemented by just inspecting\n             // size of the bag\n             if(l == null) {\n@@ -199,7 +202,7 @@ static protected Long sum(Tuple input) throws ExecException, IOException {\n         DataBag values = (DataBag)input.get(0);\n \n         // if we were handed an empty bag, return NULL\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -225,17 +228,17 @@ static protected Long sum(Tuple input) throws ExecException, IOException {\n             return null;\n         }\n     }\n-    \n+\n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.DOUBLE));\n     }\n-    \n+\n     /* Accumulator interface */\n-   \n+\n     private Long intermediateSum = null;\n     private Double intermediateCount = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -248,7 +251,7 @@ public void accumulate(Tuple b) throws IOException {\n                 intermediateSum = 0L;\n                 intermediateCount = 0.0;\n             }\n-            \n+\n             double count = (Long)count(b);\n \n             if (count > 0) {\n@@ -260,9 +263,9 @@ public void accumulate(Tuple b) throws IOException {\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing average in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n-    }        \n+    }\n \n     @Override\n     public void cleanup() {",
                "additions": 20,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/LongAvg.java",
                "status": "modified",
                "changes": 37,
                "deletions": 17,
                "sha": "de16c957492d13399953e2f4714602b152c4133b",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/LongAvg.java",
                "filename": "src/org/apache/pig/builtin/LongAvg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/LongAvg.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -45,14 +45,17 @@ public String exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -77,7 +80,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing max in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -94,7 +97,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing max in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -108,17 +111,17 @@ public String exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing max in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n \n     static protected String max(Tuple input) throws ExecException {\n         DataBag values = (DataBag)input.get(0);\n-        \n+\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -129,7 +132,7 @@ static protected String max(Tuple input) throws ExecException {\n             Tuple t = it.next();\n             curMax = (String)(t.get(0));\n         }\n-        \n+\n         for (; it.hasNext();) {\n             Tuple t = it.next();\n             try {\n@@ -138,26 +141,26 @@ static protected String max(Tuple input) throws ExecException {\n                 if( s.compareTo(curMax) > 0) {\n                     curMax = s;\n                 }\n-                \n+\n             } catch (RuntimeException exp) {\n                 int errCode = 2103;\n                 String msg = \"Problem while computing max of strings.\";\n                 throw new ExecException(msg, errCode, PigException.BUG, exp);\n             }\n         }\n-    \n+\n         return curMax;\n     }\n \n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.CHARARRAY)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.CHARARRAY));\n     }\n \n \n     /* accumulator interface */\n     private String intermediateMax = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -168,14 +171,14 @@ public void accumulate(Tuple b) throws IOException {\n             // check if it lexicographically follows curMax\n             if (intermediateMax == null || intermediateMax.compareTo(curMax) < 0) {\n                 intermediateMax = curMax;\n-            }            \n+            }\n \n         } catch (ExecException ee) {\n             throw ee;\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing max in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n     }\n ",
                "additions": 15,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/StringMax.java",
                "status": "modified",
                "changes": 27,
                "deletions": 12,
                "sha": "788bc779e53172b4954d062af9a7bbfc40beba1a",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/StringMax.java",
                "filename": "src/org/apache/pig/builtin/StringMax.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/StringMax.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -46,14 +46,17 @@ public String exec(Tuple input) throws IOException {\n         }\n     }\n \n+    @Override\n     public String getInitial() {\n         return Initial.class.getName();\n     }\n \n+    @Override\n     public String getIntermed() {\n         return Intermediate.class.getName();\n     }\n \n+    @Override\n     public String getFinal() {\n         return Final.class.getName();\n     }\n@@ -78,7 +81,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing min in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -95,7 +98,7 @@ public Tuple exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing min in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n@@ -109,17 +112,17 @@ public String exec(Tuple input) throws IOException {\n             } catch (Exception e) {\n                 int errCode = 2106;\n                 String msg = \"Error while computing min in \" + this.getClass().getSimpleName();\n-                throw new ExecException(msg, errCode, PigException.BUG, e);           \n+                throw new ExecException(msg, errCode, PigException.BUG, e);\n             }\n         }\n     }\n \n     static protected String min(Tuple input) throws ExecException {\n         DataBag values = (DataBag)input.get(0);\n-        \n+\n         // if we were handed an empty bag, return NULL\n         // this is in compliance with SQL standard\n-        if(values.size() == 0) {\n+        if(values == null || values.size() == 0) {\n             return null;\n         }\n \n@@ -130,7 +133,7 @@ static protected String min(Tuple input) throws ExecException {\n             Tuple t = it.next();\n             curMin = (String)(t.get(0));\n         }\n-        \n+\n         for (; it.hasNext();) {\n             Tuple t = it.next();\n             try {\n@@ -139,25 +142,25 @@ static protected String min(Tuple input) throws ExecException {\n                 if( s.compareTo(curMin) < 0) {\n                     curMin = s;\n                 }\n-                \n+\n             } catch (RuntimeException exp) {\n                 int errCode = 2103;\n                 String msg = \"Problem while computing min of strings.\";\n                 throw new ExecException(msg, errCode, PigException.BUG, exp);\n             }\n         }\n-    \n+\n         return curMin;\n     }\n \n     @Override\n     public Schema outputSchema(Schema input) {\n-        return new Schema(new Schema.FieldSchema(null, DataType.CHARARRAY)); \n+        return new Schema(new Schema.FieldSchema(null, DataType.CHARARRAY));\n     }\n-    \n+\n     /* accumulator interface */\n     private String intermediateMin = null;\n-    \n+\n     @Override\n     public void accumulate(Tuple b) throws IOException {\n         try {\n@@ -168,14 +171,14 @@ public void accumulate(Tuple b) throws IOException {\n             // check if it lexicographically follows curMax\n             if (intermediateMin == null || intermediateMin.compareTo(curMin) > 0) {\n                 intermediateMin = curMin;\n-            }            \n+            }\n \n         } catch (ExecException ee) {\n             throw ee;\n         } catch (Exception e) {\n             int errCode = 2106;\n             String msg = \"Error while computing max in \" + this.getClass().getSimpleName();\n-            throw new ExecException(msg, errCode, PigException.BUG, e);           \n+            throw new ExecException(msg, errCode, PigException.BUG, e);\n         }\n     }\n ",
                "additions": 16,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/StringMin.java",
                "status": "modified",
                "changes": 29,
                "deletions": 13,
                "sha": "f71c2eb4494ec42eb6f832e62e51a7b62b9b4356",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/src/org/apache/pig/builtin/StringMin.java",
                "filename": "src/org/apache/pig/builtin/StringMin.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/StringMin.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            },
            {
                "patch": "@@ -143,6 +143,8 @@\n     private TupleFactory tupleFactory = TupleFactory.getInstance();\n     private BagFactory bagFactory = DefaultBagFactory.getInstance();\n \n+    private static Tuple NULL_INPUT_TUPLE;\n+\n     // some inputs\n     private static Integer[] intInput = { 3, 1, 2, 4, 5, 7, null, 6, 8, 9, 10 };\n     private static Long[] intAsLong = { 3L, 1L, 2L, 4L, 5L, 7L, null, 6L, 8L, 9L, 10L };\n@@ -222,6 +224,9 @@ public void setUp() throws Exception {\n         // first set up EvalFuncMap and expectedMap\n         setupEvalFuncMap();\n \n+        NULL_INPUT_TUPLE = TupleFactory.getInstance().newTuple(1);\n+        NULL_INPUT_TUPLE.set(0, null);\n+\n         expectedMap.put(\"SUM\", new Double(55));\n         expectedMap.put(\"DoubleSum\", new Double(170.567391834593));\n         expectedMap.put(\"IntSum\", new Long(55));\n@@ -955,6 +960,9 @@ public void testAVG() throws Exception {\n             } else {\n                 assertEquals(msg, (Double)output, (Double)getExpected(avgTypes[k]), 0.00001);\n             }\n+\n+            // Check null input\n+            assertNull(avg.exec(NULL_INPUT_TUPLE));\n         }\n     }\n \n@@ -1423,6 +1431,9 @@ else if (inputType == \"BigInteger\")\n             else {\n                 assertEquals(msg, (Double)output, (Double)getExpected(sumTypes[k]), 0.00001);\n             }\n+\n+            // Check null input\n+            assertNull(sum.exec(NULL_INPUT_TUPLE));\n         }\n     }\n \n@@ -1488,6 +1499,9 @@ public void testMIN() throws Exception {\n             String msg = \"[Testing \" + minTypes[k] + \" on input type: \" + getInputType(minTypes[k]) + \" ( (output) \" +\n                            output + \" == \" + getExpected(minTypes[k]) + \" (expected) )]\";\n             assertForInputType(inputType, msg, getExpected(minTypes[k]), output);\n+\n+            // Check null input\n+            assertNull(min.exec(NULL_INPUT_TUPLE));\n         }\n     }\n \n@@ -1554,6 +1568,9 @@ public void testMAX() throws Exception {\n             String msg = \"[Testing \" + maxTypes[k] + \" on input type: \" + getInputType(maxTypes[k]) + \" ( (output) \" +\n                            output + \" == \" + getExpected(maxTypes[k]) + \" (expected) )]\";\n             assertForInputType(inputType, msg, getExpected(maxTypes[k]), output);\n+\n+            // Check null input\n+            assertNull(max.exec(NULL_INPUT_TUPLE));\n         }\n     }\n \n@@ -3223,6 +3240,6 @@ public void testToMapSchema() throws Exception {\n         pigServer.registerQuery(\"B = foreach A generate TOMAP(a);\");\n         s = pigServer.dumpSchema(\"B\");\n         Assert.assertEquals(s.toString(), \"{map[]}\");\n-        \n+\n     }\n }",
                "additions": 18,
                "raw_url": "https://github.com/apache/pig/raw/18c844e6e3254586d4b5ba9840c054c66c513adc/test/org/apache/pig/test/TestBuiltin.java",
                "status": "modified",
                "changes": 19,
                "deletions": 1,
                "sha": "50afa26f2d32be15fad3b50203190c4dfc955074",
                "blob_url": "https://github.com/apache/pig/blob/18c844e6e3254586d4b5ba9840c054c66c513adc/test/org/apache/pig/test/TestBuiltin.java",
                "filename": "test/org/apache/pig/test/TestBuiltin.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestBuiltin.java?ref=18c844e6e3254586d4b5ba9840c054c66c513adc"
            }
        ],
        "bug_id": "pig_30",
        "parent": "https://github.com/apache/pig/commit/5fe78aa2504d9dc1267895976a5a6cb6a5d84940",
        "message": "PIG-4774: Fix NPE in SUM,AVG,MIN,MAX UDFs for null bag input (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1723972 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/a249156f72465e3320fde609a4958af886d68029",
        "file": [
            {
                "patch": "@@ -64,6 +64,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3657: New partition filter extractor fails with NPE (cheolsoo)\n+\n PIG-3617: problem with temp file deletion in MAPREDUCE operator (nezihyigitbasi via cheolsoo)\n \n PIG-3649: POPartialAgg incorrectly calculates size reduction when multiple values aggregated (tmwoodruff via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/a249156f72465e3320fde609a4958af886d68029/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "8a1a55416db28006123ac83491dc8c25d8883064",
                "blob_url": "https://github.com/apache/pig/blob/a249156f72465e3320fde609a4958af886d68029/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=a249156f72465e3320fde609a4958af886d68029"
            },
            {
                "patch": "@@ -180,23 +180,35 @@ private LogicalExpression addToFilterPlan(LogicalExpression op) throws FrontendE\n     }\n \n     private LogicalExpression andLogicalExpressions(\n-            LogicalExpressionPlan plan, LogicalExpression a, LogicalExpression b) {\n+            LogicalExpressionPlan plan, LogicalExpression a, LogicalExpression b) throws FrontendException {\n         if (a == null) {\n             return b;\n         }\n         if (b == null) {\n             return a;\n         }\n+        if (!plan.ops.contains(a)) {\n+            a = a.deepCopy(plan);\n+        }\n+        if (!plan.ops.contains(b)) {\n+            b = b.deepCopy(plan);\n+        }\n         LogicalExpression andOp = new AndExpression(plan, a, b);\n         return andOp;\n     }\n \n     private LogicalExpression orLogicalExpressions(\n-            LogicalExpressionPlan plan, LogicalExpression a, LogicalExpression b) {\n+            LogicalExpressionPlan plan, LogicalExpression a, LogicalExpression b) throws FrontendException {\n         // Or 2 operators if they are not null\n         if (a == null || b == null) {\n             return null;\n         }\n+        if (!plan.ops.contains(a)) {\n+            a = a.deepCopy(plan);\n+        }\n+        if (!plan.ops.contains(b)) {\n+            b = b.deepCopy(plan);\n+        }\n         LogicalExpression orOp = new OrExpression(plan, a, b);\n         return orOp;\n     }\n@@ -234,7 +246,7 @@ private KeyState checkPushDown(BinaryExpression binExpr) throws FrontendExceptio\n             //              AND (leftState.filterExpr OR rightState.pushdownExpr)\n             //              AND (leftState.filterExpr OR rightState.filterExpr)\n             state.pushdownExpr = orLogicalExpressions(pushdownExprPlan, leftState.pushdownExpr, rightState.pushdownExpr);\n-            if(state.pushdownExpr == null) {\n+            if (state.pushdownExpr == null) {\n                 // Whatever we did so far on the right tree is all wasted :(\n                 // Undo all the mutation (AND OR distributions) until now\n                 removeFromFilteredPlan(leftState.filterExpr);",
                "additions": 15,
                "raw_url": "https://github.com/apache/pig/raw/a249156f72465e3320fde609a4958af886d68029/src/org/apache/pig/newplan/FilterExtractor.java",
                "status": "modified",
                "changes": 18,
                "deletions": 3,
                "sha": "2a327d37af69e195757e3599e934f6afc6bc5aee",
                "blob_url": "https://github.com/apache/pig/blob/a249156f72465e3320fde609a4958af886d68029/src/org/apache/pig/newplan/FilterExtractor.java",
                "filename": "src/org/apache/pig/newplan/FilterExtractor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/FilterExtractor.java?ref=a249156f72465e3320fde609a4958af886d68029"
            },
            {
                "patch": "@@ -61,6 +61,7 @@\n import org.apache.pig.newplan.logical.expression.ProjectExpression;\n import org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer;\n import org.apache.pig.newplan.logical.relational.LOFilter;\n+import org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor;\n import org.apache.pig.newplan.logical.relational.LogicalPlan;\n import org.apache.pig.newplan.logical.rules.LoadTypeCastInserter;\n import org.apache.pig.newplan.logical.rules.PartitionFilterOptimizer;\n@@ -466,6 +467,10 @@ private void testFull(String q, String partFilter, String filterExpr, boolean un\n                         (it.next() instanceof LOFilter));\n             }\n         }\n+\n+        // Test that the filtered plan can be translated to physical plan (PIG-3657)\n+        LogToPhyTranslationVisitor translator = new LogToPhyTranslationVisitor(newLogicalPlan);\n+        translator.visit();\n     }\n \n     /**\n@@ -671,6 +676,16 @@ public void testOrWithNonPartitionCondition() throws Exception {\n         negativeTest(q, Arrays.asList(\"srcid\", \"mrkt\", \"dstid\"));\n     }\n \n+    // PIG-3657\n+    @Test\n+    public void testFilteredPlanWithLogToPhyTranslator() throws Exception {\n+        String q = \"a = load 'foo' using \" + TestLoader.class.getName() +\n+                \"('srcid:int, mrkt:chararray', 'srcid') as (f1, f2);\" +\n+                \"b = filter a by (f1 < 5 or (f1 == 10 and f2 == 'UK'));\" +\n+                \"store b into 'out';\";\n+        testFull(q, \"((srcid < 5) or (srcid == 10))\", \"((f1 < 5) or (f2 == 'UK'))\", false);\n+    }\n+\n     //// helper methods ///////\n     private FilterExtractor test(String query, List<String> partitionCols,\n             String expPartFilterString, String expFilterString)",
                "additions": 15,
                "raw_url": "https://github.com/apache/pig/raw/a249156f72465e3320fde609a4958af886d68029/test/org/apache/pig/test/TestNewPartitionFilterPushDown.java",
                "status": "modified",
                "changes": 15,
                "deletions": 0,
                "sha": "703d86f738dd882605cb4ab1bc85cd55d34625d0",
                "blob_url": "https://github.com/apache/pig/blob/a249156f72465e3320fde609a4958af886d68029/test/org/apache/pig/test/TestNewPartitionFilterPushDown.java",
                "filename": "test/org/apache/pig/test/TestNewPartitionFilterPushDown.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestNewPartitionFilterPushDown.java?ref=a249156f72465e3320fde609a4958af886d68029"
            }
        ],
        "bug_id": "pig_31",
        "parent": "https://github.com/apache/pig/commit/750ec4a3d456a58c732114fb809499338e715eaf",
        "message": "PIG-3657: New partition filter extractor fails with NPE (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1556906 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13",
        "file": [
            {
                "patch": "@@ -176,6 +176,8 @@ PIG-3013: BinInterSedes improve chararray sort performance (rohini)\n \n BUG FIXES\n \n+PIG:3302: JSONStorage throws NPE if map has null values (rohini)\n+\n PIG-3309: TestJsonLoaderStorage fails with IBM JDK 6/7 (lrangel via daijy)\n \n PIG-3097: HiveColumnarLoader doesn't correctly load partitioned Hive table (maczech via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "ccaf586525b8bf2dc6c46d11cd8f356e571b8ddd",
                "blob_url": "https://github.com/apache/pig/blob/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13"
            },
            {
                "patch": "@@ -225,7 +225,7 @@ private Object readField(JsonParser p,\n             Map<String, String> m = new HashMap<String, String>();\n             while (p.nextToken() != JsonToken.END_OBJECT) {\n                 String k = p.getCurrentName();\n-                String v = p.getText();\n+                String v = p.getCurrentToken() == JsonToken.VALUE_NULL ? null : p.getText();\n                 m.put(k, v);\n             }\n             return m;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/src/org/apache/pig/builtin/JsonLoader.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "fe67767cf8242dde9b13cc7065979c74265968e0",
                "blob_url": "https://github.com/apache/pig/blob/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/src/org/apache/pig/builtin/JsonLoader.java",
                "filename": "src/org/apache/pig/builtin/JsonLoader.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/JsonLoader.java?ref=0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13"
            },
            {
                "patch": "@@ -199,7 +199,7 @@ private void writeField(JsonGenerator json,\n             json.writeFieldName(field.getName());\n             json.writeStartObject();\n             for (Map.Entry<String, Object> e : ((Map<String, Object>)d).entrySet()) {\n-                json.writeStringField(e.getKey(), e.getValue().toString());\n+                json.writeStringField(e.getKey(), e.getValue() == null ? null : e.getValue().toString());\n             }\n             json.writeEndObject();\n             return;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/src/org/apache/pig/builtin/JsonStorage.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "d1f3d2dc08aebbb96139d594366627da84f063cc",
                "blob_url": "https://github.com/apache/pig/blob/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/src/org/apache/pig/builtin/JsonStorage.java",
                "filename": "src/org/apache/pig/builtin/JsonStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/JsonStorage.java?ref=0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13"
            },
            {
                "patch": "@@ -1,2 +1,2 @@\n {\"a0\":1,\"a1\":[{\"a10\":1,\"a11\":\"tom\"},{\"a10\":2,\"a11\":\"jerry\"}],\"a2\":{\"a20\":1.01,\"a21\":\"sun\"},\"a3\":{\"key3\":\"c\",\"key2\":\"b\",\"key1\":\"a\"}}\n-{\"a0\":2,\"a1\":[{\"a10\":6,\"a11\":\"cat\"},{\"a10\":7,\"a11\":\"dog\"},{\"a10\":8,\"a11\":\"pig\"}],\"a2\":{\"a20\":2.3,\"a21\":\"moon\"},\"a3\":{\"key4\":\"value4\",\"key1\":\"value1\"}}\n+{\"a0\":2,\"a1\":[{\"a10\":6,\"a11\":\"cat\"},{\"a10\":7,\"a11\":\"dog\"},{\"a10\":8,\"a11\":\"pig\"}],\"a2\":{\"a20\":2.3,\"a21\":\"moon\"},\"a3\":{\"key4\":\"value4\",\"key1\":\"value1\",\"key2\":null}}",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/test/org/apache/pig/test/data/jsonStorage1.result",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "587fead95cc5323cdd64e4473390f62d06bf09b6",
                "blob_url": "https://github.com/apache/pig/blob/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/test/org/apache/pig/test/data/jsonStorage1.result",
                "filename": "test/org/apache/pig/test/data/jsonStorage1.result",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/jsonStorage1.result?ref=0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13"
            },
            {
                "patch": "@@ -1,2 +1,2 @@\n 1\t{(1,tom),(2,jerry)}\t(1.01,sun)\t[key3#c,key2#b,key1#a]\n-2\t{(6,cat),(7,dog),(8,pig)}\t(2.3,moon)\t[key4#value4,key1#value1]\n+2\t{(6,cat),(7,dog),(8,pig)}\t(2.3,moon)\t[key4#value4,key1#value1,key2#]",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/test/org/apache/pig/test/data/jsonStorage1.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "1df3eb88d3c6b227eb75914c866019b612047d6c",
                "blob_url": "https://github.com/apache/pig/blob/0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13/test/org/apache/pig/test/data/jsonStorage1.txt",
                "filename": "test/org/apache/pig/test/data/jsonStorage1.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/jsonStorage1.txt?ref=0cf5c7aa85471942cbc7e1d94a5108bdd4a28f13"
            }
        ],
        "bug_id": "pig_32",
        "parent": "https://github.com/apache/pig/commit/95830c900eacd18919bd4e47e561f0f52ff335ee",
        "message": "PIG:3302: JSONStorage throws NPE if map has null values (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1482145 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/e6326d2618b61075ba62c78049b005705ec894f2",
        "file": [
            {
                "patch": "@@ -1,3 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n package org.apache.pig.test.utils;\n \n import java.io.IOException;",
                "additions": 17,
                "raw_url": "https://github.com/apache/pig/raw/e6326d2618b61075ba62c78049b005705ec894f2/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "status": "modified",
                "changes": 17,
                "deletions": 0,
                "sha": "4d8151f7bc2fdca14ca543707eea4965cc267e9c",
                "blob_url": "https://github.com/apache/pig/blob/e6326d2618b61075ba62c78049b005705ec894f2/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "filename": "test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java?ref=e6326d2618b61075ba62c78049b005705ec894f2"
            }
        ],
        "bug_id": "pig_33",
        "parent": "https://github.com/apache/pig/commit/5c43bd4b687bba27d2abca79e2fc08a973626f39",
        "message": "PIG-3132: NPE when illustrating a relation with HCatLoader\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1460784 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/f878f90c267ec45ef1091d98b7d92e77020d5ea4",
        "file": [
            {
                "patch": "@@ -249,6 +249,8 @@ OPTIMIZATIONS\n \n BUG FIXES\n \n+PIG-3132: NPE when illustrating a relation with HCatLoader (daijy)\n+\n PIG-3194: Changes to ObjectSerializer.java break compatibility with Hadoop 0.20.2 (prkommireddi via dvryaboy)\n \n PIG-3241: ConcurrentModificationException in POPartialAgg (dvryaboy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "3cfdf3bf19430b05c51a10a420746257790707dc",
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4"
            },
            {
                "patch": "@@ -93,7 +93,7 @@ public void setUp() throws IOException{\n         loader = new ReadToEndLoader((LoadFunc)\n                 PigContext.instantiateFuncFromSpec(lFile.getFuncSpec()), \n                 ConfigurationUtil.toConfiguration(pc.getProperties()), \n-                lFile.getFileName(),0);\n+                lFile.getFileName(),0, signature);\n     }\n     \n     /**",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "55bd896245c8e3c42b8c25d2d8d78e12f853ea58",
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4"
            },
            {
                "patch": "@@ -106,6 +106,8 @@\n     private InputFormat inputFormat = null;\n     \n     private PigContext pigContext;\n+    \n+    private String udfContextSignature = null;\n \n     /**\n      * @param wrappedLoadFunc\n@@ -133,6 +135,16 @@ public ReadToEndLoader(LoadFunc wrappedLoadFunc, Configuration conf,\n         this.pigContext = pigContext;\n         init();\n     }\n+    \n+    public ReadToEndLoader(LoadFunc wrappedLoadFunc, Configuration conf,\n+            String inputLocation, int splitIndex, String signature) throws IOException {\n+        this.udfContextSignature = signature;\n+        this.wrappedLoadFunc = wrappedLoadFunc;\n+        this.inputLocation = inputLocation;\n+        this.conf = conf;\n+        this.curSplitIndex = splitIndex;\n+        init();\n+    }\n \n     /**\n      * This constructor takes an array of split indexes (toReadSplitIdxs) of the \n@@ -167,6 +179,7 @@ private void init() throws IOException {\n \n         // let's initialize the wrappedLoadFunc \n         Job job = new Job(conf);\n+        wrappedLoadFunc.setUDFContextSignature(this.udfContextSignature);\n         wrappedLoadFunc.setLocation(inputLocation, \n                 job);\n         // The above setLocation call could write to the conf within\n@@ -277,7 +290,7 @@ public void prepareToRead(RecordReader reader, PigSplit split) {\n \n     @Override\n     public void setLocation(String location, Job job) throws IOException {\n-        //no-op\n+        wrappedLoadFunc.setLocation(location, job);\n     }\n \n     @Override\n@@ -313,4 +326,9 @@ public void setPartitionFilter(Expression partitionFilter) throws IOException {\n              ((LoadMetadata) wrappedLoadFunc).setPartitionFilter(partitionFilter);\n         }\n     }\n+    \n+    @Override\n+    public void setUDFContextSignature(String signature) {\n+        this.udfContextSignature = signature;\n+    }\n }",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "status": "modified",
                "changes": 20,
                "deletions": 1,
                "sha": "8435a3590e79f51b2e6043fe08bf8e22251a4edf",
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "filename": "src/org/apache/pig/impl/io/ReadToEndLoader.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/io/ReadToEndLoader.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4"
            },
            {
                "patch": "@@ -105,6 +105,7 @@ public void launchPig(PhysicalPlan php, Map<LOLoad, DataBag> baseData,\n         // jc is null only when mrp.size == 0\n         boolean needFileInput;\n         final ArrayList<OperatorKey> emptyInpTargets = new ArrayList<OperatorKey>();\n+        pc.getProperties().setProperty(\"pig.illustrating\", \"true\");\n         while(mrp.size() != 0) {\n             jc = jcc.compile(mrp, \"Illustrator\");\n             if(jc == null) {",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "416c78fd0a3fbb0d5b9d5ec9e5b60ca282557639",
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "filename": "src/org/apache/pig/pen/LocalMapReduceSimulator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/pen/LocalMapReduceSimulator.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4"
            },
            {
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.pig.data.DataBag;\n import org.apache.pig.impl.PigContext;\n import org.apache.pig.newplan.Operator;\n+import org.apache.pig.test.utils.UDFContextTestLoaderWithSignature;\n import org.junit.BeforeClass;\n import org.junit.Test;\n \n@@ -394,5 +395,14 @@ public void testFilterGroupCountStore() throws Exception {\n     \n         assertNotNull(derivedData);\n     }\n+    \n+    @Test\n+    public void testLoaderWithContext() throws Exception {\n+        PigServer pigServer = new PigServer(pigContext);\n+        pigServer.registerQuery(\"A = load \" + A.toString() + \" using \" + UDFContextTestLoaderWithSignature.class.getName() + \"('a') as (x, y);\");\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"A\");\n+        \n+        assertNotNull(derivedData);\n+    }\n \n }",
                "additions": 10,
                "raw_url": "https://github.com/apache/pig/raw/f878f90c267ec45ef1091d98b7d92e77020d5ea4/test/org/apache/pig/test/TestExampleGenerator.java",
                "status": "modified",
                "changes": 10,
                "deletions": 0,
                "sha": "f9b5203c4329b963f500136cb9e2e76bdd607f43",
                "blob_url": "https://github.com/apache/pig/blob/f878f90c267ec45ef1091d98b7d92e77020d5ea4/test/org/apache/pig/test/TestExampleGenerator.java",
                "filename": "test/org/apache/pig/test/TestExampleGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestExampleGenerator.java?ref=f878f90c267ec45ef1091d98b7d92e77020d5ea4"
            }
        ],
        "bug_id": "pig_34",
        "parent": "https://github.com/apache/pig/commit/e59573212a5c450ace0e8de8077bfef6f148fbff",
        "message": "PIG-3132: NPE when illustrating a relation with HCatLoader\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1457884 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/9bdf3e10dcd1d78c32911488df61c7a200532824",
        "file": [
            {
                "patch": "@@ -57,6 +57,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4712: [Pig on Tez] NPE in Bloom UDF after Union (rohini)\n+\n PIG-4707: [Pig on Tez] Streaming job hangs with pig.exec.mapPartAgg=true (rohini)\n \n PIG-4703: TezOperator.stores shall not ship to backend (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "1227b5d828077b56466c32c5b94709e99baceb2a",
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=9bdf3e10dcd1d78c32911488df61c7a200532824"
            },
            {
                "patch": "@@ -566,6 +566,8 @@ public POUserFunc clone() throws CloneNotSupportedException {\n             requestedParallelism, null, funcSpec.clone());\n         clone.setResultType(resultType);\n         clone.signature = signature;\n+        clone.cacheFiles = cacheFiles;\n+        clone.shipFiles = shipFiles;\n         return clone;\n     }\n ",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "818bb4c01fee40bd4a05dfa1387ed1f6c4b643f1",
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java?ref=9bdf3e10dcd1d78c32911488df61c7a200532824"
            },
            {
                "patch": "@@ -5148,6 +5148,30 @@ store C into ':OUTPATH:';\\,\n                                 C = load ':INPATH:/singlefile/votertab10k'as (name:chararray, age:int, reg:chararray, contrib:float);\n                                 D = join C by name, B by name;\n                                 store D into ':OUTPATH:';\",\n+                    },{\n+                        'num' => 4,\n+                        'pig' => \"set pig.optimizer.rules.disabled PushUpFilter;\n+                                define bb BuildBloom('Hash.JENKINS_HASH', 'fixed', '128', '3');\n+                                A = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                B = filter A by name == 'alice allen';\n+                                C = group B all;\n+                                D = foreach C generate bb(B.name);\n+                                store D into ':HDFSTMP:/mybloom_4';\n+                                exec;\n+                                define bloom Bloom(':HDFSTMP:/mybloom_4');\n+                                E = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                F = LOAD ':INPATH:/singlefile/studenttab10k' AS (name:chararray, age:int, gpa:double);\n+                                G = union E, F;\n+                                -- PushUpFilter is disabled to avoid filter being pushed before union\n+                                H = filter G by bloom(name);\n+                                store H into ':OUTPATH:';\",\n+                        'notmq' => 1,\n+                        'verify_pig_script' => \"\n+                                A = LOAD ':INPATH:/singlefile/studenttab10k' AS (name, age:int ,gpa:double);\n+                                B = LOAD ':INPATH:/singlefile/studenttab10k' AS (name, age:int ,gpa:double);\n+                                C = UNION A,B;\n+                                D = filter C by name == 'alice allen';\n+                                store D into ':OUTPATH:';\",\n                     }\n                 ],\n             },{",
                "additions": 24,
                "raw_url": "https://github.com/apache/pig/raw/9bdf3e10dcd1d78c32911488df61c7a200532824/test/e2e/pig/tests/nightly.conf",
                "status": "modified",
                "changes": 24,
                "deletions": 0,
                "sha": "644de3bd92b48c1325309eed88b546ecb0e695b1",
                "blob_url": "https://github.com/apache/pig/blob/9bdf3e10dcd1d78c32911488df61c7a200532824/test/e2e/pig/tests/nightly.conf",
                "filename": "test/e2e/pig/tests/nightly.conf",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/e2e/pig/tests/nightly.conf?ref=9bdf3e10dcd1d78c32911488df61c7a200532824"
            }
        ],
        "bug_id": "pig_35",
        "parent": "https://github.com/apache/pig/commit/ea8fd2df27c0a3b20bfc52f6c1a308f9f944a7d4",
        "message": "PIG-4712: [Pig on Tez] NPE in Bloom UDF after Union (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1710672 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/aba9f47589d8a11b8d6ad428343eb780464496af",
        "file": [
            {
                "patch": "@@ -303,6 +303,7 @@ public void setUDFContextSignature(String signature) {\n      */\n     public final void warn(String msg, Enum warningEnum) {\n         Counter counter = PigStatusReporter.getInstance().getCounter(warningEnum);\n-        counter.increment(1);\n+        if (counter!=null)\n+            counter.increment(1);\n     }\n }",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/aba9f47589d8a11b8d6ad428343eb780464496af/src/org/apache/pig/LoadFunc.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "1cae5cf820b2b4137484b6ac7dedf34a3409b9cb",
                "blob_url": "https://github.com/apache/pig/blob/aba9f47589d8a11b8d6ad428343eb780464496af/src/org/apache/pig/LoadFunc.java",
                "filename": "src/org/apache/pig/LoadFunc.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/LoadFunc.java?ref=aba9f47589d8a11b8d6ad428343eb780464496af"
            }
        ],
        "bug_id": "pig_36",
        "parent": "https://github.com/apache/pig/commit/369b81c18afad938b9d33915cb63d5591cbe38c1",
        "message": "Tiny fix: NPE introduced by PIG-2332\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1208338 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/e881d29d478e27b2f7957451288aa409eeb321ba",
        "file": [
            {
                "patch": "@@ -158,6 +158,8 @@ PIG-2228: support partial aggregation in map task (thejas)\n \n BUG FIXES\n \n+PIG-2313: NPE in ILLUSTRATE trying to get StatusReporter in STORE (daijy)\n+\n PIG-2335: bin/pig does not work with bash 3.0 (azaroth)\n \n PIG-2275: NullPointerException from ILLUSTRATE (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "598899e865d17e5dcfc46e6ecdee8f42445067e2",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -60,38 +60,6 @@ public Context getIllustratorContext(Configuration conf, DataBag input,\n     public boolean inIllustrator(Context context) {\n         return (context instanceof PigMapBase.IllustratorContext);\n     }\n-\n-    /**\n-     * Dummy implementation of StatusReporter for illustrate mode\n-     *\n-     */\n-    @SuppressWarnings(\"deprecation\")\n-    public static class IllustrateDummyReporter extends StatusReporter{\n-\n-\n-        Counters countGen = new Counters();\n-        \n-        @Override\n-        public Counter getCounter(Enum<?> arg0) {\n-            return countGen.findCounter(arg0);\n-        }\n-\n-        @Override\n-        public Counter getCounter(String group, String name) {\n-            return countGen.findCounter(group, name);\n-        }\n-\n-        @Override\n-        public void progress() {\n-            //no-op\n-        }\n-\n-        @Override\n-        public void setStatus(String arg0) {\n-            //no-op\n-        }\n-        \n-    }\n     \n     public class IllustratorContext extends Context {\n         private DataBag input;",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "status": "modified",
                "changes": 32,
                "deletions": 32,
                "sha": "8bdfa2cea5575cac9f262dafbfa997c897e92e89",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "filename": "shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -70,7 +70,7 @@ public IllustratorContext(Job job,\n                   POPackage pkg\n                   ) throws IOException, InterruptedException {\n                 super(job.getJobConf(), new TaskAttemptID(), new FakeRawKeyValueIterator(input.iterator().hasNext()),\n-                    null, null, null, null, null, null, PigNullableWritable.class, NullableTuple.class);\n+                    null, null, null, null, new IllustrateDummyReporter(), null, PigNullableWritable.class, NullableTuple.class);\n                 bos = new ByteArrayOutputStream();\n                 dos = new DataOutputStream(bos);\n                 org.apache.hadoop.mapreduce.Job nwJob = new org.apache.hadoop.mapreduce.Job(job.getJobConf());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "50d3b1b50db86ce871db50ce09a735d1a52b7889",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "filename": "shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -85,7 +85,7 @@ public Context getIllustratorContext(Configuration conf, DataBag input,\n         public IllustratorContext(Configuration conf, DataBag input,\n               List<Pair<PigNullableWritable, Writable>> output,\n               InputSplit split) throws IOException, InterruptedException {\n-            super(conf, new TaskAttemptID(), null, null, null, null, split);\n+            super(conf, new TaskAttemptID(), null, null, null, new IllustrateDummyReporter(), split);\n             if (output == null)\n                 throw new IOException(\"Null output can not be used\");\n             this.input = input; this.output = output;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "cbbdb0c6435ab3ce83a01847539715d08d197863",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "filename": "shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -112,7 +112,7 @@ public IllustratorContextImpl(Job job,\n                   POPackage pkg\n                   ) throws IOException, InterruptedException {\n                 super(job.getJobConf(), new TaskAttemptID(), new FakeRawKeyValueIterator(input.iterator().hasNext()),\n-                    null, null, null, null, null, null, PigNullableWritable.class, NullableTuple.class);\n+                    null, null, null, null, new IllustrateDummyReporter(), null, PigNullableWritable.class, NullableTuple.class);\n                 bos = new ByteArrayOutputStream();\n                 dos = new DataOutputStream(bos);\n                 org.apache.hadoop.mapreduce.Job nwJob = new org.apache.hadoop.mapreduce.Job(job.getJobConf());",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "783ae552f070ca79bc550d1f03dae3c183757315",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "filename": "shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;\n+\n+import org.apache.hadoop.mapred.Counters;\n+import org.apache.hadoop.mapreduce.Counter;\n+import org.apache.hadoop.mapreduce.StatusReporter;\n+\n+/**\n+ * Dummy implementation of StatusReporter for illustrate mode\n+ *\n+ */\n+@SuppressWarnings(\"deprecation\")\n+public class IllustrateDummyReporter extends StatusReporter{\n+\n+\n+    Counters countGen = new Counters();\n+    \n+    @Override\n+    public Counter getCounter(Enum<?> arg0) {\n+        return countGen.findCounter(arg0);\n+    }\n+\n+    @Override\n+    public Counter getCounter(String group, String name) {\n+        return countGen.findCounter(group, name);\n+    }\n+\n+    @Override\n+    public void progress() {\n+        //no-op\n+    }\n+\n+    @Override\n+    public void setStatus(String arg0) {\n+        //no-op\n+    }\n+\n+    public float getProgress() {\n+        return 0;\n+    }\n+    \n+}\n\\ No newline at end of file",
                "additions": 59,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/IllustrateDummyReporter.java",
                "status": "added",
                "changes": 59,
                "deletions": 0,
                "sha": "c3ebeeb906aec9d0297f13eb68839d361f0a5d80",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/IllustrateDummyReporter.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/IllustrateDummyReporter.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/IllustrateDummyReporter.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -124,14 +124,16 @@ public void cleanup(Context context) throws IOException, InterruptedException {\n             runPipeline(leaf);\n         }\n \n-        for (POStore store: stores) {\n-            if (!initialized) {\n-                MapReducePOStoreImpl impl \n-                    = new MapReducePOStoreImpl(context);\n-                store.setStoreImpl(impl);\n-                store.setUp();\n+        if (!inIllustrator) {\n+            for (POStore store: stores) {\n+                if (!initialized) {\n+                    MapReducePOStoreImpl impl \n+                        = new MapReducePOStoreImpl(context);\n+                    store.setStoreImpl(impl);\n+                    store.setUp();\n+                }\n+                store.tearDown();\n             }\n-            store.tearDown();\n         }\n         \n         //Calling EvalFunc.finish()\n@@ -227,12 +229,14 @@ protected void map(Text key, Tuple inpTuple, Context context) throws IOException\n             pigReporter.setRep(context);\n             PhysicalOperator.setReporter(pigReporter);\n            \n-            for (POStore store: stores) {\n-                MapReducePOStoreImpl impl \n-                    = new MapReducePOStoreImpl(context);\n-                store.setStoreImpl(impl);\n-                if (!pigContext.inIllustrator)\n-                    store.setUp();\n+            if (!inIllustrator) {\n+                for (POStore store: stores) {\n+                    MapReducePOStoreImpl impl \n+                        = new MapReducePOStoreImpl(context);\n+                    store.setStoreImpl(impl);\n+                    if (!pigContext.inIllustrator)\n+                        store.setUp();\n+                }\n             }\n             \n             boolean aggregateWarning = \"true\".equalsIgnoreCase(pigContext.getProperties().getProperty(\"aggregate.warning\"));",
                "additions": 17,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapBase.java",
                "status": "modified",
                "changes": 30,
                "deletions": 13,
                "sha": "ac74a68d5b381e3627063e0e330c7a466c2e3cd7",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapBase.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapBase.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -518,14 +518,16 @@ protected void cleanup(Context context) throws IOException, InterruptedException\n                 runPipeline(leaf);\n             }\n \n-            for (POStore store: stores) {\n-                if (!initialized) {\n-                    MapReducePOStoreImpl impl \n-                        = new MapReducePOStoreImpl(context);\n-                    store.setStoreImpl(impl);\n-                    store.setUp();\n+            if (!inIllustrator) {\n+                for (POStore store: stores) {\n+                    if (!initialized) {\n+                        MapReducePOStoreImpl impl \n+                            = new MapReducePOStoreImpl(context);\n+                        store.setStoreImpl(impl);\n+                        store.setUp();\n+                    }\n+                    store.tearDown();\n                 }\n-                store.tearDown();\n             }\n                         \n             //Calling EvalFunc.finish()",
                "additions": 9,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "status": "modified",
                "changes": 16,
                "deletions": 7,
                "sha": "d41f8d6232a0dad43f45addc60eff61f7e576a52",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigGenericMapReduce.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            },
            {
                "patch": "@@ -390,4 +390,22 @@ public void testFilterWithUDF() throws ExecException, IOException {\n         assertTrue(derivedData != null);\n     }\n \n+    @Test\n+    public void testFilterGroupCountStore() throws Exception {\n+        File out = File.createTempFile(\"testFilterGroupCountStoreOutput\", \"\");\n+        out.deleteOnExit();\n+        out.delete();\n+    \n+        PigServer pigServer = new PigServer(pigContext);\n+        pigServer.setBatchOn();\n+        pigServer.registerQuery(\"A = load \" + A.toString() + \" as (x, y);\");\n+        pigServer.registerQuery(\"B = filter A by x < 5;\");\n+        pigServer.registerQuery(\"C = group B by x;\");\n+        pigServer.registerQuery(\"D = foreach C generate group as x, COUNT(B) as the_count;\");\n+        pigServer.registerQuery(\"store D into '\" +  out.getAbsolutePath() + \"';\");\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(null);\n+    \n+        assertTrue(derivedData != null);\n+    }\n+\n }",
                "additions": 18,
                "raw_url": "https://github.com/apache/pig/raw/e881d29d478e27b2f7957451288aa409eeb321ba/test/org/apache/pig/test/TestExampleGenerator.java",
                "status": "modified",
                "changes": 18,
                "deletions": 0,
                "sha": "4babccbd292da3874ac8c8a3cbfb344659d6bbfd",
                "blob_url": "https://github.com/apache/pig/blob/e881d29d478e27b2f7957451288aa409eeb321ba/test/org/apache/pig/test/TestExampleGenerator.java",
                "filename": "test/org/apache/pig/test/TestExampleGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestExampleGenerator.java?ref=e881d29d478e27b2f7957451288aa409eeb321ba"
            }
        ],
        "bug_id": "pig_37",
        "parent": "https://github.com/apache/pig/commit/795b645a521c852052c4206a307fb3b6f49a0c45",
        "message": "PIG-2313: NPE in ILLUSTRATE trying to get StatusReporter in STORE\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1196882 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/8cd6c1c4895dd81dbcb987e215586049eb5a7680",
        "file": [
            {
                "patch": "@@ -38,6 +38,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)\n \n BUG FIXES\n \n+PIG-4315: MergeJoin or Split followed by order by gives NPE in Tez (rohini)\n+\n PIG-4654: Reduce tez memory.reserve-fraction and clear spillables for better memory utilization (rohini)\n \n PIG-4628: Pig 0.14 job with order by fails in mapreduce mode with Oozie (knoguchi)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "ef6e4878ac5fa11828fc7a322cedcb536373a62f",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -193,10 +193,8 @@ public boolean disconnect(TezOperator from, TezOperator to) {\n     public void moveTree(TezOperator root, TezOperPlan newPlan) throws PlanException {\n         List<TezOperator> list = new ArrayList<TezOperator>();\n         list.add(root);\n-        int prevSize = 0;\n         int pos = 0;\n-        while (list.size() > prevSize) {\n-            prevSize = list.size();\n+        while (list.size() > pos) {\n             TezOperator node = list.get(pos);\n             if (getSuccessors(node)!=null) {\n                 for (TezOperator succ : getSuccessors(node)) {\n@@ -243,11 +241,11 @@ public void moveTree(TezOperator root, TezOperPlan newPlan) throws PlanException\n         }\n     }\n \n-    // This method is used in PigGraceShuffleVertexManager to get a list of grandparents. \n+    // This method is used in PigGraceShuffleVertexManager to get a list of grandparents.\n     // Also need to exclude grandparents which also a parent (a is both parent and grandparent in the diagram below)\n     //    a   ->    c\n     //      \\  b  /\n-    // \n+    //\n     public static List<TezOperator> getGrandParentsForGraceParallelism(TezOperPlan tezPlan, TezOperator op) {\n         List<TezOperator> grandParents = new ArrayList<TezOperator>();\n         List<TezOperator> preds = tezPlan.getPredecessors(op);",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperPlan.java",
                "status": "modified",
                "changes": 8,
                "deletions": 5,
                "sha": "6fbcec68e9fcbc99c34c1be86f20f638ea50c0fe",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperPlan.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperPlan.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperPlan.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -73,7 +73,7 @@ public POFRJoinTez(POFRJoin copy, List<String> inputKeys) throws ExecException {\n \n     @Override\n     public void replaceInput(String oldInputKey, String newInputKey) {\n-        if (inputKeys.remove(oldInputKey)) {\n+        while (inputKeys.remove(oldInputKey)) {\n             inputKeys.add(newInputKey);\n         }\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "dec86863b4ad5238fe093d67ed1f974fe95c1c3c",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -73,7 +73,7 @@ public POShuffleTezLoad(POPackage pack) {\n \n     @Override\n     public void replaceInput(String oldInputKey, String newInputKey) {\n-        if (inputKeys.remove(oldInputKey)) {\n+        while (inputKeys.remove(oldInputKey)) {\n             inputKeys.add(newInputKey);\n         }\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "bb88af4a23d0819309f14ac11ff9620ff2dfa09f",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -71,7 +71,7 @@ public POShuffledValueInputTez(OperatorKey k) {\n \n     @Override\n     public void replaceInput(String oldInputKey, String newInputKey) {\n-        if (inputKeys.remove(oldInputKey)) {\n+        while (inputKeys.remove(oldInputKey)) {\n             inputKeys.add(newInputKey);\n         }\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "cdde2d16351575c26912cf35dfdfcf1ebad69329",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -96,7 +96,7 @@ public void initialize(ProcessorContext processorContext)\n \n     @Override\n     public void replaceOutput(String oldOutputKey, String newOutputKey) {\n-        if (outputKeys.remove(oldOutputKey)) {\n+        while (outputKeys.remove(oldOutputKey)) {\n             outputKeys.add(newOutputKey);\n         }\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "f8065e1de41db9ec4878f875407bdd88a4860a3e",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -23,20 +23,14 @@\n import java.util.Map.Entry;\n import java.util.Set;\n \n-import org.apache.commons.lang.ArrayUtils;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit;\n-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.util.PlanHelper;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.TezEdgeDescriptor;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.TezOpPlanVisitor;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.TezOperPlan;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.TezOperator;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.operator.POValueOutputTez;\n-import org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez;\n-import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;\n-import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezOutput;\n import org.apache.pig.backend.hadoop.executionengine.tez.util.TezCompilerUtil;\n import org.apache.pig.impl.plan.OperatorKey;\n import org.apache.pig.impl.plan.PlanException;\n@@ -214,22 +208,12 @@ private void removeSplittee(TezOperPlan plan, TezOperator splitter,\n \n         if (plan.getPredecessors(splittee) != null) {\n             for (TezOperator pred : new ArrayList<TezOperator>(plan.getPredecessors(splittee))) {\n-                List<TezOutput> tezOutputs = PlanHelper.getPhysicalOperators(pred.plan,\n-                        TezOutput.class);\n-                for (TezOutput tezOut : tezOutputs) {\n-                    if (ArrayUtils.contains(tezOut.getTezOutputs(), spliteeKey)) {\n-                        tezOut.replaceOutput(spliteeKey, splitterKey);\n-                    }\n-                }\n-\n                 TezEdgeDescriptor edge = pred.outEdges.remove(splittee.getOperatorKey());\n                 if (edge == null) {\n                     throw new VisitorException(\"Edge description is empty\");\n                 }\n-                pred.outEdges.put(splitter.getOperatorKey(), edge);\n-                splitter.inEdges.put(pred.getOperatorKey(), edge);\n                 plan.disconnect(pred, splittee);\n-                plan.connect(pred, splitter);\n+                TezCompilerUtil.connectTezOpToNewSuccesor(plan, pred, splitter, edge, spliteeKey);\n             }\n         }\n \n@@ -244,27 +228,10 @@ private void removeSplittee(TezOperPlan plan, TezOperator splitter,\n \n                 // Do not connect again in case of self join/cross/cogroup or union\n                 if (splitterSuccs == null || !splitterSuccs.contains(succTezOperator)) {\n-                    TezCompilerUtil.connect(plan, splitter, succTezOperator, edge);\n+                    TezCompilerUtil.connectTezOpToNewPredecessor(plan, succTezOperator, splitter, edge, null);\n                 }\n \n-                try {\n-                    List<TezInput> inputs = PlanHelper.getPhysicalOperators(succTezOperator.plan, TezInput.class);\n-                    for (TezInput input : inputs) {\n-                        input.replaceInput(spliteeKey,\n-                                splitterKey);\n-                    }\n-                    List<POUserFunc> userFuncs = PlanHelper.getPhysicalOperators(succTezOperator.plan, POUserFunc.class);\n-                    for (POUserFunc userFunc : userFuncs) {\n-                        if (userFunc.getFunc() instanceof ReadScalarsTez) {\n-                            TezInput tezInput = (TezInput)userFunc.getFunc();\n-                            tezInput.replaceInput(spliteeKey,\n-                                    splitterKey);\n-                            userFunc.getFuncSpec().setCtorArgs(tezInput.getTezInputs());\n-                        }\n-                    }\n-                } catch (VisitorException e) {\n-                    throw new PlanException(e);\n-                }\n+                TezCompilerUtil.replaceInput(succTezOperator, spliteeKey, splitterKey);\n \n                 if (succTezOperator.isUnion()) {\n                     int index = succTezOperator.getUnionMembers().indexOf(splittee.getOperatorKey());",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/MultiQueryOptimizerTez.java",
                "status": "modified",
                "changes": 39,
                "deletions": 36,
                "sha": "7fce1b32995c9dd08503a187c0bad55b61b09a80",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/MultiQueryOptimizerTez.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/MultiQueryOptimizerTez.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/MultiQueryOptimizerTez.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -26,7 +26,6 @@\n import java.util.Map.Entry;\n import java.util.Set;\n \n-import org.apache.commons.lang.ArrayUtils;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n@@ -43,6 +42,7 @@\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez;\n import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;\n import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezOutput;\n+import org.apache.pig.backend.hadoop.executionengine.tez.util.TezCompilerUtil;\n import org.apache.pig.builtin.RoundRobinPartitioner;\n import org.apache.pig.impl.plan.OperatorKey;\n import org.apache.pig.impl.plan.PlanException;\n@@ -274,14 +274,9 @@ private void connectUnionNonMemberPredecessorsToSplit(TezOperator unionOp,\n                 }\n \n                 for (TezOperator actualPred : actualPreds) {\n-                    List<TezOutput> tezOutputs = PlanHelper.getPhysicalOperators(actualPred.plan,\n-                                    TezOutput.class);\n \n-                    for (TezOutput tezOut : tezOutputs) {\n-                        if (ArrayUtils.contains(tezOut.getTezOutputs(), unionOpKey)) {\n-                            tezOut.replaceOutput(unionOpKey, splitPredKey.toString());\n-                        }\n-                    }\n+                    TezCompilerUtil.replaceOutput(actualPred, unionOpKey, splitPredKey.toString());\n+\n                     TezEdgeDescriptor edge = actualPred.outEdges.remove(unionOp.getOperatorKey());\n                     if (edge == null) {\n                         throw new VisitorException(\"Edge description is empty\");\n@@ -343,27 +338,8 @@ private void connectSplitOpToUnionSuccessors(TezOperator unionOp,\n                 }\n \n                 for (TezOperator actualSucc : actualSuccs) {\n-                    LinkedList<TezInput> inputs = PlanHelper.getPhysicalOperators(succ.plan, TezInput.class);\n-                    for (TezInput tezInput : inputs) {\n-                        for (String inputKey : tezInput.getTezInputs()) {\n-                            if (inputKey.equals(unionOpKey)) {\n-                                tezInput.replaceInput(inputKey, splitPredOpKey);\n-                            }\n-                        }\n-                    }\n \n-                    List<POUserFunc> userFuncs = PlanHelper.getPhysicalOperators(succ.plan, POUserFunc.class);\n-                    for (POUserFunc userFunc : userFuncs) {\n-                        if (userFunc.getFunc() instanceof ReadScalarsTez) {\n-                            TezInput tezInput = (TezInput)userFunc.getFunc();\n-                            for (String inputKey : tezInput.getTezInputs()) {\n-                                if (inputKey.equals(unionOpKey)) {\n-                                    tezInput.replaceInput(inputKey, splitPredOpKey);\n-                                    userFunc.getFuncSpec().setCtorArgs(tezInput.getTezInputs());\n-                                }\n-                            }\n-                        }\n-                    }\n+                    TezCompilerUtil.replaceInput(succ, unionOpKey, splitPredOpKey);\n \n                     TezEdgeDescriptor edge = actualSucc.inEdges.remove(unionOp.getOperatorKey());\n                     if (edge == null) {",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "status": "modified",
                "changes": 32,
                "deletions": 28,
                "sha": "94a578c27dce31ac6eddf34f2f48e33ad767500a",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -22,10 +22,12 @@\n import java.util.LinkedList;\n import java.util.List;\n \n+import org.apache.commons.lang.ArrayUtils;\n import org.apache.pig.PigException;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage;\n@@ -37,6 +39,9 @@\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.operator.POLocalRearrangeTez;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.operator.POStoreTez;\n import org.apache.pig.backend.hadoop.executionengine.tez.plan.operator.POValueOutputTez;\n+import org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez;\n+import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;\n+import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezOutput;\n import org.apache.pig.builtin.RoundRobinPartitioner;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.TupleFactory;\n@@ -123,19 +128,73 @@ static public TezEdgeDescriptor connect(TezOperPlan plan, TezOperator from, TezO\n \n     static public void connect(TezOperPlan plan, TezOperator from, TezOperator to, TezEdgeDescriptor edge) throws PlanException {\n         plan.connect(from, to);\n-        if (from.plan.getLeaves()!=null && !from.plan.getLeaves().isEmpty()) {\n-            PhysicalOperator leaf = from.plan.getLeaves().get(0);\n-            // It could be POStoreTez incase of sampling job in order by\n-            if (leaf instanceof POLocalRearrangeTez) {\n-                POLocalRearrangeTez lr = (POLocalRearrangeTez) leaf;\n-                lr.setOutputKey(to.getOperatorKey().toString());\n-            }\n-        }\n+\n         // Add edge descriptors to old and new operators\n         to.inEdges.put(from.getOperatorKey(), edge);\n         from.outEdges.put(to.getOperatorKey(), edge);\n     }\n \n+    static public void connectTezOpToNewPredecessor(TezOperPlan plan,\n+            TezOperator tezOp, TezOperator newPredecessor,\n+            TezEdgeDescriptor edge, String oldInputKey) throws PlanException {\n+        plan.connect(newPredecessor, tezOp);\n+        // Add edge descriptors to old and new operators\n+        tezOp.inEdges.put(newPredecessor.getOperatorKey(), edge);\n+        newPredecessor.outEdges.put(tezOp.getOperatorKey(), edge);\n+\n+        if (oldInputKey != null) {\n+            replaceInput(tezOp, oldInputKey, newPredecessor.getOperatorKey().toString());\n+        }\n+    }\n+\n+    public static void replaceInput(TezOperator tezOp, String oldInputKey,\n+            String newInputKey) throws PlanException {\n+        try {\n+            List<TezInput> inputs = PlanHelper.getPhysicalOperators(tezOp.plan, TezInput.class);\n+            for (TezInput input : inputs) {\n+                input.replaceInput(oldInputKey, newInputKey);\n+            }\n+            List<POUserFunc> userFuncs = PlanHelper.getPhysicalOperators(tezOp.plan, POUserFunc.class);\n+            for (POUserFunc userFunc : userFuncs) {\n+                if (userFunc.getFunc() instanceof ReadScalarsTez) {\n+                    TezInput input = (TezInput)userFunc.getFunc();\n+                    input.replaceInput(oldInputKey, newInputKey);\n+                    userFunc.getFuncSpec().setCtorArgs(input.getTezInputs());\n+                }\n+            }\n+        } catch (VisitorException e) {\n+            throw new PlanException(e);\n+        }\n+    }\n+\n+    static public void connectTezOpToNewSuccesor(TezOperPlan plan,\n+            TezOperator tezOp, TezOperator newSuccessor,\n+            TezEdgeDescriptor edge, String oldOutputKey) throws PlanException {\n+        plan.connect(tezOp, newSuccessor);\n+        // Add edge descriptors to old and new operators\n+        newSuccessor.inEdges.put(tezOp.getOperatorKey(), edge);\n+        tezOp.outEdges.put(newSuccessor.getOperatorKey(), edge);\n+\n+        if (oldOutputKey != null) {\n+            replaceOutput(tezOp, oldOutputKey, newSuccessor.getOperatorKey().toString());\n+        }\n+    }\n+\n+    public static void replaceOutput(TezOperator tezOp, String oldOutputKey,\n+            String newOutputKey) throws PlanException {\n+        try {\n+            List<TezOutput> tezOutputs = PlanHelper.getPhysicalOperators(tezOp.plan,\n+                    TezOutput.class);\n+            for (TezOutput tezOut : tezOutputs) {\n+                if (ArrayUtils.contains(tezOut.getTezOutputs(), oldOutputKey)) {\n+                    tezOut.replaceOutput(oldOutputKey, newOutputKey);\n+                }\n+            }\n+        } catch (VisitorException e) {\n+            throw new PlanException(e);\n+        }\n+    }\n+\n     static public POForEach getForEach(POProject project, int rp, String scope, NodeIdGenerator nig) {\n         PhysicalPlan forEachPlan = new PhysicalPlan();\n         forEachPlan.add(project);",
                "additions": 67,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/util/TezCompilerUtil.java",
                "status": "modified",
                "changes": 75,
                "deletions": 8,
                "sha": "71083de0ac2ca6f45672d30eead4b93c922d9158",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/src/org/apache/pig/backend/hadoop/executionengine/tez/util/TezCompilerUtil.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/util/TezCompilerUtil.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/util/TezCompilerUtil.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            },
            {
                "patch": "@@ -37,7 +37,6 @@\n import org.apache.hadoop.hbase.client.ResultScanner;\n import org.apache.hadoop.hbase.client.Scan;\n import org.apache.hadoop.hbase.util.Bytes;\n-import org.apache.pig.ExecType;\n import org.apache.pig.PigServer;\n import org.apache.pig.backend.executionengine.ExecException;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRConfiguration;\n@@ -49,7 +48,6 @@\n import org.junit.After;\n import org.junit.AfterClass;\n import org.junit.Assert;\n-import org.junit.Assume;\n import org.junit.Before;\n import org.junit.BeforeClass;\n import org.junit.Test;\n@@ -835,7 +833,6 @@ public void testLoadWithProjection_2() throws IOException {\n      */\n     @Test\n     public void testMergeJoin() throws IOException {\n-        Assume.assumeTrue(\"Skip this test for TEZ. See PIG-4315\", pig.getPigContext().getExecType().equals(ExecType.LOCAL));\n         prepareTable(TESTTABLE_1, true, DataFormat.HBaseBinary);\n         prepareTable(TESTTABLE_2, true, DataFormat.HBaseBinary);\n         pig.registerQuery(\"a = load 'hbase://\" + TESTTABLE_1 + \"' using \"\n@@ -1078,7 +1075,7 @@ public void testStoreToHBase_1_with_timestamp() throws IOException {\n             long col_a_ts = getColTimestamp(result, TESTCOLUMN_A);\n             long col_b_ts = getColTimestamp(result, TESTCOLUMN_B);\n             long col_c_ts = getColTimestamp(result, TESTCOLUMN_C);\n-            \n+\n             Assert.assertEquals(timestamp, col_a_ts);\n             Assert.assertEquals(timestamp, col_b_ts);\n             Assert.assertEquals(timestamp, col_c_ts);\n@@ -1125,7 +1122,7 @@ public void testStoreToHBase_1_with_datetime_timestamp() throws IOException {\n             long col_a_ts = getColTimestamp(result, TESTCOLUMN_A);\n             long col_b_ts = getColTimestamp(result, TESTCOLUMN_B);\n             long col_c_ts = getColTimestamp(result, TESTCOLUMN_C);\n-            \n+\n             Assert.assertEquals(timestamp, col_a_ts);\n             Assert.assertEquals(timestamp, col_b_ts);\n             Assert.assertEquals(timestamp, col_c_ts);\n@@ -1172,7 +1169,7 @@ public void testStoreToHBase_1_with_bytearray_timestamp() throws IOException {\n             long col_a_ts = getColTimestamp(result, TESTCOLUMN_A);\n             long col_b_ts = getColTimestamp(result, TESTCOLUMN_B);\n             long col_c_ts = getColTimestamp(result, TESTCOLUMN_C);\n-            \n+\n             Assert.assertEquals(timestamp, col_a_ts);\n             Assert.assertEquals(timestamp, col_b_ts);\n             Assert.assertEquals(timestamp, col_c_ts);\n@@ -1217,7 +1214,7 @@ public void testStoreToHBase_1_with_delete() throws IOException {\n             long col_a_ts = getColTimestamp(result, TESTCOLUMN_A);\n             long col_b_ts = getColTimestamp(result, TESTCOLUMN_B);\n             long col_c_ts = getColTimestamp(result, TESTCOLUMN_C);\n-            \n+\n             Assert.assertEquals(\"00\".substring(v.length()) + v, rowKey);\n             Assert.assertEquals(i, col_a);\n             Assert.assertEquals(i + 0.0, col_b, 1e-6);",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/8cd6c1c4895dd81dbcb987e215586049eb5a7680/test/org/apache/pig/test/TestHBaseStorage.java",
                "status": "modified",
                "changes": 11,
                "deletions": 7,
                "sha": "8d2ad85388416ec825165fca16db7ba9cc5693ae",
                "blob_url": "https://github.com/apache/pig/blob/8cd6c1c4895dd81dbcb987e215586049eb5a7680/test/org/apache/pig/test/TestHBaseStorage.java",
                "filename": "test/org/apache/pig/test/TestHBaseStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestHBaseStorage.java?ref=8cd6c1c4895dd81dbcb987e215586049eb5a7680"
            }
        ],
        "bug_id": "pig_38",
        "parent": "https://github.com/apache/pig/commit/1edcdf86f7f5fa7fec7e78cb210fde35f2779f71",
        "message": "PIG-4315: MergeJoin or Split followed by order by gives NPE in Tez (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1700912 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/73878540198b2ab90a8422ec2e452c5a0df360c0",
        "file": [
            {
                "patch": "@@ -99,6 +99,8 @@ PIG-2011: Speed up TestTypedMap.java (dvryaboy)\n \n BUG FIXES\n \n+PIG-2170: NPE thrown during illustrate (thejas)\n+\n PIG-2186: PigStorage new warnings about missing schema file \n  can be confusing (thejas)\n ",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/73878540198b2ab90a8422ec2e452c5a0df360c0/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "a82fca94d3ead8b200ec141293f03d000e9bc72b",
                "blob_url": "https://github.com/apache/pig/blob/73878540198b2ab90a8422ec2e452c5a0df360c0/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=73878540198b2ab90a8422ec2e452c5a0df360c0"
            },
            {
                "patch": "@@ -24,7 +24,10 @@\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.io.Text;\n import org.apache.hadoop.io.Writable;\n+import org.apache.hadoop.mapreduce.Counter;\n+import org.apache.hadoop.mapred.Counters;\n import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.StatusReporter;\n import org.apache.hadoop.mapreduce.TaskAttemptID;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase;\n import org.apache.pig.data.DataBag;\n@@ -34,7 +37,7 @@\n \n abstract public class PigMapBase extends PigGenericMapBase {\n     /**\n-     * \n+     *  \n      * Get mapper's illustrator context\n      * \n      * @param conf  Configuration\n@@ -52,6 +55,40 @@ public Context getIllustratorContext(Configuration conf, DataBag input,\n         return new IllustratorContext(conf, input, output, split);\n     }\n     \n+    \n+\n+    /**\n+     * Dummy implementation of StatusReporter for illustrate mode\n+     *\n+     */\n+    @SuppressWarnings(\"deprecation\")\n+    public static class IllustrateDummyReporter extends StatusReporter{\n+\n+\n+        Counters countGen = new Counters();\n+        \n+        @Override\n+        public Counter getCounter(Enum<?> arg0) {\n+            return countGen.findCounter(arg0);\n+        }\n+\n+        @Override\n+        public Counter getCounter(String group, String name) {\n+            return countGen.findCounter(group, name);\n+        }\n+\n+        @Override\n+        public void progress() {\n+            //no-op\n+        }\n+\n+        @Override\n+        public void setStatus(String arg0) {\n+            //no-op\n+        }\n+        \n+    }\n+    \n     public class IllustratorContext extends Context {\n         private DataBag input;\n         List<Pair<PigNullableWritable, Writable>> output;\n@@ -62,12 +99,12 @@ public Context getIllustratorContext(Configuration conf, DataBag input,\n         public IllustratorContext(Configuration conf, DataBag input,\n               List<Pair<PigNullableWritable, Writable>> output,\n               InputSplit split) throws IOException, InterruptedException {\n-              super(conf, new TaskAttemptID(), null, null, null, null, split);\n-              if (output == null)\n-                  throw new IOException(\"Null output can not be used\");\n-              this.input = input; this.output = output;\n+            super(conf, new TaskAttemptID(), null, null, null, new IllustrateDummyReporter(), split);\n+            if (output == null)\n+                throw new IOException(\"Null output can not be used\");\n+            this.input = input; this.output = output;\n         }\n-        \n+\n         @Override\n         public boolean nextKeyValue() throws IOException, InterruptedException {\n             if (input == null) {",
                "additions": 43,
                "raw_url": "https://github.com/apache/pig/raw/73878540198b2ab90a8422ec2e452c5a0df360c0/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "status": "modified",
                "changes": 49,
                "deletions": 6,
                "sha": "6c4e78e0898a3476aee7648121fd2df1bb44666b",
                "blob_url": "https://github.com/apache/pig/blob/73878540198b2ab90a8422ec2e452c5a0df360c0/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "filename": "shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java?ref=73878540198b2ab90a8422ec2e452c5a0df360c0"
            },
            {
                "patch": "@@ -283,56 +283,56 @@ public void visitProject(POProject proj) throws VisitorException{\n     @Override\n     public void visitGreaterThan(GreaterThanExpr grt) throws VisitorException{\n         setIllustrator(grt, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(grt.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitLessThan(LessThanExpr lt) throws VisitorException{\n         setIllustrator(lt, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(lt.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitGTOrEqual(GTOrEqualToExpr gte) throws VisitorException{\n         setIllustrator(gte, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(gte.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitLTOrEqual(LTOrEqualToExpr lte) throws VisitorException{\n         setIllustrator(lte, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(lte.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitEqualTo(EqualToExpr eq) throws VisitorException{\n         setIllustrator(eq, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(eq.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitNotEqualTo(NotEqualToExpr eq) throws VisitorException{\n         setIllustrator(eq, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(eq.getIllustrator().getSubExpResult());\n     }\n     \n     @Override\n     public void visitRegexp(PORegexp re) throws VisitorException{\n         setIllustrator(re, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(re.getIllustrator().getSubExpResult());\n     }\n \n     @Override\n     public void visitIsNull(POIsNull isNull) throws VisitorException {\n         setIllustrator(isNull, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(isNull.getIllustrator().getSubExpResult());\n     }\n     \n@@ -349,15 +349,13 @@ public void visitOr(POOr or) throws VisitorException {\n     @Override\n     public void visitNot(PONot not) throws VisitorException {\n         setIllustrator(not, 0);\n-        if (!revisit)\n+        if (!revisit && subExpResults != null)\n             subExpResults.add(not.getIllustrator().getSubExpResult());\n     }\n \n     @Override\n     public void visitBinCond(POBinCond binCond) {\n-        setIllustrator(binCond, 0);\n-        if (!revisit)\n-            subExpResults.add(binCond.getIllustrator().getSubExpResult());\n+\n     }\n \n     @Override",
                "additions": 10,
                "raw_url": "https://github.com/apache/pig/raw/73878540198b2ab90a8422ec2e452c5a0df360c0/src/org/apache/pig/pen/IllustratorAttacher.java",
                "status": "modified",
                "changes": 22,
                "deletions": 12,
                "sha": "63089f50b7acacd7e5a6362c96dd3f6727d7fae7",
                "blob_url": "https://github.com/apache/pig/blob/73878540198b2ab90a8422ec2e452c5a0df360c0/src/org/apache/pig/pen/IllustratorAttacher.java",
                "filename": "src/org/apache/pig/pen/IllustratorAttacher.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/pen/IllustratorAttacher.java?ref=73878540198b2ab90a8422ec2e452c5a0df360c0"
            },
            {
                "patch": "@@ -18,14 +18,15 @@\n \n package org.apache.pig.test;\n \n+import static org.junit.Assert.assertTrue;\n+\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.util.Map;\n+import java.util.Properties;\n import java.util.Random;\n \n-import junit.framework.TestCase;\n-\n import org.apache.pig.ExecType;\n import org.apache.pig.PigServer;\n import org.apache.pig.backend.executionengine.ExecException;\n@@ -34,22 +35,20 @@\n import org.apache.pig.impl.io.FileLocalizer;\n import org.apache.pig.newplan.Operator;\n import org.junit.AfterClass;\n-import org.junit.Before;\n+import org.junit.BeforeClass;\n import org.junit.Test;\n-import org.junit.runner.RunWith;\n-import org.junit.runners.JUnit4;\n \n-@RunWith(JUnit4.class)\n-public class TestExampleGenerator extends TestCase {\n \n-    static MiniCluster cluster = MiniCluster.buildCluster();\n-    PigContext pigContext = new PigContext(ExecType.MAPREDUCE, cluster\n-            .getProperties());\n+public class TestExampleGenerator {\n \n-    Random rand = new Random();\n-    int MAX = 100;\n-    String A, B;\n+    \n+    static PigContext pigContext = new PigContext(ExecType.LOCAL, new Properties());\n \n+   \n+    static int MAX = 100;\n+    static String A, B;\n+    static  File fileA, fileB;\n+    \n     {\n         try {\n             pigContext.connect();\n@@ -59,32 +58,26 @@\n         }\n     }\n \n-    @Before\n-    public void setUp() throws Exception {\n-        File fileA, fileB;\n+    @BeforeClass\n+    public static void oneTimeSetup() throws Exception {\n+       \n \n         fileA = File.createTempFile(\"dataA\", \".dat\");\n         fileB = File.createTempFile(\"dataB\", \".dat\");\n \n         writeData(fileA);\n         writeData(fileB);\n+     \n \n-        A = \"'\" + FileLocalizer.hadoopify(fileA.toString(), pigContext) + \"'\";\n-        B = \"'\" + FileLocalizer.hadoopify(fileB.toString(), pigContext) + \"'\";\n-        System.out.println(\"A : \" + A + \"\\n\" + \"B : \" + B);\n-        System.out.println(\"Test data created.\");\n         fileA.deleteOnExit();\n         fileB.deleteOnExit();\n-          \n-    }\n-\n-    \n-    @AfterClass\n-    public static void oneTimeTearDown() throws Exception {\n-        cluster.shutDown();\n+        A = \"'\" + fileA.getPath() + \"'\";\n+        B = \"'\" + fileB.getPath() + \"'\";\n+        System.out.println(\"A : \" + A + \"\\n\" + \"B : \" + B);\n+        System.out.println(\"Test data created.\");\n     }\n \n-    private void writeData(File dataFile) throws Exception {\n+    private static void writeData(File dataFile) throws Exception {\n         // File dataFile = File.createTempFile(name, \".dat\");\n         FileOutputStream dat = new FileOutputStream(dataFile);\n \n@@ -176,6 +169,34 @@ public void testForeach() throws ExecException, IOException {\n \n         assertTrue(derivedData != null);\n     }\n+    \n+    //see PIG-2170\n+    @Test\n+    public void testForeachBinCondWithBooleanExp() throws ExecException, IOException {\n+        PigServer pigServer = new PigServer(pigContext);\n+\n+        pigServer.registerQuery(\"A = load \" + A\n+                + \" using PigStorage() as (x : int, y : int);\");\n+        pigServer.registerQuery(\"B = foreach A generate  (x + 1 > y ? 0 : 1);\");\n+\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"B\");\n+\n+        assertTrue(derivedData != null);\n+    }\n+    \n+    @Test\n+    public void testForeachWithTypeCastCounter() throws ExecException, IOException {\n+        PigServer pigServer = new PigServer(pigContext);\n+        //cast error results in counter being incremented and was resulting\n+        // in a NPE exception in illustrate\n+        pigServer.registerQuery(\"A = load \" + A\n+                + \" using PigStorage() as (x : int, y : int);\");\n+        pigServer.registerQuery(\"B = foreach A generate x, (int)'InvalidInt';\");\n+\n+        Map<Operator, DataBag> derivedData = pigServer.getExamples(\"B\");\n+\n+        assertTrue(derivedData != null);\n+    }\n \n     @Test\n     public void testJoin() throws IOException, ExecException {",
                "additions": 49,
                "raw_url": "https://github.com/apache/pig/raw/73878540198b2ab90a8422ec2e452c5a0df360c0/test/org/apache/pig/test/TestExampleGenerator.java",
                "status": "modified",
                "changes": 77,
                "deletions": 28,
                "sha": "9a56344f2670c44a6f3e4bb4208f2a0dc70f61a4",
                "blob_url": "https://github.com/apache/pig/blob/73878540198b2ab90a8422ec2e452c5a0df360c0/test/org/apache/pig/test/TestExampleGenerator.java",
                "filename": "test/org/apache/pig/test/TestExampleGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestExampleGenerator.java?ref=73878540198b2ab90a8422ec2e452c5a0df360c0"
            }
        ],
        "bug_id": "pig_39",
        "parent": "https://github.com/apache/pig/commit/d1e1d1b93ea4863b222fca636a5155cac1a35777",
        "message": "PIG-2170: NPE thrown during illustrate\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1154068 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/4c05bdb44dd6c9eba704f1568f076d218a430565",
        "file": [
            {
                "patch": "@@ -44,6 +44,8 @@ PIG-1876: Typed map for Pig (daijy)\n \n IMPROVEMENTS\n \n+PIG-2006: Regression: NPE when Pig processes an empty script file, fix test case (xuefu)\n+\n PIG-2006: Regression: NPE when Pig processes an empty script file (xuefu)\n \n PIG-2007: Parsing error when map key referred directly from udf in nested foreach (xuefu)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/4c05bdb44dd6c9eba704f1568f076d218a430565/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "e2cfd67b9ac211c003e002abf6bee3685985611a",
                "blob_url": "https://github.com/apache/pig/blob/4c05bdb44dd6c9eba704f1568f076d218a430565/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=4c05bdb44dd6c9eba704f1568f076d218a430565"
            },
            {
                "patch": "@@ -604,7 +604,6 @@ public void fsCommandTest() throws Exception {\n     @Test // PIG-2006\n     public void testEmptyFile() throws IOException {\n         File f1 = new File(\"myscript.pig\");\n-        f1.deleteOnExit();\n         \n         FileWriter fw1 = new FileWriter(f1);\n         fw1.close();",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/4c05bdb44dd6c9eba704f1568f076d218a430565/test/org/apache/pig/test/TestPigRunner.java",
                "status": "modified",
                "changes": 1,
                "deletions": 1,
                "sha": "6c0fb1d49cd3f5854938054861562b27ec0e4146",
                "blob_url": "https://github.com/apache/pig/blob/4c05bdb44dd6c9eba704f1568f076d218a430565/test/org/apache/pig/test/TestPigRunner.java",
                "filename": "test/org/apache/pig/test/TestPigRunner.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigRunner.java?ref=4c05bdb44dd6c9eba704f1568f076d218a430565"
            }
        ],
        "bug_id": "pig_40",
        "parent": "https://github.com/apache/pig/commit/52477dc84cb7b8ca8ed5be9a0a77bdd9a9770d18",
        "message": "PIG-2006: Regression: NPE when Pig processes an empty script file\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1096189 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/53c1c1bc1836988fc9656d310eeed940b8bb84cc",
        "file": [
            {
                "patch": "@@ -44,6 +44,8 @@ PIG-1876: Typed map for Pig (daijy)\n \n IMPROVEMENTS\n \n+PIG-2006: Regression: NPE when Pig processes an empty script file (xuefu)\n+\n PIG-2007: Parsing error when map key referred directly from udf in nested foreach (xuefu)\n \n PIG-2000: Pig gives incorrect error message dealing with scalar projection (xuefu)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/53c1c1bc1836988fc9656d310eeed940b8bb84cc/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "623d1fb5cd91a5dac92fe957d9bdeef821625b11",
                "blob_url": "https://github.com/apache/pig/blob/53c1c1bc1836988fc9656d310eeed940b8bb84cc/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=53c1c1bc1836988fc9656d310eeed940b8bb84cc"
            }
        ],
        "bug_id": "pig_41",
        "parent": "https://github.com/apache/pig/commit/7e469c81debea1a24260f4f12ef84441c53a416b",
        "message": "PIG-2006: Regression: NPE when Pig processes an empty script file\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1096087 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/7e469c81debea1a24260f4f12ef84441c53a416b",
        "file": [
            {
                "patch": "@@ -83,6 +83,8 @@ private SupportedScriptLang(String[] shebangs, String[] extensions, String engin\n          * @param firstLine The first line of the file (possibly containing #!...)\n          */\n         public boolean accepts(String file, String firstLine) {\n+            if( firstLine == null )\n+            \treturn false;\n             \n             for (String shebang : shebangs) {\n                 Pattern p = Pattern.compile(\"^#!.*/\" + shebang + \"\\\\s*$\");\n@@ -109,6 +111,8 @@ public String getEngineClassName() {\n     private static final Pattern shebangPattern = Pattern.compile(\"^#!.+\");\n     \n     private static boolean declaresShebang(String firstLine) {\n+    \tif( firstLine == null )\n+    \t\treturn false;\n         return shebangPattern.matcher(firstLine).matches();\n     }\n     ",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/7e469c81debea1a24260f4f12ef84441c53a416b/src/org/apache/pig/scripting/ScriptEngine.java",
                "status": "modified",
                "changes": 4,
                "deletions": 0,
                "sha": "69a7cbcbd3d7ba77725d3158ba3f485dd18214d1",
                "blob_url": "https://github.com/apache/pig/blob/7e469c81debea1a24260f4f12ef84441c53a416b/src/org/apache/pig/scripting/ScriptEngine.java",
                "filename": "src/org/apache/pig/scripting/ScriptEngine.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/scripting/ScriptEngine.java?ref=7e469c81debea1a24260f4f12ef84441c53a416b"
            },
            {
                "patch": "@@ -23,6 +23,7 @@\n \n import java.io.File;\n import java.io.FileWriter;\n+import java.io.IOException;\n import java.io.PrintWriter;\n import java.util.HashMap;\n import java.util.Iterator;\n@@ -600,6 +601,22 @@ public void fsCommandTest() throws Exception {\n         }\n     }\n     \n+    @Test // PIG-2006\n+    public void testEmptyFile() throws IOException {\n+        File f1 = new File(\"myscript.pig\");\n+        f1.deleteOnExit();\n+        \n+        FileWriter fw1 = new FileWriter(f1);\n+        fw1.close();\n+\n+        String[] args = { \"-x\", \"local\", \"-c\", \"myscript.pig\" };\n+        PigStats stats = PigRunner.run(args, null);\n+       \n+        Assert.assertTrue(stats.isSuccessful());\n+        Assert.assertEquals( 0, stats.getReturnCode() );\n+        Assert.assertEquals( null, stats.getErrorMessage() );\n+    }\n+    \n     @Test\n     public void returnCodeTest() throws Exception {\n         PrintWriter w = new PrintWriter(new FileWriter(PIG_FILE));",
                "additions": 17,
                "raw_url": "https://github.com/apache/pig/raw/7e469c81debea1a24260f4f12ef84441c53a416b/test/org/apache/pig/test/TestPigRunner.java",
                "status": "modified",
                "changes": 17,
                "deletions": 0,
                "sha": "7e27529fd9d68a5c44c54096cb11f846619915f2",
                "blob_url": "https://github.com/apache/pig/blob/7e469c81debea1a24260f4f12ef84441c53a416b/test/org/apache/pig/test/TestPigRunner.java",
                "filename": "test/org/apache/pig/test/TestPigRunner.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigRunner.java?ref=7e469c81debea1a24260f4f12ef84441c53a416b"
            }
        ],
        "bug_id": "pig_42",
        "parent": "https://github.com/apache/pig/commit/90d008ac79eec001314ad4f041f0955a17632315",
        "message": "PIG-2006: Regression: NPE when Pig processes an empty script file\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1096086 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/97a51f0bac943d7e6b34627424b5d16f5fdd50a3",
        "file": [
            {
                "patch": "@@ -429,6 +429,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1993: PigStorageSchema throw NPE with ColumnPruning (daijy)\n+\n PIG-1935: New logical plan: Should not push up filter in front of Bincond (daijy)\n \n PIG-1912: non-deterministic output when a file is loaded multiple times (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "14ee89df938109938a1c3d538da2797bf7209e7f",
                "blob_url": "https://github.com/apache/pig/blob/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=97a51f0bac943d7e6b34627424b5d16f5fdd50a3"
            },
            {
                "patch": "@@ -91,7 +91,7 @@ public Tuple getNext() throws IOException {\n             // We walk the requiredColumns array to find required fields,\n             // and cast those.\n             for (int i = 0; i < fieldSchemas.length; i++) {\n-                if (mRequiredColumns == null || mRequiredColumns[i]) {\n+                if (mRequiredColumns == null || (mRequiredColumns.length>i && mRequiredColumns[i])) {\n                     Object val = null;\n                     if(tup.get(tupleIdx) != null){\n                         byte[] bytes = ((DataByteArray) tup.get(tupleIdx)).get();",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/PigStorageSchema.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "f920263f6f586f59026e693d7f85b9c7e22c578a",
                "blob_url": "https://github.com/apache/pig/blob/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/PigStorageSchema.java",
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/PigStorageSchema.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/PigStorageSchema.java?ref=97a51f0bac943d7e6b34627424b5d16f5fdd50a3"
            },
            {
                "patch": "@@ -219,4 +219,32 @@ public void testByteArrayConversion() throws IOException {\n \n \n     }\n+    \n+    // See PIG-1993\n+    @Test\n+    public void testColumnPrune() throws IOException {\n+        Util.createInputFile(cluster, \"originput2\",\n+                new String[] {\"peter\\t1\", \"samir\\t2\", \"michael\\t4\",\n+                \"peter\\t2\", \"peter\\t4\", \"samir\\t1\", \"john\\t\"\n+        });\n+        Util.createInputFile(cluster, \".pig_schema\",\n+                new String[] {\n+                \"{\\\"fields\\\":[{\\\"name\\\":\\\"name\\\",\\\"type\\\":55,\\\"schema\\\":null,\" +\n+                \"\\\"description\\\":\\\"autogenerated from Pig Field Schema\\\"},\" +\n+                \"{\\\"name\\\":\\\"val\\\",\\\"type\\\":10,\\\"schema\\\":null,\\\"description\\\":\"+\n+                \"\\\"autogenerated from Pig Field Schema\\\"}],\\\"version\\\":0,\" +\n+                \"\\\"sortKeys\\\":[],\\\"sortKeyOrders\\\":[]}\"\n+        });\n+        pig.registerQuery(\"Events = LOAD 'originput2' USING org.apache.pig.piggybank.storage.PigStorageSchema();\");\n+        pig.registerQuery(\"EventsName = foreach Events generate name;\");\n+        Iterator<Tuple> sessions = pig.openIterator(\"EventsName\");\n+        sessions.next().toString().equals(\"(1)\");\n+        sessions.next().toString().equals(\"(2)\");\n+        sessions.next().toString().equals(\"(4)\");\n+        sessions.next().toString().equals(\"(2)\");\n+        sessions.next().toString().equals(\"(4)\");\n+        sessions.next().toString().equals(\"(1)\");\n+        sessions.next().toString().equals(\"()\");\n+        Assert.assertFalse(sessions.hasNext());\n+    }\n }",
                "additions": 28,
                "raw_url": "https://github.com/apache/pig/raw/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/TestPigStorageSchema.java",
                "status": "modified",
                "changes": 28,
                "deletions": 0,
                "sha": "068347843832e0efdf6bc89fff5b528e888b7919",
                "blob_url": "https://github.com/apache/pig/blob/97a51f0bac943d7e6b34627424b5d16f5fdd50a3/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/TestPigStorageSchema.java",
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/TestPigStorageSchema.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/TestPigStorageSchema.java?ref=97a51f0bac943d7e6b34627424b5d16f5fdd50a3"
            }
        ],
        "bug_id": "pig_43",
        "parent": "https://github.com/apache/pig/commit/cdce20e257efb05347a3d2a9b04caabbda04c754",
        "message": "PIG-1993: PigStorageSchema throw NPE with ColumnPruning\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1091988 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/edc5ec1d076a05591ab8cdfa2881eb317f98e202",
        "file": [
            {
                "patch": "@@ -142,6 +142,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-1988: Importing an empty macro file causing NPE (rding)\n+\n PIG-1977: \"Stream closed\" error while reading Pig temp files (results of intermediate jobs) (rding)\n \n PIG-1963: in nested foreach, accumutive udf taking input from order-by does not get results in order (thejas)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "15d13c4258b9b1e7db03a202956ee40b9c310c68",
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202"
            },
            {
                "patch": "@@ -191,7 +191,10 @@ static void replaceNodeWithNodeList(Tree oldNode, CommonTree newTree,\n \n         for (int i = 0; i < count; i++) {\n             if (i == idx) {\n-                parent.addChildren(macroList);\n+                // add only there is something to add\n+                if (macroList != null) {\n+                    parent.addChildren(macroList);\n+                }\n             } else {\n                 parent.addChild((Tree) childList.get(i));\n             }",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/src/org/apache/pig/parser/QueryParserUtils.java",
                "status": "modified",
                "changes": 5,
                "deletions": 1,
                "sha": "9a3f26db7746e5a96a41f4fc5d6957d869f6c987",
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/src/org/apache/pig/parser/QueryParserUtils.java",
                "filename": "src/org/apache/pig/parser/QueryParserUtils.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/parser/QueryParserUtils.java?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202"
            },
            {
                "patch": "@@ -1663,6 +1663,31 @@ public void test35() throws Exception {\n         testMacro( query, expected );\n     }\n     \n+    // PIG-1988\n+    @Test\n+    public void test36() throws Exception {\n+        File f = new File(\"mymacro.pig\");\n+        f.deleteOnExit();\n+        \n+        FileWriter fw = new FileWriter(f);\n+        fw.append(\" \");\n+        fw.close();\n+\n+        String query = \"import 'mymacro.pig';\" +\n+            \"define macro1() returns dummy {}; \" + \n+            \"A = load '1.txt' as (a0:int, a1:chararray);\" +\n+            \"dummy = macro1();\" +\n+            \"B = group A by a0;\" + \n+            \"store B into 'output';\";\n+        \n+        String expected = \n+            \"A = load '1.txt' as (a0:int, a1:chararray);\\n\" +\n+            \"B = group A by (a0);\\n\" +\n+            \"store B INTO 'output';\\n\";\n+        \n+        verify(query, expected);\n+    }\n+    \n     @Test\n     public void testCommentInMacro() throws Exception {\n         String query = \"a = load 'testComplexCast' as (m);\\n\" +\n@@ -1734,7 +1759,11 @@ private void verify(String s, String expected) throws Exception {\n         \n         String[] args = { \"-Dpig.import.search.path=/tmp\", \"-x\", \"local\", \"-c\", \"myscript.pig\" };\n         PigStats stats = PigRunner.run(args, null);\n- \n+        \n+        if (!stats.isSuccessful()) {\n+            System.out.println(\"error msg: \" + stats.getErrorMessage());\n+        }\n+        \n         assertTrue(stats.isSuccessful());\n         \n         String[] args2 = { \"-Dpig.import.search.path=/tmp\", \"-x\", \"local\", \"-r\", \"myscript.pig\" };",
                "additions": 30,
                "raw_url": "https://github.com/apache/pig/raw/edc5ec1d076a05591ab8cdfa2881eb317f98e202/test/org/apache/pig/test/TestMacroExpansion.java",
                "status": "modified",
                "changes": 31,
                "deletions": 1,
                "sha": "3536751e15982f9c3fecb03112b099337fc31197",
                "blob_url": "https://github.com/apache/pig/blob/edc5ec1d076a05591ab8cdfa2881eb317f98e202/test/org/apache/pig/test/TestMacroExpansion.java",
                "filename": "test/org/apache/pig/test/TestMacroExpansion.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestMacroExpansion.java?ref=edc5ec1d076a05591ab8cdfa2881eb317f98e202"
            }
        ],
        "bug_id": "pig_44",
        "parent": "https://github.com/apache/pig/commit/ce385ecec65e9ac62cec3410046dc41ec66645a5",
        "message": "PIG-1988: Importing an empty macro file causing NPE\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1091242 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/20f7c2c14519092b727904d57171b4d8a0a4732f",
        "file": [
            {
                "patch": "@@ -299,6 +299,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1843: NPE in schema generation (daijy)\n+\n PIG-1820: New logical plan: FilterLogicExpressionSimplifier fail to deal with UDF (daijy)\n \n PIG-1854: Pig returns exit code 0 for the failed Pig script (rding)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "d796576317136fe0291a8cac7459ba4b49b030af",
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=20f7c2c14519092b727904d57171b4d8a0a4732f"
            },
            {
                "patch": "@@ -73,7 +73,7 @@\n     private static int nextSchemaId; // for assigning unique ids to UDF columns\n     protected String getSchemaName(String name, Schema input) {\n         String alias = name + \"_\";\n-        if (input.getAliases().size() > 0){\n+        if (input!=null && input.getAliases().size() > 0){\n             alias += input.getAliases().iterator().next() + \"_\";\n         }\n ",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/src/org/apache/pig/EvalFunc.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "13640657c4258336dd1469007b39db5d77c8d3b3",
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/src/org/apache/pig/EvalFunc.java",
                "filename": "src/org/apache/pig/EvalFunc.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/EvalFunc.java?ref=20f7c2c14519092b727904d57171b4d8a0a4732f"
            },
            {
                "patch": "@@ -973,13 +973,13 @@ public void testBinStorageByteCast() throws Exception{\n     \n     // See PIG-1761\n     @Test\n-    public void testBagDereferenceInMiddle() throws Exception{\n+    public void testBagDereferenceInMiddle1() throws Exception{\n         String[] input1 = {\n                 \"foo@apache#44\",\n         };\n         \n-        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle\", input1);\n-        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle' as (a0:chararray);\");\n+        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle1\", input1);\n+        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle1' as (a0:chararray);\");\n         pigServer.registerQuery(\"b = foreach a generate UPPER(REGEX_EXTRACT_ALL(a0, '.*@(.*)#.*').$0);\");\n         \n         Iterator<Tuple> iter = pigServer.openIterator(\"b\");\n@@ -988,6 +988,23 @@ public void testBagDereferenceInMiddle() throws Exception{\n         assertTrue(t.get(0).equals(\"APACHE\"));\n     }\n     \n+    // See PIG-1843\n+    @Test\n+    public void testBagDereferenceInMiddle2() throws Exception{\n+        String[] input1 = {\n+                \"foo apache\",\n+        };\n+        \n+        Util.createInputFile(cluster, \"table_testBagDereferenceInMiddle2\", input1);\n+        pigServer.registerQuery(\"a = load 'table_testBagDereferenceInMiddle2' as (a0:chararray);\");\n+        pigServer.registerQuery(\"b = foreach a generate \" + MapGenerate.class.getName() + \" (STRSPLIT(a0).$0);\");\n+        \n+        Iterator<Tuple> iter = pigServer.openIterator(\"b\");\n+        Tuple t = iter.next();\n+        assertTrue(t.size()==1);\n+        assertTrue(t.toString().equals(\"([key#1])\"));\n+    }\n+    \n     // See PIG-1766\n     @Test\n     public void testForEachSameOriginColumn1() throws Exception{\n@@ -1048,7 +1065,7 @@ public Map exec(Tuple input) throws IOException {\n         \n         @Override\n         public Schema outputSchema(Schema input) {\n-            return new Schema(new Schema.FieldSchema(null, DataType.MAP));\n+            return new Schema(new Schema.FieldSchema(getSchemaName(\"parselong\", input), DataType.MAP));\n         }\n     }\n     ",
                "additions": 21,
                "raw_url": "https://github.com/apache/pig/raw/20f7c2c14519092b727904d57171b4d8a0a4732f/test/org/apache/pig/test/TestEvalPipeline2.java",
                "status": "modified",
                "changes": 25,
                "deletions": 4,
                "sha": "9d285f9499223426d8a38116e73767712cd63443",
                "blob_url": "https://github.com/apache/pig/blob/20f7c2c14519092b727904d57171b4d8a0a4732f/test/org/apache/pig/test/TestEvalPipeline2.java",
                "filename": "test/org/apache/pig/test/TestEvalPipeline2.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestEvalPipeline2.java?ref=20f7c2c14519092b727904d57171b4d8a0a4732f"
            }
        ],
        "bug_id": "pig_45",
        "parent": "https://github.com/apache/pig/commit/8c7e23cc630a3127d80cb6764d4d5e05d6d765ca",
        "message": "PIG-1843: NPE in schema generation\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1071857 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd",
        "file": [
            {
                "patch": "@@ -207,6 +207,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1647: Logical simplifier throws a NPE (yanz)\n+\n PIG-1642: Order by doesn't use estimation to determine the parallelism (rding)\n \n PIG-1644: New logical plan: Plan.connect with position is misused in some",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "30784b3126d6c135f09ff6988132413a0577a7b0",
                "blob_url": "https://github.com/apache/pig/blob/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd"
            },
            {
                "patch": "@@ -147,20 +147,30 @@ else if (!isRhsOr) {\n                     int lsize = lhsChildren.length, rsize = rhsChildren.length;\n                     LogicalExpression[][] grandChildrenL = new LogicalExpression[lsize][];;\n                     for (int i = 0; i < lsize; i++) {\n-                        if (lhsChildren[i] instanceof AndExpression || lhsChildren[i] instanceof DNFExpression) grandChildrenL[i] = dnfPlan.getSuccessors(\n-                                        lhsChildren[i]).toArray(\n-                                        new LogicalExpression[0]);\n-                        else {\n+                        if (lhsChildren[i] instanceof AndExpression) {\n+                            grandChildrenL[i] = lhsChildren[i].getPlan().getSuccessors(\n+                              lhsChildren[i]).toArray(\n+                              new LogicalExpression[0]);\n+                        } else if (lhsChildren[i] instanceof DNFExpression) {\n+                            grandChildrenL[i] = dnfPlan.getSuccessors(\n+                              lhsChildren[i]).toArray(\n+                              new LogicalExpression[0]);\n+                        } else {\n                             grandChildrenL[i] = new LogicalExpression[1];\n                             grandChildrenL[i][0] = (LogicalExpression) lhsChildren[i];\n                         }\n                     }\n                     LogicalExpression[][] grandChildrenR = new LogicalExpression[rsize][];;\n                     for (int i = 0; i < rsize; i++) {\n-                        if (rhsChildren[i] instanceof AndExpression || rhsChildren[i] instanceof DNFExpression) grandChildrenR[i] = dnfPlan.getSuccessors(\n-                                        rhsChildren[i]).toArray(\n-                                        new LogicalExpression[0]);\n-                        else {\n+                        if (rhsChildren[i] instanceof AndExpression) {\n+                            grandChildrenR[i] = rhsChildren[i].getPlan().getSuccessors(\n+                              rhsChildren[i]).toArray(\n+                              new LogicalExpression[0]);\n+                        } else if (rhsChildren[i] instanceof DNFExpression) {\n+                            grandChildrenR[i] = dnfPlan.getSuccessors(\n+                              rhsChildren[i]).toArray(\n+                              new LogicalExpression[0]);\n+                        } else {\n                             grandChildrenR[i] = new LogicalExpression[1];\n                             grandChildrenR[i][0] = (LogicalExpression) rhsChildren[i];\n                         }\n@@ -248,9 +258,14 @@ private void mergeSimpleOr(LogicalExpression current,\n         int size = orChildren.length;\n         LogicalExpression[][] grandChildrenOr = new LogicalExpression[size][];;\n         for (int i = 0; i < size; i++) {\n-            if (orChildren[i] instanceof AndExpression || orChildren[i] instanceof DNFExpression) grandChildrenOr[i] = dnfPlan.getSuccessors(\n+            if (orChildren[i] instanceof DNFExpression)\n+              grandChildrenOr[i] = dnfPlan.getSuccessors(\n                             orChildren[i]).toArray(\n                             new LogicalExpression[0]);\n+            else if (orChildren[i] instanceof AndExpression)\n+              grandChildrenOr[i] = orChildren[i].getPlan().getSuccessors(\n+                  orChildren[i]).toArray(\n+                  new LogicalExpression[0]);\n             else {\n                 grandChildrenOr[i] = new LogicalExpression[1];\n                 grandChildrenOr[i][0] = (LogicalExpression) orChildren[i];\n@@ -302,9 +317,14 @@ private void mergeAndOr(LogicalExpression current,\n         boolean andDNF = and.getPlan() == dnfPlan, orDNF = or.getPlan() == dnfPlan;\n         LogicalExpression[][] grandChildrenOr = new LogicalExpression[orSize][];;\n         for (int i = 0; i < orSize; i++) {\n-            if (orChildren[i] instanceof AndExpression || orChildren[i] instanceof DNFExpression) grandChildrenOr[i] = dnfPlan.getSuccessors(\n+            if (orChildren[i] instanceof DNFExpression)\n+              grandChildrenOr[i] = dnfPlan.getSuccessors(\n                             orChildren[i]).toArray(\n                             new LogicalExpression[0]);\n+            else if (orChildren[i] instanceof AndExpression)\n+              grandChildrenOr[i] = orChildren[i].getPlan().getSuccessors(\n+                  orChildren[i]).toArray(\n+                      new LogicalExpression[0]);\n             else {\n                 grandChildrenOr[i] = new LogicalExpression[1];\n                 grandChildrenOr[i][0] = (LogicalExpression) orChildren[i];",
                "additions": 30,
                "raw_url": "https://github.com/apache/pig/raw/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/src/org/apache/pig/newplan/logical/rules/DNFPlanGenerator.java",
                "status": "modified",
                "changes": 40,
                "deletions": 10,
                "sha": "9d471eef540eef18a119d98ab2356ac06a9a4883",
                "blob_url": "https://github.com/apache/pig/blob/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/src/org/apache/pig/newplan/logical/rules/DNFPlanGenerator.java",
                "filename": "src/org/apache/pig/newplan/logical/rules/DNFPlanGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/rules/DNFPlanGenerator.java?ref=f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd"
            },
            {
                "patch": "@@ -666,6 +666,110 @@ public void test3() throws Exception {\n         assertTrue(expected.isEqual(newLogicalPlan));\n     }\n \n+    @Test\n+    public void test4() throws Exception {\n+        LogicalPlanTester lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(\"b = filter (load 'd.txt' as (a:chararray, b:long, c:map[], d:chararray, e:chararray)) by a == 'v' and b == 117L and c#'p1' == 'h' and c#'p2' == 'to' and ((d is not null and d != '') or (e is not null and e != ''));\"); \n+\n+        org.apache.pig.impl.logicalLayer.LogicalPlan plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan newLogicalPlan = migratePlan(plan);\n+\n+        PlanOptimizer optimizer = new MyPlanOptimizer(newLogicalPlan, 10);\n+        optimizer.optimize();\n+\n+        lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(\"b = filter (load 'd.txt' as (a:chararray, b:long, c:map[], d:chararray, e:chararray)) by a == 'v' and b == 117L and c#'p1' == 'h' and c#'p2' == 'to' and ((d is not null and d != '') or (e is not null and e != ''));\"); \n+        plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan expected = migratePlan(plan);\n+\n+        assertTrue(expected.isEqual(newLogicalPlan));\n+\n+        // mirror of the above\n+        lpt.buildPlan(\"b = filter (load 'd.txt' as (a:chararray, b:long, c:map[], d:chararray, e:chararray)) by ((d is not null and d != '') or (e is not null and e != '')) and a == 'v' and b == 117L and c#'p1' == 'h' and c#'p2' == 'to';\"); \n+\n+        plan = lpt.buildPlan(\"store b into 'empty';\");\n+        newLogicalPlan = migratePlan(plan);\n+\n+        optimizer = new MyPlanOptimizer(newLogicalPlan, 10);\n+        optimizer.optimize();\n+\n+        lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(\"b = filter (load 'd.txt' as (a:chararray, b:long, c:map[], d:chararray, e:chararray)) by ((d is not null and d != '') or (e is not null and e != '')) and a == 'v' and b == 117L and c#'p1' == 'h' and c#'p2' == 'to';\"); \n+        plan = lpt.buildPlan(\"store b into 'empty';\");\n+        expected = migratePlan(plan);\n+\n+        assertTrue(expected.isEqual(newLogicalPlan));\n+\n+    }\n+\n+    @Test\n+    public void test5() throws Exception {\n+        // 2-level combo: 8 possibilities\n+        boolean[] booleans = {false, true};\n+        for (boolean b1 : booleans)\n+        for (boolean b2 : booleans)\n+        for (boolean b3 : booleans)\n+            comboRunner2(b1, b2, b3);\n+    }\n+\n+    private void comboRunner2(boolean b1, boolean b2, boolean b3) throws Exception {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(\"b = filter (load 'd.txt' as (a:int, b:int, c:int, d:int)) by (((a < 1) \" + (b1 ? \"and\" : \"or\") + \" (b < 2)) \" + (b2 ? \"and\" : \"or\") + \" ((c < 3) \" + (b3 ? \"and\" : \"or\") + \" (d < 4)));\");  \n+        String query = sb.toString();\n+\n+        LogicalPlanTester lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(query); \n+\n+        org.apache.pig.impl.logicalLayer.LogicalPlan plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan newLogicalPlan = migratePlan(plan);\n+\n+        PlanOptimizer optimizer = new MyPlanOptimizer(newLogicalPlan, 10);\n+        optimizer.optimize();\n+\n+        lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(query); \n+        plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan expected = migratePlan(plan);\n+\n+        assertTrue(expected.isEqual(newLogicalPlan));\n+    }\n+\n+    @Test\n+    public void test6() throws Exception {\n+        // 3-level combo: 128 possibilities\n+        boolean[] booleans = {false, true};\n+        for (boolean b1 : booleans)\n+        for (boolean b2 : booleans)\n+        for (boolean b3 : booleans)\n+        for (boolean b4 : booleans)\n+        for (boolean b5 : booleans)\n+        for (boolean b6 : booleans)\n+        for (boolean b7 : booleans)\n+            comboRunner3(b1, b2, b3, b4, b5, b6, b7);\n+    }\n+\n+    private void comboRunner3(boolean b1, boolean b2, boolean b3, boolean b4, boolean b5, boolean b6, boolean b7) throws Exception {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(\"b = filter (load 'd.txt' as (a:int, b:int, c:int, d:int, e:int, f:int, g:int, h:int)) by ((((a < 1) \" + (b1 ? \"and\" : \"or\") + \" (b < 2)) \" + (b2 ? \"and\" : \"or\") + \" ((c < 3) \" + (b3 ? \"and\" : \"or\") + \" (d < 4))) \" + (b4 ? \"and\" : \"or\") + \" (((e < 5) \" + (b5 ? \"and\" : \"or\") + \" (f < 6)) \" + (b6 ? \"and\" : \"or\") + \" ((g < 7) \" + (b7 ? \"and\" : \"or\") + \" (h < 8))));\");  \n+        String query = sb.toString();\n+\n+        LogicalPlanTester lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(query); \n+\n+        org.apache.pig.impl.logicalLayer.LogicalPlan plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan newLogicalPlan = migratePlan(plan);\n+\n+        PlanOptimizer optimizer = new MyPlanOptimizer(newLogicalPlan, 10);\n+        optimizer.optimize();\n+\n+        lpt = new LogicalPlanTester(pc);\n+        lpt.buildPlan(query); \n+        plan = lpt.buildPlan(\"store b into 'empty';\");\n+        LogicalPlan expected = migratePlan(plan);\n+\n+        assertTrue(expected.isEqual(newLogicalPlan));\n+    }\n+\n     public class MyPlanOptimizer extends LogicalPlanOptimizer {\n \n         protected MyPlanOptimizer(OperatorPlan p, int iterations) {",
                "additions": 104,
                "raw_url": "https://github.com/apache/pig/raw/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/test/org/apache/pig/test/TestFilterSimplification.java",
                "status": "modified",
                "changes": 104,
                "deletions": 0,
                "sha": "73773e7e061133cc51c8f26b2fe7fec85dbc4148",
                "blob_url": "https://github.com/apache/pig/blob/f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd/test/org/apache/pig/test/TestFilterSimplification.java",
                "filename": "test/org/apache/pig/test/TestFilterSimplification.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestFilterSimplification.java?ref=f8c3ad6ea19798e28de4c5bc8d76b05beb17acfd"
            }
        ],
        "bug_id": "pig_46",
        "parent": "https://github.com/apache/pig/commit/46abdac090dad98b87b33b8d9663c897354bf64d",
        "message": "PIG-1647: Logical simplifier throws a NPE (yanz)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@1001838 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/1d64916466db0da7c57a00a49f3235e7b190a074",
        "file": [
            {
                "patch": "@@ -44,6 +44,8 @@ PIG-626: Add access to hadoop counters (shubhamc via gates).\n \n BUG FIXES\n \n+PIG-810: Fixed NPE in PigStats (gates)\n+\n PIG-804: problem with lineage with double map redirection (pradeepkth)\n \n PIG-733: Order by sampling dumps entire sample to hdfs which causes dfs",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/1d64916466db0da7c57a00a49f3235e7b190a074/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "7175634f5ea7e879154ab9c4e3b01273594f21fe",
                "blob_url": "https://github.com/apache/pig/blob/1d64916466db0da7c57a00a49f3235e7b190a074/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=1d64916466db0da7c57a00a49f3235e7b190a074"
            },
            {
                "patch": "@@ -172,7 +172,7 @@ else if(mode == ExecType.LOCAL)\n             \n         }\n         \n-        lastJobID = lastJob.getAssignedJobID().toString();\n+        if (lastJob != null) lastJobID = lastJob.getAssignedJobID().toString();\n         return stats;\n     }\n     ",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/1d64916466db0da7c57a00a49f3235e7b190a074/src/org/apache/pig/tools/pigstats/PigStats.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "f0b87c7074e838c8a3fd0cb4aedc9a874f71ce09",
                "blob_url": "https://github.com/apache/pig/blob/1d64916466db0da7c57a00a49f3235e7b190a074/src/org/apache/pig/tools/pigstats/PigStats.java",
                "filename": "src/org/apache/pig/tools/pigstats/PigStats.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/tools/pigstats/PigStats.java?ref=1d64916466db0da7c57a00a49f3235e7b190a074"
            }
        ],
        "bug_id": "pig_47",
        "parent": "https://github.com/apache/pig/commit/6c0cdfeb9d2daf997df8ccea091873706ef3b160",
        "message": "PIG-810: Fixed NPE in PigStats (gates)\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@774989 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/b62527494a73749811cde80e3a1e2d7841cc8cec",
        "file": [
            {
                "patch": "@@ -265,6 +265,8 @@ PIG-2228: support partial aggregation in map task (thejas)\n \n BUG FIXES\n \n+PIG-2509: Util.getSchemaFromString fails with java.lang.NullPointerException when a tuple in a bag has no name (as when used in MongoStorage UDF) (jcoveney via daijy)\n+\n PIG-2559: Embedded pig in python; invoking sys.exit(0) causes script failure (vivekp via daijy)\n \n PIG-2530: Reusing alias name in nested foreach causes incorrect results (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/b62527494a73749811cde80e3a1e2d7841cc8cec/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "869464ef5367693903aa6fef4f5bdce9cd0a2ea6",
                "blob_url": "https://github.com/apache/pig/blob/b62527494a73749811cde80e3a1e2d7841cc8cec/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=b62527494a73749811cde80e3a1e2d7841cc8cec"
            },
            {
                "patch": "@@ -315,7 +315,9 @@ tuple_type : TUPLE? LEFT_PAREN field_def_list? RIGHT_PAREN\n           -> ^( TUPLE_TYPE field_def_list? )\n ;\n \n-bag_type : BAG? LEFT_CURLY ( ( identifier COLON )? tuple_type )? RIGHT_CURLY\n+bag_type : BAG? LEFT_CURLY ( null_keyword COLON tuple_type? ) RIGHT_CURLY\n+        -> ^( BAG_TYPE tuple_type? )\n+         | BAG? LEFT_CURLY ( ( identifier COLON )? tuple_type )? RIGHT_CURLY\n         -> ^( BAG_TYPE identifier? tuple_type? )\n ;\n ",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/b62527494a73749811cde80e3a1e2d7841cc8cec/src/org/apache/pig/parser/QueryParser.g",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "b6ba421f3e6763989097200033685a8ef8fe25a2",
                "blob_url": "https://github.com/apache/pig/blob/b62527494a73749811cde80e3a1e2d7841cc8cec/src/org/apache/pig/parser/QueryParser.g",
                "filename": "src/org/apache/pig/parser/QueryParser.g",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/parser/QueryParser.g?ref=b62527494a73749811cde80e3a1e2d7841cc8cec"
            },
            {
                "patch": "@@ -882,7 +882,8 @@ public void testGetStringFromSchema() throws ParserException {\n             \"a:double,b:float,t:tuple(x:int,b:bag{t:tuple(a:int,b:float,c:double,x:tuple(z:bag{r:tuple(z:bytearray)}))},z:bytearray)\",\n             \"a,b,t:tuple(x,b:bag{t:tuple(a,b,c,x:tuple(z:bag{r:tuple(z)}))},z)\",\n             \"a:bag{t:tuple(a:bag{t:tuple(a:bag{t:tuple(a:bag{t:tuple(a:bag{t:tuple(a:bag{t:tuple(a:int,b:float)})})})})})}\",\n-            \"a:bag{}\"\n+            \"a:bag{}\",\n+            \"b:{null:(a:int)}\"\n         };\n         for (String schemaString : schemaStrings) {\n             Schema s1 = Utils.getSchemaFromString(schemaString);",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/b62527494a73749811cde80e3a1e2d7841cc8cec/test/org/apache/pig/test/TestSchema.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "38b6821eee13dc0f9ca9e1e46b17da55ffac4b6a",
                "blob_url": "https://github.com/apache/pig/blob/b62527494a73749811cde80e3a1e2d7841cc8cec/test/org/apache/pig/test/TestSchema.java",
                "filename": "test/org/apache/pig/test/TestSchema.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestSchema.java?ref=b62527494a73749811cde80e3a1e2d7841cc8cec"
            }
        ],
        "bug_id": "pig_48",
        "parent": "https://github.com/apache/pig/commit/6456599ef063468a5640bb38b6f54b700babe7e3",
        "message": "PIG-2509: Util.getSchemaFromString fails with java.lang.NullPointerException when a tuple in a bag has no name (as when used in MongoStorage UDF)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1295994 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/72c1c418f346ea777be91ed5f6534a039526dda1",
        "file": [
            {
                "patch": "@@ -62,6 +62,8 @@ PIG-4333: Split BigData tests into multiple groups (rohini)\n  \n BUG FIXES\n \n+PIG-4503: [Pig on Tez] NPE in UnionOptimizer with multiple levels of union (rohini)\n+\n PIG-4509: [Pig on Tez] Unassigned applications not killed on shutdown (rohini)\n \n PIG-4508: [Pig on Tez] PigProcessor check for commit only on MROutput (rohini)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "6c2882643ac34c27173202e604b37f2e9d984fb1",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -153,13 +153,15 @@ public void visitTezOp(TezOperator tezOp) throws VisitorException {\n             TezOperator existingVertexGroup = null;\n             if (successors != null) {\n                 for (TezOperator succ : successors) {\n-                    if (succ.isVertexGroup() && succ.getVertexGroupInfo().getSFile().equals(unionStoreOutputs.get(i).getSFile())) {\n+                    if (succ.isVertexGroup() && unionStoreOutputs.get(i).getSFile().equals(succ.getVertexGroupInfo().getSFile())) {\n                         existingVertexGroup = succ;\n                     }\n                 }\n             }\n             if (existingVertexGroup != null) {\n                 storeVertexGroupOps[i] = existingVertexGroup;\n+                existingVertexGroup.getVertexGroupMembers().remove(unionOp.getOperatorKey());\n+                existingVertexGroup.getVertexGroupInfo().removeInput(unionOp.getOperatorKey());\n             } else {\n                 storeVertexGroupOps[i] = new TezOperator(OperatorKey.genOpKey(scope));\n                 storeVertexGroupOps[i].setVertexGroupInfo(new VertexGroupInfo(unionStoreOutputs.get(i)));\n@@ -471,8 +473,8 @@ private void connectVertexGroupsToSuccessors(TezOperator unionOp,\n             TezOperator succOpVertexGroup = null;\n             for (TezOperator succ : successors) {\n                 if (succ.isVertexGroup()\n-                        && succ.getVertexGroupInfo().getOutput()\n-                                .equals(succOp.getOperatorKey().toString())) {\n+                        && succOp.getOperatorKey().toString()\n+                                .equals(succ.getVertexGroupInfo().getOutput())) {\n                     succOpVertexGroup = succ;\n                     break;\n                 }",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "status": "modified",
                "changes": 8,
                "deletions": 3,
                "sha": "41bddcfb8055737fcd455b6488a24c529d07d137",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -4,16 +4,16 @@\n #--------------------------------------------------\n # TEZ DAG plan: pig-0_scope-0\n #--------------------------------------------------\n-Tez vertex scope-31\t->\tTez vertex scope-33,\n-Tez vertex scope-32\t->\tTez vertex scope-33,\n-Tez vertex scope-33\t->\tTez vertex scope-38,\n-Tez vertex scope-37\t->\tTez vertex scope-38,\n-Tez vertex scope-38\t->\tTez vertex scope-42,\n-Tez vertex scope-42\n+Tez vertex scope-37\t->\tTez vertex scope-39,\n+Tez vertex scope-38\t->\tTez vertex scope-39,\n+Tez vertex scope-39\t->\tTez vertex scope-44,\n+Tez vertex scope-43\t->\tTez vertex scope-44,\n+Tez vertex scope-44\t->\tTez vertex scope-53,\n+Tez vertex scope-53\n \n-Tez vertex scope-31\n+Tez vertex scope-37\n # Plan on vertex\n-POValueOutputTez - scope-35\t->\t [scope-33]\n+POValueOutputTez - scope-41\t->\t [scope-39]\n |\n |---a: New For Each(false,false)[bag] - scope-7\n     |   |\n@@ -26,9 +26,9 @@ POValueOutputTez - scope-35\t->\t [scope-33]\n     |   |---Project[bytearray][1] - scope-4\n     |\n     |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0\n-Tez vertex scope-32\n+Tez vertex scope-38\n # Plan on vertex\n-POValueOutputTez - scope-36\t->\t [scope-33]\n+POValueOutputTez - scope-42\t->\t [scope-39]\n |\n |---c: New For Each(false,false)[bag] - scope-15\n     |   |\n@@ -41,14 +41,14 @@ POValueOutputTez - scope-36\t->\t [scope-33]\n     |   |---Project[bytearray][0] - scope-12\n     |\n     |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-8\n-Tez vertex scope-33\n+Tez vertex scope-39\n # Plan on vertex\n-POValueOutputTez - scope-40\t->\t [scope-38]\n+POValueOutputTez - scope-46\t->\t [scope-44]\n |\n-|---POShuffledValueInputTez - scope-34\t<-\t [scope-31, scope-32]\n-Tez vertex scope-37\n+|---POShuffledValueInputTez - scope-40\t<-\t [scope-37, scope-38]\n+Tez vertex scope-43\n # Plan on vertex\n-POValueOutputTez - scope-41\t->\t [scope-38]\n+POValueOutputTez - scope-47\t->\t [scope-44]\n |\n |---d: New For Each(false,false)[bag] - scope-24\n     |   |\n@@ -61,15 +61,19 @@ POValueOutputTez - scope-41\t->\t [scope-38]\n     |   |---Project[bytearray][1] - scope-21\n     |\n     |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-17\n-Tez vertex scope-38\n+Tez vertex scope-44\n # Plan on vertex\n-f: Local Rearrange[tuple]{int}(false) - scope-28\t->\t scope-42\n+e: Split - scope-54\n+|   |\n+|   e: Store(file:///tmp/output1:org.apache.pig.builtin.PigStorage) - scope-29\n |   |\n-|   Project[int][0] - scope-29\n+|   f: Local Rearrange[tuple]{int}(false) - scope-34\t->\t scope-53\n+|   |   |\n+|   |   Project[int][0] - scope-35\n |\n-|---POShuffledValueInputTez - scope-39\t<-\t [scope-33, scope-37]\n-Tez vertex scope-42\n+|---POShuffledValueInputTez - scope-45\t<-\t [scope-39, scope-43]\n+Tez vertex scope-53\n # Plan on vertex\n-f: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-30\n+f: Store(file:///tmp/output2:org.apache.pig.builtin.PigStorage) - scope-36\n |\n-|---f: Package(Packager)[tuple]{int} - scope-27\n+|---f: Package(Packager)[tuple]{int} - scope-33",
                "additions": 26,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10-OPTOFF.gld",
                "status": "modified",
                "changes": 48,
                "deletions": 22,
                "sha": "3fc7248cd795009ff1a7129bef5c40ce83b99a5f",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10-OPTOFF.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10-OPTOFF.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10-OPTOFF.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -4,17 +4,22 @@\n #--------------------------------------------------\n # TEZ DAG plan: pig-0_scope-0\n #--------------------------------------------------\n-Tez vertex scope-37\t->\tTez vertex group scope-43,\n-Tez vertex scope-31\t->\tTez vertex group scope-43,\n-Tez vertex scope-32\t->\tTez vertex group scope-43,\n-Tez vertex group scope-43\t->\tTez vertex scope-42,\n-Tez vertex scope-42\n+Tez vertex scope-43\t->\tTez vertex group scope-55,Tez vertex group scope-56,\n+Tez vertex scope-37\t->\tTez vertex group scope-55,Tez vertex group scope-56,\n+Tez vertex scope-38\t->\tTez vertex group scope-55,Tez vertex group scope-56,\n+Tez vertex group scope-56\t->\tTez vertex scope-53,\n+Tez vertex scope-53\n+Tez vertex group scope-55\n \n-Tez vertex scope-37\n+Tez vertex scope-43\n # Plan on vertex\n-f: Local Rearrange[tuple]{int}(false) - scope-46\t->\t scope-42\n+e: Split - scope-61\n+|   |\n+|   e: Store(file:///tmp/output1:org.apache.pig.builtin.PigStorage) - scope-62\t->\t scope-29\n |   |\n-|   Project[int][0] - scope-47\n+|   f: Local Rearrange[tuple]{int}(false) - scope-63\t->\t scope-53\n+|   |   |\n+|   |   Project[int][0] - scope-64\n |\n |---d: New For Each(false,false)[bag] - scope-24\n     |   |\n@@ -27,11 +32,15 @@ f: Local Rearrange[tuple]{int}(false) - scope-46\t->\t scope-42\n     |   |---Project[bytearray][1] - scope-21\n     |\n     |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-17\n-Tez vertex scope-31\n+Tez vertex scope-37\n # Plan on vertex\n-f: Local Rearrange[tuple]{int}(false) - scope-49\t->\t scope-42\n+e: Split - scope-66\n |   |\n-|   Project[int][0] - scope-50\n+|   e: Store(file:///tmp/output1:org.apache.pig.builtin.PigStorage) - scope-67\t->\t scope-29\n+|   |\n+|   f: Local Rearrange[tuple]{int}(false) - scope-68\t->\t scope-53\n+|   |   |\n+|   |   Project[int][0] - scope-69\n |\n |---a: New For Each(false,false)[bag] - scope-7\n     |   |\n@@ -44,11 +53,15 @@ f: Local Rearrange[tuple]{int}(false) - scope-49\t->\t scope-42\n     |   |---Project[bytearray][1] - scope-4\n     |\n     |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0\n-Tez vertex scope-32\n+Tez vertex scope-38\n # Plan on vertex\n-f: Local Rearrange[tuple]{int}(false) - scope-51\t->\t scope-42\n+e: Split - scope-70\n+|   |\n+|   e: Store(file:///tmp/output1:org.apache.pig.builtin.PigStorage) - scope-71\t->\t scope-29\n |   |\n-|   Project[int][0] - scope-52\n+|   f: Local Rearrange[tuple]{int}(false) - scope-72\t->\t scope-53\n+|   |   |\n+|   |   Project[int][0] - scope-73\n |\n |---c: New For Each(false,false)[bag] - scope-15\n     |   |\n@@ -61,10 +74,12 @@ f: Local Rearrange[tuple]{int}(false) - scope-51\t->\t scope-42\n     |   |---Project[bytearray][0] - scope-12\n     |\n     |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-8\n-Tez vertex group scope-43\t<-\t [scope-37, scope-31, scope-32]\t->\t scope-42\n+Tez vertex group scope-56\t<-\t [scope-43, scope-37, scope-38]\t->\t scope-53\n # No plan on vertex group\n-Tez vertex scope-42\n+Tez vertex scope-53\n # Plan on vertex\n-f: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-30\n+f: Store(file:///tmp/output2:org.apache.pig.builtin.PigStorage) - scope-36\n |\n-|---f: Package(Packager)[tuple]{int} - scope-27\n+|---f: Package(Packager)[tuple]{int} - scope-33\n+Tez vertex group scope-55\t<-\t [scope-43, scope-37, scope-38]\t->\t null\n+# No plan on vertex group",
                "additions": 33,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "status": "modified",
                "changes": 51,
                "deletions": 18,
                "sha": "dfcc8e7fee0d026e06753ef573fb6e2686289f9a",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -54,5 +54,5 @@ e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-42\t->\t sc\n     |   |---Project[bytearray][0] - scope-12\n     |\n     |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-8\n-Tez vertex group scope-38\t<-\t [scope-29, scope-33, scope-27, scope-28]\t->\t null\n+Tez vertex group scope-38\t<-\t [scope-33, scope-27, scope-28]\t->\t null\n # No plan on vertex group",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-11.gld",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "aca935cb452377018ec5049345832af4df998f41",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-11.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-11.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-11.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -0,0 +1,87 @@\n+#--------------------------------------------------\n+# There are 1 DAGs in the session\n+#--------------------------------------------------\n+#--------------------------------------------------\n+# TEZ DAG plan: pig-0_scope-0\n+#--------------------------------------------------\n+Tez vertex scope-44\t->\tTez vertex scope-45,Tez vertex scope-46,\n+Tez vertex scope-45\t->\tTez vertex scope-47,\n+Tez vertex scope-46\t->\tTez vertex scope-47,\n+Tez vertex scope-47\n+\n+Tez vertex scope-44\n+# Plan on vertex\n+POValueOutputTez - scope-51\t->\t [scope-45, scope-46]\n+|\n+|---d: New For Each(false,false)[bag] - scope-15\n+    |   |\n+    |   Cast[int] - scope-10\n+    |   |\n+    |   |---Project[bytearray][0] - scope-9\n+    |   |\n+    |   Cast[chararray] - scope-13\n+    |   |\n+    |   |---Project[bytearray][1] - scope-12\n+    |\n+    |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-8\n+Tez vertex scope-45\n+# Plan on vertex\n+POValueOutputTez - scope-49\t->\t [scope-47]\n+|\n+|---e: Filter[bag] - scope-17\n+    |   |\n+    |   Equal To[boolean] - scope-22\n+    |   |\n+    |   |---Project[int][0] - scope-18\n+    |   |\n+    |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-21\n+    |       |\n+    |       |---Constant(0) - scope-19\n+    |\n+    |---a: New For Each(false,false)[bag] - scope-7\n+        |   |\n+        |   Cast[int] - scope-2\n+        |   |\n+        |   |---Project[bytearray][0] - scope-1\n+        |   |\n+        |   Cast[chararray] - scope-5\n+        |   |\n+        |   |---Project[bytearray][1] - scope-4\n+        |\n+        |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0\n+Tez vertex scope-46\n+# Plan on vertex\n+POValueOutputTez - scope-50\t->\t [scope-47]\n+|\n+|---c: New For Each(false,false)[bag] - scope-41\n+    |   |\n+    |   Project[int][1] - scope-37\n+    |   |\n+    |   Project[chararray][0] - scope-39\n+    |\n+    |---Filter[bag] - scope-31\n+        |   |\n+        |   Equal To[boolean] - scope-36\n+        |   |\n+        |   |---Project[int][1] - scope-32\n+        |   |\n+        |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-35\n+        |       |\n+        |       |---Constant(0) - scope-33\n+        |\n+        |---b: New For Each(false,false)[bag] - scope-30\n+            |   |\n+            |   Cast[chararray] - scope-25\n+            |   |\n+            |   |---Project[bytearray][0] - scope-24\n+            |   |\n+            |   Cast[int] - scope-28\n+            |   |\n+            |   |---Project[bytearray][1] - scope-27\n+            |\n+            |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-23\n+Tez vertex scope-47\n+# Plan on vertex\n+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-43\n+|\n+|---POShuffledValueInputTez - scope-48\t<-\t [scope-45, scope-46]",
                "additions": 87,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17-OPTOFF.gld",
                "status": "added",
                "changes": 87,
                "deletions": 0,
                "sha": "87f8efe0c1c8ad05f3059318d32970cf518639ba",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17-OPTOFF.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17-OPTOFF.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17-OPTOFF.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -0,0 +1,84 @@\n+#--------------------------------------------------\n+# There are 1 DAGs in the session\n+#--------------------------------------------------\n+#--------------------------------------------------\n+# TEZ DAG plan: pig-0_scope-0\n+#--------------------------------------------------\n+Tez vertex scope-44\t->\tTez vertex scope-45,Tez vertex scope-46,\n+Tez vertex scope-45\t->\tTez vertex group scope-52,\n+Tez vertex scope-46\t->\tTez vertex group scope-52,\n+Tez vertex group scope-52\n+\n+Tez vertex scope-44\n+# Plan on vertex\n+POValueOutputTez - scope-51\t->\t [scope-45, scope-46]\n+|\n+|---d: New For Each(false,false)[bag] - scope-15\n+    |   |\n+    |   Cast[int] - scope-10\n+    |   |\n+    |   |---Project[bytearray][0] - scope-9\n+    |   |\n+    |   Cast[chararray] - scope-13\n+    |   |\n+    |   |---Project[bytearray][1] - scope-12\n+    |\n+    |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-8\n+Tez vertex scope-45\n+# Plan on vertex\n+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-53\t->\t scope-43\n+|\n+|---e: Filter[bag] - scope-17\n+    |   |\n+    |   Equal To[boolean] - scope-22\n+    |   |\n+    |   |---Project[int][0] - scope-18\n+    |   |\n+    |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-21\n+    |       |\n+    |       |---Constant(0) - scope-19\n+    |\n+    |---a: New For Each(false,false)[bag] - scope-7\n+        |   |\n+        |   Cast[int] - scope-2\n+        |   |\n+        |   |---Project[bytearray][0] - scope-1\n+        |   |\n+        |   Cast[chararray] - scope-5\n+        |   |\n+        |   |---Project[bytearray][1] - scope-4\n+        |\n+        |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0\n+Tez vertex scope-46\n+# Plan on vertex\n+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-54\t->\t scope-43\n+|\n+|---c: New For Each(false,false)[bag] - scope-41\n+    |   |\n+    |   Project[int][1] - scope-37\n+    |   |\n+    |   Project[chararray][0] - scope-39\n+    |\n+    |---Filter[bag] - scope-31\n+        |   |\n+        |   Equal To[boolean] - scope-36\n+        |   |\n+        |   |---Project[int][1] - scope-32\n+        |   |\n+        |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-35\n+        |       |\n+        |       |---Constant(0) - scope-33\n+        |\n+        |---b: New For Each(false,false)[bag] - scope-30\n+            |   |\n+            |   Cast[chararray] - scope-25\n+            |   |\n+            |   |---Project[bytearray][0] - scope-24\n+            |   |\n+            |   Cast[int] - scope-28\n+            |   |\n+            |   |---Project[bytearray][1] - scope-27\n+            |\n+            |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-23\n+Tez vertex group scope-52\t<-\t [scope-45, scope-46]\t->\t null\n+# No plan on vertex group",
                "additions": 84,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17.gld",
                "status": "added",
                "changes": 84,
                "deletions": 0,
                "sha": "8be94ab46ec8cd59ac8262c08e15b58bded9eba7",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -0,0 +1,71 @@\n+#--------------------------------------------------\n+# There are 1 DAGs in the session\n+#--------------------------------------------------\n+#--------------------------------------------------\n+# TEZ DAG plan: pig-0_scope-0\n+#--------------------------------------------------\n+Tez vertex scope-33\t->\tTez vertex scope-35,\n+Tez vertex scope-34\t->\tTez vertex scope-35,\n+Tez vertex scope-35\t->\tTez vertex scope-39,\n+Tez vertex scope-39\n+\n+Tez vertex scope-33\n+# Plan on vertex\n+POValueOutputTez - scope-37\t->\t [scope-35]\n+|\n+|---a: New For Each(false,false)[bag] - scope-15\n+    |   |\n+    |   Cast[int] - scope-10\n+    |   |\n+    |   |---Project[bytearray][0] - scope-9\n+    |   |\n+    |   Cast[chararray] - scope-13\n+    |   |\n+    |   |---Project[bytearray][1] - scope-12\n+    |\n+    |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-8\n+Tez vertex scope-34\n+# Plan on vertex\n+POValueOutputTez - scope-38\t->\t [scope-35]\n+|\n+|---c: New For Each(false,false)[bag] - scope-23\n+    |   |\n+    |   Cast[int] - scope-18\n+    |   |\n+    |   |---Project[bytearray][1] - scope-17\n+    |   |\n+    |   Cast[chararray] - scope-21\n+    |   |\n+    |   |---Project[bytearray][0] - scope-20\n+    |\n+    |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-16\n+Tez vertex scope-35\n+# Plan on vertex\n+POValueOutputTez - scope-40\t->\t [scope-39]\n+|\n+|---POShuffledValueInputTez - scope-36\t<-\t [scope-33, scope-34]\n+Tez vertex scope-39\n+# Plan on vertex\n+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-32\n+|\n+|---e: Filter[bag] - scope-26\n+    |   |\n+    |   Equal To[boolean] - scope-31\n+    |   |\n+    |   |---Project[int][0] - scope-27\n+    |   |\n+    |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-30\n+    |       |\n+    |       |---Constant(0) - scope-28\n+    |\n+    |---d: New For Each(false,false)[bag] - scope-7\n+        |   |\n+        |   Cast[int] - scope-2\n+        |   |\n+        |   |---Project[bytearray][0] - scope-1\n+        |   |\n+        |   Cast[chararray] - scope-5\n+        |   |\n+        |   |---Project[bytearray][1] - scope-4\n+        |\n+        |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-0",
                "additions": 71,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18-OPTOFF.gld",
                "status": "added",
                "changes": 71,
                "deletions": 0,
                "sha": "d63afeadbe7491c9b274dafc1368fab110e5ddc0",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18-OPTOFF.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18-OPTOFF.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18-OPTOFF.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -0,0 +1,68 @@\n+#--------------------------------------------------\n+# There are 1 DAGs in the session\n+#--------------------------------------------------\n+#--------------------------------------------------\n+# TEZ DAG plan: pig-0_scope-0\n+#--------------------------------------------------\n+Tez vertex scope-33\t->\tTez vertex group scope-41,\n+Tez vertex scope-34\t->\tTez vertex group scope-41,\n+Tez vertex group scope-41\t->\tTez vertex scope-39,\n+Tez vertex scope-39\n+\n+Tez vertex scope-33\n+# Plan on vertex\n+POValueOutputTez - scope-42\t->\t [scope-39]\n+|\n+|---a: New For Each(false,false)[bag] - scope-15\n+    |   |\n+    |   Cast[int] - scope-10\n+    |   |\n+    |   |---Project[bytearray][0] - scope-9\n+    |   |\n+    |   Cast[chararray] - scope-13\n+    |   |\n+    |   |---Project[bytearray][1] - scope-12\n+    |\n+    |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-8\n+Tez vertex scope-34\n+# Plan on vertex\n+POValueOutputTez - scope-43\t->\t [scope-39]\n+|\n+|---c: New For Each(false,false)[bag] - scope-23\n+    |   |\n+    |   Cast[int] - scope-18\n+    |   |\n+    |   |---Project[bytearray][1] - scope-17\n+    |   |\n+    |   Cast[chararray] - scope-21\n+    |   |\n+    |   |---Project[bytearray][0] - scope-20\n+    |\n+    |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-16\n+Tez vertex group scope-41\t<-\t [scope-33, scope-34]\t->\t scope-39\n+# No plan on vertex group\n+Tez vertex scope-39\n+# Plan on vertex\n+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-32\n+|\n+|---e: Filter[bag] - scope-26\n+    |   |\n+    |   Equal To[boolean] - scope-31\n+    |   |\n+    |   |---Project[int][0] - scope-27\n+    |   |\n+    |   |---POUserFunc(org.apache.pig.backend.hadoop.executionengine.tez.plan.udf.ReadScalarsTez)[int] - scope-30\n+    |       |\n+    |       |---Constant(0) - scope-28\n+    |\n+    |---d: New For Each(false,false)[bag] - scope-7\n+        |   |\n+        |   Cast[int] - scope-2\n+        |   |\n+        |   |---Project[bytearray][0] - scope-1\n+        |   |\n+        |   Cast[chararray] - scope-5\n+        |   |\n+        |   |---Project[bytearray][1] - scope-4\n+        |\n+        |---d: Load(file:///tmp/input1:org.apache.pig.builtin.PigStorage) - scope-0",
                "additions": 68,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18.gld",
                "status": "added",
                "changes": 68,
                "deletions": 0,
                "sha": "5c32197613d818b53bed4662ebeb98857f464fe0",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18.gld",
                "filename": "test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18.gld",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18.gld?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            },
            {
                "patch": "@@ -618,13 +618,15 @@ public void testUnionUnion() throws Exception {\n                 \"d = load 'file:///tmp/input1' as (x:int, y:chararray);\" +\n                 \"e = union onschema c, d;\" +\n                 \"f = group e by x;\" +\n-                \"store f into 'file:///tmp/output';\";\n+                \"store e into 'file:///tmp/output1';\" +\n+                \"store f into 'file:///tmp/output2';\";\n \n         setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + true);\n         run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10.gld\");\n         resetScope();\n         setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + false);\n         run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-10-OPTOFF.gld\");\n+\n     }\n \n     @Test\n@@ -732,6 +734,38 @@ public void testUnionSplitSkewedJoin() throws Exception {\n         run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-16-OPTOFF.gld\");\n     }\n \n+    @Test\n+    public void testUnionScalar() throws Exception {\n+        String query =\n+                \"a = load 'file:///tmp/input' as (x:int, y:chararray);\" +\n+                \"b = load 'file:///tmp/input' as (y:chararray, x:int);\" +\n+                \"c = union onschema a, b;\" +\n+                \"d = load 'file:///tmp/input1' as (x:int, z:chararray);\" +\n+                \"e = filter c by x == d.x;\" +\n+                \"store e into 'file:///tmp/output';\";\n+\n+        setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + true);\n+        run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17.gld\");\n+        resetScope();\n+        setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + false);\n+        run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-17-OPTOFF.gld\");\n+\n+        query =\n+                \"a = load 'file:///tmp/input' as (x:int, y:chararray);\" +\n+                \"b = load 'file:///tmp/input' as (y:chararray, x:int);\" +\n+                \"c = union onschema a, b;\" +\n+                \"d = load 'file:///tmp/input1' as (x:int, z:chararray);\" +\n+                \"e = filter d by x == c.x;\" +\n+                \"store e into 'file:///tmp/output';\";\n+\n+        resetScope();\n+        setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + true);\n+        run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18.gld\");\n+        resetScope();\n+        setProperty(PigConfiguration.PIG_TEZ_OPT_UNION, \"\" + false);\n+        run(query, \"test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-18-OPTOFF.gld\");\n+    }\n+\n     @Test\n     public void testRank() throws Exception {\n         String query =",
                "additions": 35,
                "raw_url": "https://github.com/apache/pig/raw/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/tez/TestTezCompiler.java",
                "status": "modified",
                "changes": 36,
                "deletions": 1,
                "sha": "d42a27f124947fd961f93007c7444a95482272fc",
                "blob_url": "https://github.com/apache/pig/blob/72c1c418f346ea777be91ed5f6534a039526dda1/test/org/apache/pig/tez/TestTezCompiler.java",
                "filename": "test/org/apache/pig/tez/TestTezCompiler.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/tez/TestTezCompiler.java?ref=72c1c418f346ea777be91ed5f6534a039526dda1"
            }
        ],
        "bug_id": "pig_49",
        "parent": "https://github.com/apache/pig/commit/f54829f022c922315de4123ec54adeaac47594aa",
        "message": "PIG-4503: [Pig on Tez] NPE in UnionOptimizer with multiple levels of union (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1674348 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/4dc2910286badf25a3aa43c5ee78ee3cde306b84",
        "file": [
            {
                "patch": "@@ -92,6 +92,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4220: MapReduce-based Rank failing with NPE due to missing Counters (knoguchi)\n+\n PIG-3985: Multiquery execution of RANK with RANK BY causes NPE (rohini)\n \n PIG-4218: Pig OrcStorage fail to load a map with null key (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/4dc2910286badf25a3aa43c5ee78ee3cde306b84/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "30ba06b03fe0569a71be01bb557a99d6056c8e4a",
                "blob_url": "https://github.com/apache/pig/blob/4dc2910286badf25a3aa43c5ee78ee3cde306b84/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=4dc2910286badf25a3aa43c5ee78ee3cde306b84"
            },
            {
                "patch": "@@ -60,6 +60,13 @@ public void setup(Context context) throws IOException, InterruptedException {\n                     pOperator = mp.getPredecessors(pOperator).get(0);\n                 }\n             }\n+\n+            PigStatusReporter reporter = PigStatusReporter.getInstance();\n+            if (reporter != null) {\n+                reporter.incrCounter(\n+                        JobControlCompiler.PIG_MAP_RANK_NAME\n+                        + context.getJobID().toString(), taskID, 0);\n+            }\n         }\n \n         /**\n@@ -69,15 +76,11 @@ public void setup(Context context) throws IOException, InterruptedException {\n         public void collect(Context context, Tuple tuple)\n         throws InterruptedException, IOException {\n             context.write(null, tuple);\n-            try {\n-                PigStatusReporter reporter = PigStatusReporter.getInstance();\n-                if (reporter != null) {\n-                    reporter.incrCounter(\n-                            JobControlCompiler.PIG_MAP_RANK_NAME\n-                            + context.getJobID().toString(), taskID, 1);\n-                }\n-            } catch (Exception ex) {\n-                log.error(\"Error on incrementer of PigMapCounter\");\n+            PigStatusReporter reporter = PigStatusReporter.getInstance();\n+            if (reporter != null) {\n+                reporter.incrCounter(\n+                        JobControlCompiler.PIG_MAP_RANK_NAME\n+                        + context.getJobID().toString(), taskID, 1);\n             }\n         }\n     }\n@@ -116,6 +119,7 @@ protected void setup(Context context) throws IOException, InterruptedException {\n             }\n \n             this.context = context;\n+            incrementCounter(0L);\n         }\n \n         /**\n@@ -127,21 +131,14 @@ protected void setup(Context context) throws IOException, InterruptedException {\n          * @param increment is the value to add to the corresponding global counter.\n          **/\n         public static void incrementCounter(Long increment) {\n-            try {\n-                PigStatusReporter reporter = PigStatusReporter.getInstance();\n-                if (reporter != null) {\n-\n-                    if(leaf instanceof POCounter){\n-                        reporter.incrCounter(\n-                                JobControlCompiler.PIG_MAP_RANK_NAME\n-                                + context.getJobID().toString(), taskID, increment);\n-                    }\n-\n+            PigStatusReporter reporter = PigStatusReporter.getInstance();\n+            if (reporter != null) {\n+                if(leaf instanceof POCounter){\n+                    reporter.incrCounter(\n+                            JobControlCompiler.PIG_MAP_RANK_NAME\n+                            + context.getJobID().toString(), taskID, increment);\n                 }\n-            } catch (Exception ex) {\n-                log.error(\"Error on incrementer of PigReduceCounter\");\n             }\n-\n         }\n     }\n }",
                "additions": 19,
                "raw_url": "https://github.com/apache/pig/raw/4dc2910286badf25a3aa43c5ee78ee3cde306b84/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduceCounter.java",
                "status": "modified",
                "changes": 41,
                "deletions": 22,
                "sha": "38668bc2c0eca058318ab357a6bcb8143da14085",
                "blob_url": "https://github.com/apache/pig/blob/4dc2910286badf25a3aa43c5ee78ee3cde306b84/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduceCounter.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduceCounter.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduceCounter.java?ref=4dc2910286badf25a3aa43c5ee78ee3cde306b84"
            }
        ],
        "bug_id": "pig_50",
        "parent": "https://github.com/apache/pig/commit/8277042ff356c58c64cfcdaa0a590890a7de4ffd",
        "message": "PIG-4220: MapReduce-based Rank failing with NPE due to missing Counters (knoguchi)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1629766 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1",
        "file": [
            {
                "patch": "@@ -92,6 +92,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3985: Multiquery execution of RANK with RANK BY causes NPE (rohini)\n+\n PIG-4218: Pig OrcStorage fail to load a map with null key (daijy)\n \n PIG-4164: After Pig job finish, Pig client spend too much time retry to connect to AM (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "07a83a71c160b4d532cb5f65c76ec92294da039d",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -21,13 +21,15 @@\n import java.util.ArrayList;\n import java.util.HashSet;\n import java.util.Iterator;\n+import java.util.List;\n import java.util.Set;\n \n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROpPlanVisitor;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCounter;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;\n import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POUnion;\n import org.apache.pig.impl.plan.NodeIdGenerator;\n import org.apache.pig.impl.plan.Operator;\n@@ -523,23 +525,32 @@ public String getOperationID() {\n     }\n \n     private POCounter getCounterOperation() {\n-        PhysicalOperator operator;\n-        Iterator<PhysicalOperator> it =  this.mapPlan.getLeaves().iterator();\n-\n-        while(it.hasNext()) {\n-            operator = it.next();\n-            if(operator instanceof POCounter)\n-                return (POCounter) operator;\n+        POCounter counter = getCounterOperation(this.mapPlan);\n+        if (counter == null) {\n+            counter = getCounterOperation(this.reducePlan);\n         }\n+        return counter;\n+    }\n \n-        it =  this.reducePlan.getLeaves().iterator();\n+    private POCounter getCounterOperation(PhysicalPlan plan) {\n+        PhysicalOperator operator;\n+        Iterator<PhysicalOperator> it = plan.getLeaves().iterator();\n \n-        while(it.hasNext()) {\n+        while (it.hasNext()) {\n             operator = it.next();\n-            if(operator instanceof POCounter)\n+            if (operator instanceof POCounter) {\n                 return (POCounter) operator;\n+            } else if (operator instanceof POStore) {\n+                List<PhysicalOperator> preds = plan.getPredecessors(operator);\n+                if (preds != null) {\n+                    for (PhysicalOperator pred : preds) {\n+                        if (pred instanceof POCounter) {\n+                            return (POCounter) pred;\n+                        }\n+                    }\n+                }\n+            }\n         }\n-\n         return null;\n     }\n }",
                "additions": 22,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceOper.java",
                "status": "modified",
                "changes": 33,
                "deletions": 11,
                "sha": "b5611db44512b2b4765badb4fee81abe57c935c9",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceOper.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceOper.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceOper.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -121,6 +121,11 @@ public void visitMROp(MapReduceOper mr) throws VisitorException {\n                         + \" uses customPartitioner, do not merge it\");\n                 continue;\n             }\n+            if (successor.isCounterOperation()) {\n+                log.debug(\"Splittee \" + successor.getOperatorKey().getId()\n+                        + \" has POCounter, do not merge it\");\n+                continue;\n+            }\n             if (isMapOnly(successor)) {\n                 if (isSingleLoadMapperPlan(successor.mapPlan)\n                         && isSinglePredecessor(successor)) {",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MultiQueryOptimizer.java",
                "status": "modified",
                "changes": 5,
                "deletions": 0,
                "sha": "5331766a96d10831efd55a198a0eb6ad25a8ece0",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MultiQueryOptimizer.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MultiQueryOptimizer.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MultiQueryOptimizer.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -17,7 +17,8 @@\n  */\n package org.apache.pig.test;\n \n-import static org.junit.Assert.*;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.fail;\n \n import java.util.ArrayList;\n import java.util.List;\n@@ -324,15 +325,15 @@ private void checkInputAndOutput(String[] inputTups, String[] outputTups,\n \n             res = partAggOp.getNextTuple();\n             assertEquals(POStatus.STATUS_EOP, res.returnStatus);\n-            Util.compareActualAndExpectedResults(outputs, expectedOuts);\n+            Util.checkQueryOutputsAfterSort(outputs, expectedOuts);\n         } else {\n             while (true) {\n                 Result res = partAggOp.getNextTuple();\n                 if (!addResults(res, outputs)) {\n                     break;\n                 }\n             }\n-            Util.compareActualAndExpectedResults(outputs, expectedOuts);\n+            Util.checkQueryOutputsAfterSort(outputs, expectedOuts);\n         }\n \n     }",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestPOPartialAgg.java",
                "status": "modified",
                "changes": 7,
                "deletions": 3,
                "sha": "b9ce3604a7488453936794a5f7a117838ae4b6c1",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestPOPartialAgg.java",
                "filename": "test/org/apache/pig/test/TestPOPartialAgg.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPOPartialAgg.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -53,6 +53,12 @@ public void setUp() throws Exception {\n \n             data = resetData(pigServer);\n             data.set(\"empty\");\n+            data.set(\"testsplit\",\n+                    tuple(1, 2),\n+                    tuple(1, 2),\n+                    tuple(3, 1),\n+                    tuple(2, 4),\n+                    tuple(2, 3));\n             data.set(\n                     \"testcascade\",\n                     tuple(3,2,3),\n@@ -156,6 +162,39 @@ public void testRankEmptyRelation() throws Exception {\n       verifyExpected(data.get(\"empty_result\"), expected);\n     }\n \n+    @Test\n+    public void testRankWithSplitInMap() throws Exception {\n+        String query = \"R1 = LOAD 'testsplit' USING mock.Storage() AS (a:int,b:int);\"\n+            + \"R2 = rank R1 by a ;\"\n+            + \"R3 = rank R1 ;\"\n+            + \"R4 = union R2, R3;\"\n+            + \"store R4 into 'R4' using mock.Storage();\";\n+\n+        Util.registerMultiLineQuery(pigServer, query);\n+        List<Tuple> expectedResults = Util\n+                .getTuplesFromConstantTupleStrings(new String[] { \"(1L,1,2)\",\n+                        \"(2L,1,2)\", \"(3L,3,1)\", \"(4L,2,4)\", \"(5L,2,3)\", \"(1L,1,2)\",\n+                        \"(1L,1,2)\", \"(3L,2,3)\", \"(3L,2,4)\", \"(5L,3,1)\" });\n+        Util.checkQueryOutputsAfterSort(data.get(\"R4\"), expectedResults);\n+    }\n+\n+    @Test\n+    public void testRankWithSplitInReduce() throws Exception {\n+        String query = \"R1 = LOAD 'testsplit' USING mock.Storage() AS (a:int,b:int);\"\n+            + \"R1 = ORDER R1 by b;\"\n+            + \"R2 = rank R1 by a ;\"\n+            + \"R3 = rank R1;\"\n+            + \"R4 = union R2, R3;\"\n+            + \"store R4 into 'R4' using mock.Storage();\";\n+\n+        Util.registerMultiLineQuery(pigServer, query);\n+        List<Tuple> expectedResults = Util\n+                .getTuplesFromConstantTupleStrings(new String[] { \"(1L,3,1)\",\n+                        \"(2L,1,2)\", \"(3L,1,2)\", \"(4L,2,3)\", \"(5L,2,4)\", \"(1L,1,2)\",\n+                        \"(1L,1,2)\", \"(3L,2,4)\", \"(3L,2,3)\", \"(5L,3,1)\" });\n+        Util.checkQueryOutputsAfterSort(data.get(\"R4\"), expectedResults);\n+    }\n+\n     public void verifyExpected(List<Tuple> out, Set<Tuple> expected) {\n         for (Tuple tup : out) {\n             assertTrue(expected + \" contains \" + tup, expected.contains(tup));",
                "additions": 39,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestRank3.java",
                "status": "modified",
                "changes": 39,
                "deletions": 0,
                "sha": "a4a0ab57668468568b07f6137c6912cc244e9eea",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestRank3.java",
                "filename": "test/org/apache/pig/test/TestRank3.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestRank3.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -492,7 +492,7 @@ public void testUnionOnSchemaAdditionalColumnsWithImplicitSplit() throws IOExcep\n                                 \"(4,5,6,null)\",\n                         });\n         \n-        Util.compareActualAndExpectedResults(list1, expectedRes);\n+        Util.checkQueryOutputsAfterSort(list1, expectedRes);\n         \n         assertEquals(0, list2.size());\n     }\n@@ -852,6 +852,7 @@ public void testUnionOnSchemaUdfTypeEvolution2() throws IOException, ParserExcep\n      * Udf that has schema of tuple column with no inner schema \n      */\n     public static class UDFTupleNullSchema extends EvalFunc <Tuple> {\n+        @Override\n         public Tuple exec(Tuple input) {\n             return input;\n         }",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestUnionOnSchema.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "fa1bacbb73d8b5cb4e6443becd7eccbfb873db0f",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/TestUnionOnSchema.java",
                "filename": "test/org/apache/pig/test/TestUnionOnSchema.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestUnionOnSchema.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            },
            {
                "patch": "@@ -540,14 +540,10 @@ static public void checkQueryOutputsAfterSort(Iterator<Tuple> actualResultsIt,\n          while(actualResultsIt.hasNext()){\n              actualResList.add(actualResultsIt.next());\n          }\n-\n-         compareActualAndExpectedResults(actualResList, expectedResList);\n-\n+         checkQueryOutputsAfterSort(actualResList, expectedResList);\n      }\n \n-\n-\n-     static public void compareActualAndExpectedResults(\n+     static public void checkQueryOutputsAfterSort(\n             List<Tuple> actualResList, List<Tuple> expectedResList) {\n          Collections.sort(actualResList);\n          Collections.sort(expectedResList);",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/Util.java",
                "status": "modified",
                "changes": 8,
                "deletions": 6,
                "sha": "2e0a46ce8148d00e8eba64007c0879f208827745",
                "blob_url": "https://github.com/apache/pig/blob/04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1/test/org/apache/pig/test/Util.java",
                "filename": "test/org/apache/pig/test/Util.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/Util.java?ref=04e1bbe2c65bcff07bce0d7afc7b2d6c2ff80cb1"
            }
        ],
        "bug_id": "pig_51",
        "parent": "https://github.com/apache/pig/commit/0026db31c02138f1685c2ce6afe39dfb1058d480",
        "message": "PIG-3985: Multiquery execution of RANK with RANK BY causes NPE (rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1629020 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/f947c43b34904297f2e5fd967604631cc0c366cb",
        "file": [
            {
                "patch": "@@ -56,6 +56,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-4112: NPE in packager when union + group-by followed by replicated join in Tez (rohini via cheolsoo)\n+\n PIG-4113: TEZ-1386 breaks hadoop 2 compilation in trunk (cheolsoo)\n \n PIG-4110: TEZ-1382 breaks Hadoop 2 compilation (cheolsoo)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "3dc0179f7e52f0de9d243c7f6d808c3b8801ae87",
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=f947c43b34904297f2e5fd967604631cc0c366cb"
            },
            {
                "patch": "@@ -137,9 +137,6 @@ public void run() {\n             task.setUncaughtExceptionHandler(jctExceptionHandler);\n             task.setContextClassLoader(PigContext.getClassLoader());\n \n-            // TezJobControl always holds a single TezJob. We use JobControl\n-            // only because it is convenient to launch the job via\n-            // ControlledJob.submit().\n             tezStats.setTezJob(runningJob);\n \n             // Mark the times that the jobs were submitted so it's reflected in job",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "status": "modified",
                "changes": 3,
                "deletions": 3,
                "sha": "725ffd9ceb1c0a3182bb09a81ce0411f19343630",
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java?ref=f947c43b34904297f2e5fd967604631cc0c366cb"
            },
            {
                "patch": "@@ -140,7 +140,7 @@ public LoRearrangeDiscoverer(PhysicalPlan plan, TezOperator pkgTezOp, POPackage\n         @Override\n         public void visitLocalRearrange(POLocalRearrange lrearrange) throws VisitorException {\n             POLocalRearrangeTez lr = (POLocalRearrangeTez) lrearrange;\n-            if (!lr.getOutputKey().equals(pkgTezOp.getOperatorKey().toString())) {\n+            if (!(lr.isConnectedToPackage() && lr.getOutputKey().equals(pkgTezOp.getOperatorKey().toString()))) {\n                 return;\n             }\n             loRearrangeFound++;",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "94122a5dae612c818d33ccfbbb4cafa194ddde60",
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/tez/TezPOPackageAnnotator.java?ref=f947c43b34904297f2e5fd967604631cc0c366cb"
            },
            {
                "patch": "@@ -1493,6 +1493,16 @@ c = union a, b;\n d = foreach c generate (name is not NULL? UPPER(name) : 'FNU LNU') as name, (age < 30 ? -1 : age) as age, (gpa is NULL ? 0.0 : ((gpa > 0.5 AND gpa < 1.0) ? 1 : gpa)) as gpa;\n e = filter d by (name matches '.*MIKE.*') OR (NOT (gpa + 1.5 > 4));\n store e into ':OUTPATH:';\\,\n+            },\n+            {\n+            'num' => 13,\n+            'pig' => q\\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);\n+b = load ':INPATH:/singlefile/studentcolon10k' using PigStorage(':') as (name, age, gpa);\n+c = union a, b;\n+d = group c by name;\n+e = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);\n+f = join d by group, e by name using 'replicated';\n+store f into ':OUTPATH:';\\,\n             },\n \t\t]\n \t\t},",
                "additions": 10,
                "raw_url": "https://github.com/apache/pig/raw/f947c43b34904297f2e5fd967604631cc0c366cb/test/e2e/pig/tests/nightly.conf",
                "status": "modified",
                "changes": 10,
                "deletions": 0,
                "sha": "bc288d99d086483d045dbeac7fdc76571e9745a8",
                "blob_url": "https://github.com/apache/pig/blob/f947c43b34904297f2e5fd967604631cc0c366cb/test/e2e/pig/tests/nightly.conf",
                "filename": "test/e2e/pig/tests/nightly.conf",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/e2e/pig/tests/nightly.conf?ref=f947c43b34904297f2e5fd967604631cc0c366cb"
            }
        ],
        "bug_id": "pig_52",
        "parent": "https://github.com/apache/pig/commit/cb3e95936576278a486eae07dda93bb71c0490cd",
        "message": "PIG-4112: NPE in packager when union + group-by followed by replicated join in Tez (rohini via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1617200 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/f9a24a9b9140444e7a0559eb727b66bc036792de",
        "file": [
            {
                "patch": "@@ -28,7 +28,6 @@\n import org.apache.commons.cli.GnuParser;\n import org.apache.commons.cli.HelpFormatter;\n import org.apache.commons.cli.Option;\n-import org.apache.commons.cli.OptionBuilder;\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.commons.logging.Log;\n@@ -166,7 +165,7 @@ private Options populateValidOptions() {\n         validOptions.addOption(TAG_SOURCE_FILE, false, \"Appends input source file name to beginning of each tuple.\");\n         validOptions.addOption(TAG_SOURCE_PATH, false, \"Appends input source file path to beginning of each tuple.\");\n         validOptions.addOption(\"tagsource\", false, \"Appends input source file name to beginning of each tuple.\");\n-        Option overwrite = new Option(null, \"Overwrites the destination.\");\n+        Option overwrite = new Option(\" \", \"Overwrites the destination.\");\n         overwrite.setLongOpt(\"overwrite\");\n         overwrite.setOptionalArg(true);\n         overwrite.setArgs(1);",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/f9a24a9b9140444e7a0559eb727b66bc036792de/src/org/apache/pig/builtin/PigStorage.java",
                "status": "modified",
                "changes": 3,
                "deletions": 2,
                "sha": "675f138fc36e2595b430225c2dca3853ed82656e",
                "blob_url": "https://github.com/apache/pig/blob/f9a24a9b9140444e7a0559eb727b66bc036792de/src/org/apache/pig/builtin/PigStorage.java",
                "filename": "src/org/apache/pig/builtin/PigStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/PigStorage.java?ref=f9a24a9b9140444e7a0559eb727b66bc036792de"
            }
        ],
        "bug_id": "pig_53",
        "parent": "https://github.com/apache/pig/commit/beaca12dc346df325f98cd01911b4ae7d51a23e1",
        "message": "PIG-3988: PigStorage: CommandLineParser is not thread safe (tmwoodruff via rohini) - Fix NPE with commons-cli-1.0.jar\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1601993 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/01276f04024d2e0d16f31fddef3faf54cdb18d10",
        "file": [
            {
                "patch": "@@ -133,6 +133,8 @@ PIG-3882: Multiquery off mode execution is not done in batch and very inefficien\n  \n BUG FIXES\n \n+PIG-3944: PigNullableWritable toString method throws NPE on null value (mauzhang via cheolsoo)\n+\n PIG-3936: DBStorage fails on storing nulls for non varchar columns (jeremykarn via cheolsoo) \n \n PIG-3945: Ant not sending hadoopversion to piggybank sub-ant (mrflip via cheolsoo)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/01276f04024d2e0d16f31fddef3faf54cdb18d10/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "7bfc6563cc05b59f87036e44df3a7911e802dfbb",
                "blob_url": "https://github.com/apache/pig/blob/01276f04024d2e0d16f31fddef3faf54cdb18d10/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=01276f04024d2e0d16f31fddef3faf54cdb18d10"
            },
            {
                "patch": "@@ -181,6 +181,6 @@ public boolean equals(Object arg0) {\n \n     @Override\n     public String toString() {\n-        return \"Null: \" + mNull + \" index: \" + mIndex + \" \" + mValue.toString();\n+        return \"Null: \" + mNull + \" index: \" + mIndex + (mNull ? \"\" : \" \" + mValue.toString());\n     }\n }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/01276f04024d2e0d16f31fddef3faf54cdb18d10/src/org/apache/pig/impl/io/PigNullableWritable.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "3941c7ae970db1a37760699fe19e41800dd86ea2",
                "blob_url": "https://github.com/apache/pig/blob/01276f04024d2e0d16f31fddef3faf54cdb18d10/src/org/apache/pig/impl/io/PigNullableWritable.java",
                "filename": "src/org/apache/pig/impl/io/PigNullableWritable.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/io/PigNullableWritable.java?ref=01276f04024d2e0d16f31fddef3faf54cdb18d10"
            }
        ],
        "bug_id": "pig_54",
        "parent": "https://github.com/apache/pig/commit/dfb7e24c95818b95879779b5eee270044f993328",
        "message": "PIG-3944: PigNullableWritable toString method throws NPE on null value (mauzhang via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1596062 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/1611daabf35490a194a5d5171d1e1cfe765046ea",
        "file": [
            {
                "patch": "@@ -89,6 +89,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3746: NPE is thrown if Pig fails before PigStats is intialized (cheolsoo)\n+\n PIG-3747: Update skewed join documentation (cheolsoo)\n \n PIG-3755: auto local mode selection does not check lower bound for size (aniket486)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/1611daabf35490a194a5d5171d1e1cfe765046ea/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "3c7cb9d46f2ca6011cb23f5a477c199aa3f3af5b",
                "blob_url": "https://github.com/apache/pig/blob/1611daabf35490a194a5d5171d1e1cfe765046ea/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=1611daabf35490a194a5d5171d1e1cfe765046ea"
            },
            {
                "patch": "@@ -142,15 +142,24 @@ public static PigStats getPigStats(int code) {\n \n \n     public static void setErrorMessage(String msg) {\n-        PigStats.get().setErrorMessage(msg);\n+        PigStats ps = PigStats.get();\n+        if (ps != null) {\n+            ps.setErrorMessage(msg);\n+        }\n     }\n \n     public static void setErrorCode(int code) {\n-        PigStats.get().setErrorCode(code);\n+        PigStats ps = PigStats.get();\n+        if (ps != null) {\n+            ps.setErrorCode(code);\n+        }\n     }\n \n     public static void setErrorThrowable(Throwable t) {\n-        PigStats.get().setErrorThrowable(t);\n+        PigStats ps = PigStats.get();\n+        if (ps != null) {\n+            ps.setErrorThrowable(t);\n+        }\n     }\n \n     private static Pattern pattern = Pattern.compile(\"tmp(-)?[\\\\d]{1,10}$\");",
                "additions": 12,
                "raw_url": "https://github.com/apache/pig/raw/1611daabf35490a194a5d5171d1e1cfe765046ea/src/org/apache/pig/tools/pigstats/PigStatsUtil.java",
                "status": "modified",
                "changes": 15,
                "deletions": 3,
                "sha": "e690b8dd16365ec18ca174c304407818ff51a3b2",
                "blob_url": "https://github.com/apache/pig/blob/1611daabf35490a194a5d5171d1e1cfe765046ea/src/org/apache/pig/tools/pigstats/PigStatsUtil.java",
                "filename": "src/org/apache/pig/tools/pigstats/PigStatsUtil.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/tools/pigstats/PigStatsUtil.java?ref=1611daabf35490a194a5d5171d1e1cfe765046ea"
            }
        ],
        "bug_id": "pig_55",
        "parent": "https://github.com/apache/pig/commit/3444b733fa4a987e5a91a921d2cd8d0554778097",
        "message": "PIG-3746: NPE is thrown if Pig fails before PigStats is intialized (cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1569497 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/65b249f8c49bcbcf7aa818dad6de20b9bec70a02",
        "file": [
            {
                "patch": "@@ -62,8 +62,6 @@ PIG-3285: Jobs using HBaseStorage fail to ship dependency jars (ndimiduk via che\n \n PIG-3582: Document SUM, MIN, MAX, and AVG functions for BigInteger and BigDecimal (harichinnan via cheolsoo)\n \n-PIG-3576: NPE due to PIG-3549 when job never gets submitted (lbendig via cheolsoo)\n-\n PIG-3525: PigStats.get() and ScriptState.get() shouldn't return MR-specific objects (cheolsoo)\n \n PIG-3568: Define the semantics of POStatus.STATUS_NULL (mwagner via cheolsoo)\n@@ -121,6 +119,8 @@ PIG-3480: TFile-based tmpfile compression crashes in some cases (dvryaboy via an\n \n BUG FIXES\n \n+PIG-3576: NPE due to PIG-3549 when job never gets submitted (lbendig via cheolsoo)\n+\n PIG-3567: LogicalPlanPrinter throws OOM for large scripts (aniket486)\n \n PIG-3579: pig.script's deserialized version does not maintain line numbers (jgzhang via aniket486)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/65b249f8c49bcbcf7aa818dad6de20b9bec70a02/CHANGES.txt",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "b984bf081207dbf96aa6ecba15f63bbee97bd079",
                "blob_url": "https://github.com/apache/pig/blob/65b249f8c49bcbcf7aa818dad6de20b9bec70a02/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=65b249f8c49bcbcf7aa818dad6de20b9bec70a02"
            },
            {
                "patch": "@@ -102,7 +102,7 @@ public void kill() {\n                     RunningJob runningJob = job.getJobClient().getJob(job.getAssignedJobID());\n                     if (runningJob!=null)\n                         runningJob.killJob();\n-                    log.info(\"Job \" + job.getAssignedJobID().toString() + \" killed\");\n+                    log.info(\"Job \" + job.getAssignedJobID() + \" killed\");\n                 }\n             }\n         } catch (Exception e) {\n@@ -536,7 +536,7 @@ private void checkStopOnFailure(boolean stop_on_failure) throws ExecException{\n \n             for (int i=0; i<jc.getFailedJobs().size(); i++) {\n                 Job j = jc.getFailedJobs().get(i);\n-                msg.append(\"JobID: \" + String.valueOf(j.getAssignedJobID()) + \" Reason: \" + j.getMessage());\n+                msg.append(\"JobID: \" + j.getAssignedJobID() + \" Reason: \" + j.getMessage());\n                 if (i!=jc.getFailedJobs().size()-1) {\n                     msg.append(\"\\n\");\n                 }",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/65b249f8c49bcbcf7aa818dad6de20b9bec70a02/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "059db0c04a5509178d72270af91fd66486e4e2bd",
                "blob_url": "https://github.com/apache/pig/blob/65b249f8c49bcbcf7aa818dad6de20b9bec70a02/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java?ref=65b249f8c49bcbcf7aa818dad6de20b9bec70a02"
            }
        ],
        "bug_id": "pig_56",
        "parent": "https://github.com/apache/pig/commit/ca885a6130d4008b4025084e34e9358837a4ae94",
        "message": "PIG-3576: NPE due to PIG-3549 when job never gets submitted (lbendig via cheolsoo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1546204 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df",
        "file": [
            {
                "patch": "@@ -54,6 +54,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3576: NPE due to PIG-3549 when job never gets submitted (lbendig via cheolsoo)\n+\n PIG-3525: PigStats.get() and ScriptState.get() shouldn't return MR-specific objects (cheolsoo)\n \n PIG-3568: Define the semantics of POStatus.STATUS_NULL (mwagner via cheolsoo)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "45cf4674f178f46489942dbfd531a8e83fcfe5fb",
                "blob_url": "https://github.com/apache/pig/blob/c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df"
            },
            {
                "patch": "@@ -536,7 +536,7 @@ private void checkStopOnFailure(boolean stop_on_failure) throws ExecException{\n \n             for (int i=0; i<jc.getFailedJobs().size(); i++) {\n                 Job j = jc.getFailedJobs().get(i);\n-                msg.append(\"JobID: \" + j.getAssignedJobID().toString() + \" Reason: \" + j.getMessage());\n+                msg.append(\"JobID: \" + String.valueOf(j.getAssignedJobID()) + \" Reason: \" + j.getMessage());\n                 if (i!=jc.getFailedJobs().size()-1) {\n                     msg.append(\"\\n\");\n                 }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "9580c265546de226889318a1e37b134c38ccb982",
                "blob_url": "https://github.com/apache/pig/blob/c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "filename": "src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java?ref=c0e5bfb7d7c8b3d72d57bbcbb62eb36dc89ce1df"
            }
        ],
        "bug_id": "pig_57",
        "parent": "https://github.com/apache/pig/commit/52d852b8f8e102b4335f23e3a66c6d31a5f93844",
        "message": "PIG-3576: NPE due to PIG-3549 when job never gets submitted (lbendig via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1543100 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/d3324852207252e156d13fc6ee75d26149ff6731",
        "file": [
            {
                "patch": "@@ -40,6 +40,8 @@ OPTIMIZATIONS\n  \n BUG FIXES\n \n+PIG-3377: New AvroStorage throws NPE when storing untyped map/array/bag (jadler via cheolsoo)\n+\n PIG-3542: Javadoc of REGEX_EXTRACT_ALL (nyigitba via daijy)\n \n PIG-3518: Need to ship jruby.jar in the release (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/d3324852207252e156d13fc6ee75d26149ff6731/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "5897047b19536b3afaea6d64045740c3330e4b51",
                "blob_url": "https://github.com/apache/pig/blob/d3324852207252e156d13fc6ee75d26149ff6731/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=d3324852207252e156d13fc6ee75d26149ff6731"
            },
            {
                "patch": "@@ -427,6 +427,9 @@ private static Schema resourceFieldSchemaToAvroSchema(\n           schema.getFields()[0].getSchema(), name, null,\n           definedRecordNames,\n           doubleColonsToDoubleUnderscores);\n+      if (innerBagSchema == null) {\n+        throw new IOException(\"AvroStorage can't save bags with untyped values; please specify a value type or a schema.\");\n+      }\n       return createNullableUnion(Schema.createArray(innerBagSchema));\n     case DataType.BIGCHARARRAY:\n       return createNullableUnion(Type.STRING);\n@@ -457,10 +460,15 @@ private static Schema resourceFieldSchemaToAvroSchema(\n     case DataType.LONG:\n       return createNullableUnion(Type.LONG);\n     case DataType.MAP:\n+      if (schema == null) {\n+        throw new IOException(\"AvroStorage can't save maps with untyped values; please specify a value type or a schema.\");\n+      }\n       byte innerType = schema.getFields()[0].getType();\n       String desc = schema.getFields()[0].getDescription();\n-      if (desc.equals(\"autogenerated from Pig Field Schema\")) {\n-        desc = null;\n+      if (desc != null) {\n+        if (desc.equals(\"autogenerated from Pig Field Schema\")) {\n+          desc = null;\n+        }\n       }\n       Schema innerSchema;\n       if (DataType.isComplex(innerType)) {\n@@ -480,6 +488,9 @@ private static Schema resourceFieldSchemaToAvroSchema(\n     case DataType.NULL:\n       return Schema.create(Type.NULL);\n     case DataType.TUPLE:\n+      if (schema == null) {\n+        throw new IOException(\"AvroStorage can't save tuples with untyped values; please specify a value type or a schema.\");\n+      }\n       Schema returnSchema = createNullableUnion(\n           resourceSchemaToAvroSchema(schema, name, null,\n               definedRecordNames, doubleColonsToDoubleUnderscores));",
                "additions": 13,
                "raw_url": "https://github.com/apache/pig/raw/d3324852207252e156d13fc6ee75d26149ff6731/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "status": "modified",
                "changes": 15,
                "deletions": 2,
                "sha": "fb89e9c766de24eccd2d7485d39f799cfd0397f8",
                "blob_url": "https://github.com/apache/pig/blob/d3324852207252e156d13fc6ee75d26149ff6731/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "filename": "src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/util/avro/AvroStorageSchemaConversionUtilities.java?ref=d3324852207252e156d13fc6ee75d26149ff6731"
            }
        ],
        "bug_id": "pig_58",
        "parent": "https://github.com/apache/pig/commit/5358546758669c04fcf109210997424eadfc216c",
        "message": "PIG-3377: New AvroStorage throws NPE when storing untyped map/bag/tuple (jadler via cheolsoo)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1536044 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b",
        "file": [
            {
                "patch": "@@ -192,6 +192,8 @@ PIG-3013: BinInterSedes improve chararray sort performance (rohini)\n \n BUG FIXES\n \n+PIG-3322: AvroStorage give NPE on reading file with union as top level schema (viraj via rohini)\n+\n PIG-2828: Handle nulls in DataType.compare (aniket486)\n \n PIG-3335: TestErrorHandling.tesNegative7 fails on MR2 (xuefuz)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "78f65afae8d4995f4f59f8ff83e1c6272f1e3104",
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b"
            },
            {
                "patch": "@@ -534,7 +534,6 @@ else if (inputs.containsKey(\"schema_file\")) {\n                 AvroStorageLog.details(\"data path=\" + path.toUri().toString());\n                 FileSystem fs = FileSystem.get(path.toUri(), new Configuration());\n                 outputAvroSchema = getAvroSchema(path, fs);\n-                userSpecifiedAvroSchema = outputAvroSchema;\n             } else if (name.equalsIgnoreCase(\"nullable\")) {\n                 nullable = (Boolean) value;\n             } else if (name.equalsIgnoreCase(\"schema\")) {",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "status": "modified",
                "changes": 1,
                "deletions": 1,
                "sha": "997cf4c182dc0b45c402caeee4e970a7015a3ca9",
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/AvroStorage.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b"
            },
            {
                "patch": "@@ -141,7 +141,12 @@ public Writable getCurrentValue() throws IOException, InterruptedException {\n             AvroStorageLog.details(\"Class =\" + obj.getClass());\n             result = (Tuple) obj;\n         } else {\n-            AvroStorageLog.details(\"Wrap calss \" + obj.getClass() + \" as a tuple.\");\n+            if (obj != null) {\n+                AvroStorageLog.details(\"Wrap class \" + obj.getClass() + \" as a tuple.\");\n+            }\n+            else {\n+                AvroStorageLog.details(\"Wrap null as a tuple.\");\n+            }\n             result = wrapAsTuple(obj);\n         }\n         if (schemaToMergedSchemaMap != null) {",
                "additions": 6,
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "status": "modified",
                "changes": 7,
                "deletions": 1,
                "sha": "531030467ea8d2b92394103b903d8a99ad4c9694",
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/avro/PigAvroRecordReader.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b"
            },
            {
                "patch": "@@ -16,6 +16,10 @@\n  */\n package org.apache.pig.piggybank.test.storage.avro;\n \n+import static org.apache.pig.builtin.mock.Storage.resetData;\n+import static org.apache.pig.builtin.mock.Storage.schema;\n+import static org.apache.pig.builtin.mock.Storage.tuple;\n+\n import org.apache.avro.file.DataFileStream;\n import org.apache.avro.generic.GenericDatumReader;\n import org.apache.commons.logging.Log;\n@@ -33,6 +37,8 @@\n import org.apache.pig.backend.executionengine.ExecJob;\n import org.apache.pig.backend.executionengine.ExecJob.JOB_STATUS;\n import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobCreationException;\n+import org.apache.pig.builtin.mock.Storage.Data;\n+import org.apache.pig.data.Tuple;\n import org.apache.pig.impl.io.FileLocalizer;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n import org.apache.pig.piggybank.storage.avro.AvroStorage;\n@@ -181,6 +187,7 @@ private static String getInputFile(String file) {\n     final private String testMultipleSchemas1File = getInputFile(\"test_primitive_types/*\");\n     final private String testMultipleSchemas2File = getInputFile(\"test_complex_types/*\");\n     final private String testUserDefinedLoadSchemaFile = getInputFile(\"test_user_defined_load_schema/*\");\n+    final private String testLoadwithNullValues = getInputFile(\"test_loadavrowithnulls.avro\");\n \n     @BeforeClass\n     public static void setup() throws ExecException, IOException {\n@@ -1075,6 +1082,39 @@ public void testCorruptedFile2() throws IOException {\n         verifyResults(output, expected);\n     }\n \n+    @Test\n+    // Schema for the generated avro file test_loadavrowithnulls.avro\n+    // [\"null\",{\"type\":\"record\",\"name\":\"TUPLE_0\",\n+    // \"fields\":[\n+    // {\"name\":\"name\",\"type\":[\"null\",\"string\"],\"doc\":\"autogenerated from Pig Field Schema\"},\n+    // {\"name\":\"age\",\"type\":[\"null\",\"int\"],\"doc\":\"autogenerated from Pig Field Schema\"},\n+    // {\"name\":\"gpa\",\"type\":[\"null\",\"double\"],\"doc\":\"autogenerated from Pig Field Schema\"}]}]\n+    public void testLoadwithNullValues() throws IOException {\n+    //Input is supposed to have empty tuples\n+    PigSchema2Avro.setTupleIndex(0);\n+    Data data = resetData(pigServerLocal);\n+    String output = outbasedir + \"testLoadwithNulls\";\n+    deleteDirectory(new File(output));\n+    String [] queries = {\n+       \" A = load '\" +  testLoadwithNullValues + \"' USING \" +\n+          \" org.apache.pig.piggybank.storage.avro.AvroStorage(); \",\n+       \" B = order A by name;\",\n+       \" store B into '\" +  output +\"' USING mock.Storage();\"\n+       };\n+    testAvroStorage(queries);\n+    List<Tuple> out = data.get(output);\n+    assertEquals(out + \" size\", 4, out.size());\n+\n+    assertEquals(schema(\"name:chararray,age:int,gpa:double\"), data.getSchema(output));\n+\n+    // sorted data ordered by name\n+    assertEquals(tuple((String)null),out.get(0));\n+    assertEquals(tuple((String)null),out.get(1));\n+    assertEquals(tuple(\"calvin ellison\", 24, 0.71), out.get(2));\n+    assertEquals(tuple(\"wendy johnson\", 60, 0.07), out.get(3));\n+\n+   }\n+\n     private static void deleteDirectory (File path) {\n         if ( path.exists()) {\n             File [] files = path.listFiles();",
                "additions": 40,
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "status": "modified",
                "changes": 40,
                "deletions": 0,
                "sha": "dad54449161c84100cf2b77b5cf1255f9f849224",
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/TestAvroStorage.java?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b"
            },
            {
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "status": "added",
                "changes": 0,
                "deletions": 0,
                "sha": "1fcaf4c2d277c82af23e4bb1fd79b98ae26ff4a1",
                "blob_url": "https://github.com/apache/pig/blob/35fb1eadb7287e3904f1c1fbf9a021db30f37f6b/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "filename": "contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/test/java/org/apache/pig/piggybank/test/storage/avro/avro_test_files/test_loadavrowithnulls.avro?ref=35fb1eadb7287e3904f1c1fbf9a021db30f37f6b"
            }
        ],
        "bug_id": "pig_59",
        "parent": "https://github.com/apache/pig/commit/a13db1bc664c212177353daae9e204fd9da679bd",
        "message": "PIG-3322: AvroStorage give NPE on reading file with union as top level schema (viraj via rohini)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1489264 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/7b7a628d475f0a7c3d025b8a7db2df5c35e19c91",
        "file": [
            {
                "patch": "@@ -0,0 +1,37 @@\n+package org.apache.pig.test.utils;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.pig.builtin.PigStorage;\n+import org.apache.pig.data.Tuple;\n+import org.apache.pig.impl.util.UDFContext;\n+\n+public class UDFContextTestLoaderWithSignature extends PigStorage {\n+    private String val;\n+    \n+    public UDFContextTestLoaderWithSignature(String v1) {\n+        val = v1;\n+    }\n+    \n+    @Override\n+    public void setLocation(String location, Job job)\n+            throws IOException {\n+        super.setLocation(location, job);\n+        Properties p = UDFContext.getUDFContext().getUDFProperties(this.getClass());\n+        if (p.get(signature)==null) {\n+            p.put(\"test_\" + signature, val);\n+        }\n+    }\n+    \n+    @Override\n+    public Tuple getNext() throws IOException {\n+        Tuple t = super.getNext();\n+        if (t!=null) {\n+            Properties p = UDFContext.getUDFContext().getUDFProperties(this.getClass());\n+            t.append(p.get(\"test_\" + signature));\n+        }\n+        return t;\n+    }\n+}",
                "additions": 37,
                "raw_url": "https://github.com/apache/pig/raw/7b7a628d475f0a7c3d025b8a7db2df5c35e19c91/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "status": "added",
                "changes": 37,
                "deletions": 0,
                "sha": "db1c62e0c5b80c977e87603f490adbb956a31bc2",
                "blob_url": "https://github.com/apache/pig/blob/7b7a628d475f0a7c3d025b8a7db2df5c35e19c91/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "filename": "test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/utils/UDFContextTestLoaderWithSignature.java?ref=7b7a628d475f0a7c3d025b8a7db2df5c35e19c91"
            }
        ],
        "bug_id": "pig_60",
        "parent": "https://github.com/apache/pig/commit/1d4d72a9780a47a3b5a8929fede677dbff85be6b",
        "message": "PIG-3132:  NPE when illustrating a relation with HCatLoader (check in missing UDFContextTestLoaderWithSignature.java)\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1458036 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/cb518031e49814cce0cdaa11adbeeca52b708594",
        "file": [
            {
                "patch": "@@ -106,6 +106,8 @@ OPTIMIZATIONS\n \n BUG FIXES\n \n+PIG-2644: Piggybank's HadoopJobHistoryLoader throws NPE when reading broken history file (herberts via daijy)\n+\n PIG-2627: Custom partitioner not set when POSplit is involved in Plan (aniket486 via daijy)\n \n PIG-2596: Jython UDF does not handle boolean output (aniket486 via daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/cb518031e49814cce0cdaa11adbeeca52b708594/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "821cdd2a28de04b843aa235d11d87610c37a8db1",
                "blob_url": "https://github.com/apache/pig/blob/cb518031e49814cce0cdaa11adbeeca52b708594/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=cb518031e49814cce0cdaa11adbeeca52b708594"
            },
            {
                "patch": "@@ -482,7 +482,7 @@ private static void populateMapReduceTaskLists (MRJobInfo value,\n             // CHECK_IT: Only one SUCCESSFUL TASK ATTEMPT\n             Map.Entry<String, JobHistory.TaskAttempt> tae = kv.next();\n             JobHistory.TaskAttempt attempt = tae.getValue();\n-            if (attempt.getValues().get(JobHistory.Keys.TASK_STATUS).equals(\n+            if (null != attempt && null != attempt.getValues() && attempt.getValues().containsKey(JobHistory.Keys.TASK_STATUS) && attempt.getValues().get(JobHistory.Keys.TASK_STATUS).equals(\n                     \"SUCCESS\")) {\n                 return attempt.getValues();\n             }",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/cb518031e49814cce0cdaa11adbeeca52b708594/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/HadoopJobHistoryLoader.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "c1aba97daa9aa6a9ef04cbe08b3eaa6cda0e1cfe",
                "blob_url": "https://github.com/apache/pig/blob/cb518031e49814cce0cdaa11adbeeca52b708594/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/HadoopJobHistoryLoader.java",
                "filename": "contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/HadoopJobHistoryLoader.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/storage/HadoopJobHistoryLoader.java?ref=cb518031e49814cce0cdaa11adbeeca52b708594"
            }
        ],
        "bug_id": "pig_61",
        "parent": "https://github.com/apache/pig/commit/90aee49d68f434624032e210d3e91faf1873662b",
        "message": "PIG-2644: Piggybank's HadoopJobHistoryLoader throws NPE when reading broken history file\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1328551 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/4465d83514c1295a7340a667a7d594138d4c9072",
        "file": [
            {
                "patch": "@@ -89,6 +89,8 @@ PIG-2011: Speed up TestTypedMap.java (dvryaboy)\n \n BUG FIXES\n \n+PIG-2027: NPE if Pig don't have permission for log file (daijy)\n+\n PIG-2171: TestScriptLanguage is broken on trunk (daijy and thejas)\n \n PIG-2172: Fix test failure for ant 1.8.x (daijy)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/4465d83514c1295a7340a667a7d594138d4c9072/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "1a69b4590c82b33e2cd002bb6f38c370c3cff797",
                "blob_url": "https://github.com/apache/pig/blob/4465d83514c1295a7340a667a7d594138d4c9072/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=4465d83514c1295a7340a667a7d594138d4c9072"
            },
            {
                "patch": "@@ -169,7 +169,8 @@ public static void writeLog(Throwable t, String logFileName, Log log, boolean ve\n             log.error(bs.toString());\n         } finally {\n             try {\n-                fos.close();\n+                if (fos!=null)\n+                    fos.close();\n             } catch (IOException e) {\n             }\n         }",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/4465d83514c1295a7340a667a7d594138d4c9072/src/org/apache/pig/impl/util/LogUtils.java",
                "status": "modified",
                "changes": 3,
                "deletions": 1,
                "sha": "b5b519efebd586d236622c4052992f55d39d8456",
                "blob_url": "https://github.com/apache/pig/blob/4465d83514c1295a7340a667a7d594138d4c9072/src/org/apache/pig/impl/util/LogUtils.java",
                "filename": "src/org/apache/pig/impl/util/LogUtils.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/util/LogUtils.java?ref=4465d83514c1295a7340a667a7d594138d4c9072"
            }
        ],
        "bug_id": "pig_62",
        "parent": "https://github.com/apache/pig/commit/28b71c5a894a711b094f3c5369a729a8643e3701",
        "message": "PIG-2027: NPE if Pig don't have permission for log file\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1148855 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/adcdeab1773917322a2230b4782a14b7192d2d5d",
        "file": [
            {
                "patch": "@@ -44,8 +44,6 @@ BUG FIXES\n \n PIG-2044: Patten match bug in org.apache.pig.newplan.optimizer.Rule (knoguchi via daijy)\n \n-PIG-1938: support project-range as udf argument (thejas)\n-\n PIG-2048: Add zookeeper to pig jar (gbowyer via gates)\n \n PIG-2008: Cache outputFormat in HBaseStorage (thedatachef via gates)\n@@ -72,6 +70,8 @@ PIG-1876: Typed map for Pig (daijy)\n \n IMPROVEMENTS\n \n+PIG-1938: support project-range as udf argument (thejas)\n+\n PIG-2059: PIG doesn't validate incomplete query in batch mode even if -c option is given (xuefu)\n \n PIG-2062: Script silently ended (xuefu)\n@@ -224,6 +224,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-2072: NPE when udf has project-star argument and input schema is null (thejas)\n+\n PIG-2075: Bring back TestNewPlanPushUpFilter (daijy)\n \n PIG-1827: When passing a parameter to Pig, if the value contains $ it has to be escaped for no apparent reason (rding)",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/adcdeab1773917322a2230b4782a14b7192d2d5d/CHANGES.txt",
                "status": "modified",
                "changes": 6,
                "deletions": 2,
                "sha": "f54ed36f5a29de568faa9a75bfb7a20a3108c870",
                "blob_url": "https://github.com/apache/pig/blob/adcdeab1773917322a2230b4782a14b7192d2d5d/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=adcdeab1773917322a2230b4782a14b7192d2d5d"
            },
            {
                "patch": "@@ -973,6 +973,8 @@ private boolean byteArrayFound(UserFuncExpression func, Schema s) throws Visitor\n         for(int i=0;i<s.size();i++){\n             try {\n                 FieldSchema fs=s.getField(i);\n+                if(fs == null)\n+                    return false;\n                 if(fs.type==DataType.BYTEARRAY){\n                     return true;\n                 }\n@@ -1098,7 +1100,10 @@ public static boolean schemaEqualsForMatching(Schema inputSchema,\n \n             FieldSchema inputFieldSchema = i.next();\n             FieldSchema udfFieldSchema = j.next();\n-\n+            if(inputFieldSchema == null)\n+                return false;\n+            \n+            \n             if(ignoreByteArrays && inputFieldSchema.type == DataType.BYTEARRAY) {\n                 continue;\n             }\n@@ -1249,6 +1254,9 @@ private long fitPossible(Schema s1, Schema s2) {\n         int castCnt=0;\n         for(int i=0;i<sFields.size();i++){\n             FieldSchema sFS = sFields.get(i);\n+            if(sFS == null){\n+                return INF;\n+            }\n \n             // if we have a byte array do not include it\n             // in the computation of the score - bytearray",
                "additions": 9,
                "raw_url": "https://github.com/apache/pig/raw/adcdeab1773917322a2230b4782a14b7192d2d5d/src/org/apache/pig/newplan/logical/visitor/TypeCheckingExpVisitor.java",
                "status": "modified",
                "changes": 10,
                "deletions": 1,
                "sha": "bd4e8947e4a866b35f93a541efc7df6c13bf03b3",
                "blob_url": "https://github.com/apache/pig/blob/adcdeab1773917322a2230b4782a14b7192d2d5d/src/org/apache/pig/newplan/logical/visitor/TypeCheckingExpVisitor.java",
                "filename": "src/org/apache/pig/newplan/logical/visitor/TypeCheckingExpVisitor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/visitor/TypeCheckingExpVisitor.java?ref=adcdeab1773917322a2230b4782a14b7192d2d5d"
            },
            {
                "patch": "@@ -99,6 +99,30 @@ public void testProjStarExpandInForeach1Negative() throws IOException{\n                 \"org.apache.pig.builtin.CONCAT\");\n     }\n     \n+    @Test\n+    public void testProjStarExpandInForeach1NegativeNoSchema() throws IOException{\n+        \n+        String query;\n+\n+        query =\n+            \"  l1 = load '\" + INP_FILE_5FIELDS + \"' ;\"\n+            + \"f = foreach l1 generate CONCAT(*) as ct;\"\n+            ; \n+        Util.checkExceptionMessage(query, \"f\",\n+                \"Could not infer the matching function for \" +\n+                \"org.apache.pig.builtin.CONCAT\");\n+\n+\n+        query =\n+            \"  l1 = load '\" + INP_FILE_5FIELDS + \"' ;\"\n+            + \"f = foreach l1 generate SIZE(*) as ct;\"\n+            ; \n+        Util.checkExceptionMessage(query, \"f\",\n+                \"Could not infer the matching function for \" +\n+                \"org.apache.pig.builtin.SIZE\");\n+        \n+    }\n+    \n     @Test\n     public void testProjStarExpandInForeach2() throws IOException {\n ",
                "additions": 24,
                "raw_url": "https://github.com/apache/pig/raw/adcdeab1773917322a2230b4782a14b7192d2d5d/test/org/apache/pig/test/TestProjectStarRangeInUdf.java",
                "status": "modified",
                "changes": 24,
                "deletions": 0,
                "sha": "43cbdee6e742794146ace28a943eacc0c02c4872",
                "blob_url": "https://github.com/apache/pig/blob/adcdeab1773917322a2230b4782a14b7192d2d5d/test/org/apache/pig/test/TestProjectStarRangeInUdf.java",
                "filename": "test/org/apache/pig/test/TestProjectStarRangeInUdf.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestProjectStarRangeInUdf.java?ref=adcdeab1773917322a2230b4782a14b7192d2d5d"
            }
        ],
        "bug_id": "pig_63",
        "parent": "https://github.com/apache/pig/commit/7b650fa16ca82c00b65b04db24fc60fc29bd4a6d",
        "message": "PIG-2072: NPE when udf has project-star argument and input schema is null\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1103776 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/3505a4289fc9114f214e8e20d5cb59cfd78b16e9",
        "file": [
            {
                "patch": "@@ -188,6 +188,9 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by\n \n BUG FIXES\n \n+PIG-2018: NPE for co-group with group-by column having complex schema and \n+ different load functions for each input (thejas)\n+\n PIG-2015: Explain writes out logical plan twice (alangates)\n \n PIG-2017: consumeMap() fails with EmptyStackException (thedatachef via daijy)\n@@ -845,7 +848,7 @@ PIG-1414: Problem with parameter substitution (rding)\n PIG-1407: Logging starts before being configured (azaroth via daijy)\n \n PIG-1391: pig unit tests leave behind files in temp directory because \n-MiniCluster files don't get deleted (tejas)\n+ MiniCluster files don't get deleted (thejas)\n \n PIG-1211: Pig script runs half way after which it reports syntax error\n (pradeepkth)",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/CHANGES.txt",
                "status": "modified",
                "changes": 5,
                "deletions": 1,
                "sha": "5fe7c28bc906dd8856c97de0c088c2771130a4ad",
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9"
            },
            {
                "patch": "@@ -507,7 +507,6 @@ void mapMatchLoadFuncToUid(\n                 //check if all func spec match\n                 if(!funcSpec1.equals(uid2LoadFuncMap.get(fs.uid))){\n                     allMatch = false;\n-                    break;\n                 }\n                 //check if all inner schema match for use later\n                 if(outFS.schema == null ||  !outFS.schema.isEqual(fs.schema)){",
                "additions": 0,
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "status": "modified",
                "changes": 1,
                "deletions": 1,
                "sha": "51cc7ab6af96faaaad81247b3556c201985ac06a",
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "filename": "src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/newplan/logical/visitor/LineageFindRelVisitor.java?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9"
            },
            {
                "patch": "@@ -4106,4 +4106,17 @@ public void testUDFNoInnerSchema() throws FrontendException {\n             checkLastForeachCastLoadFunc(query, null, 0);\n         }\n \n+        //see PIG-2018\n+        @Test\n+        public void testCoGroupComplex(){\n+            String query = \n+                \"l1 = load 'x' using PigStorage(':') as (a : (i : int),b,c);\"\n+                + \"l2 = load 'x' as (a,b,c);\"\n+                + \"cg = cogroup l1 by a, l2 by a;\";\n+            try {\n+                createAndProcessLPlan(query);\n+            } catch (FrontendException e) {\n+                fail(\"caught exception creating lp\");\n+            }\n+        }\n }",
                "additions": 13,
                "raw_url": "https://github.com/apache/pig/raw/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "status": "modified",
                "changes": 13,
                "deletions": 0,
                "sha": "adf3c68527f77b173cf2cc670dfd7695dc77905f",
                "blob_url": "https://github.com/apache/pig/blob/3505a4289fc9114f214e8e20d5cb59cfd78b16e9/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "filename": "test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestTypeCheckingValidatorNewLP.java?ref=3505a4289fc9114f214e8e20d5cb59cfd78b16e9"
            }
        ],
        "bug_id": "pig_64",
        "parent": "https://github.com/apache/pig/commit/ff92a6d6eeec56d455ddd3472b3947a8d8bc3e2c",
        "message": "PIG-2018: NPE for co-group with group-by column having complex schema and\n different load functions for each input (thejas)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/pig/trunk@1098027 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c",
        "file": [
            {
                "patch": "@@ -197,6 +197,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1596: NPE's thrown when attempting to load hbase columns containing null values (zjffdu)\n+\n PIG-1597: Development snapshot jar no longer picked up by bin/pig (dvryaboy)\n \n PIG-1599: pig gives generic message for few cases (nrai via rding)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "e59239caf1aa17a8cd0217f612d6f5c160bed6db",
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c"
            },
            {
                "patch": "@@ -247,7 +247,11 @@ public Tuple getNext() throws IOException {\n                     startIndex++;\n                 }\n                 for (int i=0;i<columnList_.size();++i){\n-                    tuple.set(i+startIndex, new DataByteArray(result.getValue(columnList_.get(i))));\n+                \tbyte[] cell=result.getValue(columnList_.get(i));\n+                \tif (cell!=null)\n+                \t    tuple.set(i+startIndex, new DataByteArray(cell));\n+                \telse\n+                \t    tuple.set(i+startIndex, null);\n                 }\n                 return tuple;\n             }",
                "additions": 5,
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "status": "modified",
                "changes": 6,
                "deletions": 1,
                "sha": "1b4e5a28ffa6f23f3e08911203c4729b86dda88f",
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "filename": "src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c"
            },
            {
                "patch": "@@ -171,8 +171,8 @@ public void testLoadFromHBase() throws IOException {\n \t\tprepareTable(TESTTABLE_1, true, DataFormat.UTF8PlainText);\n \t\tpig.registerQuery(\"a = load 'hbase://\" + TESTTABLE_1 + \"' using \"\n \t\t\t\t+ \"org.apache.pig.backend.hadoop.hbase.HBaseStorage('\"\n-\t\t\t\t+ TESTCOLUMN_A + \" \" + TESTCOLUMN_B + \" \" + TESTCOLUMN_C\n-\t\t\t\t+ \"') as (col_a, col_b, col_c);\");\n+\t\t\t\t+ TESTCOLUMN_A + \" \" + TESTCOLUMN_B + \" \" + TESTCOLUMN_C +\" pig:col_d\"\n+\t\t\t\t+ \"') as (col_a, col_b, col_c, col_d);\");\n \t\tIterator<Tuple> it = pig.openIterator(\"a\");\n \t\tint count = 0;\n \t\tLOG.info(\"LoadFromHBase Starting\");\n@@ -182,10 +182,11 @@ public void testLoadFromHBase() throws IOException {\n \t\t\tString col_a = ((DataByteArray) t.get(0)).toString();\n \t\t\tString col_b = ((DataByteArray) t.get(1)).toString();\n \t\t\tString col_c = ((DataByteArray) t.get(2)).toString();\n-\n+\t\t\tObject col_d = t.get(3);       // empty cell\n \t\t\tAssert.assertEquals(count, Integer.parseInt(col_a));\n \t\t\tAssert.assertEquals(count + 0.0, Double.parseDouble(col_b), 1e-6);\n \t\t\tAssert.assertEquals(\"Text_\" + count, col_c);\n+\t\t\tAssert.assertNull(col_d);\n \t\t\tcount++;\n \t\t}\n \t\tAssert.assertEquals(TEST_ROW_COUNT, count);",
                "additions": 4,
                "raw_url": "https://github.com/apache/pig/raw/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/test/org/apache/pig/test/TestHBaseStorage.java",
                "status": "modified",
                "changes": 7,
                "deletions": 3,
                "sha": "d8f5f6e5bb4a197d77d82815850b1b3f16df7549",
                "blob_url": "https://github.com/apache/pig/blob/1a1e5e336dee8e0b5b8358b92bfab657f82cae0c/test/org/apache/pig/test/TestHBaseStorage.java",
                "filename": "test/org/apache/pig/test/TestHBaseStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestHBaseStorage.java?ref=1a1e5e336dee8e0b5b8358b92bfab657f82cae0c"
            }
        ],
        "bug_id": "pig_65",
        "parent": "https://github.com/apache/pig/commit/e08f4375537ebf0e4b4a2672444894db0c9a78c5",
        "message": "PIG-1596: NPE's thrown when attempting to load hbase columns containing null values (zjffdu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@992926 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/cc58ab80914074ff513e78234f2f2a663e078b04",
        "file": [
            {
                "patch": "@@ -197,6 +197,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1597: NPE's thrown when attempting to load hbase columns containing null values (dvryaboy)\n+\n PIG-1599: pig gives generic message for few cases (nrai via rding)\n \n PIG-1595: casting relation to scalar- problem with handling of data from non PigStorage loaders (thejas)",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/cc58ab80914074ff513e78234f2f2a663e078b04/CHANGES.txt",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "0a82df22dc789bb98fa33795e91fa90c1f9e2a8a",
                "blob_url": "https://github.com/apache/pig/blob/cc58ab80914074ff513e78234f2f2a663e078b04/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=cc58ab80914074ff513e78234f2f2a663e078b04"
            },
            {
                "patch": "@@ -131,7 +131,7 @@ for f in $PIG_HOME/pig-*-core.jar; do\n done\n \n # during development pig jar might be in build\n-for f in $PIG_HOME/build/pig-*-dev.jar; do\n+for f in $PIG_HOME/build/pig-*-SNAPSHOT.jar; do\n     CLASSPATH=${CLASSPATH}:$f;\n done\n ",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/cc58ab80914074ff513e78234f2f2a663e078b04/bin/pig",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "ffb155c3d21d7c7cb0f85914b866239141388500",
                "blob_url": "https://github.com/apache/pig/blob/cc58ab80914074ff513e78234f2f2a663e078b04/bin/pig",
                "filename": "bin/pig",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/bin/pig?ref=cc58ab80914074ff513e78234f2f2a663e078b04"
            }
        ],
        "bug_id": "pig_66",
        "parent": "https://github.com/apache/pig/commit/e440118f88700ed4efd8e6b9e14fdea854036549",
        "message": "PIG-1597: NPEs thrown when attempting to load hbase columns containing null values\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@992677 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/9c4d36691393bd0f024d7de5f79c2492cf9469ad",
        "file": [
            {
                "patch": "@@ -39,6 +39,9 @@ PIG-1309: Map-side Cogroup (ashutoshc)\n \n BUG FIXES\n \n+PIG-1366: PigStorage's pushProjection implementation results in NPE under\n+certain data conditions (pradeepkth)\n+\n PIG-1365: WrappedIOException is missing from Pig.jar (pradeepkth)\n \n PIG-1313: PigServer leaks memory over time (billgraham via daijy)",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/CHANGES.txt",
                "status": "modified",
                "changes": 3,
                "deletions": 0,
                "sha": "65cdc4e1b4b077c66a5de982a765cedf9c449f58",
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/CHANGES.txt",
                "filename": "CHANGES.txt",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/CHANGES.txt?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad"
            },
            {
                "patch": "@@ -97,6 +97,7 @@ public PigStorage(String delimiter) {\n \n     @Override\n     public Tuple getNext() throws IOException {\n+        mProtoTuple = new ArrayList<Object>();\n         if (!mRequiredColumnsInitialized) {\n             if (signature!=null) {\n                 Properties p = UDFContext.getUDFContext().getUDFProperties(this.getClass());\n@@ -127,7 +128,6 @@ public Tuple getNext() throws IOException {\n                 readField(buf, start, len);\n             }\n             Tuple t =  mTupleFactory.newTupleNoCopy(mProtoTuple);\n-            mProtoTuple = null;\n             return t;\n         } catch (InterruptedException e) {\n             int errCode = 6018;\n@@ -171,10 +171,6 @@ public void putNext(Tuple f) throws IOException {\n     }\n \n     private void readField(byte[] buf, int start, int end) {\n-        if (mProtoTuple == null) {\n-            mProtoTuple = new ArrayList<Object>();\n-        }\n-\n         if (start == end) {\n             // NULL value\n             mProtoTuple.add(null);",
                "additions": 1,
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/src/org/apache/pig/builtin/PigStorage.java",
                "status": "modified",
                "changes": 6,
                "deletions": 5,
                "sha": "de877f55ecfab3b0de9fa955bcc9bb5d304989e8",
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/src/org/apache/pig/builtin/PigStorage.java",
                "filename": "src/org/apache/pig/builtin/PigStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/PigStorage.java?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad"
            },
            {
                "patch": "@@ -26,46 +26,47 @@\n import java.io.IOException;\n import java.io.PrintWriter;\n import java.util.Iterator;\n+import java.util.Properties;\n+import java.util.Map.Entry;\n \n import junit.framework.Assert;\n \n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n+import org.apache.pig.ExecType;\n import org.apache.pig.PigServer;\n import org.apache.pig.backend.executionengine.ExecException;\n+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject;\n import org.apache.pig.data.Tuple;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n+import org.apache.pig.impl.io.FileLocalizer;\n+import org.junit.Before;\n import org.junit.Test;\n \n-public class TestPigStorage {\n+public class TestPigStorage  {\n         \n     protected final Log log = LogFactory.getLog(getClass());\n     \n     private static MiniCluster cluster = MiniCluster.buildCluster();\n-    private static PigServer pigServer = null;\n     \n-    \n-    @BeforeClass\n-    public static void setup() {\n-        try {\n-            pigServer = new PigServer(MAPREDUCE, cluster.getProperties());\n-        } catch (ExecException e) {\n-            e.printStackTrace();\n-            Assert.fail();\n-        }\n-    }\n-    \n-    @AfterClass\n-    public static void shutdown() {\n-        pigServer.shutdown();\n+    @Before\n+    public void setup() {\n+        // some tests are in map-reduce mode and some in local - so before\n+        // each test, we will de-initialize FileLocalizer so that temp files\n+        // are created correctly depending on the ExecType in the test.\n+        FileLocalizer.setInitialized(false);\n     }\n     \n     @Test\n-    public void testBlockBoundary() {\n+    public void testBlockBoundary() throws ExecException {\n         \n         // This tests PigStorage loader with records exectly \n         // on the boundary of the file blocks.\n+        Properties props = new Properties();\n+        for (Entry<Object, Object> entry : cluster.getProperties().entrySet()) {\n+            props.put(entry.getKey(), entry.getValue());\n+        }\n+        props.setProperty(\"mapred.max.split.size\", \"20\");\n+        PigServer pigServer = new PigServer(MAPREDUCE, props);\n         String[] inputs = {\n                 \"abcdefgh1\", \"abcdefgh2\", \"abcdefgh3\", \n                 \"abcdefgh4\", \"abcdefgh5\", \"abcdefgh6\",\n@@ -115,5 +116,32 @@ public void testBlockBoundary() {\n             }\n         }\n     } \n+    \n+    /**\n+     * Test to verify that PigStorage works fine in the following scenario:\n+     * The column prune optimization determines only columns 2 and 3 are needed\n+     * and there are records in the data which have only 1 column (malformed data).\n+     * In this case, PigStorage should return an empty tuple to represent columns\n+     * 2 and 3 and {@link POProject} would handle catching any \n+     * {@link IndexOutOfBoundsException} resulting from accessing a field in the\n+     * tuple and substitute a null. \n+     */\n+    @Test\n+    public void testPruneColumnsWithMissingFields() throws IOException {\n+        String inputFileName = \"TestPigStorage-testPruneColumnsWithMissingFields-input.txt\";\n+        Util.createLocalInputFile(\n+                inputFileName, \n+                new String[] {\"1\\t2\\t3\", \"4\", \"5\\t6\\t7\"});\n+        PigServer ps = new PigServer(ExecType.LOCAL);\n+        String script = \"a = load '\" + inputFileName + \"' as (i:int, j:int, k:int);\" +\n+        \t\t\"b = foreach a generate j, k;\";\n+        Util.registerMultiLineQuery(ps, script);\n+        Iterator<Tuple> it = ps.openIterator(\"b\");\n+        assertEquals(Util.createTuple(new Integer[] { 2, 3}), it.next());\n+        assertEquals(Util.createTuple(new Integer[] { null, null}), it.next());\n+        assertEquals(Util.createTuple(new Integer[] { 6, 7}), it.next());\n+        assertFalse(it.hasNext());\n+                \n+    }\n \n }",
                "additions": 47,
                "raw_url": "https://github.com/apache/pig/raw/9c4d36691393bd0f024d7de5f79c2492cf9469ad/test/org/apache/pig/test/TestPigStorage.java",
                "status": "modified",
                "changes": 66,
                "deletions": 19,
                "sha": "356b082d8aa0bee9ef02022c664b311990f91ef4",
                "blob_url": "https://github.com/apache/pig/blob/9c4d36691393bd0f024d7de5f79c2492cf9469ad/test/org/apache/pig/test/TestPigStorage.java",
                "filename": "test/org/apache/pig/test/TestPigStorage.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/test/org/apache/pig/test/TestPigStorage.java?ref=9c4d36691393bd0f024d7de5f79c2492cf9469ad"
            }
        ],
        "bug_id": "pig_67",
        "parent": "https://github.com/apache/pig/commit/28f0849b88b81e2703c633af5082744f1a7bcc45",
        "message": "PIG-1366: PigStorage's pushProjection implementation results in NPE under certain data conditions (pradeepkth)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@932144 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/3a356b5e672dab1a3ad52c7b8d1b396bc3f5965b",
        "file": [
            {
                "patch": "@@ -70,7 +70,9 @@ public Schema getSchema() {\n     public Schema.FieldSchema getFieldSchema() throws FrontendException {\n         if(!mIsFieldSchemaComputed) {\n             mFieldSchema = new Schema.FieldSchema(null, mType);\n-            mFieldSchema.setParent(getExpression().mFieldSchema.canonicalName, getExpression());\n+            Schema.FieldSchema parFs  = getExpression().getFieldSchema();\n+            String canonicalName = (parFs != null ? parFs.canonicalName : null);\n+            mFieldSchema.setParent(canonicalName, getExpression());\n             mIsFieldSchemaComputed = true;\n         }\n         return mFieldSchema;",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/3a356b5e672dab1a3ad52c7b8d1b396bc3f5965b/src/org/apache/pig/impl/logicalLayer/LOCast.java",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "1757078a8b8f87358e73d53af144749559b606f9",
                "blob_url": "https://github.com/apache/pig/blob/3a356b5e672dab1a3ad52c7b8d1b396bc3f5965b/src/org/apache/pig/impl/logicalLayer/LOCast.java",
                "filename": "src/org/apache/pig/impl/logicalLayer/LOCast.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/impl/logicalLayer/LOCast.java?ref=3a356b5e672dab1a3ad52c7b8d1b396bc3f5965b"
            }
        ],
        "bug_id": "pig_68",
        "parent": "https://github.com/apache/pig/commit/8eec835de57b4c29519efd3107e277eb948829c2",
        "message": "PIG-942: Maps are not implicitly casted (fixed a possible NPE from earlier commit for this patch) (pradeepkth)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@818929 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    },
    {
        "commit": "https://github.com/apache/pig/commit/cb9e4699894adae3b547328f0b6663d9672e687c",
        "file": [
            {
                "patch": "@@ -45,6 +45,8 @@ public DataByteArray exec(Tuple input) throws IOException {\n \n             DataByteArray db = new DataByteArray();\n             for (int i = 0; i < input.size(); i++) {\n+                if (input.get(i)==null)\n+                    return null;\n                 db.append((DataByteArray)(input.get(i)));\n             }\n             return db;",
                "additions": 2,
                "raw_url": "https://github.com/apache/pig/raw/cb9e4699894adae3b547328f0b6663d9672e687c/src/org/apache/pig/builtin/CONCAT.java",
                "status": "modified",
                "changes": 2,
                "deletions": 0,
                "sha": "815479d7d33ee74b09034127389a5360a2b038fa",
                "blob_url": "https://github.com/apache/pig/blob/cb9e4699894adae3b547328f0b6663d9672e687c/src/org/apache/pig/builtin/CONCAT.java",
                "filename": "src/org/apache/pig/builtin/CONCAT.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/CONCAT.java?ref=cb9e4699894adae3b547328f0b6663d9672e687c"
            },
            {
                "patch": "@@ -39,7 +39,9 @@ public String exec(Tuple input) throws IOException {\n \n           StringBuilder sb = new StringBuilder();\n           for (int i = 0; i < input.size(); i++){\n-            sb.append(String.valueOf(input.get(i)));\n+              if (input.get(i)==null)\n+                  return null;\n+              sb.append(String.valueOf(input.get(i)));\n           }\n           return sb.toString();\n         } catch (ExecException exp) {",
                "additions": 3,
                "raw_url": "https://github.com/apache/pig/raw/cb9e4699894adae3b547328f0b6663d9672e687c/src/org/apache/pig/builtin/StringConcat.java",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "815e3bf89e22f0a943d891de4c1305bed11bc44b",
                "blob_url": "https://github.com/apache/pig/blob/cb9e4699894adae3b547328f0b6663d9672e687c/src/org/apache/pig/builtin/StringConcat.java",
                "filename": "src/org/apache/pig/builtin/StringConcat.java",
                "contents_url": "https://api.github.com/repos/apache/pig/contents/src/org/apache/pig/builtin/StringConcat.java?ref=cb9e4699894adae3b547328f0b6663d9672e687c"
            }
        ],
        "bug_id": "pig_69",
        "parent": "https://github.com/apache/pig/commit/d3b2bab0f3b3b6154dfff8b3b0afef9e4508d150",
        "message": "PIG-1420: Make CONCAT act on all fields of a tuple, instead of just the first two fields of a tuple (fix NPE)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/pig/trunk@947105 13f79535-47bb-0310-9956-ffa450edef68",
        "repo": "pig"
    }
]