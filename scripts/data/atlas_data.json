[
    {
        "commit": "https://github.com/apache/atlas/commit/c95aba218b9318ce44abf574faff62908f24916d",
        "file": [
            {
                "patch": "@@ -1862,6 +1862,10 @@ public void deleteClassification(String entityGuid, String classificationName) t\n         AtlasVertex         classificationVertex = getClassificationVertex(entityVertex, classificationName);\n         AtlasClassification classification       = entityRetriever.toAtlasClassification(classificationVertex);\n \n+        if (classification == null) {\n+            throw new AtlasBaseException(AtlasErrorCode.CLASSIFICATION_NOT_FOUND, classificationName);\n+        }\n+\n         // remove classification from propagated entities if propagation is turned on\n         if (isPropagationEnabled(classificationVertex)) {\n             List<AtlasVertex> propagatedEntityVertices = deleteDelegate.getHandler().removeTagPropagation(classificationVertex);\n@@ -2028,6 +2032,10 @@ public void updateClassifications(EntityMutationContext context, String guid, Li\n \n             AtlasClassification currentClassification = entityRetriever.toAtlasClassification(classificationVertex);\n \n+            if (currentClassification == null) {\n+                continue;\n+            }\n+\n             validateAndNormalizeForUpdate(classification);\n \n             boolean isClassificationUpdated = false;",
                "additions": 8,
                "raw_url": "https://github.com/apache/atlas/raw/c95aba218b9318ce44abf574faff62908f24916d/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphMapper.java",
                "status": "modified",
                "changes": 8,
                "deletions": 0,
                "sha": "a415d3084c80e57b682175d9a7f34145fcf54147",
                "blob_url": "https://github.com/apache/atlas/blob/c95aba218b9318ce44abf574faff62908f24916d/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphMapper.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphMapper.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphMapper.java?ref=c95aba218b9318ce44abf574faff62908f24916d"
            },
            {
                "patch": "@@ -277,20 +277,27 @@ public AtlasObjectId toAtlasObjectIdWithoutGuid(AtlasEntity entity) {\n     }\n \n     public AtlasClassification toAtlasClassification(AtlasVertex classificationVertex) throws AtlasBaseException {\n-        AtlasClassification ret = new AtlasClassification(getTypeName(classificationVertex));\n+        AtlasClassification ret                = null;\n+        String              classificationName = getTypeName(classificationVertex);\n \n-        ret.setEntityGuid(AtlasGraphUtilsV2.getEncodedProperty(classificationVertex, CLASSIFICATION_ENTITY_GUID, String.class));\n-        ret.setEntityStatus(getClassificationEntityStatus(classificationVertex));\n-        ret.setPropagate(isPropagationEnabled(classificationVertex));\n-        ret.setRemovePropagationsOnEntityDelete(getRemovePropagations(classificationVertex));\n+        if (StringUtils.isEmpty(classificationName)) {\n+            LOG.warn(\"Ignoring invalid classification vertex: {}\", AtlasGraphUtilsV2.toString(classificationVertex));\n+        } else {\n+            ret = new AtlasClassification(classificationName);\n \n-        String strValidityPeriods = AtlasGraphUtilsV2.getEncodedProperty(classificationVertex, CLASSIFICATION_VALIDITY_PERIODS_KEY, String.class);\n+            ret.setEntityGuid(AtlasGraphUtilsV2.getEncodedProperty(classificationVertex, CLASSIFICATION_ENTITY_GUID, String.class));\n+            ret.setEntityStatus(getClassificationEntityStatus(classificationVertex));\n+            ret.setPropagate(isPropagationEnabled(classificationVertex));\n+            ret.setRemovePropagationsOnEntityDelete(getRemovePropagations(classificationVertex));\n \n-        if (strValidityPeriods != null) {\n-            ret.setValidityPeriods(AtlasJson.fromJson(strValidityPeriods, TIME_BOUNDARIES_LIST_TYPE));\n-        }\n+            String strValidityPeriods = AtlasGraphUtilsV2.getEncodedProperty(classificationVertex, CLASSIFICATION_VALIDITY_PERIODS_KEY, String.class);\n \n-        mapAttributes(classificationVertex, ret, null);\n+            if (strValidityPeriods != null) {\n+                ret.setValidityPeriods(AtlasJson.fromJson(strValidityPeriods, TIME_BOUNDARIES_LIST_TYPE));\n+            }\n+\n+            mapAttributes(classificationVertex, ret, null);\n+        }\n \n         return ret;\n     }\n@@ -621,10 +628,12 @@ private void mapAttributes(AtlasVertex entityVertex, AtlasStruct struct, AtlasEn\n             Iterator<AtlasEdge> iterator = edges.iterator();\n \n             while (iterator.hasNext()) {\n-                AtlasEdge edge = iterator.next();\n+                AtlasEdge           classificationEdge   = iterator.next();\n+                AtlasVertex         classificationVertex = classificationEdge != null ? classificationEdge.getInVertex() : null;\n+                AtlasClassification classification       = toAtlasClassification(classificationVertex);\n \n-                if (edge != null) {\n-                    ret.add(toAtlasClassification(edge.getInVertex()));\n+                if (classification != null) {\n+                    ret.add(classification);\n                 }\n             }\n         }\n@@ -711,12 +720,15 @@ private void mapClassifications(AtlasVertex entityVertex, AtlasEntity entity) th\n         List<AtlasEdge> edges = getAllClassificationEdges(entityVertex);\n \n         if (CollectionUtils.isNotEmpty(edges)) {\n-            List<AtlasClassification> allClassifications                 = new ArrayList<>();\n+            List<AtlasClassification> allClassifications = new ArrayList<>();\n \n             for (AtlasEdge edge : edges) {\n-                AtlasVertex classificationVertex = edge.getInVertex();\n+                AtlasVertex         classificationVertex = edge.getInVertex();\n+                AtlasClassification classification       = toAtlasClassification(classificationVertex);\n \n-                allClassifications.add(toAtlasClassification(classificationVertex));\n+                if (classification != null) {\n+                    allClassifications.add(classification);\n+                }\n             }\n \n             entity.setClassifications(allClassifications);\n@@ -1387,7 +1399,10 @@ private void readClassificationsFromEdge(AtlasEdge edge, AtlasRelationshipWithEx\n         for (AtlasVertex classificationVertex : classificationVertices) {\n             String              classificationId = classificationVertex.getIdForDisplay();\n             AtlasClassification classification   = toAtlasClassification(classificationVertex);\n-            String              entityGuid       = classification.getEntityGuid();\n+\n+            if (classification == null) {\n+                continue;\n+            }\n \n             if (blockedClassificationIds.contains(classificationId)) {\n                 blockedClassifications.add(classification);\n@@ -1397,7 +1412,7 @@ private void readClassificationsFromEdge(AtlasEdge edge, AtlasRelationshipWithEx\n \n             // add entity headers to referred entities\n             if (extendedInfo) {\n-                addToReferredEntities(relationshipWithExtInfo, entityGuid);\n+                addToReferredEntities(relationshipWithExtInfo, classification.getEntityGuid());\n             }\n         }\n ",
                "additions": 33,
                "raw_url": "https://github.com/apache/atlas/raw/c95aba218b9318ce44abf574faff62908f24916d/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphRetriever.java",
                "status": "modified",
                "changes": 51,
                "deletions": 18,
                "sha": "8a24fa1272d6d4e8c83decc76860e572de7a4e17",
                "blob_url": "https://github.com/apache/atlas/blob/c95aba218b9318ce44abf574faff62908f24916d/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphRetriever.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphRetriever.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v2/EntityGraphRetriever.java?ref=c95aba218b9318ce44abf574faff62908f24916d"
            }
        ],
        "bug_id": "atlas_1",
        "parent": "https://github.com/apache/atlas/commit/8ca94c8de23c2453385656862244b268ea6482fe",
        "message": "ATLAS-3545: NullPointerException while trying to delete classification",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/d9ebc242be55be0d898d95e02283a84cc887807b",
        "file": [
            {
                "patch": "@@ -99,22 +99,27 @@ public DeleteHandlerV1(AtlasTypeRegistry typeRegistry, boolean shouldUpdateInver\n      * @throws AtlasException\n      */\n     public void deleteEntities(Collection<AtlasVertex> instanceVertices) throws AtlasBaseException {\n-        RequestContext   requestContext            = RequestContext.get();\n-        Set<AtlasVertex> deletionCandidateVertices = new HashSet<>();\n+        final RequestContext   requestContext            = RequestContext.get();\n+        final Set<AtlasVertex> deletionCandidateVertices = new HashSet<>();\n+        final boolean          isPurgeRequested          = requestContext.isPurgeRequested();\n \n         for (AtlasVertex instanceVertex : instanceVertices) {\n-            String              guid = AtlasGraphUtilsV2.getIdFromVertex(instanceVertex);\n-            AtlasEntity.Status state = getState(instanceVertex);\n+            final String             guid  = AtlasGraphUtilsV2.getIdFromVertex(instanceVertex);\n+            final AtlasEntity.Status state = getState(instanceVertex);\n+            final boolean            needToSkip;\n \n-            boolean needToSkip = requestContext.isPurgeRequested() ? (state == ACTIVE || requestContext.isPurgedEntity(guid)) :\n-                    (state == DELETED || requestContext.isDeletedEntity(guid));\n+            if (isPurgeRequested) {\n+                needToSkip = state == ACTIVE || requestContext.isPurgedEntity(guid);\n+            } else {\n+                needToSkip = state == DELETED || requestContext.isDeletedEntity(guid);\n+            }\n \n             if (needToSkip) {\n                 if (LOG.isDebugEnabled()) {\n-                    if(RequestContext.get().isPurgeRequested()) {\n-                        LOG.debug(\"Skipping purging of {} as it is active or already purged\", guid);\n+                    if (isPurgeRequested) {\n+                        LOG.debug(\"Skipping purging of entity={} as it is active or already purged\", guid);\n                     } else {\n-                        LOG.debug(\"Skipping deletion of {} as it is already deleted\", guid);\n+                        LOG.debug(\"Skipping deletion of entity={} as it is already deleted\", guid);\n                     }\n                 }\n \n@@ -154,16 +159,18 @@ public void deleteRelationship(AtlasEdge edge) throws AtlasBaseException {\n      * @throws AtlasBaseException\n      */\n     public void deleteRelationships(Collection<AtlasEdge> edges, final boolean forceDelete) throws AtlasBaseException {\n+        final boolean isPurgeRequested = RequestContext.get().isPurgeRequested();\n+\n         for (AtlasEdge edge : edges) {\n             boolean isInternal = isInternalType(edge.getInVertex()) && isInternalType(edge.getOutVertex());\n-            boolean needToSkip = !isInternal && (RequestContext.get().isPurgeRequested() ? getState(edge) == ACTIVE : getState(edge) == DELETED);\n+            boolean needToSkip = !isInternal && (getState(edge) == (isPurgeRequested ? ACTIVE : DELETED));\n \n             if (needToSkip) {\n                 if (LOG.isDebugEnabled()) {\n-                    if(RequestContext.get().isPurgeRequested()) {\n-                        LOG.debug(\"Skipping purging of {} as it is active or already purged\", getIdFromEdge(edge));\n+                    if(isPurgeRequested) {\n+                        LOG.debug(\"Skipping purging of edge={} as it is active or already purged\", getIdFromEdge(edge));\n                     } else{\n-                        LOG.debug(\"Skipping deletion of {} as it is already deleted\", getIdFromEdge(edge));\n+                        LOG.debug(\"Skipping deletion of edge={} as it is already deleted\", getIdFromEdge(edge));\n                     }\n                 }\n \n@@ -186,8 +193,9 @@ public void deleteRelationships(Collection<AtlasEdge> edges, final boolean force\n      * @throws AtlasException\n      */\n     public Collection<GraphHelper.VertexInfo> getOwnedVertices(AtlasVertex entityVertex) throws AtlasBaseException {\n-        Map<String, GraphHelper.VertexInfo> vertexInfoMap = new HashMap<>();\n-        Stack<AtlasVertex>                  vertices      = new Stack<>();\n+        final Map<String, GraphHelper.VertexInfo> vertexInfoMap    = new HashMap<>();\n+        final Stack<AtlasVertex>                  vertices         = new Stack<>();\n+        final boolean                             isPurgeRequested = RequestContext.get().isPurgeRequested();\n \n         vertices.push(entityVertex);\n \n@@ -197,8 +205,7 @@ public void deleteRelationships(Collection<AtlasEdge> edges, final boolean force\n \n             //In case of purge If the reference vertex is active then skip it or else\n             //If the vertex marked for deletion, skip it\n-            boolean needToSkip = RequestContext.get().isPurgeRequested() ? (state == ACTIVE) : (state == DELETED);\n-            if (needToSkip) {\n+            if (state == (isPurgeRequested ? ACTIVE : DELETED)) {\n                 continue;\n             }\n \n@@ -235,9 +242,7 @@ public void deleteRelationships(Collection<AtlasEdge> edges, final boolean force\n                     } else {\n                         AtlasEdge edge = graphHelper.getEdgeForLabel(vertex, edgeLabel);\n \n-                        needToSkip = (edge == null || RequestContext.get().isPurgeRequested() ?\n-                                getState(edge) == ACTIVE : getState(edge) == DELETED);\n-                        if (needToSkip) {\n+                        if (edge == null || (getState(edge) == (isPurgeRequested ? ACTIVE : DELETED))) {\n                             continue;\n                         }\n \n@@ -290,9 +295,7 @@ public void deleteRelationships(Collection<AtlasEdge> edges, final boolean force\n \n                         if (CollectionUtils.isNotEmpty(edges)) {\n                             for (AtlasEdge edge : edges) {\n-                                needToSkip = (edge == null || RequestContext.get().isPurgeRequested() ?\n-                                        getState(edge) == ACTIVE : getState(edge) == DELETED);\n-                                if (needToSkip) {\n+                                if (edge == null || (getState(edge) == (isPurgeRequested ? ACTIVE : DELETED))) {\n                                     continue;\n                                 }\n \n@@ -852,12 +855,17 @@ protected void deleteEdgeBetweenVertices(AtlasVertex outVertex, AtlasVertex inVe\n             LOG.debug(\"Removing edge from {} to {} with attribute name {}\", string(outVertex), string(inVertex), attribute.getName());\n         }\n \n-        final String typeName = GraphHelper.getTypeName(outVertex);\n-        final String outId    = GraphHelper.getGuid(outVertex);\n-        final Status state    = getState(outVertex);\n+        final RequestContext requestContext = RequestContext.get();\n+        final String         typeName       = GraphHelper.getTypeName(outVertex);\n+        final String         outId          = GraphHelper.getGuid(outVertex);\n+        final Status         state          = getState(outVertex);\n+        final boolean        needToSkip;\n \n-        boolean needToSkip = RequestContext.get().isPurgeRequested() ? state == ACTIVE || (outId != null && RequestContext.get().isPurgedEntity(outId)) :\n-                state == DELETED || (outId != null && RequestContext.get().isDeletedEntity(outId));\n+        if (requestContext.isPurgeRequested()) {\n+            needToSkip = state == ACTIVE || (outId != null && requestContext.isPurgedEntity(outId));\n+        } else {\n+            needToSkip = state == DELETED || (outId != null && requestContext.isDeletedEntity(outId));\n+        }\n \n         if (needToSkip) {\n             return;\n@@ -952,8 +960,6 @@ protected void deleteEdgeBetweenVertices(AtlasVertex outVertex, AtlasVertex inVe\n         if (edge != null) {\n             deleteEdge(edge, isInternalType(inVertex) && isInternalType(outVertex));\n \n-            RequestContext requestContext = RequestContext.get();\n-\n             if (! requestContext.isUpdatedEntity(outId)) {\n                 AtlasGraphUtilsV2.setEncodedProperty(outVertex, MODIFICATION_TIMESTAMP_PROPERTY_KEY, requestContext.getRequestTime());\n                 AtlasGraphUtilsV2.setEncodedProperty(outVertex, MODIFIED_BY_KEY, requestContext.getUser());\n@@ -969,12 +975,13 @@ protected void deleteVertex(AtlasVertex instanceVertex, boolean force) throws At\n         }\n \n         // Delete external references to this vertex - incoming edges from lineage or glossary term edges\n-        Iterable<AtlasEdge> incomingEdges = instanceVertex.getEdges(AtlasEdgeDirection.IN);\n+        final Iterable<AtlasEdge> incomingEdges    = instanceVertex.getEdges(AtlasEdgeDirection.IN);\n+        final boolean             isPurgeRequested = RequestContext.get().isPurgeRequested();\n \n         for (AtlasEdge edge : incomingEdges) {\n-            Status edgeState = getState(edge);\n+            AtlasEntity.Status edgeStatus = getStatus(edge);\n+            boolean            isProceed   = edgeStatus == (isPurgeRequested ? DELETED : ACTIVE);\n \n-            boolean isProceed = RequestContext.get().isPurgeRequested()? edgeState == DELETED : edgeState == ACTIVE;\n             if (isProceed) {\n                 if (isRelationshipEdge(edge)) {\n                     deleteRelationship(edge);",
                "additions": 40,
                "raw_url": "https://github.com/apache/atlas/raw/d9ebc242be55be0d898d95e02283a84cc887807b/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/DeleteHandlerV1.java",
                "status": "modified",
                "changes": 73,
                "deletions": 33,
                "sha": "c9ed7975006da65e4513542995ca0edd201034b3",
                "blob_url": "https://github.com/apache/atlas/blob/d9ebc242be55be0d898d95e02283a84cc887807b/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/DeleteHandlerV1.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v1/DeleteHandlerV1.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/DeleteHandlerV1.java?ref=d9ebc242be55be0d898d95e02283a84cc887807b"
            }
        ],
        "bug_id": "atlas_2",
        "parent": "https://github.com/apache/atlas/commit/9f5b7861e6bf4975b84cd9db0f3397d128cb3157",
        "message": "ATLAS-3544: fix NPE during entity-delete",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/f75d7f409f3323e799bb33e6ae1da89526fc475c",
        "file": [
            {
                "patch": "@@ -475,7 +475,7 @@ protected AtlasEntity getStorageDescEntity(AtlasObjectId tableId, Table table) {\n             ret.setAttribute(ATTRIBUTE_NUM_BUCKETS, sd.getNumBuckets());\n             ret.setAttribute(ATTRIBUTE_STORED_AS_SUB_DIRECTORIES, sd.isStoredAsSubDirectories());\n \n-            if (sd.getBucketCols().size() > 0) {\n+            if (sd.getBucketCols() != null && sd.getBucketCols().size() > 0) {\n                 ret.setAttribute(ATTRIBUTE_BUCKET_COLS, sd.getBucketCols());\n             }\n \n@@ -512,36 +512,38 @@ protected AtlasEntity getStorageDescEntity(AtlasObjectId tableId, Table table) {\n     }\n \n     protected List<AtlasEntity> getColumnEntities(AtlasObjectId tableId, Table table, List<FieldSchema> fieldSchemas) {\n-        List<AtlasEntity> ret          = new ArrayList<>();\n-        boolean           isKnownTable = tableId.getGuid() == null;\n-\n-        int columnPosition = 0;\n-        for (FieldSchema fieldSchema : fieldSchemas) {\n-            String      colQualifiedName = getQualifiedName(table, fieldSchema);\n-            AtlasEntity column           = context.getEntity(colQualifiedName);\n+        List<AtlasEntity> ret            = new ArrayList<>();\n+        boolean           isKnownTable   = tableId.getGuid() == null;\n+        int               columnPosition = 0;\n+\n+        if (CollectionUtils.isNotEmpty(fieldSchemas)) {\n+            for (FieldSchema fieldSchema : fieldSchemas) {\n+                String      colQualifiedName = getQualifiedName(table, fieldSchema);\n+                AtlasEntity column           = context.getEntity(colQualifiedName);\n+\n+                if (column == null) {\n+                    column = new AtlasEntity(HIVE_TYPE_COLUMN);\n+\n+                    // if column's table was sent in an earlier notification, set 'guid' to null - which will:\n+                    //  - result in this entity to be not included in 'referredEntities'\n+                    //  - cause Atlas server to resolve the entity by its qualifiedName\n+                    if (isKnownTable) {\n+                        column.setGuid(null);\n+                    }\n \n-            if (column == null) {\n-                column = new AtlasEntity(HIVE_TYPE_COLUMN);\n+                    column.setAttribute(ATTRIBUTE_TABLE, tableId);\n+                    column.setAttribute(ATTRIBUTE_QUALIFIED_NAME, colQualifiedName);\n+                    column.setAttribute(ATTRIBUTE_NAME, fieldSchema.getName());\n+                    column.setAttribute(ATTRIBUTE_OWNER, table.getOwner());\n+                    column.setAttribute(ATTRIBUTE_COL_TYPE, fieldSchema.getType());\n+                    column.setAttribute(ATTRIBUTE_COL_POSITION, columnPosition++);\n+                    column.setAttribute(ATTRIBUTE_COMMENT, fieldSchema.getComment());\n \n-                // if column's table was sent in an earlier notification, set 'guid' to null - which will:\n-                //  - result in this entity to be not included in 'referredEntities'\n-                //  - cause Atlas server to resolve the entity by its qualifiedName\n-                if (isKnownTable) {\n-                    column.setGuid(null);\n+                    context.putEntity(colQualifiedName, column);\n                 }\n \n-                column.setAttribute(ATTRIBUTE_TABLE, tableId);\n-                column.setAttribute(ATTRIBUTE_QUALIFIED_NAME, colQualifiedName);\n-                column.setAttribute(ATTRIBUTE_NAME, fieldSchema.getName());\n-                column.setAttribute(ATTRIBUTE_OWNER, table.getOwner());\n-                column.setAttribute(ATTRIBUTE_COL_TYPE, fieldSchema.getType());\n-                column.setAttribute(ATTRIBUTE_COL_POSITION, columnPosition++);\n-                column.setAttribute(ATTRIBUTE_COMMENT, fieldSchema.getComment());\n-\n-                context.putEntity(colQualifiedName, column);\n+                ret.add(column);\n             }\n-\n-            ret.add(column);\n         }\n \n         return ret;",
                "additions": 28,
                "raw_url": "https://github.com/apache/atlas/raw/f75d7f409f3323e799bb33e6ae1da89526fc475c/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "status": "modified",
                "changes": 54,
                "deletions": 26,
                "sha": "7b4b8935dac94e4695ab46ff17703b2fd61da611",
                "blob_url": "https://github.com/apache/atlas/blob/f75d7f409f3323e799bb33e6ae1da89526fc475c/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java?ref=f75d7f409f3323e799bb33e6ae1da89526fc475c"
            }
        ],
        "bug_id": "atlas_3",
        "parent": "https://github.com/apache/atlas/commit/49db4cacbb07dd018876e77b872f483ef941a152",
        "message": "ATLAS-3202: Hive hook: getStorageDescEntity() throws NPE if bucketCols is null",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/a5f971a322b75a7cc2bd9e8bdf021be46e03b63d",
        "file": [
            {
                "patch": "@@ -6,9 +6,9 @@\n  * to you under the Apache License, Version 2.0 (the\n  * \"License\"); you may not use this file except in compliance\n  * with the License.  You may obtain a copy of the License at\n- *\n+ * <p>\n  * http://www.apache.org/licenses/LICENSE-2.0\n- *\n+ * <p>\n  * Unless required by applicable law or agreed to in writing, software\n  * distributed under the License is distributed on an \"AS IS\" BASIS,\n  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n@@ -40,31 +40,31 @@\n import static com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.PUBLIC_ONLY;\n \n \n-@JsonAutoDetect(getterVisibility=PUBLIC_ONLY, setterVisibility=PUBLIC_ONLY, fieldVisibility=NONE)\n-@JsonSerialize(include=JsonSerialize.Inclusion.NON_NULL)\n-@JsonIgnoreProperties(ignoreUnknown=true)\n+@JsonAutoDetect(getterVisibility = PUBLIC_ONLY, setterVisibility = PUBLIC_ONLY, fieldVisibility = NONE)\n+@JsonSerialize(include = JsonSerialize.Inclusion.NON_NULL)\n+@JsonIgnoreProperties(ignoreUnknown = true)\n @XmlRootElement\n @XmlAccessorType(XmlAccessType.PROPERTY)\n public class AtlasExportRequest implements Serializable {\n \n     private static final long serialVersionUID = 1L;\n \n-    public static final String OPTION_FETCH_TYPE                    = \"fetchType\";\n-    public static final String OPTION_ATTR_MATCH_TYPE               = \"matchType\";\n-    public static final String OPTION_SKIP_LINEAGE                  = \"skipLineage\";\n-    public static final String OPTION_KEY_REPLICATED_TO             = \"replicatedTo\";\n-    public static final String FETCH_TYPE_FULL                      = \"full\";\n-    public static final String FETCH_TYPE_CONNECTED                 = \"connected\";\n-    public static final String FETCH_TYPE_INCREMENTAL               = \"incremental\";\n+    public static final String OPTION_FETCH_TYPE = \"fetchType\";\n+    public static final String OPTION_ATTR_MATCH_TYPE = \"matchType\";\n+    public static final String OPTION_SKIP_LINEAGE = \"skipLineage\";\n+    public static final String OPTION_KEY_REPLICATED_TO = \"replicatedTo\";\n+    public static final String FETCH_TYPE_FULL = \"full\";\n+    public static final String FETCH_TYPE_CONNECTED = \"connected\";\n+    public static final String FETCH_TYPE_INCREMENTAL = \"incremental\";\n     public static final String FETCH_TYPE_INCREMENTAL_CHANGE_MARKER = \"changeMarker\";\n-    public static final String MATCH_TYPE_STARTS_WITH               = \"startsWith\";\n-    public static final String MATCH_TYPE_ENDS_WITH                 = \"endsWith\";\n-    public static final String MATCH_TYPE_CONTAINS                  = \"contains\";\n-    public static final String MATCH_TYPE_MATCHES                   = \"matches\";\n-    public static final String MATCH_TYPE_FOR_TYPE                  = \"forType\";\n+    public static final String MATCH_TYPE_STARTS_WITH = \"startsWith\";\n+    public static final String MATCH_TYPE_ENDS_WITH = \"endsWith\";\n+    public static final String MATCH_TYPE_CONTAINS = \"contains\";\n+    public static final String MATCH_TYPE_MATCHES = \"matches\";\n+    public static final String MATCH_TYPE_FOR_TYPE = \"forType\";\n \n     private List<AtlasObjectId> itemsToExport = new ArrayList<>();\n-    private Map<String, Object> options       = new HashMap<>();\n+    private Map<String, Object> options = new HashMap<>();\n \n     public List<AtlasObjectId> getItemsToExport() {\n         return itemsToExport;\n@@ -83,7 +83,7 @@ public void setOptions(Map<String, Object> options) {\n     }\n \n     public String getFetchTypeOptionValue() {\n-        if(MapUtils.isEmpty(getOptions()) || !getOptions().containsKey(OPTION_FETCH_TYPE)) {\n+        if (MapUtils.isEmpty(getOptions()) || !getOptions().containsKey(OPTION_FETCH_TYPE)) {\n             return FETCH_TYPE_FULL;\n         }\n \n@@ -96,17 +96,17 @@ public String getFetchTypeOptionValue() {\n     }\n \n     public boolean getSkipLineageOptionValue() {\n-        if(MapUtils.isEmpty(getOptions()) ||\n+        if (MapUtils.isEmpty(getOptions()) ||\n                 !getOptions().containsKey(AtlasExportRequest.OPTION_SKIP_LINEAGE)) {\n             return false;\n         }\n \n         Object o = getOptions().get(AtlasExportRequest.OPTION_SKIP_LINEAGE);\n-        if(o instanceof String) {\n+        if (o instanceof String) {\n             return Boolean.parseBoolean((String) o);\n         }\n \n-        if(o instanceof Boolean) {\n+        if (o instanceof Boolean) {\n             return (Boolean) o;\n         }\n \n@@ -142,7 +142,13 @@ public boolean isReplicationOptionSet() {\n \n     @JsonIgnore\n     public String getOptionKeyReplicatedTo() {\n-        return isReplicationOptionSet() ? (String) options.get(OPTION_KEY_REPLICATED_TO) : StringUtils.EMPTY;\n+        String replicateToServerName = isReplicationOptionSet() ? (String) options.get(OPTION_KEY_REPLICATED_TO) : StringUtils.EMPTY;\n+\n+        if (replicateToServerName == null) {\n+            return StringUtils.EMPTY;\n+        } else {\n+            return replicateToServerName;\n+        }\n     }\n \n     public StringBuilder toString(StringBuilder sb) {",
                "additions": 29,
                "raw_url": "https://github.com/apache/atlas/raw/a5f971a322b75a7cc2bd9e8bdf021be46e03b63d/intg/src/main/java/org/apache/atlas/model/impexp/AtlasExportRequest.java",
                "status": "modified",
                "changes": 52,
                "deletions": 23,
                "sha": "b03b386c0c619f14bac1e3b6672ddbb6efcb13ed",
                "blob_url": "https://github.com/apache/atlas/blob/a5f971a322b75a7cc2bd9e8bdf021be46e03b63d/intg/src/main/java/org/apache/atlas/model/impexp/AtlasExportRequest.java",
                "filename": "intg/src/main/java/org/apache/atlas/model/impexp/AtlasExportRequest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/intg/src/main/java/org/apache/atlas/model/impexp/AtlasExportRequest.java?ref=a5f971a322b75a7cc2bd9e8bdf021be46e03b63d"
            },
            {
                "patch": "@@ -64,7 +64,11 @@ public void addParentTransformsToSubTypes(String parentType, Set<String> subType\n                 getTransforms().put(subType, attribtueTransformMap);\n             } else {\n                 for (Map.Entry<String, List<ImportTransformer>> entry : attribtueTransformMap.entrySet()) {\n-                    getTransforms().get(subType).get(entry.getKey()).addAll(entry.getValue());\n+                    if((getTransforms().get(subType).containsKey(entry.getKey()))){\n+                        getTransforms().get(subType).get(entry.getKey()).addAll(entry.getValue());\n+                    } else {\n+                        LOG.warn(\"Attribute {} does not exist for Type : {}\", entry.getKey(), parentType);\n+                    }\n                 }\n             }\n         }",
                "additions": 5,
                "raw_url": "https://github.com/apache/atlas/raw/a5f971a322b75a7cc2bd9e8bdf021be46e03b63d/repository/src/main/java/org/apache/atlas/repository/impexp/ImportTransforms.java",
                "status": "modified",
                "changes": 6,
                "deletions": 1,
                "sha": "a2f592c3693468abc7349ca0abb05995f9d63341",
                "blob_url": "https://github.com/apache/atlas/blob/a5f971a322b75a7cc2bd9e8bdf021be46e03b63d/repository/src/main/java/org/apache/atlas/repository/impexp/ImportTransforms.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/impexp/ImportTransforms.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/impexp/ImportTransforms.java?ref=a5f971a322b75a7cc2bd9e8bdf021be46e03b63d"
            }
        ],
        "bug_id": "atlas_4",
        "parent": "https://github.com/apache/atlas/commit/22041f51ce9a52f2c7b2634024e20765347a794a",
        "message": "ATLAS-3019 Handle NPE while transform and adding replicatedTo in import-export\n\nSigned-off-by: nixonrodrigues <nixon@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/519314f0a1911cfd5fc46196e5f031a83c5bb09e",
        "file": [
            {
                "patch": "@@ -618,9 +618,13 @@ protected String getQualifiedName(DependencyKey column) {\n     protected String getQualifiedName(BaseColumnInfo column) {\n         String dbName    = column.getTabAlias().getTable().getDbName();\n         String tableName = column.getTabAlias().getTable().getTableName();\n-        String colName   = column.getColumn().getName();\n+        String colName   = column.getColumn() != null ? column.getColumn().getName() : null;\n \n-        return getQualifiedName(dbName, tableName, colName);\n+        if (colName == null) {\n+            return (dbName + QNAME_SEP_ENTITY_NAME + tableName + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();\n+        } else {\n+            return (dbName + QNAME_SEP_ENTITY_NAME + tableName + QNAME_SEP_ENTITY_NAME + colName + QNAME_SEP_CLUSTER_NAME).toLowerCase() + getClusterName();\n+        }\n     }\n \n     protected String getQualifiedName(String dbName, String tableName, String colName) {",
                "additions": 6,
                "raw_url": "https://github.com/apache/atlas/raw/519314f0a1911cfd5fc46196e5f031a83c5bb09e/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "status": "modified",
                "changes": 8,
                "deletions": 2,
                "sha": "ca1381260fc79babe2c8a3c023f5ca05b1575a35",
                "blob_url": "https://github.com/apache/atlas/blob/519314f0a1911cfd5fc46196e5f031a83c5bb09e/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/BaseHiveEvent.java?ref=519314f0a1911cfd5fc46196e5f031a83c5bb09e"
            }
        ],
        "bug_id": "atlas_5",
        "parent": "https://github.com/apache/atlas/commit/e86fc944edff263c38b17741a68b9966050030af",
        "message": "ATLAS-2536: fix NPE in Hive hook",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/75da039043f61c33330686e362de5c8c35996906",
        "file": [
            {
                "patch": "@@ -54,10 +54,17 @@ public AlterTableRenameCol(AtlasHiveHookContext context) {\n             return null;\n         }\n \n-        List<HookNotification> ret = new ArrayList<>(super.getNotificationMessages());\n+        List<HookNotification> baseMsgs = super.getNotificationMessages();\n \n-        Table oldTable = getHiveContext().getInputs().iterator().next().getTable();\n-        Table newTable = getHiveContext().getOutputs().iterator().next().getTable();\n+        if (CollectionUtils.isEmpty(baseMsgs)) {\n+            LOG.debug(\"Skipped processing of column-rename (on a temporary table?)\");\n+\n+            return null;\n+        }\n+\n+        List<HookNotification> ret      = new ArrayList<>(baseMsgs);\n+        Table                  oldTable = getHiveContext().getInputs().iterator().next().getTable();\n+        Table                  newTable = getHiveContext().getOutputs().iterator().next().getTable();\n \n         newTable = getHive().getTable(newTable.getDbName(), newTable.getTableName());\n ",
                "additions": 10,
                "raw_url": "https://github.com/apache/atlas/raw/75da039043f61c33330686e362de5c8c35996906/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/AlterTableRenameCol.java",
                "status": "modified",
                "changes": 13,
                "deletions": 3,
                "sha": "5bbdd81d37cf171be329cbedd80b0eb88625514e",
                "blob_url": "https://github.com/apache/atlas/blob/75da039043f61c33330686e362de5c8c35996906/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/AlterTableRenameCol.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/AlterTableRenameCol.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/AlterTableRenameCol.java?ref=75da039043f61c33330686e362de5c8c35996906"
            }
        ],
        "bug_id": "atlas_6",
        "parent": "https://github.com/apache/atlas/commit/399468e6d758550d1af1ad329e9a2bc38a8b17b3",
        "message": "ATLAS-2757: fix for NPE in Hive hook in handling column-rename on temporary table",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/810aceb5dc212ec68b598227677aa9c5683db8e9",
        "file": [
            {
                "patch": "@@ -36,7 +36,10 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n import java.util.ArrayList;\n+import java.util.Collection;\n import java.util.Collections;\n import java.util.HashSet;\n import java.util.List;\n@@ -141,7 +144,7 @@ private void processColumnLineage(AtlasEntity hiveProcess, AtlasEntitiesWithExtI\n \n             List<AtlasEntity> inputColumns = new ArrayList<>();\n \n-            for (BaseColumnInfo baseColumn : entry.getValue().getBaseCols()) {\n+            for (BaseColumnInfo baseColumn : getBaseCols(entry.getValue())) {\n                 String      inputColName = getQualifiedName(baseColumn);\n                 AtlasEntity inputColumn  = context.getEntity(inputColName);\n \n@@ -172,6 +175,32 @@ private void processColumnLineage(AtlasEntity hiveProcess, AtlasEntitiesWithExtI\n         }\n     }\n \n+    private Collection<BaseColumnInfo> getBaseCols(Dependency lInfoDep) {\n+        Collection<BaseColumnInfo> ret = Collections.emptyList();\n+\n+        if (lInfoDep != null) {\n+            try {\n+                Method getBaseColsMethod = lInfoDep.getClass().getMethod(\"getBaseCols\");\n+\n+                Object retGetBaseCols = getBaseColsMethod.invoke(lInfoDep);\n+\n+                if (retGetBaseCols != null) {\n+                    if (retGetBaseCols instanceof Collection) {\n+                        ret = (Collection) retGetBaseCols;\n+                    } else {\n+                        LOG.warn(\"{}: unexpected return type from LineageInfo.Dependency.getBaseCols(), expected type {}\",\n+                                retGetBaseCols.getClass().getName(), \"Collection\");\n+                    }\n+                }\n+            } catch (NoSuchMethodException | InvocationTargetException | IllegalAccessException ex) {\n+                LOG.warn(\"getBaseCols()\", ex);\n+            }\n+        }\n+\n+        return ret;\n+    }\n+\n+\n     private boolean skipProcess() {\n         Set<ReadEntity>  inputs  = getHiveContext().getInputs();\n         Set<WriteEntity> outputs = getHiveContext().getOutputs();",
                "additions": 30,
                "raw_url": "https://github.com/apache/atlas/raw/810aceb5dc212ec68b598227677aa9c5683db8e9/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/CreateHiveProcess.java",
                "status": "modified",
                "changes": 31,
                "deletions": 1,
                "sha": "33a263338356a8c5f8bf377179f3440db7241cf6",
                "blob_url": "https://github.com/apache/atlas/blob/810aceb5dc212ec68b598227677aa9c5683db8e9/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/CreateHiveProcess.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/CreateHiveProcess.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/events/CreateHiveProcess.java?ref=810aceb5dc212ec68b598227677aa9c5683db8e9"
            }
        ],
        "bug_id": "atlas_7",
        "parent": "https://github.com/apache/atlas/commit/3f7c5811faa9c9c9b61f9e6760904aeafb221224",
        "message": "ATLAS-2611: fix for NPE in Hive hook\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/fe1c7a3b48a751c20e51ee7d97c30da84af21b85",
        "file": [
            {
                "patch": "@@ -199,13 +199,17 @@ private AtlasEntity addDataSet(String dataSetType, String topologyOwner, Seriali\n \n                 clusterName = getClusterName(stormConf);\n \n-                ret = new AtlasEntity(StormDataTypes.KAFKA_TOPIC.getName());\n+                if (topicName == null) {\n+                    LOG.error(\"Kafka topic name not found\");\n+                } else {\n+                    ret = new AtlasEntity(StormDataTypes.KAFKA_TOPIC.getName());\n \n-                ret.setAttribute(\"topic\", topicName);\n-                ret.setAttribute(\"uri\", uri);\n-                ret.setAttribute(AtlasClient.OWNER, topologyOwner);\n-                ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, getKafkaTopicQualifiedName(clusterName, topicName));\n-                ret.setAttribute(AtlasClient.NAME, topicName);\n+                    ret.setAttribute(\"topic\", topicName);\n+                    ret.setAttribute(\"uri\", uri);\n+                    ret.setAttribute(AtlasClient.OWNER, topologyOwner);\n+                    ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, getKafkaTopicQualifiedName(clusterName, topicName));\n+                    ret.setAttribute(AtlasClient.NAME, topicName);\n+                }\n             }\n             break;\n \n@@ -219,13 +223,17 @@ private AtlasEntity addDataSet(String dataSetType, String topologyOwner, Seriali\n \n                 clusterName = extractComponentClusterName(HBaseConfiguration.create(), stormConf);\n \n-                ret = new AtlasEntity(StormDataTypes.HBASE_TABLE.getName());\n+                if (hbaseTableName == null) {\n+                    LOG.error(\"HBase table name not found\");\n+                } else {\n+                    ret = new AtlasEntity(StormDataTypes.HBASE_TABLE.getName());\n \n-                ret.setAttribute(\"uri\", hbaseTableName);\n-                ret.setAttribute(AtlasClient.NAME, uri);\n-                ret.setAttribute(AtlasClient.OWNER, stormConf.get(\"storm.kerberos.principal\"));\n-                //TODO - Hbase Namespace is hardcoded to 'default'. need to check how to get this or is it already part of tableName\n-                ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, getHbaseTableQualifiedName(clusterName, HBASE_NAMESPACE_DEFAULT, hbaseTableName));\n+                    ret.setAttribute(\"uri\", hbaseTableName);\n+                    ret.setAttribute(AtlasClient.NAME, uri);\n+                    ret.setAttribute(AtlasClient.OWNER, stormConf.get(\"storm.kerberos.principal\"));\n+                    //TODO - Hbase Namespace is hardcoded to 'default'. need to check how to get this or is it already part of tableName\n+                    ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, getHbaseTableQualifiedName(clusterName, HBASE_NAMESPACE_DEFAULT, hbaseTableName));\n+                }\n             }\n             break;\n \n@@ -259,24 +267,27 @@ private AtlasEntity addDataSet(String dataSetType, String topologyOwner, Seriali\n             case \"HiveBolt\": {\n                 clusterName = extractComponentClusterName(new HiveConf(), stormConf);\n \n-                final String dbName           = config.get(\"HiveBolt.options.databaseName\");\n-                final String tblName          = config.get(\"HiveBolt.options.tableName\");\n-                final String tblQualifiedName = HiveMetaStoreBridge.getTableQualifiedName(clusterName, dbName, tblName);\n+                final String dbName  = config.get(\"HiveBolt.options.databaseName\");\n+                final String tblName = config.get(\"HiveBolt.options.tableName\");\n \n-                AtlasEntity dbEntity = new AtlasEntity(\"hive_db\");\n+                if (dbName == null || tblName ==null) {\n+                    LOG.error(\"Hive database or table name not found\");\n+                } else {\n+                    AtlasEntity dbEntity = new AtlasEntity(\"hive_db\");\n \n-                dbEntity.setAttribute(AtlasClient.NAME, dbName);\n-                dbEntity.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, HiveMetaStoreBridge.getDBQualifiedName(getClusterName(stormConf), dbName));\n-                dbEntity.setAttribute(AtlasConstants.CLUSTER_NAME_ATTRIBUTE, getClusterName(stormConf));\n+                    dbEntity.setAttribute(AtlasClient.NAME, dbName);\n+                    dbEntity.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, HiveMetaStoreBridge.getDBQualifiedName(getClusterName(stormConf), dbName));\n+                    dbEntity.setAttribute(AtlasConstants.CLUSTER_NAME_ATTRIBUTE, getClusterName(stormConf));\n \n-                entityExtInfo.addReferredEntity(dbEntity);\n+                    entityExtInfo.addReferredEntity(dbEntity);\n \n-                // todo: verify if hive table has everything needed to retrieve existing table\n-                ret = new AtlasEntity(\"hive_table\");\n+                    // todo: verify if hive table has everything needed to retrieve existing table\n+                    ret = new AtlasEntity(\"hive_table\");\n \n-                ret.setAttribute(AtlasClient.NAME, tblName);\n-                ret.setAttribute(ATTRIBUTE_DB, AtlasTypeUtil.getAtlasObjectId(dbEntity));\n-                ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, tblQualifiedName);\n+                    ret.setAttribute(AtlasClient.NAME, tblName);\n+                    ret.setAttribute(ATTRIBUTE_DB, AtlasTypeUtil.getAtlasObjectId(dbEntity));\n+                    ret.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, HiveMetaStoreBridge.getTableQualifiedName(clusterName, dbName, tblName));\n+                }\n             }\n             break;\n ",
                "additions": 36,
                "raw_url": "https://github.com/apache/atlas/raw/fe1c7a3b48a751c20e51ee7d97c30da84af21b85/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormAtlasHook.java",
                "status": "modified",
                "changes": 61,
                "deletions": 25,
                "sha": "fdce5eb120fd71a8c2fb32118ddd0e26a6700e2e",
                "blob_url": "https://github.com/apache/atlas/blob/fe1c7a3b48a751c20e51ee7d97c30da84af21b85/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormAtlasHook.java",
                "filename": "addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormAtlasHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormAtlasHook.java?ref=fe1c7a3b48a751c20e51ee7d97c30da84af21b85"
            }
        ],
        "bug_id": "atlas_8",
        "parent": "https://github.com/apache/atlas/commit/57c7e85ec126f7f4cb6df0edcd6076dd2266667a",
        "message": "ATLAS-2592 Storm atlas hook fails with NPE\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/6a1c4f4df2b906673a8cedd6abbd20761fcfb183",
        "file": [
            {
                "patch": "@@ -66,10 +66,14 @@ public AtlasEntity fromV1ToV2(Object v1Obj, AtlasType type, ConverterContext con\n \n                     entity.setGuid(entRef.getId().getId());\n                     entity.setStatus(convertState(entRef.getId().getState()));\n-                    entity.setCreatedBy(entRef.getSystemAttributes().getCreatedBy());\n-                    entity.setCreateTime(entRef.getSystemAttributes().getCreatedTime());\n-                    entity.setUpdatedBy(entRef.getSystemAttributes().getModifiedBy());\n-                    entity.setUpdateTime(entRef.getSystemAttributes().getModifiedTime());\n+\n+                    if (entRef.getSystemAttributes() != null) {\n+                        entity.setCreatedBy(entRef.getSystemAttributes().getCreatedBy());\n+                        entity.setCreateTime(entRef.getSystemAttributes().getCreatedTime());\n+                        entity.setUpdatedBy(entRef.getSystemAttributes().getModifiedBy());\n+                        entity.setUpdateTime(entRef.getSystemAttributes().getModifiedTime());\n+                    }\n+\n                     entity.setVersion((long) entRef.getId().getVersion());\n \n                     if (CollectionUtils.isNotEmpty(entRef.getTraitNames())) {",
                "additions": 8,
                "raw_url": "https://github.com/apache/atlas/raw/6a1c4f4df2b906673a8cedd6abbd20761fcfb183/repository/src/main/java/org/apache/atlas/repository/converters/AtlasEntityFormatConverter.java",
                "status": "modified",
                "changes": 12,
                "deletions": 4,
                "sha": "2229ecec0690b33d6a28a9fb90c28e48e69285c2",
                "blob_url": "https://github.com/apache/atlas/blob/6a1c4f4df2b906673a8cedd6abbd20761fcfb183/repository/src/main/java/org/apache/atlas/repository/converters/AtlasEntityFormatConverter.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/converters/AtlasEntityFormatConverter.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/converters/AtlasEntityFormatConverter.java?ref=6a1c4f4df2b906673a8cedd6abbd20761fcfb183"
            }
        ],
        "bug_id": "atlas_9",
        "parent": "https://github.com/apache/atlas/commit/41e5404f96395c8fc3f1f8045ba921f283a49cce",
        "message": "ATLAS-2251: fixed NPE in V1 to V2 entity conversion",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/39be2ccfdf5ec3edb59d7779e7b3f7d95413b632",
        "file": [
            {
                "patch": "@@ -457,10 +457,14 @@ private void addEntity(AtlasEntityWithExtInfo entity, ExportContext context) thr\n     }\n \n     private void removeRelationshipAttributes(AtlasEntityWithExtInfo entity) {\n-        entity.getEntity().getRelationshipAttributes().clear();\n-        if(entity.getReferredEntities() != null) {\n-            for (AtlasEntity e: entity.getReferredEntities().values()) {\n-                e.getRelationshipAttributes().clear();\n+        if (entity.getEntity().getRelationshipAttributes() != null) {\n+            entity.getEntity().getRelationshipAttributes().clear();\n+        }\n+        if (entity.getReferredEntities() != null) {\n+            for (AtlasEntity e : entity.getReferredEntities().values()) {\n+                if (e.getRelationshipAttributes() != null) {\n+                    e.getRelationshipAttributes().clear();\n+                }\n             }\n         }\n     }",
                "additions": 8,
                "raw_url": "https://github.com/apache/atlas/raw/39be2ccfdf5ec3edb59d7779e7b3f7d95413b632/repository/src/main/java/org/apache/atlas/repository/impexp/ExportService.java",
                "status": "modified",
                "changes": 12,
                "deletions": 4,
                "sha": "c5e6534c62d51293c4777f8c7f0fda012454441d",
                "blob_url": "https://github.com/apache/atlas/blob/39be2ccfdf5ec3edb59d7779e7b3f7d95413b632/repository/src/main/java/org/apache/atlas/repository/impexp/ExportService.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/impexp/ExportService.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/impexp/ExportService.java?ref=39be2ccfdf5ec3edb59d7779e7b3f7d95413b632"
            }
        ],
        "bug_id": "atlas_10",
        "parent": "https://github.com/apache/atlas/commit/bd87c3f624d45e9d6d2080c28197e3e1ab9a4ebc",
        "message": "ATLAS-2376: Fix for unitTest case in ExportServiceTest due to NPE",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/ca04aead3220da83f22c08fab16db9276b3574c0",
        "file": [
            {
                "patch": "@@ -346,7 +346,7 @@ void walkEntityGraph(AtlasEntity entity) throws AtlasBaseException {\n         AtlasEntityType type = typeRegistry.getEntityTypeByName(entity.getTypeName());\n \n         if (type == null) {\n-            throw new AtlasBaseException(AtlasErrorCode.UNKNOWN_TYPENAME, entity.getTypeName());\n+            throw new AtlasBaseException(AtlasErrorCode.TYPE_NAME_NOT_FOUND, entity.getTypeName());\n         }\n \n         recordObjectReference(entity.getGuid());",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/ca04aead3220da83f22c08fab16db9276b3574c0/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "d6effbf77b7dbd3479bab3899730bdcbabdce351",
                "blob_url": "https://github.com/apache/atlas/blob/ca04aead3220da83f22c08fab16db9276b3574c0/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java?ref=ca04aead3220da83f22c08fab16db9276b3574c0"
            }
        ],
        "bug_id": "atlas_11",
        "parent": "https://github.com/apache/atlas/commit/2b5c0047fbbc7e573f4fdf8b74dccfac231918b2",
        "message": "ATLAS-2299: Regression : Creating an entity of unknown type throws NPE - update error message",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/7892a331cd665f81ee782d90638cf66ca5bf8617",
        "file": [
            {
                "patch": "@@ -345,6 +345,10 @@ void walkEntityGraph(AtlasEntity entity) throws AtlasBaseException {\n \n         AtlasEntityType type = typeRegistry.getEntityTypeByName(entity.getTypeName());\n \n+        if (type == null) {\n+            throw new AtlasBaseException(AtlasErrorCode.UNKNOWN_TYPENAME, entity.getTypeName());\n+        }\n+\n         recordObjectReference(entity.getGuid());\n \n         visitEntity(type, entity);",
                "additions": 4,
                "raw_url": "https://github.com/apache/atlas/raw/7892a331cd665f81ee782d90638cf66ca5bf8617/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "status": "modified",
                "changes": 4,
                "deletions": 0,
                "sha": "1fc1a06ecfa0d8a3f91863d5aae2ab1d3c1a1193",
                "blob_url": "https://github.com/apache/atlas/blob/7892a331cd665f81ee782d90638cf66ca5bf8617/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityGraphDiscoveryV1.java?ref=7892a331cd665f81ee782d90638cf66ca5bf8617"
            }
        ],
        "bug_id": "atlas_12",
        "parent": "https://github.com/apache/atlas/commit/1c58f3aae4bef0406c2415a8fc148b3558e02cae",
        "message": "ATLAS-2299: Regression : Creating an entity of unknown type throws NPE",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/729d92386ed833ef743f1cee707a473fffdcf6c0",
        "file": [
            {
                "patch": "@@ -29,7 +29,8 @@\n import org.apache.atlas.model.instance.AtlasEntity;\n import org.apache.atlas.model.instance.AtlasEntity.AtlasEntitiesWithExtInfo;\n import org.apache.atlas.model.notification.HookNotification;\n-import org.apache.atlas.model.notification.HookNotification.EntityUpdateRequestV2;\n+import org.apache.atlas.model.notification.HookNotification.EntityCreateRequestV2;\n+import org.apache.atlas.model.instance.AtlasObjectId;\n import org.apache.atlas.sqoop.model.SqoopDataTypes;\n import org.apache.atlas.type.AtlasTypeUtil;\n import org.apache.commons.configuration.Configuration;\n@@ -39,12 +40,12 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.util.Arrays;\n-import java.util.Date;\n-import java.util.HashMap;\n+import java.util.Collections;\n import java.util.Map;\n+import java.util.HashMap;\n import java.util.Properties;\n-\n+import java.util.List;\n+import java.util.Date;\n /**\n  * AtlasHook sends lineage information to the AtlasSever.\n  */\n@@ -79,26 +80,30 @@ public void publish(SqoopJobDataPublisher.Data data) throws AtlasHookException {\n         try {\n             Configuration atlasProperties = ApplicationProperties.get();\n             String        clusterName     = atlasProperties.getString(ATLAS_CLUSTER_NAME, DEFAULT_CLUSTER_NAME);\n-            AtlasEntity   entDbStore      = createDBStoreInstance(data);\n-            AtlasEntity   entHiveDb       = createHiveDatabaseInstance(clusterName, data.getHiveDB());\n-            AtlasEntity   entHiveTable    = createHiveTableInstance(entHiveDb, data.getHiveTable());\n-            AtlasEntity   entProcess      = createSqoopProcessInstance(entDbStore, entHiveTable, data, clusterName);\n+            AtlasEntity   entDbStore      = toSqoopDBStoreEntity(data);\n+            AtlasEntity   entHiveDb       = toHiveDatabaseEntity(clusterName, data.getHiveDB());\n+            AtlasEntity   entHiveTable    = data.getHiveTable() != null ? toHiveTableEntity(entHiveDb, data.getHiveTable()) : null;\n+            AtlasEntity   entProcess      = toSqoopProcessEntity(entDbStore, entHiveDb, entHiveTable, data, clusterName);\n \n             AtlasEntitiesWithExtInfo entities = new AtlasEntitiesWithExtInfo(entProcess);\n \n             entities.addReferredEntity(entDbStore);\n             entities.addReferredEntity(entHiveDb);\n-            entities.addReferredEntity(entHiveTable);\n+            if (entHiveTable != null) {\n+                entities.addReferredEntity(entHiveTable);\n+            }\n \n-            HookNotification message  = new EntityUpdateRequestV2(AtlasHook.getUser(), entities);\n+            HookNotification message = new EntityCreateRequestV2(AtlasHook.getUser(), entities);\n \n-            AtlasHook.notifyEntities(Arrays.asList(message), atlasProperties.getInt(HOOK_NUM_RETRIES, 3));\n+            AtlasHook.notifyEntities(Collections.singletonList(message), atlasProperties.getInt(HOOK_NUM_RETRIES, 3));\n         } catch(Exception e) {\n+            LOG.error(\"SqoopHook.publish() failed\", e);\n+\n             throw new AtlasHookException(\"SqoopHook.publish() failed.\", e);\n         }\n     }\n \n-    private AtlasEntity createHiveDatabaseInstance(String clusterName, String dbName) {\n+    private AtlasEntity toHiveDatabaseEntity(String clusterName, String dbName) {\n         AtlasEntity entHiveDb     = new AtlasEntity(HiveDataTypes.HIVE_DB.getName());\n         String      qualifiedName = HiveMetaStoreBridge.getDBQualifiedName(clusterName, dbName);\n \n@@ -109,7 +114,7 @@ private AtlasEntity createHiveDatabaseInstance(String clusterName, String dbName\n         return entHiveDb;\n     }\n \n-    private AtlasEntity createHiveTableInstance(AtlasEntity entHiveDb, String tableName) {\n+    private AtlasEntity toHiveTableEntity(AtlasEntity entHiveDb, String tableName) {\n         AtlasEntity entHiveTable  = new AtlasEntity(HiveDataTypes.HIVE_TABLE.getName());\n         String      qualifiedName = HiveMetaStoreBridge.getTableQualifiedName((String)entHiveDb.getAttribute(AtlasConstants.CLUSTER_NAME_ATTRIBUTE), (String)entHiveDb.getAttribute(AtlasClient.NAME), tableName);\n \n@@ -120,7 +125,7 @@ private AtlasEntity createHiveTableInstance(AtlasEntity entHiveDb, String tableN\n         return entHiveTable;\n     }\n \n-    private AtlasEntity createDBStoreInstance(SqoopJobDataPublisher.Data data) throws ImportException {\n+    private AtlasEntity toSqoopDBStoreEntity(SqoopJobDataPublisher.Data data) throws ImportException {\n         String table = data.getStoreTable();\n         String query = data.getStoreQuery();\n \n@@ -146,7 +151,7 @@ private AtlasEntity createDBStoreInstance(SqoopJobDataPublisher.Data data) throw\n         return entDbStore;\n     }\n \n-    private AtlasEntity createSqoopProcessInstance(AtlasEntity entDbStore, AtlasEntity entHiveTable, SqoopJobDataPublisher.Data data, String clusterName) {\n+    private AtlasEntity toSqoopProcessEntity(AtlasEntity entDbStore, AtlasEntity entHiveDb, AtlasEntity entHiveTable, SqoopJobDataPublisher.Data data, String clusterName) {\n         AtlasEntity         entProcess       = new AtlasEntity(SqoopDataTypes.SQOOP_PROCESS.getName());\n         String              sqoopProcessName = getSqoopProcessName(data, clusterName);\n         Map<String, String> sqoopOptionsMap  = new HashMap<>();\n@@ -160,12 +165,15 @@ private AtlasEntity createSqoopProcessInstance(AtlasEntity entDbStore, AtlasEnti\n         entProcess.setAttribute(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, sqoopProcessName);\n         entProcess.setAttribute(SqoopHook.OPERATION, data.getOperation());\n \n+        List<AtlasObjectId> sqoopObjects = Collections.singletonList(AtlasTypeUtil.getAtlasObjectId(entDbStore));\n+        List<AtlasObjectId> hiveObjects  = Collections.singletonList(AtlasTypeUtil.getAtlasObjectId(entHiveTable != null ? entHiveTable : entHiveDb));\n+\n         if (isImportOperation(data)) {\n-            entProcess.setAttribute(SqoopHook.INPUTS, Arrays.asList(AtlasTypeUtil.getAtlasObjectId(entDbStore)));\n-            entProcess.setAttribute(SqoopHook.OUTPUTS, Arrays.asList(AtlasTypeUtil.getAtlasObjectId(entHiveTable)));\n+            entProcess.setAttribute(SqoopHook.INPUTS, sqoopObjects);\n+            entProcess.setAttribute(SqoopHook.OUTPUTS, hiveObjects);\n         } else {\n-            entProcess.setAttribute(SqoopHook.INPUTS, Arrays.asList(AtlasTypeUtil.getAtlasObjectId(entHiveTable)));\n-            entProcess.setAttribute(SqoopHook.OUTPUTS, Arrays.asList(AtlasTypeUtil.getAtlasObjectId(entDbStore)));\n+            entProcess.setAttribute(SqoopHook.INPUTS, hiveObjects);\n+            entProcess.setAttribute(SqoopHook.OUTPUTS, sqoopObjects);\n         }\n \n         entProcess.setAttribute(SqoopHook.USER, data.getUser());\n@@ -183,24 +191,32 @@ private boolean isImportOperation(SqoopJobDataPublisher.Data data) {\n     static String getSqoopProcessName(Data data, String clusterName) {\n         StringBuilder name = new StringBuilder(String.format(\"sqoop %s --connect %s\", data.getOperation(), data.getUrl()));\n \n-        if (StringUtils.isNotEmpty(data.getStoreTable())) {\n+        if (StringUtils.isNotEmpty(data.getHiveTable())) {\n             name.append(\" --table \").append(data.getStoreTable());\n+        } else {\n+            name.append(\" --database \").append(data.getHiveDB());\n         }\n \n         if (StringUtils.isNotEmpty(data.getStoreQuery())) {\n             name.append(\" --query \").append(data.getStoreQuery());\n         }\n \n-        name.append(String.format(\" --hive-%s --hive-database %s --hive-table %s --hive-cluster %s\", data.getOperation(), data.getHiveDB().toLowerCase(), data.getHiveTable().toLowerCase(), clusterName));\n+        if (data.getHiveTable() != null) {\n+            name.append(String.format(\" --hive-%s --hive-database %s --hive-table %s --hive-cluster %s\", data.getOperation(), data.getHiveDB().toLowerCase(), data.getHiveTable().toLowerCase(), clusterName));\n+        } else {\n+            name.append(String.format(\"--hive-%s --hive-database %s --hive-cluster %s\", data.getOperation(), data.getHiveDB(), clusterName));\n+        }\n \n         return name.toString();\n     }\n \n     static String getSqoopDBStoreName(SqoopJobDataPublisher.Data data)  {\n         StringBuilder name = new StringBuilder(String.format(\"%s --url %s\", data.getStoreType(), data.getUrl()));\n \n-        if (StringUtils.isNotEmpty(data.getStoreTable())) {\n+        if (StringUtils.isNotEmpty(data.getHiveTable())) {\n             name.append(\" --table \").append(data.getStoreTable());\n+        } else {\n+            name.append(\" --database \").append(data.getHiveDB());\n         }\n \n         if (StringUtils.isNotEmpty(data.getStoreQuery())) {",
                "additions": 39,
                "raw_url": "https://github.com/apache/atlas/raw/729d92386ed833ef743f1cee707a473fffdcf6c0/addons/sqoop-bridge/src/main/java/org/apache/atlas/sqoop/hook/SqoopHook.java",
                "status": "modified",
                "changes": 62,
                "deletions": 23,
                "sha": "ac496012255389ec12d313910ef4585ae7c45442",
                "blob_url": "https://github.com/apache/atlas/blob/729d92386ed833ef743f1cee707a473fffdcf6c0/addons/sqoop-bridge/src/main/java/org/apache/atlas/sqoop/hook/SqoopHook.java",
                "filename": "addons/sqoop-bridge/src/main/java/org/apache/atlas/sqoop/hook/SqoopHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/sqoop-bridge/src/main/java/org/apache/atlas/sqoop/hook/SqoopHook.java?ref=729d92386ed833ef743f1cee707a473fffdcf6c0"
            }
        ],
        "bug_id": "atlas_13",
        "parent": "https://github.com/apache/atlas/commit/ae23e78369ce765c5353923754374bbd74c1bd47",
        "message": "ATLAS-2462: Sqoop import for all tables throws NPE for no table provided in command\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>\n(cherry picked from commit 7adbf8ffd27904577ecf694a9f861cdd46833069)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/a9928f90e14877c1cee81a47e32fb8ff016480f3",
        "file": [
            {
                "patch": "@@ -0,0 +1,134 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.thinkaurelius.titan.graphdb.query.condition;\n+\n+import com.google.common.base.Preconditions;\n+import com.thinkaurelius.titan.core.*;\n+import com.thinkaurelius.titan.graphdb.internal.InternalElement;\n+import com.thinkaurelius.titan.graphdb.internal.InternalRelationType;\n+import com.thinkaurelius.titan.graphdb.query.TitanPredicate;\n+import com.thinkaurelius.titan.graphdb.util.ElementHelper;\n+import com.tinkerpop.blueprints.Direction;\n+import org.apache.commons.lang.builder.HashCodeBuilder;\n+\n+import java.util.Iterator;\n+\n+/**\n+ * @author Matthias Broecheler (me@matthiasb.com)\n+ */\n+\n+public class PredicateCondition<K, E extends TitanElement> extends Literal<E> {\n+\n+    private final K key;\n+    private final TitanPredicate predicate;\n+    private final Object value;\n+\n+    public PredicateCondition(K key, TitanPredicate predicate, Object value) {\n+        Preconditions.checkNotNull(key);\n+        Preconditions.checkArgument(key instanceof String || key instanceof RelationType);\n+        Preconditions.checkNotNull(predicate);\n+        this.key = key;\n+        this.predicate = predicate;\n+        this.value = value;\n+    }\n+\n+\n+    private boolean satisfiesCondition(Object value) {\n+        return predicate.evaluate(value, this.value);\n+    }\n+\n+    @Override\n+    public boolean evaluate(E element) {\n+        RelationType type;\n+        if (key instanceof String) {\n+            type = ((InternalElement) element).tx().getRelationType((String) key);\n+            if (type == null)\n+                return satisfiesCondition(null);\n+        } else {\n+            type = (RelationType) key;\n+        }\n+\n+        Preconditions.checkNotNull(type);\n+\n+        if (type.isPropertyKey()) {\n+            Iterator<Object> iter = ElementHelper.getValues(element,(PropertyKey)type).iterator();\n+            if (iter.hasNext()) {\n+                while (iter.hasNext()) {\n+                    if (satisfiesCondition(iter.next()))\n+                        return true;\n+                }\n+                return false;\n+            }\n+            return satisfiesCondition(null);\n+        } else {\n+            assert ((InternalRelationType)type).getMultiplicity().isUnique(Direction.OUT);\n+            return satisfiesCondition(((TitanRelation) element).getProperty((EdgeLabel) type));\n+        }\n+    }\n+\n+    public K getKey() {\n+        return key;\n+    }\n+\n+    public TitanPredicate getPredicate() {\n+        return predicate;\n+    }\n+\n+    public Object getValue() {\n+        return value;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return new HashCodeBuilder().append(getType()).append(key).append(predicate).append(value).toHashCode();\n+    }\n+\n+    @Override\n+    public boolean equals(Object other) {\n+        if (this == other)\n+            return true;\n+\n+        if (other == null || !getClass().isInstance(other))\n+            return false;\n+\n+        PredicateCondition oth = (PredicateCondition) other;\n+        return key.equals(oth.key) && predicate.equals(oth.predicate) && compareValue(value, oth.value);\n+    }\n+\n+    // ATLAS-2214: There's a issue when working with isNull, notNull operators\n+    // When string/boolean attributes use the following sequence of filtering on AtlasVertex attributes then the code\n+    // runs into NPE\n+    // 1. boolean attr \"x\" != false/true        | boolean attr \"x\" == false/true\n+    // 2. boolean attr notNull 'query.has(\"x\")  | boolean attr isNull 'query.hasNot(\"x\")'\n+    // whereas if the sequence is reversed then the NPE is not encountered\n+    // Similar behavior is exhibited for the string attributes\n+    // Workaround is to allow null == null value comparision\n+    private boolean compareValue(final Object left, final Object right) {\n+        return left == null ? right == null : left.equals(right);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return key + \" \" + predicate + \" \" + String.valueOf(value);\n+    }\n+\n+    public static <K, E extends TitanElement> PredicateCondition<K, E> of(K key, TitanPredicate titanPredicate, Object condition) {\n+        return new PredicateCondition<K, E>(key, titanPredicate, condition);\n+    }\n+\n+}\n\\ No newline at end of file",
                "additions": 134,
                "raw_url": "https://github.com/apache/atlas/raw/a9928f90e14877c1cee81a47e32fb8ff016480f3/graphdb/titan0/src/main/java/com/thinkaurelius/titan/graphdb/query/condition/PredicateCondition.java",
                "status": "added",
                "changes": 134,
                "deletions": 0,
                "sha": "3a466c0ba08cc2cd4db03ae6d67e4e5ee8c6a536",
                "blob_url": "https://github.com/apache/atlas/blob/a9928f90e14877c1cee81a47e32fb8ff016480f3/graphdb/titan0/src/main/java/com/thinkaurelius/titan/graphdb/query/condition/PredicateCondition.java",
                "filename": "graphdb/titan0/src/main/java/com/thinkaurelius/titan/graphdb/query/condition/PredicateCondition.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/graphdb/titan0/src/main/java/com/thinkaurelius/titan/graphdb/query/condition/PredicateCondition.java?ref=a9928f90e14877c1cee81a47e32fb8ff016480f3"
            }
        ],
        "bug_id": "atlas_14",
        "parent": "https://github.com/apache/atlas/commit/96d4d31d0216061846d1fc894763fc50a1aaf8c7",
        "message": "ATLAS-2214: fix for NPE during notNull condition\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/c1f4007a9d9f85f888a5c9164e11937025157edb",
        "file": [
            {
                "patch": "@@ -1079,8 +1079,12 @@ public static boolean isReference(IDataType type) {\n \n     }\n \n+    public static boolean isInternalType(AtlasVertex vertex) {\n+        return vertex != null && isInternalType(getTypeName(vertex));\n+    }\n+\n     public static boolean isInternalType(String typeName) {\n-        return typeName.startsWith(Constants.INTERNAL_PROPERTY_KEY_PREFIX);\n+        return typeName != null && typeName.startsWith(Constants.INTERNAL_PROPERTY_KEY_PREFIX);\n     }\n \n     public static void setArrayElementsProperty(IDataType elementType, AtlasVertex instanceVertex, String propertyName, List<Object> values) {",
                "additions": 5,
                "raw_url": "https://github.com/apache/atlas/raw/c1f4007a9d9f85f888a5c9164e11937025157edb/repository/src/main/java/org/apache/atlas/repository/graph/GraphHelper.java",
                "status": "modified",
                "changes": 6,
                "deletions": 1,
                "sha": "639077ddaf02e02799bb990319877f38b3e6b247",
                "blob_url": "https://github.com/apache/atlas/blob/c1f4007a9d9f85f888a5c9164e11937025157edb/repository/src/main/java/org/apache/atlas/repository/graph/GraphHelper.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/graph/GraphHelper.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/graph/GraphHelper.java?ref=c1f4007a9d9f85f888a5c9164e11937025157edb"
            },
            {
                "patch": "@@ -227,14 +227,10 @@ private void doFullTextMapping(List<AtlasEntityHeader> atlasEntityHeaders) {\n         }\n \n         for (AtlasEntityHeader atlasEntityHeader : atlasEntityHeaders) {\n-            if(GraphHelper.isInternalType(atlasEntityHeader.getTypeName())) {\n-                continue;\n-            }\n-\n             String      guid        = atlasEntityHeader.getGuid();\n             AtlasVertex atlasVertex = AtlasGraphUtilsV1.findByGuid(guid);\n \n-            if(atlasVertex == null) {\n+            if(atlasVertex == null || GraphHelper.isInternalType(atlasVertex)) {\n                 continue;\n             }\n \n@@ -262,12 +258,7 @@ private void updateFullTextMapping(String entityId, List<AtlasClassification> cl\n         }\n \n         AtlasVertex atlasVertex = AtlasGraphUtilsV1.findByGuid(entityId);\n-        if(atlasVertex == null) {\n-            return;\n-        }\n-\n-        if (atlasVertex == null) {\n-            LOG.warn(\"updateFullTextMapping(): no entity exists with guid {}\", entityId);\n+        if(atlasVertex == null || GraphHelper.isInternalType(atlasVertex)) {\n             return;\n         }\n ",
                "additions": 2,
                "raw_url": "https://github.com/apache/atlas/raw/c1f4007a9d9f85f888a5c9164e11937025157edb/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityChangeNotifier.java",
                "status": "modified",
                "changes": 13,
                "deletions": 11,
                "sha": "7b349c4600aa6a6917b562d5163a70ac080b3e4e",
                "blob_url": "https://github.com/apache/atlas/blob/c1f4007a9d9f85f888a5c9164e11937025157edb/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityChangeNotifier.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityChangeNotifier.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityChangeNotifier.java?ref=c1f4007a9d9f85f888a5c9164e11937025157edb"
            },
            {
                "patch": "@@ -187,7 +187,9 @@ private void notifyOfEntityEvent(Collection<ITypedReferenceableInstance> entityD\n             messages.add(notification);\n         }\n \n-        notificationInterface.send(NotificationInterface.NotificationType.ENTITIES, messages);\n+        if (!messages.isEmpty()) {\n+            notificationInterface.send(NotificationInterface.NotificationType.ENTITIES, messages);\n+        }\n     }\n \n     private List<String> getNotificationAttributes(String entityType) {",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/c1f4007a9d9f85f888a5c9164e11937025157edb/webapp/src/main/java/org/apache/atlas/notification/NotificationEntityChangeListener.java",
                "status": "modified",
                "changes": 4,
                "deletions": 1,
                "sha": "53acf5631204ae9bc2237f199354f40e45984f91",
                "blob_url": "https://github.com/apache/atlas/blob/c1f4007a9d9f85f888a5c9164e11937025157edb/webapp/src/main/java/org/apache/atlas/notification/NotificationEntityChangeListener.java",
                "filename": "webapp/src/main/java/org/apache/atlas/notification/NotificationEntityChangeListener.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/notification/NotificationEntityChangeListener.java?ref=c1f4007a9d9f85f888a5c9164e11937025157edb"
            }
        ],
        "bug_id": "atlas_15",
        "parent": "https://github.com/apache/atlas/commit/ccd121e74204e1d85001be62abf09446d879889d",
        "message": "ATLAS-2141: edit/disassociate tag results in NPE\n\n(cherry picked from commit 4b9d2670709df52e0d983587832fe6256220691b)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/906f36517bd13cb3f5318e7843ebfd0276a2975f",
        "file": [
            {
                "patch": "@@ -44,6 +44,11 @@ public static String getApi(String contextPath) {\n         if (isDebugEnabled) {\n             LOG.debug(\"==> getApi({})\", contextPath);\n         }\n+\n+        if(contextPath == null){\n+            contextPath = \"\";\n+        }\n+\n         if (contextPath.startsWith(BASE_URL)) {\n             contextPath = contextPath.substring(BASE_URL.length());\n         } else {",
                "additions": 5,
                "raw_url": "https://github.com/apache/atlas/raw/906f36517bd13cb3f5318e7843ebfd0276a2975f/authorization/src/main/java/org/apache/atlas/authorize/simple/AtlasAuthorizationUtils.java",
                "status": "modified",
                "changes": 5,
                "deletions": 0,
                "sha": "93d988e668ac4865621472b50724ead38406fee1",
                "blob_url": "https://github.com/apache/atlas/blob/906f36517bd13cb3f5318e7843ebfd0276a2975f/authorization/src/main/java/org/apache/atlas/authorize/simple/AtlasAuthorizationUtils.java",
                "filename": "authorization/src/main/java/org/apache/atlas/authorize/simple/AtlasAuthorizationUtils.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/authorization/src/main/java/org/apache/atlas/authorize/simple/AtlasAuthorizationUtils.java?ref=906f36517bd13cb3f5318e7843ebfd0276a2975f"
            }
        ],
        "bug_id": "atlas_16",
        "parent": "https://github.com/apache/atlas/commit/c6081ddcfdb4c8100a4b099405ac8d397fbf9583",
        "message": "ATLAS-1878 - Fix for NPE when a request without any query path lands on atlas",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/485573fcab1c7cd263289ccc4da40357607dce82",
        "file": [
            {
                "patch": "@@ -23,6 +23,7 @@\n import org.apache.atlas.model.TypeCategory;\n import org.apache.atlas.model.instance.AtlasStruct;\n import org.apache.atlas.type.AtlasStructType;\n+import org.apache.atlas.type.AtlasStructType.AtlasAttribute;\n import org.apache.atlas.type.AtlasType;\n import org.apache.atlas.type.AtlasTypeRegistry;\n import org.apache.atlas.typesystem.IStruct;\n@@ -31,11 +32,8 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.util.Collection;\n-import java.util.Collections;\n import java.util.HashMap;\n import java.util.Map;\n-import java.util.Set;\n \n public class AtlasStructFormatConverter extends AtlasAbstractFormatConverter {\n     private static final Logger LOG = LoggerFactory.getLogger(AtlasStructFormatConverter.class);\n@@ -119,22 +117,23 @@ public Object fromV2ToV1(Object v2Obj, AtlasType type, ConverterContext converte\n         return ret;\n     }\n \n-    protected Map<String, Object> fromV2ToV1(AtlasStructType structType, Map attributes, ConverterContext context) throws AtlasBaseException {\n+    protected Map<String, Object> fromV2ToV1(AtlasStructType structType, Map<String, Object> attributes, ConverterContext context) throws AtlasBaseException {\n         Map<String, Object> ret = null;\n \n         if (MapUtils.isNotEmpty(attributes)) {\n             ret = new HashMap<>();\n \n             // Only process the requested/set attributes\n-            for (Object attribKey : attributes.keySet()) {\n-                AtlasStructType.AtlasAttribute attr = structType.getAttribute((String) attribKey);\n-                AtlasType attrType = attr.getAttributeType();\n+            for (String attrName : attributes.keySet()) {\n+                AtlasAttribute attr = structType.getAttribute(attrName);\n \n-                if (attrType == null) {\n-                    LOG.warn(\"ignored attribute {}.{}: failed to find AtlasType\", structType.getTypeName(), attr.getName());\n+                if (attr == null) {\n+                    LOG.warn(\"ignored unknown attribute {}.{}\", structType.getTypeName(), attrName);\n                     continue;\n                 }\n \n+                AtlasType attrType = attr.getAttributeType();\n+\n                 Object v2Value = attributes.get(attr.getName());\n                 Object v1Value;\n \n@@ -155,15 +154,16 @@ public Object fromV2ToV1(Object v2Obj, AtlasType type, ConverterContext converte\n \n             // Only process the requested/set attributes\n             for (Object attribKey : attributes.keySet()) {\n-                AtlasStructType.AtlasAttribute attr = structType.getAttribute((String) attribKey);\n+                String         attrName = attribKey.toString();\n+                AtlasAttribute attr     = structType.getAttribute(attrName);\n \n-                AtlasType attrType = attr.getAttributeType();\n-\n-                if (attrType == null) {\n-                    LOG.warn(\"ignored attribute {}.{}: failed to find AtlasType\", structType.getTypeName(), attr.getName());\n+                if (attr == null) {\n+                    LOG.warn(\"ignored unknown attribute {}.{}\", structType.getTypeName(), attrName);\n                     continue;\n                 }\n \n+                AtlasType attrType = attr.getAttributeType();\n+\n                 AtlasFormatConverter attrConverter = converterRegistry.getConverter(attrType.getTypeCategory());\n                 Object               v1Value       = attributes.get(attr.getName());\n                 Object               v2Value       = attrConverter.fromV1ToV2(v1Value, attrType, context);",
                "additions": 14,
                "raw_url": "https://github.com/apache/atlas/raw/485573fcab1c7cd263289ccc4da40357607dce82/repository/src/main/java/org/apache/atlas/repository/converters/AtlasStructFormatConverter.java",
                "status": "modified",
                "changes": 28,
                "deletions": 14,
                "sha": "6b6ee015e6d9fd3c01cd78ede619d79b9975e4d3",
                "blob_url": "https://github.com/apache/atlas/blob/485573fcab1c7cd263289ccc4da40357607dce82/repository/src/main/java/org/apache/atlas/repository/converters/AtlasStructFormatConverter.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/converters/AtlasStructFormatConverter.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/converters/AtlasStructFormatConverter.java?ref=485573fcab1c7cd263289ccc4da40357607dce82"
            }
        ],
        "bug_id": "atlas_17",
        "parent": "https://github.com/apache/atlas/commit/b4a694154de8372b405ed3eca6f0254753e146e5",
        "message": "ATLAS-1576: fix for NPE while handling unknown attributes",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/38297a8441e7d32d41e717fd6efc415804e640af",
        "file": [
            {
                "patch": "@@ -263,17 +263,19 @@ public void onChange(Collection<? extends IDataType> dataTypes) throws AtlasExce\n             }\n \n             if (management != null) {\n-                recomputeIndexedKeys = false;\n-\n                 AtlasGraphIndex vertexIndex = management.getGraphIndex(Constants.VERTEX_INDEX);\n \n-                Set<String> indexKeys = new HashSet<>();\n+                if (vertexIndex != null) {\n+                    recomputeIndexedKeys = false;\n \n-                for (AtlasPropertyKey fieldKey : vertexIndex.getFieldKeys()) {\n-                    indexKeys.add(fieldKey.getName());\n-                }\n+                    Set<String> indexKeys = new HashSet<>();\n \n-                vertexIndexKeys = indexKeys;\n+                    for (AtlasPropertyKey fieldKey : vertexIndex.getFieldKeys()) {\n+                        indexKeys.add(fieldKey.getName());\n+                    }\n+\n+                    vertexIndexKeys = indexKeys;\n+                }\n             }\n         }\n ",
                "additions": 9,
                "raw_url": "https://github.com/apache/atlas/raw/38297a8441e7d32d41e717fd6efc415804e640af/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "status": "modified",
                "changes": 16,
                "deletions": 7,
                "sha": "632b479064f80b1e2c7a68171e85b51806139081",
                "blob_url": "https://github.com/apache/atlas/blob/38297a8441e7d32d41e717fd6efc415804e640af/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java?ref=38297a8441e7d32d41e717fd6efc415804e640af"
            }
        ],
        "bug_id": "atlas_18",
        "parent": "https://github.com/apache/atlas/commit/eb5d6fcdcbbfb6d6a69f2c78ef64a7c5a47425ec",
        "message": "ATLAS-1997: fix to avoid NPE while getting vertex_indices\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/eddab3b12a1318f6e787d062816e28479715f077",
        "file": [
            {
                "patch": "@@ -370,6 +370,10 @@ public AtlasImportResult importData(@FormDataParam(\"request\") String jsonData,\n         AtlasImportResult result;\n \n         try {\n+            if (StringUtils.isEmpty(jsonData)) {\n+                jsonData = \"{}\";\n+            }\n+\n             AtlasImportRequest request = AtlasType.fromJson(jsonData, AtlasImportRequest.class);\n             ZipSource zipSource = new ZipSource(inputStream);\n ",
                "additions": 4,
                "raw_url": "https://github.com/apache/atlas/raw/eddab3b12a1318f6e787d062816e28479715f077/webapp/src/main/java/org/apache/atlas/web/resources/AdminResource.java",
                "status": "modified",
                "changes": 4,
                "deletions": 0,
                "sha": "fe9111bb99c69a3678a1797d88b569b50d672db2",
                "blob_url": "https://github.com/apache/atlas/blob/eddab3b12a1318f6e787d062816e28479715f077/webapp/src/main/java/org/apache/atlas/web/resources/AdminResource.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/resources/AdminResource.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/resources/AdminResource.java?ref=eddab3b12a1318f6e787d062816e28479715f077"
            }
        ],
        "bug_id": "atlas_19",
        "parent": "https://github.com/apache/atlas/commit/84c6d52d266c6aa2039e7e8cb9a7edb8f4bb8a93",
        "message": "ATLAS-1939: added parameter validation to prevent NPE during import\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/c3318467eb3954b7fc6490312bee4ce0d36cf081",
        "file": [
            {
                "patch": "@@ -125,7 +125,13 @@ public Object fromV2ToV1(Object v2Obj, AtlasType type) throws AtlasBaseException\n             ret = new HashMap<>();\n \n             for (AtlasStructDef.AtlasAttributeDef attrDef : getAttributeDefs(structType)) {\n-                AtlasType            attrType      = structType.getAttributeType(attrDef.getName());\n+                AtlasType attrType = structType.getAttributeType(attrDef.getName());\n+\n+                if (attrType == null) {\n+                    LOG.warn(\"ignored attribute {}.{}: failed to find AtlasType\", structType.getTypeName(), attrDef.getName());\n+                    continue;\n+                }\n+\n                 AtlasFormatConverter attrConverter = converterRegistry.getConverter(attrType.getTypeCategory());\n \n                 Object v2Value = attributes.get(attrDef.getName());",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/c3318467eb3954b7fc6490312bee4ce0d36cf081/webapp/src/main/java/org/apache/atlas/web/adapters/AtlasStructFormatConverter.java",
                "status": "modified",
                "changes": 8,
                "deletions": 1,
                "sha": "3565ab31c390ff63f95a5b0b59ac4ee7ebb94df7",
                "blob_url": "https://github.com/apache/atlas/blob/c3318467eb3954b7fc6490312bee4ce0d36cf081/webapp/src/main/java/org/apache/atlas/web/adapters/AtlasStructFormatConverter.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/adapters/AtlasStructFormatConverter.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/adapters/AtlasStructFormatConverter.java?ref=c3318467eb3954b7fc6490312bee4ce0d36cf081"
            },
            {
                "patch": "@@ -174,9 +174,13 @@ public EntityMutationResponse deleteById(@QueryParam(\"guid\") final List<String>\n         AtlasEntity.AtlasEntities atlasEntities = entitiesStore.searchEntities(searchFilter);\n         AtlasEntityHeader.AtlasEntityHeaders entityHeaders = new AtlasEntityHeader.AtlasEntityHeaders();\n         entityHeaders.setList(new LinkedList<AtlasEntityHeader>());\n-        for (AtlasEntity atlasEntity : atlasEntities.getList()) {\n-            entityHeaders.getList().add(new AtlasEntityHeader(atlasEntity.getTypeName(), atlasEntity.getAttributes()));\n+\n+        if (atlasEntities != null) {\n+            for (AtlasEntity atlasEntity : atlasEntities.getList()) {\n+                entityHeaders.getList().add(new AtlasEntityHeader(atlasEntity.getTypeName(), atlasEntity.getAttributes()));\n+            }\n         }\n+\n         return entityHeaders;\n     }\n ",
                "additions": 6,
                "raw_url": "https://github.com/apache/atlas/raw/c3318467eb3954b7fc6490312bee4ce0d36cf081/webapp/src/main/java/org/apache/atlas/web/rest/EntitiesREST.java",
                "status": "modified",
                "changes": 8,
                "deletions": 2,
                "sha": "f6acd07b065584f232864ac3a07161d4017e86a6",
                "blob_url": "https://github.com/apache/atlas/blob/c3318467eb3954b7fc6490312bee4ce0d36cf081/webapp/src/main/java/org/apache/atlas/web/rest/EntitiesREST.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/rest/EntitiesREST.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/rest/EntitiesREST.java?ref=c3318467eb3954b7fc6490312bee4ce0d36cf081"
            }
        ],
        "bug_id": "atlas_20",
        "parent": "https://github.com/apache/atlas/commit/0e7ef3af9e59584bd9ea87b10d6264a97ba4b41e",
        "message": "ATLAS-1415: fix potential NPE issues found by Coverity scan",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707",
        "file": [
            {
                "patch": "@@ -9,6 +9,7 @@ ATLAS-1060 Add composite indexes for exact match performance improvements for al\n ATLAS-1127 Modify creation and modification timestamps to Date instead of Long(sumasai)\n \n ALL CHANGES:\n+ATLAS-1305 Fix potential NPEs in instance conversion code (sumasai)\n ATLAS-1349 Reduce excessive exception logging (apoorvnaik via svimal2106)\n ATLAS-1343 CTAS query is not captured by Atlas with Hive2 (svimal2106)\n ATLAS-1337 fixed FalconHookIT (ayubpathan via mneethiraj)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "1d44e3e56eb31ab709ca3d2f4dbacfd17490256f",
                "blob_url": "https://github.com/apache/atlas/blob/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=6fb7b82a8fb2442f6ffb08c9946fc446c34b6707"
            },
            {
                "patch": "@@ -393,7 +393,7 @@ private AtlasType validateType(String entityType, TypeCategory expectedCategory)\n      */\n     private void validateUniqueAttribute(AtlasEntityType entityType, String attributeName) throws AtlasBaseException {\n         AtlasStructDef.AtlasAttributeDef attribute = entityType.getAttributeDef(attributeName);\n-        if (!attribute.getIsUnique()) {\n+        if (attribute != null && !attribute.getIsUnique()) {\n             throw new AtlasBaseException(AtlasErrorCode.ATTRIBUTE_UNIQUE_INVALID, entityType.getTypeName(), attributeName);\n         }\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/webapp/src/main/java/org/apache/atlas/web/rest/EntityREST.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "2529f0dd52c14dde44712071596d23b8ac949289",
                "blob_url": "https://github.com/apache/atlas/blob/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/webapp/src/main/java/org/apache/atlas/web/rest/EntityREST.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/rest/EntityREST.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/rest/EntityREST.java?ref=6fb7b82a8fb2442f6ffb08c9946fc446c34b6707"
            },
            {
                "patch": "@@ -337,7 +337,7 @@ private void verifyByNameAndGUID(AtlasBaseTypeDef typeDef) {\n                 } else if (typeDef.getCategory() == TypeCategory.ENTITY) {\n                     byGuid = clientV2.getEntityByGuid(typeDef.getGuid());\n                 } else if (typeDef.getCategory() == TypeCategory.CLASSIFICATION) {\n-                    byGuid = clientV2.getClassificationByGuid(typeDef.getName());\n+                    byGuid = clientV2.getClassificationByGuid(typeDef.getGuid());\n                 } else if (typeDef.getCategory() == TypeCategory.STRUCT) {\n                     byGuid = clientV2.getStructByGuid(typeDef.getGuid());\n                 }",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/webapp/src/test/java/org/apache/atlas/web/resources/TypedefsJerseyResourceIT.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "8e8684faa3c879fcb7c94add40a1fa7d109926a3",
                "blob_url": "https://github.com/apache/atlas/blob/6fb7b82a8fb2442f6ffb08c9946fc446c34b6707/webapp/src/test/java/org/apache/atlas/web/resources/TypedefsJerseyResourceIT.java",
                "filename": "webapp/src/test/java/org/apache/atlas/web/resources/TypedefsJerseyResourceIT.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/test/java/org/apache/atlas/web/resources/TypedefsJerseyResourceIT.java?ref=6fb7b82a8fb2442f6ffb08c9946fc446c34b6707"
            }
        ],
        "bug_id": "atlas_21",
        "parent": "https://github.com/apache/atlas/commit/c413975aa9a10b2e3f576c68fefeffe11229b693",
        "message": "ATLAS-1305 Fix potential NPEs in instance conversion code(sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/0c1d599ddca7ad9e4c677c77908e96dd492a8f90",
        "file": [
            {
                "patch": "@@ -248,7 +248,7 @@ private void collect(HiveEventContext event) throws Exception {\n \n         case CREATETABLE:\n             LinkedHashMap<Type, Referenceable> tablesCreated = handleEventOutputs(dgiBridge, event, Type.TABLE);\n-            if (tablesCreated.size() > 0) {\n+            if (tablesCreated != null && tablesCreated.size() > 0) {\n                 handleExternalTables(dgiBridge, event, tablesCreated);\n             }\n             break;\n@@ -730,7 +730,7 @@ private void handleExternalTables(final HiveMetaStoreBridge dgiBridge, final Hiv\n             final String location = lower(hiveTable.getDataLocation().toString());\n             final ReadEntity dfsEntity = new ReadEntity();\n             dfsEntity.setTyp(Type.DFS_DIR);\n-            dfsEntity.setName(location);\n+            dfsEntity.setD(new Path(location));\n \n             SortedMap<ReadEntity, Referenceable> hiveInputsMap = new TreeMap<ReadEntity, Referenceable>(entityComparator) {{\n                 put(dfsEntity, dgiBridge.fillHDFSDataSet(location));",
                "additions": 2,
                "raw_url": "https://github.com/apache/atlas/raw/0c1d599ddca7ad9e4c677c77908e96dd492a8f90/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "status": "modified",
                "changes": 4,
                "deletions": 2,
                "sha": "16835cf88410276712a54d8de75cf78768fbe35c",
                "blob_url": "https://github.com/apache/atlas/blob/0c1d599ddca7ad9e4c677c77908e96dd492a8f90/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java?ref=0c1d599ddca7ad9e4c677c77908e96dd492a8f90"
            },
            {
                "patch": "@@ -21,7 +21,6 @@\n import com.google.inject.Inject;\n import com.google.inject.Singleton;\n import org.apache.atlas.AtlasErrorCode;\n-import org.apache.atlas.AtlasException;\n import org.apache.atlas.GraphTransaction;\n import org.apache.atlas.RequestContextV1;\n import org.apache.atlas.exception.AtlasBaseException;\n@@ -38,12 +37,10 @@\n import org.apache.atlas.repository.store.graph.EntityGraphDiscovery;\n import org.apache.atlas.repository.store.graph.EntityGraphDiscoveryContext;\n import org.apache.atlas.type.AtlasEntityType;\n-import org.apache.atlas.type.AtlasStructType;\n import org.apache.atlas.type.AtlasStructType.AtlasAttribute;\n import org.apache.atlas.type.AtlasType;\n import org.apache.atlas.type.AtlasTypeRegistry;\n import org.apache.atlas.type.AtlasTypeUtil;\n-import org.apache.atlas.typesystem.persistence.Id;\n import org.apache.commons.collections.CollectionUtils;\n import org.apache.commons.collections.MapUtils;\n import org.apache.commons.lang3.StringUtils;\n@@ -326,17 +323,18 @@ public EntityMutationResponse deleteById(final String guid) throws AtlasBaseExce\n         // Retrieve vertices for requested guids.\n         AtlasVertex vertex = AtlasGraphUtilsV1.findByGuid(guid);\n \n-        if (LOG.isDebugEnabled()) {\n-            if (vertex == null) {\n+        Collection<AtlasVertex> deletionCandidates = new ArrayList<>();\n+\n+        if (vertex != null) {\n+            deletionCandidates.add(vertex);\n+        } else {\n+            if (LOG.isDebugEnabled()) {\n                 // Entity does not exist - treat as non-error, since the caller\n                 // wanted to delete the entity and it's already gone.\n                 LOG.debug(\"Deletion request ignored for non-existent entity with guid \" + guid);\n             }\n         }\n \n-        Collection<AtlasVertex> deletionCandidates = new ArrayList<>();\n-        deletionCandidates.add(vertex);\n-\n         EntityMutationResponse ret = deleteVertices(deletionCandidates);\n \n         // Notify the change listeners\n@@ -357,15 +355,16 @@ public EntityMutationResponse deleteByIds(final List<String> guids) throws Atlas\n         for (String guid : guids) {\n             // Retrieve vertices for requested guids.\n             AtlasVertex vertex = AtlasGraphUtilsV1.findByGuid(guid);\n-            if (LOG.isDebugEnabled()) {\n-                if (vertex == null) {\n+\n+            if (vertex != null) {\n+                deletionCandidates.add(vertex);\n+            } else {\n+                if (LOG.isDebugEnabled()) {\n                     // Entity does not exist - treat as non-error, since the caller\n                     // wanted to delete the entity and it's already gone.\n                     LOG.debug(\"Deletion request ignored for non-existent entity with guid \" + guid);\n                 }\n             }\n-            deletionCandidates.add(vertex);\n-\n         }\n \n         if (deletionCandidates.isEmpty()) {\n@@ -391,7 +390,16 @@ public EntityMutationResponse deleteByUniqueAttributes(AtlasEntityType entityTyp\n \n         final AtlasVertex vertex = AtlasGraphUtilsV1.findByUniqueAttributes(entityType, uniqAttributes);\n         Collection<AtlasVertex> deletionCandidates = new ArrayList<>();\n-        deletionCandidates.add(vertex);\n+\n+        if (vertex != null) {\n+            deletionCandidates.add(vertex);\n+        } else {\n+            if (LOG.isDebugEnabled()) {\n+                // Entity does not exist - treat as non-error, since the caller\n+                // wanted to delete the entity and it's already gone.\n+                LOG.debug(\"Deletion request ignored for non-existent entity with uniqueAttributes \" + uniqAttributes);\n+            }\n+        }\n \n         EntityMutationResponse ret = deleteVertices(deletionCandidates);\n ",
                "additions": 21,
                "raw_url": "https://github.com/apache/atlas/raw/0c1d599ddca7ad9e4c677c77908e96dd492a8f90/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityStoreV1.java",
                "status": "modified",
                "changes": 34,
                "deletions": 13,
                "sha": "587f3c74ea95af926caaebf549bb4c443db414f8",
                "blob_url": "https://github.com/apache/atlas/blob/0c1d599ddca7ad9e4c677c77908e96dd492a8f90/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityStoreV1.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityStoreV1.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/store/graph/v1/AtlasEntityStoreV1.java?ref=0c1d599ddca7ad9e4c677c77908e96dd492a8f90"
            }
        ],
        "bug_id": "atlas_22",
        "parent": "https://github.com/apache/atlas/commit/08944c54de13054b4b7a76dbcba79218779f02d3",
        "message": "ATLAS-1598: fix for NPE in Hive hook while processing create-table",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/19a5f65c9bcafc77df164c4dd75c89782b4f4076",
        "file": [
            {
                "patch": "@@ -1,3 +1,20 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n package org.apache.atlas.services;\n \n import org.apache.atlas.model.metrics.AtlasMetrics;\n@@ -49,6 +66,17 @@ public void init() throws ScriptException {\n         mockMapList.add(cMockMap);\n \n         when(mockConfig.getInt(anyString(), anyInt())).thenReturn(5);\n+        when(mockConfig.getString(anyString(), anyString()))\n+                // we have seven count queries so stubbing 7 counts\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                .thenReturn(\"dummyTestQuery.count()\")\n+                // The last query is a map\n+                .thenReturn(\"dummyTestQuery\");\n         assertEquals(mockConfig.getInt(\"test\", 1), 5);\n         when(mockTypeRegistry.getAllEntityDefNames()).thenReturn(Arrays.asList(\"a\", \"b\", \"c\"));\n         setupMockGraph();",
                "additions": 28,
                "raw_url": "https://github.com/apache/atlas/raw/19a5f65c9bcafc77df164c4dd75c89782b4f4076/repository/src/test/java/org/apache/atlas/services/MetricsServiceTest.java",
                "status": "modified",
                "changes": 28,
                "deletions": 0,
                "sha": "bb8c223e82874d261383bcd7657a70042e48e79d",
                "blob_url": "https://github.com/apache/atlas/blob/19a5f65c9bcafc77df164c4dd75c89782b4f4076/repository/src/test/java/org/apache/atlas/services/MetricsServiceTest.java",
                "filename": "repository/src/test/java/org/apache/atlas/services/MetricsServiceTest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/test/java/org/apache/atlas/services/MetricsServiceTest.java?ref=19a5f65c9bcafc77df164c4dd75c89782b4f4076"
            }
        ],
        "bug_id": "atlas_23",
        "parent": "https://github.com/apache/atlas/commit/89f70609645fa53cb5492035c49c2aa4b99031e9",
        "message": "ATLAS-1436: test fix to address NPE\n\nSigned-off-by: Madhan Neethiraj <madhan@apache.org>",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/64f017a7079d547ebd9b972b4a115ce807855e33",
        "file": [
            {
                "patch": "@@ -71,14 +71,6 @@\n             <artifactId>testng</artifactId>\n         </dependency>\n \n-        <!-- to bring up atlas server for integration tests -->\n-        <dependency>\n-            <groupId>org.apache.atlas</groupId>\n-            <artifactId>atlas-webapp</artifactId>\n-            <type>war</type>\n-            <scope>test</scope>\n-        </dependency>\n-\n         <dependency>\n             <groupId>org.apache.atlas</groupId>\n             <artifactId>atlas-repository</artifactId>",
                "additions": 0,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/addons/hdfs-model/pom.xml",
                "status": "modified",
                "changes": 8,
                "deletions": 8,
                "sha": "492f39cea085c6e69781e17bcbdbc3a231806df3",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/addons/hdfs-model/pom.xml",
                "filename": "addons/hdfs-model/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hdfs-model/pom.xml?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -228,7 +228,7 @@ private void createColumnClass() throws AtlasException {\n \n         HierarchicalTypeDefinition<ClassType> definition =\n                 new HierarchicalTypeDefinition<>(ClassType.class, HiveDataTypes.HIVE_COLUMN.getName(), null,\n-                    ImmutableSet.of(AtlasClient.REFERENCEABLE_SUPER_TYPE, AtlasClient.ASSET_TYPE), attributeDefinitions);\n+                    ImmutableSet.of(AtlasClient.DATA_SET_SUPER_TYPE), attributeDefinitions);\n         classTypeDefinitions.put(HiveDataTypes.HIVE_COLUMN.getName(), definition);\n         LOG.debug(\"Created definition for \" + HiveDataTypes.HIVE_COLUMN.getName());\n     }",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/addons/hive-bridge/src/main/java/org/apache/atlas/hive/model/HiveDataModelGenerator.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "b308cc955d8c0417c6034b15f01e8274e994ed2a",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/addons/hive-bridge/src/main/java/org/apache/atlas/hive/model/HiveDataModelGenerator.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/model/HiveDataModelGenerator.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/model/HiveDataModelGenerator.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -24,7 +24,11 @@\n import junit.framework.Assert;\n import junit.framework.TestCase;\n import org.apache.hadoop.util.StringUtils;\n+import org.testng.annotations.Test;\n \n+\n+//Unstable test. Disabling\n+@Test(enabled=false)\n public class InMemoryJAASConfigurationTest extends TestCase {\n \n     private static final String ATLAS_JAAS_PROP_FILE = \"atlas-jaas.properties\";\n@@ -42,6 +46,7 @@ protected void tearDown() throws Exception {\n         super.tearDown();\n     }\n \n+    @Test(enabled=false)\n     public void testGetAppConfigurationEntryStringForKafkaClient() {\n         AppConfigurationEntry[] entries =\n                 Configuration.getConfiguration().getAppConfigurationEntry(\"KafkaClient\");\n@@ -55,6 +60,7 @@ public void testGetAppConfigurationEntryStringForKafkaClient() {\n \n     }\n \n+    @Test(enabled=false)\n     public void testGetAppConfigurationEntryStringForMyClient() {\n         AppConfigurationEntry[] entries =\n                 Configuration.getConfiguration().getAppConfigurationEntry(\"myClient\");\n@@ -72,6 +78,7 @@ public void testGetAppConfigurationEntryStringForMyClient() {\n         Assert.assertEquals(2, components.length);\n     }\n \n+    @Test(enabled=false)\n     public void testGetAppConfigurationEntryStringForUnknownClient() {\n         AppConfigurationEntry[] entries =\n                 Configuration.getConfiguration().getAppConfigurationEntry(\"UnknownClient\");",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/common/src/test/java/org/apache/atlas/security/InMemoryJAASConfigurationTest.java",
                "status": "modified",
                "changes": 7,
                "deletions": 0,
                "sha": "b26ac7f6f3504b65fdc1c031b5ff8aefe3b675c5",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/common/src/test/java/org/apache/atlas/security/InMemoryJAASConfigurationTest.java",
                "filename": "common/src/test/java/org/apache/atlas/security/InMemoryJAASConfigurationTest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/common/src/test/java/org/apache/atlas/security/InMemoryJAASConfigurationTest.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -9,6 +9,7 @@ ATLAS-1122 Change trait edge labels to have trait name alone (sumasai)\n ATLAS-1060 Add composite indexes for exact match performance improvements for all attributes (sumasai via shwethags)\n \n ALL CHANGES:\n+ATLAS-1126 Fix NPE in getSchema calls (sumasai)\n ATLAS-1125 Enable compression on hbase audit table (shwethags via sumasai)\n ATLAS-1121 NPE while submitting topology in StormHook (ayubkhan via sumasai)\n ATLAS-1119 Add retries for edge label creation (sumasai via shwethags)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "4469c81a8923d8dc17b35c9eba3a656a9af6fdd7",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -33,6 +33,7 @@\n import org.apache.atlas.repository.MetadataRepository;\n import org.apache.atlas.repository.graph.GraphProvider;\n import org.apache.atlas.typesystem.exception.EntityNotFoundException;\n+import org.apache.atlas.typesystem.exception.SchemaNotFoundException;\n import org.apache.atlas.typesystem.persistence.ReferenceableInstance;\n import org.apache.atlas.utils.ParamChecker;\n import org.apache.commons.configuration.Configuration;\n@@ -172,11 +173,15 @@ public String getSchema(String datasetName) throws AtlasException {\n         return getSchemaForId(datasetInstance.getTypeName(), datasetInstance.getId()._getId());\n     }\n \n-    private String getSchemaForId(String typeName, String guid) throws DiscoveryException {\n-        final String schemaQuery =\n-                String.format(propertiesConf.getString(DATASET_SCHEMA_QUERY_PREFIX + typeName), guid);\n-        int limit = AtlasProperties.getProperty(AtlasProperties.AtlasProperty.SEARCH_MAX_LIMIT);\n-        return discoveryService.searchByDSL(schemaQuery, new QueryParams(limit, 0));\n+    private String getSchemaForId(String typeName, String guid) throws DiscoveryException, SchemaNotFoundException {\n+        String configName = DATASET_SCHEMA_QUERY_PREFIX + typeName;\n+        if (propertiesConf.getString(configName) != null) {\n+            final String schemaQuery =\n+                String.format(propertiesConf.getString(configName), guid);\n+            int limit = AtlasProperties.getProperty(AtlasProperties.AtlasProperty.SEARCH_MAX_LIMIT);\n+            return discoveryService.searchByDSL(schemaQuery, new QueryParams(limit, 0));\n+        }\n+        throw new SchemaNotFoundException(\"Schema is not configured for type \" + typeName + \". Configure \" + configName);\n     }\n \n     @Override\n@@ -218,5 +223,4 @@ private String validateDatasetExists(String guid) throws AtlasException {\n         ReferenceableInstance referenceable = (ReferenceableInstance)queryResult.rows().apply(0);\n         return referenceable.getTypeName();\n     }\n-\n }",
                "additions": 10,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/main/java/org/apache/atlas/discovery/DataSetLineageService.java",
                "status": "modified",
                "changes": 16,
                "deletions": 6,
                "sha": "c216469ceb1d89b5f6a578f9bd96f01c09cccd06",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/main/java/org/apache/atlas/discovery/DataSetLineageService.java",
                "filename": "repository/src/main/java/org/apache/atlas/discovery/DataSetLineageService.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/discovery/DataSetLineageService.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -80,10 +80,10 @@\n     public static final String CONFIG_PERSIST_ENTITY_DEFINITION = CONFIG_PREFIX + \".persistEntityDefinition\";\n \n     public static final byte[] COLUMN_FAMILY = Bytes.toBytes(\"dt\");\n-    public static final byte[] COLUMN_ACTION = Bytes.toBytes(\"action\");\n-    public static final byte[] COLUMN_DETAIL = Bytes.toBytes(\"detail\");\n-    public static final byte[] COLUMN_USER = Bytes.toBytes(\"user\");\n-    public static final byte[] COLUMN_DEFINITION = Bytes.toBytes(\"def\");\n+    public static final byte[] COLUMN_ACTION = Bytes.toBytes(\"a\");\n+    public static final byte[] COLUMN_DETAIL = Bytes.toBytes(\"d\");\n+    public static final byte[] COLUMN_USER = Bytes.toBytes(\"u\");\n+    public static final byte[] COLUMN_DEFINITION = Bytes.toBytes(\"f\");\n \n     private static boolean persistEntityDefinition;\n ",
                "additions": 4,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/main/java/org/apache/atlas/repository/audit/HBaseBasedAuditRepository.java",
                "status": "modified",
                "changes": 8,
                "deletions": 4,
                "sha": "50995216ac31233aec260592ce6cd9759dddb925",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/main/java/org/apache/atlas/repository/audit/HBaseBasedAuditRepository.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/audit/HBaseBasedAuditRepository.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/audit/HBaseBasedAuditRepository.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -101,6 +101,7 @@ private void setUpTypes() throws Exception {\n     private static final String STORAGE_DESC_TYPE = \"StorageDesc\";\n     private static final String VIEW_TYPE = \"View\";\n     private static final String PARTITION_TYPE = \"hive_partition\";\n+    protected static final String DATASET_SUBTYPE = \"dataset_subtype\";\n \n     TypesDef createTypeDefinitions() {\n         HierarchicalTypeDefinition<ClassType> dbClsDef = TypesUtil\n@@ -156,7 +157,10 @@ TypesDef createTypeDefinitions() {\n             new HierarchicalTypeDefinition<>(ClassType.class, PARTITION_TYPE, null, null,\n                 attributeDefinitions);\n \n-        HierarchicalTypeDefinition<TraitType> dimTraitDef = TypesUtil.createTraitTypeDef(\"Dimension\", null);\n+        HierarchicalTypeDefinition<ClassType> datasetSubTypeClsDef = TypesUtil\n+            .createClassTypeDef(DATASET_SUBTYPE, ImmutableSet.of(\"DataSet\"));\n+\n+                HierarchicalTypeDefinition < TraitType > dimTraitDef = TypesUtil.createTraitTypeDef(\"Dimension\", null);\n \n         HierarchicalTypeDefinition<TraitType> factTraitDef = TypesUtil.createTraitTypeDef(\"Fact\", null);\n \n@@ -172,7 +176,7 @@ TypesDef createTypeDefinitions() {\n \n         return TypesUtil.getTypesDef(ImmutableList.<EnumTypeDefinition>of(), ImmutableList.<StructTypeDefinition>of(),\n             ImmutableList.of(dimTraitDef, factTraitDef, piiTraitDef, metricTraitDef, etlTraitDef, jdbcTraitDef, logTraitDef),\n-            ImmutableList.of(dbClsDef, storageDescClsDef, columnClsDef, tblClsDef, loadProcessClsDef, viewClsDef, partClsDef));\n+            ImmutableList.of(dbClsDef, storageDescClsDef, columnClsDef, tblClsDef, loadProcessClsDef, viewClsDef, partClsDef, datasetSubTypeClsDef));\n     }\n \n     AttributeDefinition attrDef(String name, IDataType dT) {\n@@ -280,6 +284,8 @@ private void setupInstances() throws Exception {\n             ImmutableList.of(loggingFactMonthly), \"create table as select \", \"plan\", \"id\", \"graph\", \"ETL\");\n \n         partition(new ArrayList() {{ add(\"2015-01-01\"); }}, salesFactDaily);\n+\n+        datasetSubType(\"dataSetSubTypeInst1\", \"testOwner\");\n     }\n \n     Id database(String name, String description, String owner, String locationUri, String... traitNames)\n@@ -379,6 +385,15 @@ Id partition(List<String> values, Id table, String... traitNames) throws Excepti\n         ClassType clsType = TypeSystem.getInstance().getDataType(ClassType.class, PARTITION_TYPE);\n         return createInstance(referenceable, clsType);\n     }\n+\n+    Id datasetSubType(final String name, String owner) throws Exception {\n+        Referenceable referenceable = new Referenceable(DATASET_SUBTYPE);\n+        referenceable.set(AtlasClient.REFERENCEABLE_ATTRIBUTE_NAME, name);\n+        referenceable.set(AtlasClient.NAME, name);\n+        referenceable.set(\"owner\", owner);\n+        ClassType clsType = TypeSystem.getInstance().getDataType(ClassType.class, DATASET_SUBTYPE);\n+        return createInstance(referenceable, clsType);\n+    }\n     private Id createInstance(Referenceable referenceable, ClassType clsType) throws Exception {\n         ITypedReferenceableInstance typedInstance = clsType.convert(referenceable, Multiplicity.REQUIRED);\n         List<String> guids = repository.createEntities(typedInstance);",
                "additions": 17,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/test/java/org/apache/atlas/BaseRepositoryTest.java",
                "status": "modified",
                "changes": 19,
                "deletions": 2,
                "sha": "01c4bfab9d2c876d6c5ca653372b2c1752fcf5e3",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/test/java/org/apache/atlas/BaseRepositoryTest.java",
                "filename": "repository/src/test/java/org/apache/atlas/BaseRepositoryTest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/test/java/org/apache/atlas/BaseRepositoryTest.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -28,6 +28,7 @@\n import org.apache.atlas.typesystem.Referenceable;\n import org.apache.atlas.typesystem.Struct;\n import org.apache.atlas.typesystem.exception.EntityNotFoundException;\n+import org.apache.atlas.typesystem.exception.SchemaNotFoundException;\n import org.apache.atlas.typesystem.json.InstanceSerialization;\n import org.apache.atlas.typesystem.persistence.Id;\n import org.apache.commons.collections.ArrayStack;\n@@ -312,6 +313,12 @@ public void testGetSchemaForEntity(String tableName, String expected) throws Exc\n         }\n     }\n \n+    @Test(expectedExceptions = SchemaNotFoundException.class)\n+    public void testGetSchemaForDBEntity() throws Exception {\n+        String dbId = getEntityId(DATASET_SUBTYPE, \"name\", \"dataSetSubTypeInst1\");\n+        JSONObject results = new JSONObject(lineageService.getSchemaForEntity(dbId));\n+    }\n+\n     @DataProvider(name = \"invalidArgumentsProvider\")\n     private Object[][] arguments() {\n         return new String[][]{{null, IllegalArgumentException.class.getName()},",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/test/java/org/apache/atlas/discovery/DataSetLineageServiceTest.java",
                "status": "modified",
                "changes": 7,
                "deletions": 0,
                "sha": "b6754598c27bb2788b0bf4f43134ed40720c2178",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/repository/src/test/java/org/apache/atlas/discovery/DataSetLineageServiceTest.java",
                "filename": "repository/src/test/java/org/apache/atlas/discovery/DataSetLineageServiceTest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/test/java/org/apache/atlas/discovery/DataSetLineageServiceTest.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -0,0 +1,42 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.atlas.typesystem.exception;\n+\n+import org.apache.atlas.AtlasException;\n+\n+public class SchemaNotFoundException extends AtlasException {\n+    public SchemaNotFoundException() {\n+    }\n+\n+    public SchemaNotFoundException(String message) {\n+        super(message);\n+    }\n+\n+    public SchemaNotFoundException(String message, Throwable cause) {\n+        super(message, cause);\n+    }\n+\n+    public SchemaNotFoundException(Throwable cause) {\n+        super(cause);\n+    }\n+\n+    public SchemaNotFoundException(String message, Throwable cause, boolean enableSuppression,\n+        boolean writableStackTrace) {\n+        super(message, cause, enableSuppression, writableStackTrace);\n+    }\n+}",
                "additions": 42,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/server-api/src/main/java/org/apache/atlas/typesystem/exception/SchemaNotFoundException.java",
                "status": "added",
                "changes": 42,
                "deletions": 0,
                "sha": "3214149efe87cb6ba61965c6360892659128ffda",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/server-api/src/main/java/org/apache/atlas/typesystem/exception/SchemaNotFoundException.java",
                "filename": "server-api/src/main/java/org/apache/atlas/typesystem/exception/SchemaNotFoundException.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/server-api/src/main/java/org/apache/atlas/typesystem/exception/SchemaNotFoundException.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -90,7 +90,7 @@ public Response inputsGraph(@Context HttpServletRequest request, @PathParam(\"tab\n \n             return Response.ok(response).build();\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"table entity not found for {}\", tableName, e);\n+            LOG.error(\"table entity not found for {}\", tableName);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get lineage inputs graph for table {}\", tableName, e);\n@@ -130,7 +130,7 @@ public Response outputsGraph(@Context HttpServletRequest request, @PathParam(\"ta\n \n             return Response.ok(response).build();\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"table entity not found for {}\", tableName, e);\n+            LOG.error(\"table entity not found for {}\", tableName);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get lineage outputs graph for table {}\", tableName, e);\n@@ -170,7 +170,7 @@ public Response schema(@Context HttpServletRequest request, @PathParam(\"tableNam\n \n             return Response.ok(response).build();\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"table entity not found for {}\", tableName, e);\n+            LOG.error(\"table entity not found for {}\", tableName);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get schema for table {}\", tableName, e);",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/main/java/org/apache/atlas/web/resources/DataSetLineageResource.java",
                "status": "modified",
                "changes": 6,
                "deletions": 3,
                "sha": "a11c0cfa123217a26f2f476de551df346e47be6d",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/main/java/org/apache/atlas/web/resources/DataSetLineageResource.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/resources/DataSetLineageResource.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/resources/DataSetLineageResource.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -22,6 +22,7 @@\n import org.apache.atlas.discovery.DiscoveryException;\n import org.apache.atlas.discovery.LineageService;\n import org.apache.atlas.typesystem.exception.EntityNotFoundException;\n+import org.apache.atlas.typesystem.exception.SchemaNotFoundException;\n import org.apache.atlas.utils.AtlasPerfTracer;\n import org.apache.atlas.web.util.Servlets;\n import org.codehaus.jettison.json.JSONObject;\n@@ -83,7 +84,7 @@ public Response inputsGraph(@PathParam(\"guid\") String guid) {\n \n             return Response.ok(response).build();\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"entity not found for guid={}\", guid, e);\n+            LOG.error(\"entity not found for guid={}\", guid);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get lineage inputs graph for entity  guid={}\", guid, e);\n@@ -122,7 +123,7 @@ public Response outputsGraph(@PathParam(\"guid\") String guid) {\n \n             return Response.ok(response).build();\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"table entity not found for {}\", guid, e);\n+            LOG.error(\"table entity not found for {}\", guid);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get lineage outputs graph for entity guid={}\", guid, e);\n@@ -160,8 +161,11 @@ public Response schema(@PathParam(\"guid\") String guid) {\n             response.put(AtlasClient.RESULTS, new JSONObject(jsonResult));\n \n             return Response.ok(response).build();\n+        } catch (SchemaNotFoundException e) {\n+            LOG.error(\"schema not found for {}\", guid);\n+            throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (EntityNotFoundException e) {\n-            LOG.error(\"table entity not found for {}\", guid, e);\n+            LOG.error(\"table entity not found for {}\", guid);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.NOT_FOUND));\n         } catch (DiscoveryException | IllegalArgumentException e) {\n             LOG.error(\"Unable to get schema for entity guid={}\", guid, e);",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/main/java/org/apache/atlas/web/resources/LineageResource.java",
                "status": "modified",
                "changes": 10,
                "deletions": 3,
                "sha": "811c4868a2cc259296b54c0355fccde2bd497ffa",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/main/java/org/apache/atlas/web/resources/LineageResource.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/resources/LineageResource.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/resources/LineageResource.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            },
            {
                "patch": "@@ -48,6 +48,7 @@\n     private static final String BASE_URI = \"api/atlas/lineage/hive/table/\";\n     private String salesFactTable;\n     private String salesMonthlyTable;\n+    private String salesDBName;\n \n     @BeforeClass\n     public void setUp() throws Exception {\n@@ -209,8 +210,18 @@ public void testSchemaForInvalidTable() throws Exception {\n         Assert.assertEquals(clientResponse.getStatus(), Response.Status.NOT_FOUND.getStatusCode());\n     }\n \n+    @Test\n+    public void testSchemaForDB() throws Exception {\n+        WebResource resource = service.path(BASE_URI).path(salesDBName).path(\"schema\");\n+\n+        ClientResponse clientResponse = resource.accept(Servlets.JSON_MEDIA_TYPE).type(Servlets.JSON_MEDIA_TYPE)\n+            .method(HttpMethod.GET, ClientResponse.class);\n+        Assert.assertEquals(clientResponse.getStatus(), Response.Status.NOT_FOUND.getStatusCode());\n+    }\n+\n     private void setupInstances() throws Exception {\n-        Id salesDB = database(\"Sales\" + randomString(), \"Sales Database\", \"John ETL\",\n+        salesDBName = \"Sales\" + randomString();\n+        Id salesDB = database(salesDBName, \"Sales Database\", \"John ETL\",\n                 \"hdfs://host:8000/apps/warehouse/sales\");\n \n         List<Referenceable> salesFactColumns = ImmutableList",
                "additions": 12,
                "raw_url": "https://github.com/apache/atlas/raw/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/test/java/org/apache/atlas/web/resources/DataSetLineageJerseyResourceIT.java",
                "status": "modified",
                "changes": 13,
                "deletions": 1,
                "sha": "d8568ae04a35ec9023f0c76769fdd92f27abb911",
                "blob_url": "https://github.com/apache/atlas/blob/64f017a7079d547ebd9b972b4a115ce807855e33/webapp/src/test/java/org/apache/atlas/web/resources/DataSetLineageJerseyResourceIT.java",
                "filename": "webapp/src/test/java/org/apache/atlas/web/resources/DataSetLineageJerseyResourceIT.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/test/java/org/apache/atlas/web/resources/DataSetLineageJerseyResourceIT.java?ref=64f017a7079d547ebd9b972b4a115ce807855e33"
            }
        ],
        "bug_id": "atlas_24",
        "parent": "https://github.com/apache/atlas/commit/7b7f4e0b68637fec82af4443aedcecc63cf10747",
        "message": "ATLAS-1126 Fix NPE in getSchema calls (sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/d9d487bc33b4711d483490ccaaf17aabf5c480aa",
        "file": [
            {
                "patch": "@@ -73,7 +73,13 @@ public void setParams(MultivaluedMap<String, String> params) {\n     }\n \n     public String getParam(String name) {\n-        return getParams(name).get(0);\n+        String ret = null;\n+\n+        if (name != null && params != null) {\n+            ret = params.getFirst(name);\n+        }\n+\n+        return ret;\n     }\n \n     public List<String> getParams(String name) {",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/d9d487bc33b4711d483490ccaaf17aabf5c480aa/intg/src/main/java/org/apache/atlas/model/SearchFilter.java",
                "status": "modified",
                "changes": 8,
                "deletions": 1,
                "sha": "93e89c8f89d970bb8dec728e3bece7aaa24665dc",
                "blob_url": "https://github.com/apache/atlas/blob/d9d487bc33b4711d483490ccaaf17aabf5c480aa/intg/src/main/java/org/apache/atlas/model/SearchFilter.java",
                "filename": "intg/src/main/java/org/apache/atlas/model/SearchFilter.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/intg/src/main/java/org/apache/atlas/model/SearchFilter.java?ref=d9d487bc33b4711d483490ccaaf17aabf5c480aa"
            },
            {
                "patch": "@@ -9,6 +9,7 @@ ATLAS-1060 Add composite indexes for exact match performance improvements for al\n ATLAS-1127 Modify creation and modification timestamps to Date instead of Long(sumasai)\n \n ALL CHANGES:\n+ATLAS-1358 NPE Fix for search filter changes & callAPI related fixes (apoorvnaik via sumasai)\n ATLAS-1357: Fixes for test failures from ATLAS-1307 (apoorvnaik via sumasai)\n ATLAS-1307: Integration test calls routing via the Client. (apoorvnaik via sumasai)\n ATLAS-1355: Fix for bad error translation from V2 API (apoorvnaik via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/d9d487bc33b4711d483490ccaaf17aabf5c480aa/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "eec5a0f952bde3cbf47e96ebacdff0ae9dc7159a",
                "blob_url": "https://github.com/apache/atlas/blob/d9d487bc33b4711d483490ccaaf17aabf5c480aa/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=d9d487bc33b4711d483490ccaaf17aabf5c480aa"
            },
            {
                "patch": "@@ -429,10 +429,10 @@ public void testGetEntityList() throws Exception {\n \n     @Test(expectedExceptions = AtlasServiceException.class)\n     public void testGetEntityListForBadEntityType() throws Exception {\n-        Map<String, String> queryParams = new HashMap<>();\n-        queryParams.put(\"type\", \"blah\");\n+        MultivaluedMap<String, String> queryParams = new MultivaluedMapImpl();\n+        queryParams.add(\"type\", \"blah\");\n \n-        JSONObject response = serviceClient.callAPIWithBody(AtlasClient.API.GET_ENTITY, queryParams);\n+        JSONObject response = serviceClient.callAPIWithQueryParams(AtlasClient.API.GET_ENTITY, queryParams);\n         assertNotNull(response);\n         Assert.assertNotNull(response.get(AtlasClient.ERROR));\n         Assert.assertNotNull(response.get(AtlasClient.STACKTRACE));",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/d9d487bc33b4711d483490ccaaf17aabf5c480aa/webapp/src/test/java/org/apache/atlas/web/resources/EntityJerseyResourceIT.java",
                "status": "modified",
                "changes": 6,
                "deletions": 3,
                "sha": "b5af111fb5f8ee3d8b84ae43304454e28c1ff563",
                "blob_url": "https://github.com/apache/atlas/blob/d9d487bc33b4711d483490ccaaf17aabf5c480aa/webapp/src/test/java/org/apache/atlas/web/resources/EntityJerseyResourceIT.java",
                "filename": "webapp/src/test/java/org/apache/atlas/web/resources/EntityJerseyResourceIT.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/test/java/org/apache/atlas/web/resources/EntityJerseyResourceIT.java?ref=d9d487bc33b4711d483490ccaaf17aabf5c480aa"
            },
            {
                "patch": "@@ -20,6 +20,7 @@\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableSet;\n+import com.sun.jersey.core.util.MultivaluedMapImpl;\n import org.apache.atlas.AtlasClient;\n import org.apache.atlas.AtlasServiceException;\n import org.apache.atlas.typesystem.TypesDef;\n@@ -41,12 +42,11 @@\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n \n+import javax.ws.rs.core.MultivaluedMap;\n import javax.ws.rs.core.Response;\n import java.util.ArrayList;\n import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n-import java.util.Map;\n \n import static org.apache.atlas.typesystem.types.utils.TypesUtil.createOptionalAttrDef;\n import static org.testng.Assert.assertEquals;\n@@ -187,10 +187,10 @@ public void testGetTypeNames() throws Exception {\n     public void testGetTraitNames() throws Exception {\n         String[] traitsAdded = addTraits();\n \n-            Map<String, String> queryParams = new HashMap<>();\n-        queryParams.put(\"type\", DataTypes.TypeCategory.TRAIT.name());\n+        MultivaluedMap<String, String> queryParams = new MultivaluedMapImpl();\n+        queryParams.add(\"type\", DataTypes.TypeCategory.TRAIT.name());\n \n-        JSONObject response = serviceClient.callAPIWithBody(AtlasClient.API.LIST_TYPES, queryParams);\n+        JSONObject response = serviceClient.callAPIWithQueryParams(AtlasClient.API.LIST_TYPES, queryParams);\n         Assert.assertNotNull(response);\n \n         Assert.assertNotNull(response.get(AtlasClient.REQUEST_ID));",
                "additions": 5,
                "raw_url": "https://github.com/apache/atlas/raw/d9d487bc33b4711d483490ccaaf17aabf5c480aa/webapp/src/test/java/org/apache/atlas/web/resources/TypesJerseyResourceIT.java",
                "status": "modified",
                "changes": 10,
                "deletions": 5,
                "sha": "87bf9a89440f6a7ab703043bc2ddc98c152cf9fd",
                "blob_url": "https://github.com/apache/atlas/blob/d9d487bc33b4711d483490ccaaf17aabf5c480aa/webapp/src/test/java/org/apache/atlas/web/resources/TypesJerseyResourceIT.java",
                "filename": "webapp/src/test/java/org/apache/atlas/web/resources/TypesJerseyResourceIT.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/test/java/org/apache/atlas/web/resources/TypesJerseyResourceIT.java?ref=d9d487bc33b4711d483490ccaaf17aabf5c480aa"
            }
        ],
        "bug_id": "atlas_25",
        "parent": "https://github.com/apache/atlas/commit/28410df5f40cdfd2cb09c9fe99cbfb615b2038c0",
        "message": "ATLAS-1357: NPE Fix for search filter changes & callAPI related fixes",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/78c835edf1597c7d0082790c248235f08fb8474a",
        "file": [
            {
                "patch": "@@ -1087,7 +1087,13 @@ public void addMessage(HookNotification.HookNotificationMessage message) {\n     static final class EntityComparator implements Comparator<Entity> {\n         @Override\n         public int compare(Entity o1, Entity o2) {\n-            return o1.getName().toLowerCase().compareTo(o2.getName().toLowerCase());\n+            String s1 = o1.getName();\n+            String s2 = o2.getName();\n+            if (s1 == null || s2 == null){\n+                s1 = o1.getD().toString();\n+                s2 = o2.getD().toString();\n+            }\n+            return s1.toLowerCase().compareTo(s2.toLowerCase());\n         }\n     }\n ",
                "additions": 7,
                "raw_url": "https://github.com/apache/atlas/raw/78c835edf1597c7d0082790c248235f08fb8474a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "status": "modified",
                "changes": 8,
                "deletions": 1,
                "sha": "91b97f118b2c0150af759d42d057af980ae6dafa",
                "blob_url": "https://github.com/apache/atlas/blob/78c835edf1597c7d0082790c248235f08fb8474a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java?ref=78c835edf1597c7d0082790c248235f08fb8474a"
            },
            {
                "patch": "@@ -9,6 +9,7 @@ ATLAS-1060 Add composite indexes for exact match performance improvements for al\n ATLAS-1127 Modify creation and modification timestamps to Date instead of Long(sumasai)\n \n ALL CHANGES:\n+ATLAS-1351 HiveHook fails with NPE for hive process registration (vimalsharma via sumasai)\n ATLAS-1342 Titan Solrclient - Add timeouts for zookeeper connect and session (sumasai)\n ATLAS-1353 Invalid error message(500 internal server error) for lineage query on non-existing table. (sumasai)\n ATLAS-1347 Creating a class with unknown supertype results in \"409 Conflict\", where as expected is \"400 Bad Message\" (apoorvnairk via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/78c835edf1597c7d0082790c248235f08fb8474a/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "c4d2a49f3334d7b6a62cd65617aa698b6f43af49",
                "blob_url": "https://github.com/apache/atlas/blob/78c835edf1597c7d0082790c248235f08fb8474a/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=78c835edf1597c7d0082790c248235f08fb8474a"
            }
        ],
        "bug_id": "atlas_26",
        "parent": "https://github.com/apache/atlas/commit/c91f582a787a6ea88c4b8d2e4828e85f708ce7f0",
        "message": "ATLAS-1351 HiveHook fails with NPE for hive process registration (vimalsharma via sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/aad34ae00fb0d39d292dff9743fce1ceb3eaa270",
        "file": [
            {
                "patch": "@@ -23,6 +23,7 @@ ATLAS-409 Atlas will not import avro tables with schema read from a file (dosset\n ATLAS-379 Create sqoop and falcon metadata addons (venkatnrangan,bvellanki,sowmyaramesh via shwethags)\n \n ALL CHANGES:\n+ATLAS-888 NPE in NotificationHookConsumer (sumasai via shwethags)\n ATLAS-884 Process registration should call Entity update instead of create (sumasai)\n ATLAS-515 Ability to initialize Kafka topics with more than 1 replica (yhemanth)\n ATLAS-891 UI changes to implement Update term (Kalyanikashikar via yhemanth)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "0f384d29d06b6a49788aee9de1bf08040fbe3978",
                "blob_url": "https://github.com/apache/atlas/blob/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=aad34ae00fb0d39d292dff9743fce1ceb3eaa270"
            },
            {
                "patch": "@@ -241,6 +241,11 @@\n             <artifactId>commons-io</artifactId>\n         </dependency>\n \n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n         <dependency>\n                 <groupId>org.springframework</groupId>\n                 <artifactId>spring-core</artifactId>",
                "additions": 5,
                "raw_url": "https://github.com/apache/atlas/raw/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/pom.xml",
                "status": "modified",
                "changes": 5,
                "deletions": 0,
                "sha": "bc62f874e3c58a6f40592e8c1a44305ac2043c8e",
                "blob_url": "https://github.com/apache/atlas/blob/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/pom.xml",
                "filename": "webapp/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/pom.xml?ref=aad34ae00fb0d39d292dff9743fce1ceb3eaa270"
            },
            {
                "patch": "@@ -18,8 +18,10 @@\n \n package org.apache.atlas.web.resources;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import org.apache.atlas.AtlasClient;\n+import org.apache.atlas.AtlasConstants;\n import org.apache.atlas.AtlasException;\n import org.apache.atlas.EntityAuditEvent;\n import org.apache.atlas.services.MetadataService;\n@@ -33,6 +35,7 @@\n import org.apache.atlas.utils.ParamChecker;\n import org.apache.atlas.web.util.Servlets;\n import org.apache.commons.lang.StringUtils;\n+import org.apache.http.protocol.HTTP;\n import org.codehaus.jettison.json.JSONArray;\n import org.codehaus.jettison.json.JSONException;\n import org.codehaus.jettison.json.JSONObject;\n@@ -59,6 +62,7 @@\n import javax.ws.rs.core.UriBuilder;\n import javax.ws.rs.core.UriInfo;\n import java.net.URI;\n+import java.util.ArrayList;\n import java.util.Collection;\n import java.util.List;\n \n@@ -119,16 +123,15 @@ public Response submit(@Context HttpServletRequest request) {\n             final List<String> guids = metadataService.createEntities(entities);\n             JSONObject response = getResponse(new AtlasClient.EntityResult(guids, null, null));\n \n-            UriBuilder ub = uriInfo.getAbsolutePathBuilder();\n-            URI locationURI = guids.isEmpty() ? null : ub.path(guids.get(0)).build();\n+            URI locationURI = getLocationURI(guids);\n \n             return Response.created(locationURI).entity(response).build();\n \n         } catch(EntityExistsException e) {\n             LOG.error(\"Unique constraint violation\", e);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.CONFLICT));\n         } catch (ValueConversionException ve) {\n-            LOG.error(\"Unable to persist entity instance due to a desrialization error \", ve);\n+            LOG.error(\"Unable to persist entity instance due to a deserialization error \", ve);\n             throw new WebApplicationException(Servlets.getErrorResponse(ve.getCause(), Response.Status.BAD_REQUEST));\n         } catch (AtlasException | IllegalArgumentException e) {\n             LOG.error(\"Unable to persist entity instance\", e);\n@@ -139,6 +142,23 @@ public Response submit(@Context HttpServletRequest request) {\n         }\n     }\n \n+\n+    @VisibleForTesting\n+    public URI getLocationURI(List<String> guids) {\n+        URI locationURI = null;\n+        if (uriInfo != null) {\n+            UriBuilder ub = uriInfo.getAbsolutePathBuilder();\n+            locationURI = guids.isEmpty() ? null : ub.path(guids.get(0)).build();\n+        } else {\n+            String uriPath = AtlasClient.API.GET_ENTITY.getPath();\n+            locationURI = guids.isEmpty() ? null : UriBuilder\n+                .fromPath(AtlasConstants.DEFAULT_ATLAS_REST_ADDRESS)\n+                .path(uriPath).path(guids.get(0)).build();\n+\n+        }\n+        return locationURI;\n+    }\n+\n     private JSONObject getResponse(AtlasClient.EntityResult entityResult) throws AtlasException, JSONException {\n         JSONObject response = new JSONObject();\n         response.put(AtlasClient.REQUEST_ID, Servlets.getRequestId());\n@@ -171,7 +191,7 @@ public Response updateEntities(@Context HttpServletRequest request) {\n             LOG.error(\"Unique constraint violation\", e);\n             throw new WebApplicationException(Servlets.getErrorResponse(e, Response.Status.CONFLICT));\n         } catch (ValueConversionException ve) {\n-            LOG.error(\"Unable to persist entity instance due to a desrialization error \", ve);\n+            LOG.error(\"Unable to persist entity instance due to a deserialization error \", ve);\n             throw new WebApplicationException(Servlets.getErrorResponse(ve.getCause(), Response.Status.BAD_REQUEST));\n         } catch (AtlasException | IllegalArgumentException e) {\n             LOG.error(\"Unable to persist entity instance\", e);\n@@ -234,7 +254,7 @@ public Response updateByUniqueAttribute(@QueryParam(\"type\") String entityType,\n             JSONObject response = getResponse(entityResult);\n             return Response.ok(response).build();\n         } catch (ValueConversionException ve) {\n-            LOG.error(\"Unable to persist entity instance due to a desrialization error \", ve);\n+            LOG.error(\"Unable to persist entity instance due to a deserialization error \", ve);\n             throw new WebApplicationException(Servlets.getErrorResponse(ve.getCause(), Response.Status.BAD_REQUEST));\n         } catch(EntityExistsException e) {\n             LOG.error(\"Unique constraint violation\", e);\n@@ -549,8 +569,9 @@ public Response addTrait(@Context HttpServletRequest request, @PathParam(\"guid\")\n             LOG.debug(\"Adding trait={} for entity={} \", traitDefinition, guid);\n             metadataService.addTrait(guid, traitDefinition);\n \n-            UriBuilder ub = uriInfo.getAbsolutePathBuilder();\n-            URI locationURI = ub.path(guid).build();\n+            URI locationURI = getLocationURI(new ArrayList<String>() {{\n+                add(guid);\n+            }});\n \n             JSONObject response = new JSONObject();\n             response.put(AtlasClient.REQUEST_ID, Servlets.getRequestId());",
                "additions": 28,
                "raw_url": "https://github.com/apache/atlas/raw/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/src/main/java/org/apache/atlas/web/resources/EntityResource.java",
                "status": "modified",
                "changes": 35,
                "deletions": 7,
                "sha": "364f17a621dbaaba3765bd48b068558315592d86",
                "blob_url": "https://github.com/apache/atlas/blob/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/src/main/java/org/apache/atlas/web/resources/EntityResource.java",
                "filename": "webapp/src/main/java/org/apache/atlas/web/resources/EntityResource.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/main/java/org/apache/atlas/web/resources/EntityResource.java?ref=aad34ae00fb0d39d292dff9743fce1ceb3eaa270"
            },
            {
                "patch": "@@ -18,6 +18,7 @@\n \n package org.apache.atlas;\n \n+import com.google.inject.Inject;\n import com.sun.jersey.api.client.ClientResponse;\n import org.apache.atlas.typesystem.Referenceable;\n import org.apache.atlas.web.resources.EntityResource;\n@@ -27,11 +28,14 @@\n import org.mockito.Mock;\n import org.mockito.MockitoAnnotations;\n import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n import org.testng.annotations.Test;\n \n import javax.servlet.http.HttpServletRequest;\n import javax.ws.rs.WebApplicationException;\n import javax.ws.rs.core.Response;\n+import java.net.URI;\n+import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.List;\n \n@@ -46,8 +50,12 @@\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n \n+@Guice(modules= RepositoryMetadataModule.class)\n public class LocalAtlasClientTest {\n     @Mock\n+    private EntityResource mockEntityResource;\n+\n+    @Inject\n     private EntityResource entityResource;\n \n     @Mock\n@@ -61,25 +69,25 @@ public void setup() {\n     @Test\n     public void testCreateEntity() throws Exception {\n         Response response = mock(Response.class);\n-        when(entityResource.submit(any(HttpServletRequest.class))).thenReturn(response);\n+        when(mockEntityResource.submit(any(HttpServletRequest.class))).thenReturn(response);\n         final String guid = random();\n         when(response.getEntity()).thenReturn(new JSONObject() {{\n             put(ENTITIES, new JSONObject(\n                     new AtlasClient.EntityResult(Arrays.asList(guid), null, null).toString()).get(ENTITIES));\n         }});\n \n-        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, entityResource);\n+        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, mockEntityResource);\n         List<String> results = atlasClient.createEntity(new Referenceable(random()));\n         assertEquals(results.size(), 1);\n         assertEquals(results.get(0), guid);\n     }\n \n     @Test\n     public void testException() throws Exception {\n-        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, entityResource);\n+        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, mockEntityResource);\n \n         Response response = mock(Response.class);\n-        when(entityResource.submit(any(HttpServletRequest.class))).thenThrow(new WebApplicationException(response));\n+        when(mockEntityResource.submit(any(HttpServletRequest.class))).thenThrow(new WebApplicationException(response));\n         when(response.getEntity()).thenReturn(new JSONObject() {{\n             put(\"stackTrace\", \"stackTrace\");\n         }});\n@@ -91,7 +99,7 @@ public void testException() throws Exception {\n             assertEquals(e.getStatus(), ClientResponse.Status.BAD_REQUEST);\n         }\n \n-        when(entityResource.updateByUniqueAttribute(anyString(), anyString(), anyString(),\n+        when(mockEntityResource.updateByUniqueAttribute(anyString(), anyString(), anyString(),\n                 any(HttpServletRequest.class))).thenThrow(new WebApplicationException(response));\n         when(response.getStatus()).thenReturn(Response.Status.NOT_FOUND.getStatusCode());\n         try {\n@@ -106,7 +114,7 @@ public void testException() throws Exception {\n     @Test\n     public void testIsServerReady() throws Exception {\n         when(serviceState.getState()).thenReturn(ServiceState.ServiceStateValue.ACTIVE);\n-        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, entityResource);\n+        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, mockEntityResource);\n         assertTrue(atlasClient.isServerReady());\n \n         when(serviceState.getState()).thenReturn(ServiceState.ServiceStateValue.BECOMING_ACTIVE);\n@@ -117,14 +125,14 @@ public void testIsServerReady() throws Exception {\n     public void testUpdateEntity() throws Exception {\n         final String guid = random();\n         Response response = mock(Response.class);\n-        when(entityResource.updateByUniqueAttribute(anyString(), anyString(), anyString(),\n+        when(mockEntityResource.updateByUniqueAttribute(anyString(), anyString(), anyString(),\n                 any(HttpServletRequest.class))).thenReturn(response);\n         when(response.getEntity()).thenReturn(new JSONObject() {{\n             put(ENTITIES, new JSONObject(\n                     new AtlasClient.EntityResult(null, Arrays.asList(guid), null).toString()).get(ENTITIES));\n         }});\n \n-        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, entityResource);\n+        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, mockEntityResource);\n         AtlasClient.EntityResult\n                 entityResult = atlasClient.updateEntity(random(), random(), random(), new Referenceable(random()));\n         assertEquals(entityResult.getUpdateEntities(), Arrays.asList(guid));\n@@ -139,13 +147,21 @@ public void testDeleteEntity() throws Exception {\n                     new AtlasClient.EntityResult(null, null, Arrays.asList(guid)).toString()).get(ENTITIES));\n         }});\n \n-        when(entityResource.deleteEntities(anyListOf(String.class), anyString(), anyString(), anyString())).thenReturn(response);\n-        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, entityResource);\n+        when(mockEntityResource.deleteEntities(anyListOf(String.class), anyString(), anyString(), anyString())).thenReturn(response);\n+        LocalAtlasClient atlasClient = new LocalAtlasClient(serviceState, mockEntityResource);\n         AtlasClient.EntityResult entityResult = atlasClient.deleteEntity(random(), random(), random());\n         assertEquals(entityResult.getDeletedEntities(), Arrays.asList(guid));\n     }\n \n     private String random() {\n         return RandomStringUtils.randomAlphanumeric(10);\n     }\n+\n+    @Test\n+    @Inject\n+    public void testGetLocationURI() {\n+        final String guid = \"123\";\n+        URI uri = entityResource.getLocationURI(new ArrayList<String>() {{ add(guid); }});\n+        uri.getRawPath().equals(AtlasConstants.DEFAULT_ATLAS_REST_ADDRESS + \"/\" + AtlasClient.API.GET_ENTITY.getPath() + \"/\" + guid);\n+    }\n }",
                "additions": 26,
                "raw_url": "https://github.com/apache/atlas/raw/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/src/test/java/org/apache/atlas/LocalAtlasClientTest.java",
                "status": "modified",
                "changes": 36,
                "deletions": 10,
                "sha": "c5616dfe29071c1b2c8ce823100e6a69244066df",
                "blob_url": "https://github.com/apache/atlas/blob/aad34ae00fb0d39d292dff9743fce1ceb3eaa270/webapp/src/test/java/org/apache/atlas/LocalAtlasClientTest.java",
                "filename": "webapp/src/test/java/org/apache/atlas/LocalAtlasClientTest.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/webapp/src/test/java/org/apache/atlas/LocalAtlasClientTest.java?ref=aad34ae00fb0d39d292dff9743fce1ceb3eaa270"
            }
        ],
        "bug_id": "atlas_27",
        "parent": "https://github.com/apache/atlas/commit/8fefd165586f5fd8acd5c3a5786d6012dda68a5b",
        "message": "ATLAS-888 NPE in NotificationHookConsumer (sumasai via shwethags)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/29880e77c953cf4ddc8e9733b5d71c6dd75a328c",
        "file": [
            {
                "patch": "@@ -9,6 +9,7 @@ ATLAS-1060 Add composite indexes for exact match performance improvements for al\n ATLAS-1127 Modify creation and modification timestamps to Date instead of Long(sumasai)\n \n ALL CHANGES:\n+ATLAS-1258 BugFix for Indexer NPE on StructDef lookup (apoorvnaik via sumasai)\n ATLAS-1233 UnitTests for the TypeDefStores (apoorvnaik via sumasai)\n ATLAS-1240 Adding Change listeners to react on changes in TypesDef (apoorvnaik via sumasai)\n ATLAS-1239 when stopping Atlas on the command line it should explicitly say when it has stopped (ayubkhan via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/29880e77c953cf4ddc8e9733b5d71c6dd75a328c/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "e44d8efb197dcd3a95d66dfe4ad70831941845f0",
                "blob_url": "https://github.com/apache/atlas/blob/29880e77c953cf4ddc8e9733b5d71c6dd75a328c/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=29880e77c953cf4ddc8e9733b5d71c6dd75a328c"
            },
            {
                "patch": "@@ -280,17 +280,11 @@ private void createIndexForAttribute(AtlasGraphManagement management, String typ\n \n             if (isMapType || isArrayType || isClassificationType(atlasType) || isEntityType(atlasType)) {\n                 LOG.warn(\"Ignoring non-indexable attribute {}\", attribTypeName);\n-            }\n-\n-            if (isBuiltInType) {\n+            } else if (isBuiltInType) {\n                 createIndexes(management, propertyName, getPrimitiveClass(attribTypeName), isUnique, cardinality, false, isIndexable);\n-            }\n-\n-            if (isEnumType(atlasType)) {\n+            } else if (isEnumType(atlasType)) {\n                 createIndexes(management, propertyName, String.class, isUnique, cardinality, false, isIndexable);\n-            }\n-\n-            if (isStructType(atlasType)) {\n+            } else if (isStructType(atlasType)) {\n                 AtlasStructDef structDef = typeRegistry.getStructDefByName(attributeDef.getName());\n                 updateIndexForTypeDef(management, structDef);\n             }",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/29880e77c953cf4ddc8e9733b5d71c6dd75a328c/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "status": "modified",
                "changes": 12,
                "deletions": 9,
                "sha": "3c7f63bbf244d3e4a38ad6eca9f73d65293e5cb3",
                "blob_url": "https://github.com/apache/atlas/blob/29880e77c953cf4ddc8e9733b5d71c6dd75a328c/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "filename": "repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/atlas/repository/graph/GraphBackedSearchIndexer.java?ref=29880e77c953cf4ddc8e9733b5d71c6dd75a328c"
            }
        ],
        "bug_id": "atlas_28",
        "parent": "https://github.com/apache/atlas/commit/c9e58e0aa31fa833981a8c069e23a4ca3e07b293",
        "message": "ATLAS-1258 BugFix for Indexer NPE on StructDef lookup (apoorvnaik via sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/6fddccd6a28d7cf194926c3d44debeb1b49cd434",
        "file": [
            {
                "patch": "@@ -36,6 +36,7 @@\n  * A storm topology utility class.\n  */\n public final class StormTopologyUtil {\n+    public static final Logger LOG = org.slf4j.LoggerFactory.getLogger(StormTopologyUtil.class);\n \n     private StormTopologyUtil() {\n     }\n@@ -136,74 +137,79 @@ public static boolean isMapType(Class clazz) {\n \n         Map<String, String> output = new HashMap<>();\n \n-        if (objectsToSkip.add(instance)) {\n-            Class clazz = instance.getClass();\n-            for (Class<?> c = clazz; c != null; c = c.getSuperclass()) {\n-                Field[] fields = c.getDeclaredFields();\n-                for (Field field : fields) {\n-                    if (java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n-                        continue;\n-                    }\n-\n-                    String key;\n-                    if (prependClassName) {\n-                        key = String.format(\"%s.%s\", clazz.getSimpleName(), field.getName());\n-                    } else {\n-                        key = field.getName();\n-                    }\n+        try {\n+            if (objectsToSkip.add(instance)) {\n+                Class clazz = instance.getClass();\n+                for (Class<?> c = clazz; c != null; c = c.getSuperclass()) {\n+                    Field[] fields = c.getDeclaredFields();\n+                    for (Field field : fields) {\n+                        if (java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n+                            continue;\n+                        }\n \n-                    boolean accessible = field.isAccessible();\n-                    if (!accessible) {\n-                        field.setAccessible(true);\n-                    }\n-                    Object fieldVal = field.get(instance);\n-                    if (fieldVal == null) {\n-                        continue;\n-                    } else if (fieldVal.getClass().isPrimitive() ||\n-                            isWrapperType(fieldVal.getClass())) {\n-                        if (toString(fieldVal, false).isEmpty()) continue;\n-                        output.put(key, toString(fieldVal, false));\n-                    } else if (isMapType(fieldVal.getClass())) {\n-                        //TODO: check if it makes more sense to just stick to json\n-                        // like structure instead of a flatten output.\n-                        Map map = (Map) fieldVal;\n-                        for (Object entry : map.entrySet()) {\n-                            Object mapKey = ((Map.Entry) entry).getKey();\n-                            Object mapVal = ((Map.Entry) entry).getValue();\n-\n-                            String keyStr = getString(mapKey, false, objectsToSkip);\n-                            String valStr = getString(mapVal, false, objectsToSkip);\n-                            if ((valStr == null) || (valStr.isEmpty())) {\n-                                continue;\n-                            } else {\n-                                output.put(String.format(\"%s.%s\", key, keyStr), valStr);\n-                            }\n+                        String key;\n+                        if (prependClassName) {\n+                            key = String.format(\"%s.%s\", clazz.getSimpleName(), field.getName());\n+                        } else {\n+                            key = field.getName();\n                         }\n-                    } else if (isCollectionType(fieldVal.getClass())) {\n-                        //TODO check if it makes more sense to just stick to\n-                        // json like structure instead of a flatten output.\n-                        Collection collection = (Collection) fieldVal;\n-                        if (collection.size() == 0) continue;\n-                        String outStr = \"\";\n-                        for (Object o : collection) {\n-                            outStr += getString(o, false, objectsToSkip) + \",\";\n+\n+                        boolean accessible = field.isAccessible();\n+                        if (!accessible) {\n+                            field.setAccessible(true);\n                         }\n-                        if (outStr.length() > 0) {\n-                            outStr = outStr.substring(0, outStr.length() - 1);\n+                        Object fieldVal = field.get(instance);\n+                        if (fieldVal == null) {\n+                            continue;\n+                        } else if (fieldVal.getClass().isPrimitive() ||\n+                                isWrapperType(fieldVal.getClass())) {\n+                            if (toString(fieldVal, false).isEmpty()) continue;\n+                            output.put(key, toString(fieldVal, false));\n+                        } else if (isMapType(fieldVal.getClass())) {\n+                            //TODO: check if it makes more sense to just stick to json\n+                            // like structure instead of a flatten output.\n+                            Map map = (Map) fieldVal;\n+                            for (Object entry : map.entrySet()) {\n+                                Object mapKey = ((Map.Entry) entry).getKey();\n+                                Object mapVal = ((Map.Entry) entry).getValue();\n+\n+                                String keyStr = getString(mapKey, false, objectsToSkip);\n+                                String valStr = getString(mapVal, false, objectsToSkip);\n+                                if ((valStr == null) || (valStr.isEmpty())) {\n+                                    continue;\n+                                } else {\n+                                    output.put(String.format(\"%s.%s\", key, keyStr), valStr);\n+                                }\n+                            }\n+                        } else if (isCollectionType(fieldVal.getClass())) {\n+                            //TODO check if it makes more sense to just stick to\n+                            // json like structure instead of a flatten output.\n+                            Collection collection = (Collection) fieldVal;\n+                            if (collection.size() == 0) continue;\n+                            String outStr = \"\";\n+                            for (Object o : collection) {\n+                                outStr += getString(o, false, objectsToSkip) + \",\";\n+                            }\n+                            if (outStr.length() > 0) {\n+                                outStr = outStr.substring(0, outStr.length() - 1);\n+                            }\n+                            output.put(key, String.format(\"%s\", outStr));\n+                        } else {\n+                            Map<String, String> nestedFieldValues = getFieldValues(fieldVal, false, objectsToSkip);\n+                            for (Map.Entry<String, String> entry : nestedFieldValues.entrySet()) {\n+                                output.put(String.format(\"%s.%s\", key, entry.getKey()), entry.getValue());\n+                            }\n                         }\n-                        output.put(key, String.format(\"%s\", outStr));\n-                    } else {\n-                        Map<String, String> nestedFieldValues = getFieldValues(fieldVal, false, objectsToSkip);\n-                        for (Map.Entry<String, String> entry : nestedFieldValues.entrySet()) {\n-                            output.put(String.format(\"%s.%s\", key, entry.getKey()), entry.getValue());\n+                        if (!accessible) {\n+                            field.setAccessible(false);\n                         }\n                     }\n-                    if (!accessible) {\n-                        field.setAccessible(false);\n-                    }\n                 }\n             }\n         }\n+        catch (Exception e){\n+            LOG.warn(\"Exception while constructing topology\", e);\n+        }\n         return output;\n     }\n ",
                "additions": 65,
                "raw_url": "https://github.com/apache/atlas/raw/6fddccd6a28d7cf194926c3d44debeb1b49cd434/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormTopologyUtil.java",
                "status": "modified",
                "changes": 124,
                "deletions": 59,
                "sha": "edd95ba4c31a7c32b00ed0e32f037540f88d7078",
                "blob_url": "https://github.com/apache/atlas/blob/6fddccd6a28d7cf194926c3d44debeb1b49cd434/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormTopologyUtil.java",
                "filename": "addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormTopologyUtil.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/storm-bridge/src/main/java/org/apache/atlas/storm/hook/StormTopologyUtil.java?ref=6fddccd6a28d7cf194926c3d44debeb1b49cd434"
            },
            {
                "patch": "@@ -6,6 +6,7 @@ INCOMPATIBLE CHANGES:\n ATLAS-1060 Add composite indexes for exact match performance improvements for all attributes (sumasai via shwethags)\n \n ALL CHANGES:\n+ATLAS-1121 NPE while submitting topology in StormHook (ayubkhan via sumasai)\n ATLAS-1119 Add retries for edge label creation (sumasai via shwethags)\n ATLAS-1111 Data loss is observed when atlas is restarted while hive_table metadata ingestion into kafka topic is in-progress(shwethags via sumasai)\n ATLAS-1115 Show Tag / Taxonomy Listing in sorted order (Kalyanikashikar via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/6fddccd6a28d7cf194926c3d44debeb1b49cd434/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "13f00e3d684536474fe985f136a5b78a078805b6",
                "blob_url": "https://github.com/apache/atlas/blob/6fddccd6a28d7cf194926c3d44debeb1b49cd434/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=6fddccd6a28d7cf194926c3d44debeb1b49cd434"
            }
        ],
        "bug_id": "atlas_29",
        "parent": "https://github.com/apache/atlas/commit/ab95c1a7bbf1209c22aaf661a69bd007c5277bc8",
        "message": "ATLAS-1121 NPE while submitting topology in StormHook (ayubkhan via sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/89f25d411897dbd35a2baf7a96a0cf137c273f4a",
        "file": [
            {
                "patch": "@@ -773,10 +773,14 @@ static String getProcessQualifiedName(HiveMetaStoreBridge dgiBridge, HiveEventCo\n                                           SortedMap<WriteEntity, Referenceable> hiveOutputsMap) throws HiveException {\n         HiveOperation op = eventContext.getOperation();\n         if (isCreateOp(eventContext)) {\n-            Table outTable = getEntityByType(sortedHiveOutputs, Type.TABLE).getTable();\n-            //refresh table\n-            outTable = dgiBridge.hiveClient.getTable(outTable.getDbName(), outTable.getTableName());\n-            return HiveMetaStoreBridge.getTableProcessQualifiedName(dgiBridge.getClusterName(), outTable);\n+            Entity entity = getEntityByType(sortedHiveOutputs, Type.TABLE);\n+\n+            if (entity != null) {\n+                Table outTable = entity.getTable();\n+                //refresh table\n+                outTable = dgiBridge.hiveClient.getTable(outTable.getDbName(), outTable.getTableName());\n+                return HiveMetaStoreBridge.getTableProcessQualifiedName(dgiBridge.getClusterName(), outTable);\n+            }\n         }\n \n         StringBuilder buffer = new StringBuilder(op.getOperationName());",
                "additions": 8,
                "raw_url": "https://github.com/apache/atlas/raw/89f25d411897dbd35a2baf7a96a0cf137c273f4a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "status": "modified",
                "changes": 12,
                "deletions": 4,
                "sha": "14359c57c990a5b7ec64b92b9f25e688996593a8",
                "blob_url": "https://github.com/apache/atlas/blob/89f25d411897dbd35a2baf7a96a0cf137c273f4a/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java?ref=89f25d411897dbd35a2baf7a96a0cf137c273f4a"
            },
            {
                "patch": "@@ -6,6 +6,7 @@ INCOMPATIBLE CHANGES:\n \n \n ALL CHANGES:\n+ATLAS-1097 Fix a potential NPE issue flagged by Coverity scan (mneethiraj via shwethags)\n ATLAS-1090 UI: Multi-Select Tagging. (Kalyanikashikar via kevalbhatt)\n ATLAS-1092 Add Table.CreateTime to process qualified Name for all hive_process (sumasai via shwethags)\n ATLAS-1096 Modify HveMetaStoreBridge.import to use getEntity instead of DSL (sumasai via shwethags)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/89f25d411897dbd35a2baf7a96a0cf137c273f4a/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "f6daa1cc57162966c7a17b23841c16022dcf50d6",
                "blob_url": "https://github.com/apache/atlas/blob/89f25d411897dbd35a2baf7a96a0cf137c273f4a/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=89f25d411897dbd35a2baf7a96a0cf137c273f4a"
            }
        ],
        "bug_id": "atlas_30",
        "parent": "https://github.com/apache/atlas/commit/d671b12768b19d9d2b4e84c3528db1bec43388de",
        "message": "ATLAS-1097 Fix a potential NPE issue flagged by Coverity scan (mneethiraj via shwethags)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/d0a9b99999a8d51a6612da62d025fbb48c471bc6",
        "file": [
            {
                "patch": "@@ -123,7 +123,10 @@ private void importDatabases(boolean failOnError) throws Exception {\n         List<String> databases = hiveClient.getAllDatabases();\n         for (String databaseName : databases) {\n             Referenceable dbReference = registerDatabase(databaseName);\n-            importTables(dbReference, databaseName, failOnError);\n+\n+            if (dbReference != null) {\n+                importTables(dbReference, databaseName, failOnError);\n+            }\n         }\n     }\n \n@@ -146,13 +149,16 @@ public Referenceable createDBInstance(Database hiveDB) throws HiveException {\n     private Referenceable registerDatabase(String databaseName) throws Exception {\n         Referenceable dbRef = getDatabaseReference(clusterName, databaseName);\n         Database db = hiveClient.getDatabase(databaseName);\n-        if (dbRef == null) {\n-            dbRef = createDBInstance(db);\n-            dbRef = registerInstance(dbRef);\n-        } else {\n-            LOG.info(\"Database {} is already registered with id {}. Updating it.\", databaseName, dbRef.getId().id);\n-            dbRef = createOrUpdateDBInstance(db, dbRef);\n-            updateInstance(dbRef);\n+\n+        if (db != null) {\n+            if (dbRef == null) {\n+                dbRef = createDBInstance(db);\n+                dbRef = registerInstance(dbRef);\n+            } else {\n+                LOG.info(\"Database {} is already registered with id {}. Updating it.\", databaseName, dbRef.getId().id);\n+                dbRef = createOrUpdateDBInstance(db, dbRef);\n+                updateInstance(dbRef);\n+            }\n         }\n         return dbRef;\n     }",
                "additions": 14,
                "raw_url": "https://github.com/apache/atlas/raw/d0a9b99999a8d51a6612da62d025fbb48c471bc6/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "status": "modified",
                "changes": 22,
                "deletions": 8,
                "sha": "e0d802441eeaf35757fc8b5b5dc3e1a5f5129233",
                "blob_url": "https://github.com/apache/atlas/blob/d0a9b99999a8d51a6612da62d025fbb48c471bc6/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java?ref=d0a9b99999a8d51a6612da62d025fbb48c471bc6"
            },
            {
                "patch": "@@ -499,6 +499,9 @@ private Referenceable replaceSDQFName(final HiveEventContext event, Referenceabl\n \n         if (db != null) {\n             db = dgiBridge.hiveClient.getDatabase(db.getName());\n+        }\n+\n+        if (db != null) {\n             Referenceable dbEntity = dgiBridge.createDBInstance(db);\n \n             entities.add(dbEntity);",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/d0a9b99999a8d51a6612da62d025fbb48c471bc6/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "status": "modified",
                "changes": 3,
                "deletions": 0,
                "sha": "e27e52c352b9dd488443b4aa914daf6de89e393d",
                "blob_url": "https://github.com/apache/atlas/blob/d0a9b99999a8d51a6612da62d025fbb48c471bc6/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/hook/HiveHook.java?ref=d0a9b99999a8d51a6612da62d025fbb48c471bc6"
            },
            {
                "patch": "@@ -6,6 +6,7 @@ INCOMPATIBLE CHANGES:\n \n \n ALL CHANGES:\n+ATLAS-1053 Fix issues flagged by Coverity scan - potential NPE (mneethiraj via sumasai)\n ATLAS-1052 Fix NPE in HiveHook due to null Session State (sumasai)\n ATLAS-1051 Sqoop Hook does not package HDFS model jars which is required (sumasai)\n ATLAS-1049 List types by supertype (shwethags via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/d0a9b99999a8d51a6612da62d025fbb48c471bc6/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "c3ab28b0e4d1effd24ec168fa3fbcd6c36bad70e",
                "blob_url": "https://github.com/apache/atlas/blob/d0a9b99999a8d51a6612da62d025fbb48c471bc6/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=d0a9b99999a8d51a6612da62d025fbb48c471bc6"
            }
        ],
        "bug_id": "atlas_31",
        "parent": "https://github.com/apache/atlas/commit/56e97e225e65b50d15e6f59211f796788dd97446",
        "message": "ATLAS-1053: Fix for issues flagged by Coverity scan - potential NPE",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/56e97e225e65b50d15e6f59211f796788dd97446",
        "file": [
            {
                "patch": "@@ -362,7 +362,7 @@ static String getTableDSLQuery(String clusterName, String dbName, String tableNa\n     public static String getTableQualifiedName(String clusterName, String dbName, String tableName, boolean isTemporaryTable) {\n         String tableTempName = tableName;\n         if (isTemporaryTable) {\n-            if (SessionState.get().getSessionId() != null) {\n+            if (SessionState.get() != null && SessionState.get().getSessionId() != null) {\n                 tableTempName = tableName + TEMP_TABLE_PREFIX + SessionState.get().getSessionId();\n             } else {\n                 tableTempName = tableName + TEMP_TABLE_PREFIX + RandomStringUtils.random(10);",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/56e97e225e65b50d15e6f59211f796788dd97446/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "status": "modified",
                "changes": 2,
                "deletions": 1,
                "sha": "fcc45ab0314ff881f68359f74511882f1e08b596",
                "blob_url": "https://github.com/apache/atlas/blob/56e97e225e65b50d15e6f59211f796788dd97446/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "filename": "addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.java?ref=56e97e225e65b50d15e6f59211f796788dd97446"
            },
            {
                "patch": "@@ -6,6 +6,7 @@ INCOMPATIBLE CHANGES:\n \n \n ALL CHANGES:\n+ATLAS-1052 Fix NPE in HiveHook due to null Session State (sumasai)\n ATLAS-1051 Sqoop Hook does not package HDFS model jars which is required (sumasai)\n ATLAS-1049 List types by supertype (shwethags via sumasai)\n ATLAS-1032 Atlas hook package should not include libraries already present in host component - like log4j(mneethiraj via sumasai)",
                "additions": 1,
                "raw_url": "https://github.com/apache/atlas/raw/56e97e225e65b50d15e6f59211f796788dd97446/release-log.txt",
                "status": "modified",
                "changes": 1,
                "deletions": 0,
                "sha": "334a1c5394292ee16a2487b32c653cd82fa55c38",
                "blob_url": "https://github.com/apache/atlas/blob/56e97e225e65b50d15e6f59211f796788dd97446/release-log.txt",
                "filename": "release-log.txt",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/release-log.txt?ref=56e97e225e65b50d15e6f59211f796788dd97446"
            }
        ],
        "bug_id": "atlas_32",
        "parent": "https://github.com/apache/atlas/commit/46ec799cc53af51806722e2e7ad7d5ef61e02df6",
        "message": "ATLAS-1052 Fix NPE in HiveHook due to null Session State (sumasai)",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/93f34483973e5b8cf7b0eb08852c2f69eb3f1da6",
        "file": [
            {
                "patch": "@@ -53,6 +53,7 @@\n \n import javax.inject.Inject;\n import javax.inject.Singleton;\n+import java.util.HashMap;\n import java.util.LinkedHashSet;\n import java.util.List;\n import java.util.Map;\n@@ -83,8 +84,8 @@\n         this.typeSystem = TypeSystem.getInstance();\n         this.repository = repository;\n \n-        restoreTypeSystem();\n         registerListener(searchIndexer);\n+        restoreTypeSystem();\n     }\n \n     private void restoreTypeSystem() {\n@@ -113,17 +114,18 @@ private void createSuperTypes() throws MetadataException {\n             return; // this is already registered\n         }\n \n+        Map<String, IDataType> superTypes = new HashMap();\n         HierarchicalTypeDefinition<ClassType> superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.INFRASTRUCTURE_SUPER_TYPE,\n-                        ImmutableList.<String>of(),\n-                        NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n-        typeSystem.defineClassType(superTypeDefinition);\n+                        ImmutableList.<String>of(), NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n+        superTypes.put(MetadataServiceClient.INFRASTRUCTURE_SUPER_TYPE, typeSystem.defineClassType\n+                (superTypeDefinition));\n \n         superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.DATA_SET_SUPER_TYPE,\n                         ImmutableList.<String>of(),\n                         NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n-        typeSystem.defineClassType(superTypeDefinition);\n+        superTypes.put(MetadataServiceClient.DATA_SET_SUPER_TYPE, typeSystem.defineClassType(superTypeDefinition));\n \n         superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.PROCESS_SUPER_TYPE,\n@@ -136,7 +138,8 @@ private void createSuperTypes() throws MetadataException {\n                                 DataTypes.arrayTypeName(MetadataServiceClient.DATA_SET_SUPER_TYPE),\n                                 new Multiplicity(0, Integer.MAX_VALUE, false), false, null)\n                 );\n-        typeSystem.defineClassType(superTypeDefinition);\n+        superTypes.put(MetadataServiceClient.PROCESS_SUPER_TYPE, typeSystem.defineClassType(superTypeDefinition));\n+        onTypesAddedToRepo(superTypes);\n     }\n \n     /**",
                "additions": 9,
                "raw_url": "https://github.com/apache/atlas/raw/93f34483973e5b8cf7b0eb08852c2f69eb3f1da6/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "status": "modified",
                "changes": 15,
                "deletions": 6,
                "sha": "6272cce6d7c55893a586bfc6adeba4400b8acd2a",
                "blob_url": "https://github.com/apache/atlas/blob/93f34483973e5b8cf7b0eb08852c2f69eb3f1da6/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "filename": "repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java?ref=93f34483973e5b8cf7b0eb08852c2f69eb3f1da6"
            },
            {
                "patch": "@@ -70,7 +70,7 @@\n         this.fieldMapping = null;\n         this.numFields = numFields;\n         this.superTypes = superTypes;\n-        this.immediateAttrs = null;\n+        this.immediateAttrs = ImmutableList.of();\n         this.attributeNameToType = null;\n     }\n \n@@ -86,7 +86,7 @@\n         this.attributeNameToType = p.right;\n         this.numFields = this.fieldMapping.fields.size();\n         this.superTypes = superTypes == null ? ImmutableList.<String>of() : superTypes;\n-        this.immediateAttrs = ImmutableList.<AttributeInfo>copyOf(fields);\n+        this.immediateAttrs = ImmutableList.copyOf(fields);\n     }\n \n     @Override\n@@ -184,7 +184,7 @@ private void setupSuperTypesGraph(ImmutableList<String> superTypes)\n                     (ST) typeSystem.getDataType(superTypeClass, currentPath.typeName);\n \n             ImmutableList<AttributeInfo> superTypeFields = superType == this ?\n-                    ImmutableList.<AttributeInfo>copyOf(fields) : superType.immediateAttrs;\n+                    ImmutableList.copyOf(fields) : superType.immediateAttrs;\n \n             Set<String> immediateFields = new HashSet<String>();\n ",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/93f34483973e5b8cf7b0eb08852c2f69eb3f1da6/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "status": "modified",
                "changes": 6,
                "deletions": 3,
                "sha": "7fff80683b374957b5ae69e26c3713c5faaf737b",
                "blob_url": "https://github.com/apache/atlas/blob/93f34483973e5b8cf7b0eb08852c2f69eb3f1da6/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "filename": "typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java?ref=93f34483973e5b8cf7b0eb08852c2f69eb3f1da6"
            }
        ],
        "bug_id": "atlas_33",
        "parent": "https://github.com/apache/atlas/commit/ef2332efec48f8172a4d9c4a632b1033acef28de",
        "message": "BUG-38870 npe during loading of the data in atlas on restart",
        "repo": "atlas"
    },
    {
        "commit": "https://github.com/apache/atlas/commit/ce61caae71a9456d4e48cbc5c151c3b019dd4796",
        "file": [
            {
                "patch": "@@ -53,6 +53,7 @@\n \n import javax.inject.Inject;\n import javax.inject.Singleton;\n+import java.util.HashMap;\n import java.util.LinkedHashSet;\n import java.util.List;\n import java.util.Map;\n@@ -83,8 +84,8 @@\n         this.typeSystem = TypeSystem.getInstance();\n         this.repository = repository;\n \n-        restoreTypeSystem();\n         registerListener(searchIndexer);\n+        restoreTypeSystem();\n     }\n \n     private void restoreTypeSystem() {\n@@ -113,17 +114,18 @@ private void createSuperTypes() throws MetadataException {\n             return; // this is already registered\n         }\n \n+        Map<String, IDataType> superTypes = new HashMap();\n         HierarchicalTypeDefinition<ClassType> superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.INFRASTRUCTURE_SUPER_TYPE,\n-                        ImmutableList.<String>of(),\n-                        NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n-        typeSystem.defineClassType(superTypeDefinition);\n+                        ImmutableList.<String>of(), NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n+        superTypes.put(MetadataServiceClient.INFRASTRUCTURE_SUPER_TYPE, typeSystem.defineClassType\n+                (superTypeDefinition));\n \n         superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.DATA_SET_SUPER_TYPE,\n                         ImmutableList.<String>of(),\n                         NAME_ATTRIBUTE, DESCRIPTION_ATTRIBUTE);\n-        typeSystem.defineClassType(superTypeDefinition);\n+        superTypes.put(MetadataServiceClient.DATA_SET_SUPER_TYPE, typeSystem.defineClassType(superTypeDefinition));\n \n         superTypeDefinition =\n                 TypesUtil.createClassTypeDef(MetadataServiceClient.PROCESS_SUPER_TYPE,\n@@ -136,7 +138,8 @@ private void createSuperTypes() throws MetadataException {\n                                 DataTypes.arrayTypeName(MetadataServiceClient.DATA_SET_SUPER_TYPE),\n                                 new Multiplicity(0, Integer.MAX_VALUE, false), false, null)\n                 );\n-        typeSystem.defineClassType(superTypeDefinition);\n+        superTypes.put(MetadataServiceClient.PROCESS_SUPER_TYPE, typeSystem.defineClassType(superTypeDefinition));\n+        onTypesAddedToRepo(superTypes);\n     }\n \n     /**",
                "additions": 9,
                "raw_url": "https://github.com/apache/atlas/raw/ce61caae71a9456d4e48cbc5c151c3b019dd4796/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "status": "modified",
                "changes": 15,
                "deletions": 6,
                "sha": "6272cce6d7c55893a586bfc6adeba4400b8acd2a",
                "blob_url": "https://github.com/apache/atlas/blob/ce61caae71a9456d4e48cbc5c151c3b019dd4796/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "filename": "repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/repository/src/main/java/org/apache/hadoop/metadata/services/DefaultMetadataService.java?ref=ce61caae71a9456d4e48cbc5c151c3b019dd4796"
            },
            {
                "patch": "@@ -70,7 +70,7 @@\n         this.fieldMapping = null;\n         this.numFields = numFields;\n         this.superTypes = superTypes;\n-        this.immediateAttrs = null;\n+        this.immediateAttrs = ImmutableList.of();\n         this.attributeNameToType = null;\n     }\n \n@@ -86,7 +86,7 @@\n         this.attributeNameToType = p.right;\n         this.numFields = this.fieldMapping.fields.size();\n         this.superTypes = superTypes == null ? ImmutableList.<String>of() : superTypes;\n-        this.immediateAttrs = ImmutableList.<AttributeInfo>copyOf(fields);\n+        this.immediateAttrs = ImmutableList.copyOf(fields);\n     }\n \n     @Override\n@@ -184,7 +184,7 @@ private void setupSuperTypesGraph(ImmutableList<String> superTypes)\n                     (ST) typeSystem.getDataType(superTypeClass, currentPath.typeName);\n \n             ImmutableList<AttributeInfo> superTypeFields = superType == this ?\n-                    ImmutableList.<AttributeInfo>copyOf(fields) : superType.immediateAttrs;\n+                    ImmutableList.copyOf(fields) : superType.immediateAttrs;\n \n             Set<String> immediateFields = new HashSet<String>();\n ",
                "additions": 3,
                "raw_url": "https://github.com/apache/atlas/raw/ce61caae71a9456d4e48cbc5c151c3b019dd4796/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "status": "modified",
                "changes": 6,
                "deletions": 3,
                "sha": "7fff80683b374957b5ae69e26c3713c5faaf737b",
                "blob_url": "https://github.com/apache/atlas/blob/ce61caae71a9456d4e48cbc5c151c3b019dd4796/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "filename": "typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java",
                "contents_url": "https://api.github.com/repos/apache/atlas/contents/typesystem/src/main/java/org/apache/hadoop/metadata/typesystem/types/HierarchicalType.java?ref=ce61caae71a9456d4e48cbc5c151c3b019dd4796"
            }
        ],
        "bug_id": "atlas_34",
        "parent": "https://github.com/apache/atlas/commit/f0682e416947d069e6aa9df70f4dac1a78b95e79",
        "message": "Merge pull request #131 from shwethags/utf8\n\nBUG-38870 npe during loading of the data in atlas on restart",
        "repo": "atlas"
    }
]