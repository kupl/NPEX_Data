[
    {
        "commit": "https://github.com/apache/helix/commit/52cb22282b7c93ed05ee6e582bbb641c2900992f",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/9d440c50d7e4ddb6bf00c8f5d66c5df322e82c53",
        "message": "Fix NullPointerException in TestBatchMessage. (#580)\n\nNullPointerException in TestBatchMessage when currentChildren is null and currentChildren.size() is called.\r\nChangelist:\r\nAdd a null check in handleChildChange().",
        "bug_id": "helix_1",
        "file": [
            {
                "sha": "eac8860cb7fb2e6d67a88ca61f4f3eeabc1cfcb7",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/messaging/TestBatchMessage.java",
                "status": "modified",
                "additions": 11,
                "deletions": 8,
                "changes": 19,
                "blob_url": "https://github.com/apache/helix/blob/52cb22282b7c93ed05ee6e582bbb641c2900992f/helix-core/src/test/java/org/apache/helix/integration/messaging/TestBatchMessage.java",
                "raw_url": "https://github.com/apache/helix/raw/52cb22282b7c93ed05ee6e582bbb641c2900992f/helix-core/src/test/java/org/apache/helix/integration/messaging/TestBatchMessage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/messaging/TestBatchMessage.java?ref=52cb22282b7c93ed05ee6e582bbb641c2900992f",
                "patch": "@@ -45,13 +45,16 @@\n \n public class TestBatchMessage extends ZkTestBase {\n   class TestZkChildListener implements IZkChildListener {\n-    int _maxNbOfChilds = 0;\n+    int _maxNumberOfChildren = 0;\n \n     @Override\n-    public void handleChildChange(String parentPath, List<String> currentChilds) throws Exception {\n-      System.out.println(parentPath + \" has \" + currentChilds.size() + \" messages\");\n-      if (currentChilds.size() > _maxNbOfChilds) {\n-        _maxNbOfChilds = currentChilds.size();\n+    public void handleChildChange(String parentPath, List<String> currentChildren) {\n+      if (currentChildren == null) {\n+        return;\n+      }\n+      System.out.println(parentPath + \" has \" + currentChildren.size() + \" messages\");\n+      if (currentChildren.size() > _maxNumberOfChildren) {\n+        _maxNumberOfChildren = currentChildren.size();\n       }\n     }\n \n@@ -107,7 +110,7 @@ public void testBasic() throws Exception {\n     Assert.assertTrue(result);\n     // Change to three is because there is an extra factory registered\n     // So one extra NO_OP message send\n-    Assert.assertTrue(listener._maxNbOfChilds <= 3,\n+    Assert.assertTrue(listener._maxNumberOfChildren <= 3,\n         \"Should get no more than 2 messages (O->S and S->M)\");\n \n     // clean up\n@@ -190,7 +193,7 @@ public void testChangeBatchMessageMode() throws Exception {\n     Assert.assertTrue(result);\n     // Change to three is because there is an extra factory registered\n     // So one extra NO_OP message send\n-    Assert.assertTrue(listener._maxNbOfChilds <= 3,\n+    Assert.assertTrue(listener._maxNumberOfChildren <= 3,\n         \"Should get no more than 2 messages (O->S and S->M)\");\n \n     // clean up\n@@ -349,7 +352,7 @@ public void testParticipantIncompatibleWithBatchMsg() throws Exception {\n         ClusterStateVerifier.verifyByZkCallback(new BestPossAndExtViewZkVerifier(ZK_ADDR,\n             clusterName));\n     Assert.assertTrue(result);\n-    Assert.assertTrue(listener._maxNbOfChilds > 16,\n+    Assert.assertTrue(listener._maxNumberOfChildren > 16,\n         \"Should see more than 16 messages at the same time (32 O->S and 32 S->M)\");\n \n     // clean up"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/a264841cc2efcf1ffb58a4af6f5c0f60adb123b0",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/88296bc41df1a31131659f7004146f14f94b7da3",
        "message": "Fix NullPointerException and test failure for testDisablePartitionAndStopInstance. (#613)\n\nStrictMatchExternalViewVerifier's toString() has a bug that causes NullPointerException if _resources is null. The code fails to check if _resources is null. And NullPointerException causes testDisablePartitionAndStopInstance's failure.\r\n\r\nFix the bug by checking if _resources is null in StrictMatchExternalViewVerifier's toString().",
        "bug_id": "helix_2",
        "file": [
            {
                "sha": "13cc260a12b84fb5f468e2f5af8927d05efe8eee",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterVerifiers/StrictMatchExternalViewVerifier.java",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/a264841cc2efcf1ffb58a4af6f5c0f60adb123b0/helix-core/src/main/java/org/apache/helix/tools/ClusterVerifiers/StrictMatchExternalViewVerifier.java",
                "raw_url": "https://github.com/apache/helix/raw/a264841cc2efcf1ffb58a4af6f5c0f60adb123b0/helix-core/src/main/java/org/apache/helix/tools/ClusterVerifiers/StrictMatchExternalViewVerifier.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterVerifiers/StrictMatchExternalViewVerifier.java?ref=a264841cc2efcf1ffb58a4af6f5c0f60adb123b0",
                "patch": "@@ -298,7 +298,8 @@ private boolean verifyExternalView(ResourceControllerDataProvider dataCache, Ext\n   @Override\n   public String toString() {\n     String verifierName = getClass().getSimpleName();\n-    return verifierName + \"(\" + _clusterName + \"@\" + _zkClient.getServers() + \"@resources[\"\n-        + _resources != null ? Arrays.toString(_resources.toArray()) : \"\" + \"])\";\n+    return String\n+        .format(\"%s(%s@%s@resources[%s])\", verifierName, _clusterName, _zkClient.getServers(),\n+            _resources != null ? Arrays.toString(_resources.toArray()) : \"\");\n   }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/644a5687fb27b879959c6a75cbefbc6395249d08",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/52cb22282b7c93ed05ee6e582bbb641c2900992f",
        "message": "Fix NullPointerException for testCustomCodeRunner. (#581)\n\nThe new live instance doesn't have its instance config. This causes NullPointerException when monitor is trying to get the instance config. \r\nChangelist:\r\nAdd instance config for the new live instance.",
        "bug_id": "helix_3",
        "file": [
            {
                "sha": "819ee8fa0dd2edfc971e7c606adb5132d7f82578",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "status": "modified",
                "additions": 8,
                "deletions": 16,
                "changes": 24,
                "blob_url": "https://github.com/apache/helix/blob/644a5687fb27b879959c6a75cbefbc6395249d08/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "raw_url": "https://github.com/apache/helix/raw/644a5687fb27b879959c6a75cbefbc6395249d08/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java?ref=644a5687fb27b879959c6a75cbefbc6395249d08",
                "patch": "@@ -20,18 +20,14 @@\n  */\n \n import java.util.Date;\n+\n import org.apache.helix.HelixConstants.ChangeType;\n-import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n import org.apache.helix.NotificationContext;\n-import org.apache.helix.PropertyKey.Builder;\n import org.apache.helix.TestHelper;\n import org.apache.helix.common.ZkTestBase;\n import org.apache.helix.integration.manager.ClusterControllerManager;\n import org.apache.helix.integration.manager.MockParticipantManager;\n-import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n-import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n-import org.apache.helix.model.LiveInstance;\n import org.apache.helix.participant.CustomCodeCallbackHandler;\n import org.apache.helix.participant.HelixCustomCodeRunner;\n import org.apache.helix.tools.ClusterStateVerifier;\n@@ -109,15 +105,11 @@ public void testCustomCodeRunner() throws Exception {\n     Assert.assertTrue(_callback._isCallbackInvoked);\n     _callback._isCallbackInvoked = false;\n \n-    // add a new live instance\n-    HelixDataAccessor accessor =\n-        new ZKHelixDataAccessor(_clusterName, new ZkBaseDataAccessor<>(_gZkClient));\n-    Builder keyBuilder = accessor.keyBuilder();\n-\n-    LiveInstance newLiveIns = new LiveInstance(\"newLiveInstance\");\n-    newLiveIns.setHelixVersion(\"0.6.0\");\n-    newLiveIns.setSessionId(\"randomSessionId\");\n-    accessor.setProperty(keyBuilder.liveInstance(\"newLiveInstance\"), newLiveIns);\n+    // add a new live instance and its instance config.\n+    // instance name: localhost_1000\n+    int[] newLiveInstance = new int[]{1000};\n+    setupInstances(_clusterName, newLiveInstance);\n+    setupLiveInstances(_clusterName, newLiveInstance);\n \n     Thread.sleep(1000); // wait for the CALLBACK type callback to finish\n     Assert.assertTrue(_callback._isCallbackInvoked);\n@@ -127,8 +119,8 @@ public void testCustomCodeRunner() throws Exception {\n     for (int i = 0; i < nodeNb; i++) {\n       participants[i].syncStop();\n     }\n-    accessor.removeProperty(keyBuilder.liveInstance(\"newLiveInstance\"));\n-    TestHelper.dropCluster(_clusterName, _gZkClient);\n+    deleteLiveInstances(_clusterName);\n+    deleteCluster(_clusterName);\n \n     System.out.println(\"END \" + _clusterName + \" at \" + new Date(System.currentTimeMillis()));\n   }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/8e0ac7697fd519e3760bff0678aad4664f7c1853",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/bc46dad1922c143407085a5c21ebed3707be7c7e",
        "message": "Fix NullPointerException in TestDisableCustomCodeRunner_test. (#617)\n\nIn TestDisableCustomCodeRunner_test, a new fake live instance is created without an instance config, so when the cluster monitor is reporting metrics for this instance, its instance config is not found, thus a NullPointerException is thrown.\r\n\r\nFix it by adding an instance config to the cluster for the fake live instance.",
        "bug_id": "helix_4",
        "file": [
            {
                "sha": "ab5a8306fb27ce6c05fca84c645d06c122c46700",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestDisableCustomCodeRunner.java",
                "status": "modified",
                "additions": 12,
                "deletions": 4,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/8e0ac7697fd519e3760bff0678aad4664f7c1853/helix-core/src/test/java/org/apache/helix/integration/TestDisableCustomCodeRunner.java",
                "raw_url": "https://github.com/apache/helix/raw/8e0ac7697fd519e3760bff0678aad4664f7c1853/helix-core/src/test/java/org/apache/helix/integration/TestDisableCustomCodeRunner.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestDisableCustomCodeRunner.java?ref=8e0ac7697fd519e3760bff0678aad4664f7c1853",
                "patch": "@@ -38,6 +38,7 @@\n import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.InstanceConfig;\n import org.apache.helix.model.LiveInstance;\n import org.apache.helix.participant.CustomCodeCallbackHandler;\n import org.apache.helix.participant.HelixCustomCodeRunner;\n@@ -177,10 +178,17 @@ public void test() throws Exception {\n     Assert.assertTrue(result);\n \n     // Change live-instance should not invoke any custom-code runner\n-    LiveInstance fakeInstance = new LiveInstance(\"fakeInstance\");\n+    String fakeInstanceName = \"fakeInstance\";\n+    InstanceConfig instanceConfig = new InstanceConfig(fakeInstanceName);\n+    instanceConfig.setHostName(\"localhost\");\n+    instanceConfig.setPort(\"10000\");\n+    instanceConfig.setInstanceEnabled(true);\n+    admin.addInstance(clusterName, instanceConfig);\n+\n+    LiveInstance fakeInstance = new LiveInstance(fakeInstanceName);\n     fakeInstance.setSessionId(\"fakeSessionId\");\n     fakeInstance.setHelixVersion(\"0.6\");\n-    accessor.setProperty(keyBuilder.liveInstance(\"fakeInstance\"), fakeInstance);\n+    accessor.setProperty(keyBuilder.liveInstance(fakeInstanceName), fakeInstance);\n     Thread.sleep(1000);\n \n     for (Map.Entry<String, DummyCallback> e : callbacks.entrySet()) {\n@@ -196,7 +204,7 @@ public void test() throws Exception {\n     }\n \n     // Remove fake instance\n-    accessor.removeProperty(keyBuilder.liveInstance(\"fakeInstance\"));\n+    accessor.removeProperty(keyBuilder.liveInstance(fakeInstanceName));\n \n     // Re-enable custom-code runner\n     admin.enableResource(clusterName, customCodeRunnerResource, true);\n@@ -227,7 +235,7 @@ public void test() throws Exception {\n     }\n \n     // Add a fake instance should invoke custom-code runner\n-    accessor.setProperty(keyBuilder.liveInstance(\"fakeInstance\"), fakeInstance);\n+    accessor.setProperty(keyBuilder.liveInstance(fakeInstanceName), fakeInstance);\n     Thread.sleep(1000);\n     for (String instance : callbacks.keySet()) {\n       DummyCallback callback = callbacks.get(instance);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/b429d4815f5314bdb0c67ca7ed31d17270a4b878",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/c9300968690024765fe9d66ca1ac248720cd0af8",
        "message": "Remove TODO NPE log for computeResourceBestPossibleState\n\nThe logs related to NPE in computeResourceBestPossibleState is not needed anymore.\n\nThis commit fixes issue #351.",
        "bug_id": "helix_5",
        "file": [
            {
                "sha": "85a4add52dfe2edec42c03c3d36e083873ce3993",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "status": "modified",
                "additions": 7,
                "deletions": 13,
                "changes": 20,
                "blob_url": "https://github.com/apache/helix/blob/b429d4815f5314bdb0c67ca7ed31d17270a4b878/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "raw_url": "https://github.com/apache/helix/raw/b429d4815f5314bdb0c67ca7ed31d17270a4b878/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/BestPossibleStateCalcStage.java?ref=b429d4815f5314bdb0c67ca7ed31d17270a4b878",
                "patch": "@@ -250,6 +250,13 @@ private boolean computeResourceBestPossibleState(ClusterEvent event, ResourceCon\n         // The next release will support rebalancers that compute the mapping from start to finish\n         partitionStateAssignment = mappingCalculator\n             .computeBestPossiblePartitionState(cache, idealState, resource, currentStateOutput);\n+\n+        if (partitionStateAssignment == null) {\n+          LogUtil.logWarn(logger, _eventId,\n+              \"PartitionStateAssignment is null, resource: \" + resourceName);\n+          return false;\n+        }\n+\n         for (Partition partition : resource.getPartitions()) {\n           Map<String, String> newStateMap = partitionStateAssignment.getReplicaMap(partition);\n           output.setState(resourceName, partition, newStateMap);\n@@ -263,19 +270,6 @@ private boolean computeResourceBestPossibleState(ClusterEvent event, ResourceCon\n       } catch (Exception e) {\n         LogUtil.logError(logger, _eventId,\n             \"Error computing assignment for resource \" + resourceName + \". Skipping.\");\n-        // TODO : remove this part after debugging NPE\n-        StringBuilder sb = new StringBuilder();\n-\n-        sb.append(String\n-            .format(\"HelixManager is null : %s\\n\", event.getAttribute(\"helixmanager\") == null));\n-        sb.append(String.format(\"Rebalancer is null : %s\\n\", rebalancer == null));\n-        sb.append(String.format(\"Calculated idealState is null : %s\\n\", idealState == null));\n-        sb.append(String.format(\"MappingCaculator is null : %s\\n\", mappingCalculator == null));\n-        sb.append(\n-            String.format(\"PartitionAssignment is null : %s\\n\", partitionStateAssignment == null));\n-        sb.append(String.format(\"Output is null : %s\\n\", output == null));\n-\n-        LogUtil.logError(logger, _eventId, sb.toString());\n       }\n     }\n     // Exception or rebalancer is not found"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/67aa48f5d6fe1a4222c05e6665b8516d688c81c1",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/e6b88d7d44a49b3d27b7d049ec2abafcb5ad4414",
        "message": "Add a null check for StateModel in Participant reset logic (#523)\n\nIt was discovered that sometimes during shutdown/disconnect, this reset() gets called, and due to the partition having been dropped right around the same time, we get an NPE on the state model. Added a null check.",
        "bug_id": "helix_6",
        "file": [
            {
                "sha": "2e40d803c7cc58a304dd5c40bc0a4c8c05ba5e53",
                "filename": "helix-core/src/main/java/org/apache/helix/participant/HelixStateMachineEngine.java",
                "status": "modified",
                "additions": 20,
                "deletions": 5,
                "changes": 25,
                "blob_url": "https://github.com/apache/helix/blob/67aa48f5d6fe1a4222c05e6665b8516d688c81c1/helix-core/src/main/java/org/apache/helix/participant/HelixStateMachineEngine.java",
                "raw_url": "https://github.com/apache/helix/raw/67aa48f5d6fe1a4222c05e6665b8516d688c81c1/helix-core/src/main/java/org/apache/helix/participant/HelixStateMachineEngine.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/participant/HelixStateMachineEngine.java?ref=67aa48f5d6fe1a4222c05e6665b8516d688c81c1",
                "patch": "@@ -155,11 +155,26 @@ public void reset() {\n           for (String partitionKey : stateModelFactory.getPartitionSet(resourceName)) {\n             logger.info(\"Resetting {}::{}\", resourceName, partitionKey);\n             StateModel stateModel = stateModelFactory.getStateModel(resourceName, partitionKey);\n-            stateModel.reset();\n-            String initialState = _stateModelParser.getInitialState(stateModel.getClass());\n-            stateModel.updateState(initialState);\n-            // TODO probably should update the state on ZK. Shi confirm what needs\n-            // to be done here.\n+            if (stateModel != null) {\n+              stateModel.reset();\n+              String initialState = _stateModelParser.getInitialState(stateModel.getClass());\n+              stateModel.updateState(initialState);\n+              // TODO probably should update the state on ZK. Shi confirm what needs\n+              // to be done here.\n+            } else {\n+              // TODO: If stateModel is null, we might need to do something here\n+              // This reset() is not synchronized. We observed that during a shutdown (where\n+              // resources\n+              // are all dropped), an NPE could be possible due to stateModel being null\n+              // Two cases are possible: 1) removing a partition/resource 2) adding a\n+              // partition/resource\n+              // We may need to add more processing here to make sure things are being set to\n+              // initialState. Otherwise, there might be inconsistencies that might cause partitions\n+              // to be stuck in some state (because reset() would be a NOP here)\n+              logger.warn(\n+                  \"Failed to reset due to StateModel being null! Resource: {}, Partition: {}\",\n+                  resourceName, partitionKey);\n+            }\n           }\n         }\n       }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/8f6091b05f1d9995bc95cf819d91e11e71292c2c",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/011e67c3125fb6e6a87d8555ebf4c41949cfa011",
        "message": "Fixed NPE in GenericHelixController",
        "bug_id": "helix_7",
        "file": [
            {
                "sha": "4e691ed832d8fd06c88297d4df41260f347b4481",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/GenericHelixController.java",
                "status": "modified",
                "additions": 11,
                "deletions": 10,
                "changes": 21,
                "blob_url": "https://github.com/apache/helix/blob/8f6091b05f1d9995bc95cf819d91e11e71292c2c/helix-core/src/main/java/org/apache/helix/controller/GenericHelixController.java",
                "raw_url": "https://github.com/apache/helix/raw/8f6091b05f1d9995bc95cf819d91e11e71292c2c/helix-core/src/main/java/org/apache/helix/controller/GenericHelixController.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/GenericHelixController.java?ref=8f6091b05f1d9995bc95cf819d91e11e71292c2c",
                "patch": "@@ -243,9 +243,8 @@ private void forceRebalance(HelixManager manager, ClusterEventType eventType) {\n     event.addAttribute(AttributeName.eventData.name(), new ArrayList<>());\n     event.addAttribute(AttributeName.AsyncFIFOWorkerPool.name(), _asyncFIFOWorkerPool);\n \n-    _taskEventQueue.put(event);\n-    _eventQueue.put(event.clone(uid));\n-\n+    enqueueEvent(_taskEventQueue, event);\n+    enqueueEvent(_eventQueue, event.clone(uid));\n     logger.info(String\n         .format(\"Controller rebalance event triggered with event type: %s for cluster %s\",\n             eventType, _clusterName));\n@@ -462,9 +461,9 @@ private void shutdownAsyncFIFOWorkers() {\n \n   private boolean isEventQueueEmpty(boolean taskQueue) {\n     if (taskQueue) {\n-      return _taskEventQueue.isEmpty();\n+      return _taskEventQueue == null ||  _taskEventQueue.isEmpty();\n     } else {\n-      return _eventQueue.isEmpty();\n+      return _eventQueue == null || _eventQueue.isEmpty();\n     }\n   }\n \n@@ -845,8 +844,7 @@ private void enqueueEvent(ClusterEventBlockingQueue queue, ClusterEvent event) {\n   public void onControllerChange(NotificationContext changeContext) {\n     logger.info(\"START: GenericClusterController.onControllerChange() for cluster \" + _clusterName);\n \n-    _resourceControlDataProvider.requireFullRefresh();\n-    _workflowControlDataProvider.requireFullRefresh();\n+    requestDataProvidersFullRefresh();\n \n     boolean controllerIsLeader;\n \n@@ -990,7 +988,9 @@ private void enableClusterStatusMonitor(boolean enable) {\n           logger.info(\"Enable clusterStatusMonitor for cluster \" + _clusterName);\n           // Clear old cached monitoring related data to avoid reporting stats cross different\n           // leadership periods\n-          _resourceControlDataProvider.clearMonitoringRecords();\n+          if (_resourceControlDataProvider != null) {\n+            _resourceControlDataProvider.clearMonitoringRecords();\n+          }\n           _clusterStatusMonitor.active();\n         } else {\n           logger.info(\"Disable clusterStatusMonitor for cluster \" + _clusterName);\n@@ -1045,8 +1045,9 @@ private boolean updateControllerState(NotificationContext changeContext, PauseSi\n         event.addAttribute(AttributeName.changeContext.name(), changeContext);\n         event.addAttribute(AttributeName.helixmanager.name(), changeContext.getManager());\n         event.addAttribute(AttributeName.AsyncFIFOWorkerPool.name(), _asyncFIFOWorkerPool);\n-        _eventQueue.put(event);\n-        _taskEventQueue.put(event.clone(String.format(\"%s_%s\", uid, Pipeline.Type.TASK.name())));\n+        enqueueEvent(_eventQueue, event);\n+        enqueueEvent(_taskEventQueue,\n+            event.clone(String.format(\"%s_%s\", uid, Pipeline.Type.TASK.name())));\n       }\n     }\n     return statusFlag;"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/a133fd6bfe669fb1086ec45eec89aa90cf1bd912",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/ce9498cd1c79cc2bbe3026960055721068e9f35a",
        "message": "Fix ZNode does not exist in HealthCheck\n\nIf the ZNode of PartitionHealth does not exist, REST will return failed checks due to NPE. The fix will be adding the instance to be refreshed entirely. Then REST can check based on API refreshed result.",
        "bug_id": "helix_8",
        "file": [
            {
                "sha": "6e9e8e6a7e7836d63bdf8b86f8ee42c7a941acae",
                "filename": "helix-rest/src/main/java/org/apache/helix/rest/server/json/cluster/PartitionHealth.java",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/a133fd6bfe669fb1086ec45eec89aa90cf1bd912/helix-rest/src/main/java/org/apache/helix/rest/server/json/cluster/PartitionHealth.java",
                "raw_url": "https://github.com/apache/helix/raw/a133fd6bfe669fb1086ec45eec89aa90cf1bd912/helix-rest/src/main/java/org/apache/helix/rest/server/json/cluster/PartitionHealth.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-rest/src/main/java/org/apache/helix/rest/server/json/cluster/PartitionHealth.java?ref=a133fd6bfe669fb1086ec45eec89aa90cf1bd912",
                "patch": "@@ -20,6 +20,7 @@\n  */\n \n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n@@ -42,6 +43,10 @@ public void addInstanceThatNeedDirectCallWithPartition(String instanceName,\n         .computeIfAbsent(instanceName, partitions -> new ArrayList<>()).add(partitionName);\n   }\n \n+  public void addInstanceThatNeedDirectCall(String instanceName) {\n+    _instanceToPartitionsMap.put(instanceName, Collections.EMPTY_LIST);\n+  }\n+\n   public void addSinglePartitionHealthForInstance(String instanceName, String partitionName,\n       Boolean isHealthy) {\n     _instanceToPartitionHealthMap.computeIfAbsent(instanceName, partitionMap -> new HashMap<>())"
            },
            {
                "sha": "babce07be646824c550898cf732a9d9c5f22e0f4",
                "filename": "helix-rest/src/main/java/org/apache/helix/rest/server/service/InstanceServiceImpl.java",
                "status": "modified",
                "additions": 8,
                "deletions": 3,
                "changes": 11,
                "blob_url": "https://github.com/apache/helix/blob/a133fd6bfe669fb1086ec45eec89aa90cf1bd912/helix-rest/src/main/java/org/apache/helix/rest/server/service/InstanceServiceImpl.java",
                "raw_url": "https://github.com/apache/helix/raw/a133fd6bfe669fb1086ec45eec89aa90cf1bd912/helix-rest/src/main/java/org/apache/helix/rest/server/service/InstanceServiceImpl.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-rest/src/main/java/org/apache/helix/rest/server/service/InstanceServiceImpl.java?ref=a133fd6bfe669fb1086ec45eec89aa90cf1bd912",
                "patch": "@@ -243,6 +243,8 @@ private StoppableCheck performCustomInstanceCheck(String clusterId, String insta\n         new HashMap<>();\n     for (Map.Entry<String, List<String>> entry : expiredPartitionsByInstance.entrySet()) {\n       String instance = entry.getKey();\n+      // If expiredPartitions list is empty, it means all the partition statues need to be refreshed\n+      // by directly calling the instance API.\n       List<String> expiredPartitions = entry.getValue();\n       Callable<Map<String, Boolean>> refreshTask =\n           () -> _customRestClient.getPartitionStoppableCheck(getBaseUrl(instance, restConfig),\n@@ -303,10 +305,13 @@ protected PartitionHealth generatePartitionHealthMapFromZK() {\n         .collect(Collectors.toList()));\n     for (int i = 0; i < liveInstances.size(); i++) {\n       String instance = liveInstances.get(i);\n-      // TODO: Check ZNRecord is null or not. Need logic to check whether the healthreports exist\n-      // or not. If it does not exist, we should query the participant directly for the health\n-      // report.\n       ZNRecord customizedHealth = healthReports.get(i).getRecord();\n+\n+      // No partition health ZNode found for that instance\n+      // Direct call the instance to get partition health report.\n+      if (customizedHealth == null) {\n+        partitionHealth.addInstanceThatNeedDirectCall(instance);\n+      }\n       for (String partitionName : customizedHealth.getMapFields().keySet()) {\n         try {\n           Map<String, String> healthMap = customizedHealth.getMapField(partitionName);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/177a3fb8485391e353cfc99e394d212bf8bc9950",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/6e94d97a7a490bcf430bff34077b18324fe36751",
        "message": "HELIX: Fix all DataUpdaters so that it checks for null previous records\n\nSome implementations are missing the null check for the ZNRecord data prior to the update in the DataUpdater pattern. This is a fatal bug that could cause NullPointerExceptions. This diff goes through the codebase and address this.\nChangelist:\n1. Add null checks for all DataUpdater implementations",
        "bug_id": "helix_9",
        "file": [
            {
                "sha": "59e81fa25e0ac5533048960e1ee05a989278b1d3",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKUtil.java",
                "status": "modified",
                "additions": 7,
                "deletions": 1,
                "changes": 8,
                "blob_url": "https://github.com/apache/helix/blob/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/manager/zk/ZKUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/manager/zk/ZKUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKUtil.java?ref=177a3fb8485391e353cfc99e394d212bf8bc9950",
                "patch": "@@ -25,6 +25,7 @@\n \n import org.I0Itec.zkclient.DataUpdater;\n import org.apache.helix.BaseDataAccessor;\n+import org.apache.helix.HelixException;\n import org.apache.helix.InstanceType;\n import org.apache.helix.PropertyPathBuilder;\n import org.apache.helix.ZNRecord;\n@@ -315,14 +316,19 @@ public Object update(Object currentData) {\n     }\n   }\n \n-  public static void subtract(HelixZkClient client, String path, final ZNRecord recordTosubtract) {\n+  public static void subtract(HelixZkClient client, final String path,\n+      final ZNRecord recordTosubtract) {\n     int retryCount = 0;\n     while (retryCount < RETRYLIMIT) {\n       try {\n         if (client.exists(path)) {\n           DataUpdater<ZNRecord> updater = new DataUpdater<ZNRecord>() {\n             @Override\n             public ZNRecord update(ZNRecord currentData) {\n+              if (currentData == null) {\n+                throw new HelixException(\n+                    String.format(\"subtract DataUpdater: ZNode at path %s is not found!\", path));\n+              }\n               currentData.subtract(recordTosubtract);\n               return currentData;\n             }"
            },
            {
                "sha": "f31c68baf683fe844d0c9005d877015120bb9b15",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "status": "modified",
                "additions": 9,
                "deletions": 2,
                "changes": 11,
                "blob_url": "https://github.com/apache/helix/blob/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java?ref=177a3fb8485391e353cfc99e394d212bf8bc9950",
                "patch": "@@ -417,6 +417,13 @@ public void enqueueJobs(final String queue, final List<String> jobs,\n     DataUpdater<ZNRecord> updater = new DataUpdater<ZNRecord>() {\n       @Override\n       public ZNRecord update(ZNRecord currentData) {\n+        if (currentData == null) {\n+          // For some reason, the WorkflowConfig for this JobQueue doesn't exist\n+          // In this case, we cannot proceed and must alert the user\n+          throw new HelixException(\n+              String.format(\"enqueueJobs DataUpdater: JobQueue %s config is not found!\", queue));\n+        }\n+\n         // Add the node to the existing DAG\n         JobDag jobDag = JobDag.fromJson(\n             currentData.getSimpleField(WorkflowConfig.WorkflowConfigProperty.Dag.name()));\n@@ -1078,8 +1085,8 @@ public String getUserContent(String key, UserContentStore.Scope scope, String wo\n    */\n   public void addOrUpdateWorkflowUserContentMap(String workflowName,\n       final Map<String, String> contentToAddOrUpdate) {\n-    TaskUtil\n-        .addOrUpdateWorkflowJobUserContentMap(_propertyStore, workflowName, contentToAddOrUpdate);\n+    TaskUtil.addOrUpdateWorkflowJobUserContentMap(_propertyStore, workflowName,\n+        contentToAddOrUpdate);\n   }\n \n   /**"
            },
            {
                "sha": "456520939e45c6bb67d618b903835e1ad1cc6dcc",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "status": "modified",
                "additions": 22,
                "deletions": 7,
                "changes": 29,
                "blob_url": "https://github.com/apache/helix/blob/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java?ref=177a3fb8485391e353cfc99e394d212bf8bc9950",
                "patch": "@@ -366,18 +366,26 @@ protected static void addWorkflowJobUserContent(final HelixManager manager,\n   static void addOrUpdateWorkflowJobUserContentMap(final HelixPropertyStore<ZNRecord> propertyStore,\n       String workflowJobResource, final Map<String, String> contentToAddOrUpdate) {\n     if (workflowJobResource == null) {\n-      throw new IllegalArgumentException(\"workflowJobResource must be not null when adding workflow / job user content\");\n+      throw new IllegalArgumentException(\n+          \"workflowJobResource must be not null when adding workflow / job user content\");\n     }\n-    String path = Joiner.on(\"/\")\n-        .join(TaskConstants.REBALANCER_CONTEXT_ROOT, workflowJobResource, USER_CONTENT_NODE);\n+    String path = Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, workflowJobResource,\n+        USER_CONTENT_NODE);\n \n-    propertyStore.update(path, new DataUpdater<ZNRecord>() {\n+    if (!propertyStore.update(path, new DataUpdater<ZNRecord>() {\n       @Override\n       public ZNRecord update(ZNRecord znRecord) {\n+        if (znRecord == null) {\n+          // This indicates that somehow the UserContentStore ZNode is missing\n+          // This should not happen, but if it is missing, create one\n+          znRecord = new ZNRecord(new ZNRecord(TaskUtil.USER_CONTENT_NODE));\n+        }\n         znRecord.getSimpleFields().putAll(contentToAddOrUpdate);\n         return znRecord;\n       }\n-    }, AccessOption.PERSISTENT);\n+    }, AccessOption.PERSISTENT)) {\n+      LOG.error(\"Failed to update the UserContentStore for {}\", workflowJobResource);\n+    }\n   }\n \n   /**\n@@ -433,16 +441,23 @@ static void addOrUpdateTaskUserContentMap(final HelixPropertyStore<ZNRecord> pro\n     String path =\n         Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, job, USER_CONTENT_NODE);\n \n-    propertyStore.update(path, new DataUpdater<ZNRecord>() {\n+    if (!propertyStore.update(path, new DataUpdater<ZNRecord>() {\n       @Override\n       public ZNRecord update(ZNRecord znRecord) {\n+        if (znRecord == null) {\n+          // This indicates that somehow the UserContentStore ZNode is missing\n+          // This should not happen, but if it is missing, create one\n+          znRecord = new ZNRecord(new ZNRecord(TaskUtil.USER_CONTENT_NODE));\n+        }\n         if (znRecord.getMapField(task) == null) {\n           znRecord.setMapField(task, new HashMap<String, String>());\n         }\n         znRecord.getMapField(task).putAll(contentToAddOrUpdate);\n         return znRecord;\n       }\n-    }, AccessOption.PERSISTENT);\n+    }, AccessOption.PERSISTENT)) {\n+      LOG.error(\"Failed to update the task UserContentStore for task {} in job {}\", task, job);\n+    }\n   }\n \n   /**"
            },
            {
                "sha": "e8903dc6591bada1fcd1111919bdc86bf6ba0dde",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterSetup.java",
                "status": "modified",
                "additions": 8,
                "deletions": 2,
                "changes": 10,
                "blob_url": "https://github.com/apache/helix/blob/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/tools/ClusterSetup.java",
                "raw_url": "https://github.com/apache/helix/raw/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/tools/ClusterSetup.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterSetup.java?ref=177a3fb8485391e353cfc99e394d212bf8bc9950",
                "patch": "@@ -293,7 +293,7 @@ public void swapInstance(String clusterName, final String oldInstanceName, final\n     List<String> existingIdealStateNames =\n         accessor.getChildNames(accessor.keyBuilder().idealStates());\n \n-    for (String resourceName : existingIdealStateNames) {\n+    for (final String resourceName : existingIdealStateNames) {\n       IdealState resourceIdealState =\n           accessor.getProperty(accessor.keyBuilder().idealStates(resourceName));\n       if (resourceIdealState.getRebalanceMode().equals(RebalanceMode.FULL_AUTO)) {\n@@ -306,7 +306,13 @@ public void swapInstance(String clusterName, final String oldInstanceName, final\n       // Update ideal state\n       accessor.updateProperty(accessor.keyBuilder().idealStates(resourceName),\n           new DataUpdater<ZNRecord>() {\n-            @Override public ZNRecord update(ZNRecord znRecord) {\n+            @Override\n+            public ZNRecord update(ZNRecord znRecord) {\n+              if (znRecord == null) {\n+                throw new HelixException(String.format(\n+                    \"swapInstance DataUpdater: IdealState for resource %s no longer exists!\",\n+                    resourceName));\n+              }\n               // Need to swap again in case there are added partition with old instance\n               swapInstanceInIdealState(new IdealState(znRecord), oldInstanceName, newInstanceName);\n               return znRecord;"
            },
            {
                "sha": "3bdc290fa18a2904abc13b81eb0e61104ee4d101",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/commandtools/CurrentStateCleanUp.java",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8,
                "blob_url": "https://github.com/apache/helix/blob/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/tools/commandtools/CurrentStateCleanUp.java",
                "raw_url": "https://github.com/apache/helix/raw/177a3fb8485391e353cfc99e394d212bf8bc9950/helix-core/src/main/java/org/apache/helix/tools/commandtools/CurrentStateCleanUp.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/commandtools/CurrentStateCleanUp.java?ref=177a3fb8485391e353cfc99e394d212bf8bc9950",
                "patch": "@@ -81,14 +81,18 @@ private static Options parseCommandLineOptions() {\n   public static void cleanupCurrentStatesForCluster(String zkConnectString, String clusterName,\n       String instanceName, String session) throws Exception {\n     HelixManager manager = HelixManagerFactory\n-        .getZKHelixManager(clusterName, \"Administorator\", InstanceType.ADMINISTRATOR,\n+        .getZKHelixManager(clusterName, \"Administrator\", InstanceType.ADMINISTRATOR,\n             zkConnectString);\n     manager.connect();\n     try {\n       HelixDataAccessor accessor = manager.getHelixDataAccessor();\n \n       DataUpdater<ZNRecord> updater = new DataUpdater<ZNRecord>() {\n-        @Override public ZNRecord update(ZNRecord currentData) {\n+        @Override\n+        public ZNRecord update(ZNRecord currentData) {\n+          if (currentData == null) {\n+            return null;\n+          }\n           Set<String> partitionToRemove = new HashSet<>();\n           for (String partition : currentData.getMapFields().keySet()) {\n             if (currentData.getMapField(partition).get(\"CURRENT_STATE\")"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/d75d5fcdc9736a0023e8b98a1e55d802fbf4212b",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/4a8e78531191e99a8ee1de2b63a81d6a54c0961a",
        "message": "Fix mappingCalculator NPE",
        "bug_id": "helix_10",
        "file": [
            {
                "sha": "cbb01603814bd2fb7a9cb93cb261dedd6248110c",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "status": "modified",
                "additions": 1,
                "deletions": 0,
                "changes": 1,
                "blob_url": "https://github.com/apache/helix/blob/d75d5fcdc9736a0023e8b98a1e55d802fbf4212b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "raw_url": "https://github.com/apache/helix/raw/d75d5fcdc9736a0023e8b98a1e55d802fbf4212b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java?ref=d75d5fcdc9736a0023e8b98a1e55d802fbf4212b",
                "patch": "@@ -134,6 +134,7 @@ private boolean computeResourceBestPossibleState(ClusterEvent event, ClusterData\n     } else {\n       // Create dummy rebalancer for dropping existing current states\n       rebalancer = new SemiAutoRebalancer();\n+      mappingCalculator = new SemiAutoRebalancer();\n     }\n \n     if (rebalancer instanceof TaskRebalancer) {"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/43555ff0d8cae917accac201e13bafdaf6d32370",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/18aa67b6d5c703e5b938b2f915f52a6ca856e889",
        "message": "fix potential NPE in TopStateHandoffReportStage",
        "bug_id": "helix_11",
        "file": [
            {
                "sha": "5bfd5e6324c38760a554841ab3bbd98359e12362",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/TopStateHandoffReportStage.java",
                "status": "modified",
                "additions": 3,
                "deletions": 4,
                "changes": 7,
                "blob_url": "https://github.com/apache/helix/blob/43555ff0d8cae917accac201e13bafdaf6d32370/helix-core/src/main/java/org/apache/helix/controller/stages/TopStateHandoffReportStage.java",
                "raw_url": "https://github.com/apache/helix/raw/43555ff0d8cae917accac201e13bafdaf6d32370/helix-core/src/main/java/org/apache/helix/controller/stages/TopStateHandoffReportStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/TopStateHandoffReportStage.java?ref=43555ff0d8cae917accac201e13bafdaf6d32370",
                "patch": "@@ -490,10 +490,9 @@ private void removeFromStatsMap(\n       Partition partition) {\n     if (missingTopStateMap.containsKey(resourceName)) {\n       missingTopStateMap.get(resourceName).remove(partition.getPartitionName());\n-    }\n-\n-    if (missingTopStateMap.get(resourceName).size() == 0) {\n-      missingTopStateMap.remove(resourceName);\n+      if (missingTopStateMap.get(resourceName).isEmpty()) {\n+        missingTopStateMap.remove(resourceName);\n+      }\n     }\n   }\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/867aa5f4593ea303a8cd15475550ef86ace61d1d",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/060ef363dbe28df326b377d5844a84459cf7aae4",
        "message": "Add ZkConnection.reconnect to avoid NPE when reset ZkConnection.\n\nIn the old version, reconnect was done by closing and then connecting. In between, the zookeeper ref is null. This may cause NPE which terminate ZkClient operation retry earlier than expected.\nThis change copy the existing ZkConnection and add reconnect. The new method ensures reconnecting without leaving the field empty.",
        "bug_id": "helix_12",
        "file": [
            {
                "sha": "03de88011d90c08a236f554b31da8e9cf93470f9",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkClient.java",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/867aa5f4593ea303a8cd15475550ef86ace61d1d/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkClient.java",
                "raw_url": "https://github.com/apache/helix/raw/867aa5f4593ea303a8cd15475550ef86ace61d1d/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkClient.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkClient.java?ref=867aa5f4593ea303a8cd15475550ef86ace61d1d",
                "patch": "@@ -823,9 +823,8 @@ private void reconnectOnExpiring() {\n   private void reconnect() {\n     getEventLock().lock();\n     try {\n-      IZkConnection connection = getConnection();\n-      connection.close();\n-      connection.connect(this);\n+      ZkConnection connection = ((ZkConnection) getConnection());\n+      connection.reconnect(this);\n     } catch (InterruptedException e) {\n       throw new ZkInterruptedException(e);\n     } finally {"
            },
            {
                "sha": "6f1e88080161ef3708572e9856312d5671058cd6",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkConnection.java",
                "status": "modified",
                "additions": 19,
                "deletions": 1,
                "changes": 20,
                "blob_url": "https://github.com/apache/helix/blob/867aa5f4593ea303a8cd15475550ef86ace61d1d/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkConnection.java",
                "raw_url": "https://github.com/apache/helix/raw/867aa5f4593ea303a8cd15475550ef86ace61d1d/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkConnection.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/zookeeper/ZkConnection.java?ref=867aa5f4593ea303a8cd15475550ef86ace61d1d",
                "patch": "@@ -31,7 +31,6 @@\n import org.apache.zookeeper.data.Stat;\n \n public class ZkConnection implements IZkConnection {\n-\n   private static final Logger LOG = Logger.getLogger(ZkConnection.class);\n \n   /** It is recommended to use quite large sessions timeouts for ZooKeeper. */\n@@ -84,6 +83,25 @@ public void close() throws InterruptedException {\n     }\n   }\n \n+  protected void reconnect(Watcher watcher) throws InterruptedException {\n+    _zookeeperLock.lock();\n+    try {\n+      if (_zk == null) {\n+        throw new IllegalStateException(\"zk client has not been connected or already been closed\");\n+      }\n+      ZooKeeper prevZk = _zk;\n+      try {\n+        LOG.debug(\"Creating new ZookKeeper instance to reconnect to \" + _servers + \".\");\n+        _zk = new ZooKeeper(_servers, _sessionTimeOut, watcher);\n+        prevZk.close();\n+      } catch (IOException e) {\n+        throw new ZkException(\"Unable to connect to \" + _servers, e);\n+      }\n+    } finally {\n+      _zookeeperLock.unlock();\n+    }\n+  }\n+\n   @Override\n   public String create(String path, byte[] data, CreateMode mode) throws KeeperException, InterruptedException {\n     return _zk.create(path, data, Ids.OPEN_ACL_UNSAFE, mode);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/f61cbadd3ecb8461dc3001e6bd47b43382d68c19",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/870cf7cd824efbcd6e01a975e7f5bf6b5c6470d8",
        "message": "TASK: Fix possible NPE in getWorkflowId()\n\nOld workflows may not have WorkflowID field set. This makes getWorkflowId() backward-compatible by falling back on its ZNRecord id instead.\n\nRB=1617517\nG=helix-reviewers\nA=jxue\n\nSigned-off-by: Hunter Lee <hulee@linkedin.com>",
        "bug_id": "helix_13",
        "file": [
            {
                "sha": "9f98f6b9c4b0041df668f0ee75015d3d08b0919d",
                "filename": "helix-core/src/main/java/org/apache/helix/task/WorkflowConfig.java",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/f61cbadd3ecb8461dc3001e6bd47b43382d68c19/helix-core/src/main/java/org/apache/helix/task/WorkflowConfig.java",
                "raw_url": "https://github.com/apache/helix/raw/f61cbadd3ecb8461dc3001e6bd47b43382d68c19/helix-core/src/main/java/org/apache/helix/task/WorkflowConfig.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/WorkflowConfig.java?ref=f61cbadd3ecb8461dc3001e6bd47b43382d68c19",
                "patch": "@@ -154,7 +154,8 @@ protected WorkflowConfig(String workflowId, JobDag jobDag, int parallelJobs,\n   }\n \n   public String getWorkflowId() {\n-    return getSimpleConfig(WorkflowConfigProperty.WorkflowID.name());\n+    String workflowId = getSimpleConfig(WorkflowConfigProperty.WorkflowID.name());\n+    return workflowId != null ? workflowId : getId();\n   }\n \n   public JobDag getJobDag() {"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/9fcfa81f3975f599c1ad993e34e86eef31609d82",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/5b972f1971d3ca959906ac31353787fb1f9bff32",
        "message": "TEST: Fix UserContentStore related tests in helix-rest\n\nThe behavior changed such that if the client-side code does not find the UserContent ZNode, it creates one instead of throwing an NPE. This fixes the tests so that it adapts to the new behavior. This behavior should be reverted eventually because UserContent ZNode should be created only by the Controller.\n\nRB=1618685\nG=helix-reviewers\nA=jxue\n\nSigned-off-by: Hunter Lee <hulee@linkedin.com>",
        "bug_id": "helix_14",
        "file": [
            {
                "sha": "54515afb2924ad19cd54548f96833400580658d7",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestDrop.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-core/src/test/java/org/apache/helix/integration/TestDrop.java",
                "raw_url": "https://github.com/apache/helix/raw/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-core/src/test/java/org/apache/helix/integration/TestDrop.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestDrop.java?ref=9fcfa81f3975f599c1ad993e34e86eef31609d82",
                "patch": "@@ -263,7 +263,6 @@ public void testDropErrorPartitionFailedAutoIS() throws Exception {\n     Assert.assertEquals(disabledPartitions.get(0), \"TestDB0_4\");\n \n     // ExteranlView should have TestDB0_4->localhost_12918_>ERROR\n-    Thread.sleep(2000);\n     ExternalView ev = accessor.getProperty(keyBuilder.externalView(\"TestDB0\"));\n     Set<String> partitions = ev.getPartitionSet();\n     Assert.assertEquals(partitions.size(), 1, \"Should have TestDB0_4->localhost_12918->ERROR\");\n@@ -441,6 +440,7 @@ public void testDropSchemataResource() throws Exception {\n     Assert.assertTrue(verifier.verifyByPolling());\n \n     Thread.sleep(400);\n+\n     assertEmptyCSandEV(clusterName, \"schemata\", participants);\n \n     // clean up"
            },
            {
                "sha": "b76ba711bef782db1308c9324fa8764540716bfa",
                "filename": "helix-rest/src/test/java/org/apache/helix/rest/server/TestJobAccessor.java",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestJobAccessor.java",
                "raw_url": "https://github.com/apache/helix/raw/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestJobAccessor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-rest/src/test/java/org/apache/helix/rest/server/TestJobAccessor.java?ref=9fcfa81f3975f599c1ad993e34e86eef31609d82",
                "patch": "@@ -186,8 +186,10 @@ public void testInvalidGetAndUpdateJobContentStore() {\n     get(invalidURI1, null, Response.Status.NOT_FOUND.getStatusCode(), false);\n     get(invalidURI2, null, Response.Status.NOT_FOUND.getStatusCode(), false);\n \n-    post(invalidURI1, validCmd, validEntity, Response.Status.NOT_FOUND.getStatusCode());\n-    post(invalidURI2, validCmd, validEntity, Response.Status.NOT_FOUND.getStatusCode());\n+    // The following two lines should get OK even though they should be NOT FOUND because the client\n+    // side code create UserContent znodes when not found\n+    post(invalidURI1, validCmd, validEntity, Response.Status.OK.getStatusCode());\n+    post(invalidURI2, validCmd, validEntity, Response.Status.OK.getStatusCode());\n \n     post(validURI, invalidCmd, validEntity, Response.Status.BAD_REQUEST.getStatusCode());\n     post(validURI, validCmd, invalidEntity, Response.Status.BAD_REQUEST.getStatusCode());"
            },
            {
                "sha": "3f9a0e20d4e2a2a4e9f23e97160ca19f6f80f170",
                "filename": "helix-rest/src/test/java/org/apache/helix/rest/server/TestTaskAccessor.java",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestTaskAccessor.java",
                "raw_url": "https://github.com/apache/helix/raw/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestTaskAccessor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-rest/src/test/java/org/apache/helix/rest/server/TestTaskAccessor.java?ref=9fcfa81f3975f599c1ad993e34e86eef31609d82",
                "patch": "@@ -74,8 +74,10 @@ public void testInvalidGetAddTaskUserContent() {\n     get(invalidURI2, null, Response.Status.NOT_FOUND.getStatusCode(), false);\n     get(invalidURI3, null, Response.Status.NOT_FOUND.getStatusCode(), false);\n \n-    post(invalidURI1, validCmd, validEntity, Response.Status.NOT_FOUND.getStatusCode());\n-    post(invalidURI2, validCmd, validEntity, Response.Status.NOT_FOUND.getStatusCode());\n+    // The following two lines should get OK even though they should be NOT FOUND because the client\n+    // side code create UserContent znodes when not found\n+    post(invalidURI1, validCmd, validEntity, Response.Status.OK.getStatusCode());\n+    post(invalidURI2, validCmd, validEntity, Response.Status.OK.getStatusCode());\n \n     post(validURI, invalidCmd, validEntity, Response.Status.BAD_REQUEST.getStatusCode());\n     post(validURI, validCmd, invalidEntity, Response.Status.BAD_REQUEST.getStatusCode());"
            },
            {
                "sha": "aa4118d4f1fe333c436d8c047fd1c96aefbcba6f",
                "filename": "helix-rest/src/test/java/org/apache/helix/rest/server/TestWorkflowAccessor.java",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestWorkflowAccessor.java",
                "raw_url": "https://github.com/apache/helix/raw/9fcfa81f3975f599c1ad993e34e86eef31609d82/helix-rest/src/test/java/org/apache/helix/rest/server/TestWorkflowAccessor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-rest/src/test/java/org/apache/helix/rest/server/TestWorkflowAccessor.java?ref=9fcfa81f3975f599c1ad993e34e86eef31609d82",
                "patch": "@@ -187,7 +187,8 @@ public void testInvalidGetAndUpdateWorkflowContentStore() {\n     Map<String, String> invalidCmd = ImmutableMap.of(\"command\", \"delete\"); // cmd not supported\n \n     get(invalidURI, null, Response.Status.NOT_FOUND.getStatusCode(), false);\n-    post(invalidURI, validCmd, validEntity, Response.Status.NOT_FOUND.getStatusCode());\n+    // The following expects a OK because if the usercontent ZNode is not there, it is created\n+    post(invalidURI, validCmd, validEntity, Response.Status.OK.getStatusCode());\n \n     post(validURI, invalidCmd, validEntity, Response.Status.BAD_REQUEST.getStatusCode());\n     post(validURI, validCmd, invalidEntity, Response.Status.BAD_REQUEST.getStatusCode());"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/c1f9af5b4ffb88a4893ac04890690946e97082e4",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/ae586ac6f511ebed7bb01e0bec61f526b7d4b178",
        "message": "[HELIX-810] HELIX: Fix NPE in InstanceMessagesCache\n\nIt was observed that InstanceMessagesCache was throwing an NPE when it tries to setRelayTime(). This is likely because some relay messages have target instances that are no longer live (thus not in liveInstanceMap). InstanceMessagesCache must handle this gracefully by skipping the operation. We do not delete these msgs right away because the instance may come back alive. Otherwise, after some time has passed, the msg will get expired by the Controller and be removed.\n    Changelist;\n    1. Add a try-catch block\n    2. Improve logging",
        "bug_id": "helix_15",
        "file": [
            {
                "sha": "21c35af99cb821defbf72e706b5db0b10e3e9059",
                "filename": "helix-core/src/main/java/org/apache/helix/common/caches/InstanceMessagesCache.java",
                "status": "modified",
                "additions": 72,
                "deletions": 61,
                "changes": 133,
                "blob_url": "https://github.com/apache/helix/blob/c1f9af5b4ffb88a4893ac04890690946e97082e4/helix-core/src/main/java/org/apache/helix/common/caches/InstanceMessagesCache.java",
                "raw_url": "https://github.com/apache/helix/raw/c1f9af5b4ffb88a4893ac04890690946e97082e4/helix-core/src/main/java/org/apache/helix/common/caches/InstanceMessagesCache.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/common/caches/InstanceMessagesCache.java?ref=c1f9af5b4ffb88a4893ac04890690946e97082e4",
                "patch": "@@ -326,84 +326,95 @@ private void scheduleFuturePipeline(long rebalanceTime) {\n \n   private void setRelayTime(Message relayMessage, Map<String, LiveInstance> liveInstanceMap,\n       Map<String, Map<String, Map<String, CurrentState>>> currentStateMap) {\n-\n     // relay time already set, avoid to reset it to a later time.\n     if (relayMessage.getRelayTime() > relayMessage.getCreateTimeStamp()) {\n       return;\n     }\n \n-    Message hostedMessage = _relayHostMessageCache.get(relayMessage.getMsgId());\n-    String sessionId = hostedMessage.getTgtSessionId();\n-    String instance = hostedMessage.getTgtName();\n-    String resourceName = hostedMessage.getResourceName();\n-    String instanceSessionId = liveInstanceMap.get(instance).getSessionId();\n-\n-    long currentTime = System.currentTimeMillis();\n-    long expiredTime = currentTime + relayMessage.getExpiryPeriod();\n-\n-    if (!instanceSessionId.equals(sessionId)) {\n-      LOG.debug(\n-          \"Hosted Instance SessionId {} does not match sessionId {} in hosted message , set relay message {} to be expired at {}, hosted message \",\n-          instanceSessionId, sessionId, relayMessage.getId(), expiredTime,\n-          hostedMessage.getMsgId());\n-      relayMessage.setRelayTime(currentTime);\n-      return;\n-    }\n-\n-    Map<String, Map<String, CurrentState>> instanceCurrentStateMap = currentStateMap.get(instance);\n-    if (instanceCurrentStateMap == null) {\n-      LOG.debug(\n-          \"No instanceCurrentStateMap found for {} on {}, set relay messages {} to be expired at {}\"\n-              + resourceName, instance, relayMessage.getId(), expiredTime);\n-      relayMessage.setRelayTime(currentTime);\n-      return;\n-    }\n+    // Relay time has not been set. Proceed to set the relay time\n+    try {\n+      long currentTime = System.currentTimeMillis();\n+      long expiredTime = currentTime + relayMessage.getExpiryPeriod();\n+\n+      Message hostedMessage = _relayHostMessageCache.get(relayMessage.getMsgId());\n+      String sessionId = hostedMessage.getTgtSessionId();\n+      String instance = hostedMessage.getTgtName();\n+      String resourceName = hostedMessage.getResourceName();\n+      if (!liveInstanceMap.containsKey(instance)) {\n+        // It's possible that hostedMsg's target is no longer live. In this case, we just set the\n+        // relay time and return so that the message could be cleaned up after a short delay\n+        relayMessage.setRelayTime(currentTime);\n+        return;\n+      }\n+      String instanceSessionId = liveInstanceMap.get(instance).getSessionId();\n+\n+      if (!instanceSessionId.equals(sessionId)) {\n+        LOG.debug(\n+            \"Hosted Instance SessionId {} does not match sessionId {} in hosted message , set relay message {} to be expired at {}, hosted message \",\n+            instanceSessionId, sessionId, relayMessage.getId(), expiredTime,\n+            hostedMessage.getMsgId());\n+        relayMessage.setRelayTime(currentTime);\n+        return;\n+      }\n \n-    Map<String, CurrentState> sessionCurrentStateMap = instanceCurrentStateMap.get(sessionId);\n-    if (sessionCurrentStateMap == null) {\n-      LOG.debug(\"No sessionCurrentStateMap found, set relay messages {} to be expired at {}. \",\n-          relayMessage.getId(), expiredTime);\n-      relayMessage.setRelayTime(currentTime);\n-      return;\n-    }\n+      Map<String, Map<String, CurrentState>> instanceCurrentStateMap =\n+          currentStateMap.get(instance);\n+      if (instanceCurrentStateMap == null) {\n+        LOG.debug(\n+            \"No instanceCurrentStateMap found for {} on {}, set relay messages {} to be expired at {}\"\n+                + resourceName,\n+            instance, relayMessage.getId(), expiredTime);\n+        relayMessage.setRelayTime(currentTime);\n+        return;\n+      }\n \n-    String partitionName = hostedMessage.getPartitionName();\n-    String targetState = hostedMessage.getToState();\n-    String fromState = hostedMessage.getFromState();\n+      Map<String, CurrentState> sessionCurrentStateMap = instanceCurrentStateMap.get(sessionId);\n+      if (sessionCurrentStateMap == null) {\n+        LOG.debug(\"No sessionCurrentStateMap found, set relay messages {} to be expired at {}. \",\n+            relayMessage.getId(), expiredTime);\n+        relayMessage.setRelayTime(currentTime);\n+        return;\n+      }\n \n-    CurrentState currentState = sessionCurrentStateMap.get(resourceName);\n-    if (currentState == null) {\n-      LOG.debug(\"No currentState found for {} on {}, set relay message {} to be expired at {} \",\n-          resourceName, instance, relayMessage.getId(),\n-          (currentTime + relayMessage.getExpiryPeriod()));\n-      relayMessage.setRelayTime(currentTime);\n-      return;\n-    }\n+      String partitionName = hostedMessage.getPartitionName();\n+      String targetState = hostedMessage.getToState();\n+      String fromState = hostedMessage.getFromState();\n+\n+      CurrentState currentState = sessionCurrentStateMap.get(resourceName);\n+      if (currentState == null) {\n+        LOG.debug(\"No currentState found for {} on {}, set relay message {} to be expired at {} \",\n+            resourceName, instance, relayMessage.getId(),\n+            (currentTime + relayMessage.getExpiryPeriod()));\n+        relayMessage.setRelayTime(currentTime);\n+        return;\n+      }\n \n-    if (targetState.equals(currentState.getState(partitionName))) {\n-      long completeTime = currentState.getEndTime(partitionName);\n-      if (completeTime < relayMessage.getCreateTimeStamp()) {\n-        completeTime = currentTime;\n+      if (targetState.equals(currentState.getState(partitionName))) {\n+        long completeTime = currentState.getEndTime(partitionName);\n+        if (completeTime < relayMessage.getCreateTimeStamp()) {\n+          completeTime = currentTime;\n+        }\n+        relayMessage.setRelayTime(completeTime);\n+        LOG.debug(\n+            \"Target state match the hosted message's target state, set relay message {} relay time at {}.\",\n+            relayMessage.getId(), completeTime);\n       }\n-      relayMessage.setRelayTime(completeTime);\n-      LOG.debug(\n-          \"Target state match the hosted message's target state, set relay message {} relay time at {}.\",\n-          relayMessage.getId(), completeTime);\n-    }\n \n-    if (!fromState.equals(currentState.getState(partitionName))) {\n-      LOG.debug(\n-          \"Current state does not match hosted message's from state, set relay message {} relay time at {}.\",\n-          relayMessage.getId(), currentTime);\n-      relayMessage.setRelayTime(currentTime);\n+      if (!fromState.equals(currentState.getState(partitionName))) {\n+        LOG.debug(\n+            \"Current state does not match hosted message's from state, set relay message {} relay time at {}.\",\n+            relayMessage.getId(), currentTime);\n+        relayMessage.setRelayTime(currentTime);\n+      }\n+    } catch (Exception e) {\n+      LOG.warn(\"Failed to set the relay time. RelayMsgId: {} Exception: {}\", relayMessage.getId(),\n+          e);\n     }\n   }\n \n   /**\n    * Provides a list of current outstanding pending state transition messages on a given instance.\n-   *\n    * @param instanceName\n-   *\n    * @return\n    */\n   public Map<String, Message> getMessages(String instanceName) {"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/cf010f90426003dab7e713945c2c9daa23ffed13",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/7bb55742e2fe2b61c634dd559cf86a71da50fcdf",
        "message": "[HELIX-770] HELIX: Fix a possible NPE in loadBalance in IntermediateStateCalcStage\n\nIn isLoadBalanceDownwardForAllReplicas() in IntermediateStateCalcStage, statePriorityMap was throwing a NPE because the partition contained a replica in ERROR state, and the map did not have an entry for it. To amend the issue, Venice added the ERROR state in the state model with a priority, and Helix added checks to prevent NPEs.\nChangelist:\n1. Add containsKey checks in isLoadBalanceDownwardForAllReplicas()\n2. Make the Controller correctly log all partitions with ERROR state replicas\n3. Add HelixDefinedStates in statePriorityList if not already added",
        "bug_id": "helix_16",
        "file": [
            {
                "sha": "c156c066f9c2f4eb7bb5ff1147e42d382811b332",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "status": "modified",
                "additions": 12,
                "deletions": 4,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "raw_url": "https://github.com/apache/helix/raw/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java?ref=cf010f90426003dab7e713945c2c9daa23ffed13",
                "patch": "@@ -267,12 +267,13 @@ private PartitionStateMap computeIntermediatePartitionState(ClusterDataCache cac\n       // logic doesn't need to check for more details.\n       boolean isRebalanceNeeded = false;\n \n+      // Check whether partition has any ERROR state replicas\n+      if (currentStateMap.values().contains(HelixDefinedState.ERROR.name())) {\n+        partitionsWithErrorStateReplica.add(partition);\n+      }\n+\n       // Number of states required by StateModelDefinition are not satisfied, need recovery\n       if (rebalanceType.equals(RebalanceType.RECOVERY_BALANCE)) {\n-        // Check whether partition is in ERROR state\n-        if (currentStateMap.values().contains(HelixDefinedState.ERROR.name())) {\n-          partitionsWithErrorStateReplica.add(partition);\n-        }\n         // Check if recovery is needed for this partition\n         if (!currentStateMap.equals(bestPossibleMap)) {\n           partitionsNeedRecovery.add(partition);\n@@ -284,6 +285,7 @@ private PartitionStateMap computeIntermediatePartitionState(ClusterDataCache cac\n         partitionsNeedLoadBalance.add(partition);\n         isRebalanceNeeded = true;\n       }\n+\n       // Currently at BestPossibleState, no further action necessary\n       if (!isRebalanceNeeded) {\n         Map<String, String> intermediateMap = new HashMap<>(bestPossibleMap);\n@@ -388,6 +390,12 @@ private boolean isLoadBalanceDownwardForAllReplicas(Map<String, String> currentS\n       if (bestPossibleState != null) {\n         // Compare priority values and return if an upward transition is found\n         // Note that lower integer value implies higher priority\n+        if (!statePriorityMap.containsKey(currentState)\n+            || !statePriorityMap.containsKey(bestPossibleState)) {\n+          // If the state is not found in statePriorityMap, consider it not strictly downward by\n+          // default because we can't determine whether it is downward\n+          return false;\n+        }\n         if (statePriorityMap.get(currentState) > statePriorityMap.get(bestPossibleState)) {\n           return false;\n         }"
            },
            {
                "sha": "ae5952225ec40c6b1ffce1176fb7877a6831d2e2",
                "filename": "helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "status": "modified",
                "additions": 10,
                "deletions": 2,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "raw_url": "https://github.com/apache/helix/raw/cf010f90426003dab7e713945c2c9daa23ffed13/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/StateModelDefinition.java?ref=cf010f90426003dab7e713945c2c9daa23ffed13",
                "patch": "@@ -70,7 +70,7 @@\n \n   private final List<String> _stateTransitionPriorityList;\n \n-  Map<String, Integer> _statesPriorityMap = new HashMap<String, Integer>();\n+  private Map<String, Integer> _statesPriorityMap = new HashMap<>();\n \n   /**\n    * StateTransition which is used to find the nextState given StartState and\n@@ -112,9 +112,17 @@ public StateModelDefinition(ZNRecord record) {\n       }\n     }\n \n+    // add HelixDefinedStates to statesPriorityMap in case it hasn't been added already\n+    for (HelixDefinedState state : HelixDefinedState.values()) {\n+      if (!_statesPriorityMap.containsKey(state.name())) {\n+        // Make it the lowest priority\n+        _statesPriorityMap.put(state.name(), Integer.MAX_VALUE);\n+      }\n+    }\n+\n     // add transitions for helix-defined states\n     for (HelixDefinedState state : HelixDefinedState.values()) {\n-      if (!_statesPriorityList.contains(state.toString())) {\n+      if (_statesPriorityList == null || !_statesPriorityList.contains(state.toString())) {\n         _statesCountMap.put(state.toString(), \"-1\");\n       }\n     }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/012e780607604f1ecfc57f86c11466e4f89240c5",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/47d790e0c6ac388ee38b829bbc9311d21d001705",
        "message": "Fix NPE in TestRoutingTableProvider.",
        "bug_id": "helix_17",
        "file": [
            {
                "sha": "1a41e08dc367e47d40c050081aa7b1f66001ae99",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/rebalancer/CrushRebalancers/TestCrushAutoRebalanceNonRack.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/integration/rebalancer/CrushRebalancers/TestCrushAutoRebalanceNonRack.java",
                "raw_url": "https://github.com/apache/helix/raw/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/integration/rebalancer/CrushRebalancers/TestCrushAutoRebalanceNonRack.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/rebalancer/CrushRebalancers/TestCrushAutoRebalanceNonRack.java?ref=012e780607604f1ecfc57f86c11466e4f89240c5",
                "patch": "@@ -220,7 +220,7 @@ public void testLackEnoughInstances(String rebalanceStrategyName, String rebalan\n       p.syncStop();\n       _setupTool.getClusterManagementTool()\n           .enableInstance(CLUSTER_NAME, p.getInstanceName(), false);\n-      Thread.sleep(50);\n+      Thread.sleep(200);\n       _setupTool.dropInstanceFromCluster(CLUSTER_NAME, p.getInstanceName());\n     }\n "
            },
            {
                "sha": "b34e4476314243989f22c891cb94993ea0930414",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "raw_url": "https://github.com/apache/helix/raw/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java?ref=012e780607604f1ecfc57f86c11466e4f89240c5",
                "patch": "@@ -61,8 +61,8 @@ public void onRoutingTableChange(RoutingTableSnapshot routingTableSnapshot, Obje\n       for (InstanceConfig config : routingTableSnapshot.getInstancesForResource(TEST_DB, \"SLAVE\")) {\n         slaveInstances.add(config.getInstanceName());\n       }\n-      if (!masterInstances.equals(Map.class.cast(context).get(\"MASTER\")) || !slaveInstances\n-          .equals(Map.class.cast(context).get(\"SLAVE\"))) {\n+      if (context != null && (!masterInstances.equals(Map.class.cast(context).get(\"MASTER\"))\n+          || !slaveInstances.equals(Map.class.cast(context).get(\"SLAVE\")))) {\n         _listenerTestResult = false;\n       } else {\n         _listenerTestResult = true;"
            },
            {
                "sha": "349712f7decff053589da2fc388ddd7c3413c323",
                "filename": "helix-core/src/test/java/org/apache/helix/mock/MockManager.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/mock/MockManager.java",
                "raw_url": "https://github.com/apache/helix/raw/012e780607604f1ecfc57f86c11466e4f89240c5/helix-core/src/test/java/org/apache/helix/mock/MockManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/mock/MockManager.java?ref=012e780607604f1ecfc57f86c11466e4f89240c5",
                "patch": "@@ -45,6 +45,7 @@\n import org.apache.helix.ZNRecord;\n import org.apache.helix.healthcheck.ParticipantHealthReportCollector;\n import org.apache.helix.model.HelixConfigScope;\n+import org.apache.helix.participant.HelixStateMachineEngine;\n import org.apache.helix.participant.StateMachineEngine;\n import org.apache.helix.store.zk.ZkHelixPropertyStore;\n \n@@ -237,8 +238,7 @@ public void setVersion(String version) {\n \n   @Override\n   public StateMachineEngine getStateMachineEngine() {\n-    // TODO Auto-generated method stub\n-    return null;\n+    return new HelixStateMachineEngine(this);\n   }\n \n   @Override"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/5fb6563da5fe4ab89274fa1b982452ec11774550",
        "message": "HELIX: Fix null tgtSessionId message bug\n\nIt has been reported that the Controller sometimes sends a message with a null tgtSessionId, which was causing an NPE on the Participant.\nChangelist:\n    1. Controller side fix\n    2. Participant side fix with a try-catch\n    3. Modify isValid for messages",
        "bug_id": "helix_18",
        "file": [
            {
                "sha": "4c693a639900236a6c2c27ab406c85440fe9c6d7",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "status": "modified",
                "additions": 9,
                "deletions": 0,
                "changes": 9,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/MessageGenerationPhase.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "patch": "@@ -267,6 +267,15 @@ private void generateMessage(final Resource resource, final ClusterDataCache cac\n       for (String state : statesPriorityList) {\n         if (messageMap.containsKey(state)) {\n           for (Message message : messageMap.get(state)) {\n+            // This is for a bug where a message's target session id is null\n+            if (!message.isValid()) {\n+              LogUtil.logError(logger, _eventId, String.format(\n+                  \"An invalid message was generated! Discarding this message. sessionIdMap: %s, CurrentStateMap: %s, InstanceStateMap: %s, AllInstances: %s, LiveInstances: %s, Message: %s\",\n+                  sessionIdMap, currentStateOutput.getCurrentStateMap(resourceName, partition),\n+                  instanceStateMap, cache.getAllInstances(), cache.getLiveInstances().keySet(),\n+                  message));\n+              continue; // Do not add this message\n+            }\n             output.addMessage(resourceName, partition, message);\n           }\n         }"
            },
            {
                "sha": "a0481e327d5eb520faffe253a49430a3239ae18c",
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "status": "modified",
                "additions": 70,
                "deletions": 62,
                "changes": 132,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "patch": "@@ -779,78 +779,86 @@ public void onMessage(String instanceName, List<Message> messages,\n     Set<String> createCurStateNames = new HashSet<>();\n \n     for (Message message : messages) {\n-      // nop messages are simply removed. It is used to trigger onMessage() in\n-      // situations such as register a new message handler factory\n-      if (message.getMsgType().equalsIgnoreCase(MessageType.NO_OP.toString())) {\n-        LOG.info(\n-            \"Dropping NO-OP message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc());\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        continue;\n-      }\n+      try {\n+        // nop messages are simply removed. It is used to trigger onMessage() in\n+        // situations such as register a new message handler factory\n+        if (message.getMsgType().equalsIgnoreCase(MessageType.NO_OP.toString())) {\n+          LOG.info(\n+              \"Dropping NO-OP message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc());\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n+          continue;\n+        }\n \n-      String tgtSessionId = message.getTgtSessionId();\n-      // sessionId mismatch normally means message comes from expired session, just remove it\n-      if (!sessionId.equals(tgtSessionId) && !tgtSessionId.equals(\"*\")) {\n-        String warningMessage =\n-            \"SessionId does NOT match. expected sessionId: \" + sessionId\n-                + \", tgtSessionId in message: \" + tgtSessionId + \", messageId: \"\n-                + message.getMsgId();\n-        LOG.warn(warningMessage);\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        _statusUpdateUtil.logWarning(message, HelixStateMachineEngine.class, warningMessage, manager);\n-\n-        // Proactively send a session sync message from participant to controller\n-        // upon session mismatch after a new session is established\n-        if (manager.getInstanceType() == InstanceType.PARTICIPANT\n-            || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT) {\n-          if (message.getCreateTimeStamp() > manager.getSessionStartTime()) {\n-            syncSessionToController(manager);\n+        String tgtSessionId = message.getTgtSessionId();\n+        // sessionId mismatch normally means message comes from expired session, just remove it\n+        if (!sessionId.equals(tgtSessionId) && !tgtSessionId.equals(\"*\")) {\n+          String warningMessage =\n+              \"SessionId does NOT match. expected sessionId: \" + sessionId\n+                  + \", tgtSessionId in message: \" + tgtSessionId + \", messageId: \"\n+                  + message.getMsgId();\n+          LOG.warn(warningMessage);\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n+          _statusUpdateUtil.logWarning(message, HelixStateMachineEngine.class, warningMessage, manager);\n+\n+          // Proactively send a session sync message from participant to controller\n+          // upon session mismatch after a new session is established\n+          if (manager.getInstanceType() == InstanceType.PARTICIPANT\n+              || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT) {\n+            if (message.getCreateTimeStamp() > manager.getSessionStartTime()) {\n+              syncSessionToController(manager);\n+            }\n           }\n+          continue;\n         }\n-        continue;\n-      }\n-\n-      if ((manager.getInstanceType() == InstanceType.CONTROLLER\n-          || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT)\n-          && MessageType.PARTICIPANT_SESSION_CHANGE.name().equals(message.getMsgType())) {\n-        LOG.info(String.format(\"Controller received PARTICIPANT_SESSION_CHANGE msg from src: %s\",\n-            message.getMsgSrc()));\n-        PropertyKey key = new Builder(manager.getClusterName()).liveInstances();\n-        List<LiveInstance> liveInstances = manager.getHelixDataAccessor().getChildValues(key);\n-        _controller.onLiveInstanceChange(liveInstances, changeContext);\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.COMPLETED);\n-        continue;\n-      }\n \n-      // don't process message that is of READ or UNPROCESSABLE state\n-      if (MessageState.NEW != message.getMsgState()) {\n-        // It happens because we don't delete message right after\n-        // read. Instead we keep it until the current state is updated.\n-        // We will read the message again if there is a new message but we\n-        // check for the status and ignore if its already read\n-        if (LOG.isTraceEnabled()) {\n-          LOG.trace(\"Message already read. msgId: \" + message.getMsgId());\n+        if ((manager.getInstanceType() == InstanceType.CONTROLLER\n+            || manager.getInstanceType() == InstanceType.CONTROLLER_PARTICIPANT)\n+            && MessageType.PARTICIPANT_SESSION_CHANGE.name().equals(message.getMsgType())) {\n+          LOG.info(String.format(\"Controller received PARTICIPANT_SESSION_CHANGE msg from src: %s\",\n+              message.getMsgSrc()));\n+          PropertyKey key = new Builder(manager.getClusterName()).liveInstances();\n+          List<LiveInstance> liveInstances = manager.getHelixDataAccessor().getChildValues(key);\n+          _controller.onLiveInstanceChange(liveInstances, changeContext);\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.COMPLETED);\n+          continue;\n         }\n-        continue;\n-      }\n \n-      if (message.isExpired()) {\n-        LOG.info(\n-            \"Dropping expired message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc()\n-                + \" relayed from: \" + message.getRelaySrcHost());\n-        reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n-        continue;\n-      }\n+        // don't process message that is of READ or UNPROCESSABLE state\n+        if (MessageState.NEW != message.getMsgState()) {\n+          // It happens because we don't delete message right after\n+          // read. Instead we keep it until the current state is updated.\n+          // We will read the message again if there is a new message but we\n+          // check for the status and ignore if its already read\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Message already read. msgId: \" + message.getMsgId());\n+          }\n+          continue;\n+        }\n \n-      // State Transition Cancellation\n-      if (message.getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n-        boolean success = cancelNotStartedStateTransition(message, stateTransitionHandlers, accessor, instanceName);\n-        if (success) {\n+        if (message.isExpired()) {\n+          LOG.info(\n+              \"Dropping expired message. mid: \" + message.getId() + \", from: \" + message.getMsgSrc()\n+                  + \" relayed from: \" + message.getRelaySrcHost());\n+          reportAndRemoveMessage(message, accessor, instanceName, ProcessedMessageState.DISCARDED);\n           continue;\n         }\n-      }\n \n-      _monitor.reportReceivedMessage(message);\n+        // State Transition Cancellation\n+        if (message.getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n+          boolean success = cancelNotStartedStateTransition(message, stateTransitionHandlers, accessor, instanceName);\n+          if (success) {\n+            continue;\n+          }\n+        }\n+\n+        _monitor.reportReceivedMessage(message);\n+      } catch (Exception e) {\n+        LOG.error(\"Failed to process the message {}. Deleting the message from ZK. Exception: {}\",\n+            message, e);\n+        removeMessageFromTaskAndFutureMap(message);\n+        removeMessageFromZK(accessor, message, instanceName);\n+        continue;\n+      }\n \n       // create message handlers, if handlers not found, leave its state as NEW\n       NotificationContext msgWorkingContext = changeContext.clone();"
            },
            {
                "sha": "4177b441489e7c5ed566b163e50a01f7c1ada77a",
                "filename": "helix-core/src/main/java/org/apache/helix/model/Message.java",
                "status": "modified",
                "additions": 6,
                "deletions": 7,
                "changes": 13,
                "blob_url": "https://github.com/apache/helix/blob/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/model/Message.java",
                "raw_url": "https://github.com/apache/helix/raw/b0c3bfd693b9e8352ffa55ce3c429a46057d3512/helix-core/src/main/java/org/apache/helix/model/Message.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/Message.java?ref=b0c3bfd693b9e8352ffa55ce3c429a46057d3512",
                "patch": "@@ -905,16 +905,15 @@ public boolean isValid() {\n     // TODO: refactor message to state transition message and task-message and\n     // implement this function separately\n \n-    if (getMsgType().equals(MessageType.STATE_TRANSITION.name())) {\n-      boolean isNotValid =\n-          isNullOrEmpty(getTgtName()) || isNullOrEmpty(getPartitionName())\n-              || isNullOrEmpty(getResourceName()) || isNullOrEmpty(getStateModelDef())\n-              || isNullOrEmpty(getToState()) || isNullOrEmpty(getStateModelFactoryName())\n-              || isNullOrEmpty(getFromState());\n+    if (getMsgType().equals(MessageType.STATE_TRANSITION.name())\n+        || getMsgType().equals(MessageType.STATE_TRANSITION_CANCELLATION.name())) {\n+      boolean isNotValid = isNullOrEmpty(getTgtName()) || isNullOrEmpty(getPartitionName())\n+          || isNullOrEmpty(getResourceName()) || isNullOrEmpty(getStateModelDef())\n+          || isNullOrEmpty(getToState()) || isNullOrEmpty(getFromState())\n+          || isNullOrEmpty(getTgtSessionId());\n \n       return !isNotValid;\n     }\n-\n     return true;\n   }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/f4bb7d60782150c7d713c907211cc9d41f002c48",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/abfb894e508938ee51c73fb8abcb02f7615386e0",
        "message": "[HELIX-740] check NPE in getInstancesInClusterWithTag and throw more meaningful exception",
        "bug_id": "helix_19",
        "file": [
            {
                "sha": "59336fd7662c24720c3da53e84ee5581b5681cf5",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/f4bb7d60782150c7d713c907211cc9d41f002c48/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "raw_url": "https://github.com/apache/helix/raw/f4bb7d60782150c7d713c907211cc9d41f002c48/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java?ref=f4bb7d60782150c7d713c907211cc9d41f002c48",
                "patch": "@@ -36,7 +36,6 @@\n import java.util.TreeMap;\n import java.util.UUID;\n import java.util.concurrent.TimeUnit;\n-\n import org.I0Itec.zkclient.DataUpdater;\n import org.I0Itec.zkclient.exception.ZkNoNodeException;\n import org.apache.helix.AccessOption;\n@@ -666,6 +665,11 @@ private void createZKPaths(String clusterName) {\n \n     for (String instanceName : instances) {\n       InstanceConfig config = accessor.getProperty(keyBuilder.instanceConfig(instanceName));\n+      if (config == null) {\n+        throw new IllegalStateException(String\n+            .format(\"Instance %s does not have a config, cluster might be in bad state\",\n+                instanceName));\n+      }\n       if (config.containsTag(tag)) {\n         result.add(instanceName);\n       }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/1c78fef91e48345876ccdb038aa4ca1099a3bacd",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/90730bff49120fc1ca0103e8be2cbab90e6ceced",
        "message": "Fix NPE for RoutingTableProvider listener",
        "bug_id": "helix_20",
        "file": [
            {
                "sha": "89079220cde88de4d81b0afaada68ded002a569b",
                "filename": "helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "status": "modified",
                "additions": 17,
                "deletions": 5,
                "changes": 22,
                "blob_url": "https://github.com/apache/helix/blob/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "raw_url": "https://github.com/apache/helix/raw/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/spectator/RoutingTableProvider.java?ref=1c78fef91e48345876ccdb038aa4ca1099a3bacd",
                "patch": "@@ -60,7 +60,7 @@\n   private final HelixManager _helixManager;\n   private final RouterUpdater _routerUpdater;\n   private final PropertyType _sourceDataType;\n-  private final Map<RoutingTableChangeListener, Object> _routingTableChangeListenerMap;\n+  private final Map<RoutingTableChangeListener, ListenerContext> _routingTableChangeListenerMap;\n \n   public RoutingTableProvider() {\n     this(null);\n@@ -173,7 +173,7 @@ public RoutingTableSnapshot getRoutingTableSnapshot() {\n    */\n   public void addRoutingTableChangeListener(final RoutingTableChangeListener routingTableChangeListener,\n       Object context) {\n-    _routingTableChangeListenerMap.put(routingTableChangeListener, context);\n+    _routingTableChangeListenerMap.put(routingTableChangeListener, new ListenerContext(context));\n   }\n \n   /**\n@@ -494,10 +494,10 @@ protected void refresh(Map<String, Map<String, Map<String, CurrentState>>> curre\n   }\n \n   private void notifyRoutingTableChange() {\n-    for (Map.Entry<RoutingTableChangeListener, Object> entry : _routingTableChangeListenerMap\n+    for (Map.Entry<RoutingTableChangeListener, ListenerContext> entry : _routingTableChangeListenerMap\n         .entrySet()) {\n-      entry.getKey()\n-          .onRoutingTableChange(new RoutingTableSnapshot(_routingTableRef.get()), entry.getValue());\n+      entry.getKey().onRoutingTableChange(new RoutingTableSnapshot(_routingTableRef.get()),\n+          entry.getValue().getContext());\n     }\n   }\n \n@@ -561,4 +561,16 @@ public void queueEvent(NotificationContext context, ClusterEventType eventType,\n       queueEvent(event);\n     }\n   }\n+\n+  private class ListenerContext {\n+    private Object _context;\n+\n+    public ListenerContext(Object context) {\n+      _context = context;\n+    }\n+\n+    public Object getContext() {\n+      return _context;\n+    }\n+  }\n }"
            },
            {
                "sha": "ff35dbd9cc657435d3508285e9cc7422f969a14e",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "raw_url": "https://github.com/apache/helix/raw/1c78fef91e48345876ccdb038aa4ca1099a3bacd/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/spectator/TestRoutingTableProvider.java?ref=1c78fef91e48345876ccdb038aa4ca1099a3bacd",
                "patch": "@@ -164,7 +164,7 @@ public void testRoutingTableListener() throws InterruptedException {\n     context.put(\"MASTER\", Sets.newSet(_instances.get(0)));\n     context.put(\"SLAVE\", Sets.newSet(_instances.get(1), _instances.get(2)));\n     _routingTableProvider.addRoutingTableChangeListener(routingTableChangeListener, context);\n-\n+    _routingTableProvider.addRoutingTableChangeListener(new MockRoutingTableChangeListener(), null);\n     // reenable the master instance to cause change\n     String prevMasterInstance = _instances.get(0);\n     _gSetupTool.getClusterManagementTool().enableInstance(CLUSTER_NAME, prevMasterInstance, true);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/d9ac96eb842d2025168bce5a87268c5bc5bd3a77",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/9178f035569db3288590ae505c2b692aaf27700a",
        "message": "Fix NPEs for HelixTask Executors\n\nHelixTaskExecutors has some NPEs when participant disconnects from ZK. Fix those NPEs by protective checks and shut downs signals.\nx",
        "bug_id": "helix_21",
        "file": [
            {
                "sha": "ad4a2767687a5a1634879c706cd4c5d6e767464e",
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "status": "modified",
                "additions": 26,
                "deletions": 0,
                "changes": 26,
                "blob_url": "https://github.com/apache/helix/blob/d9ac96eb842d2025168bce5a87268c5bc5bd3a77/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "raw_url": "https://github.com/apache/helix/raw/d9ac96eb842d2025168bce5a87268c5bc5bd3a77/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=d9ac96eb842d2025168bce5a87268c5bc5bd3a77",
                "patch": "@@ -132,6 +132,8 @@ MessageHandlerFactory factory() {\n   // timer for schedule timeout tasks\n   final Timer _timer;\n \n+  private boolean _isShuttingDown;\n+\n   public HelixTaskExecutor() {\n     this(new ParticipantStatusMonitor(false, null));\n   }\n@@ -157,6 +159,8 @@ public HelixTaskExecutor(ParticipantStatusMonitor participantStatusMonitor) {\n \n     _timer = new Timer(true); // created as a daemon timer thread to handle task timeout\n \n+    _isShuttingDown = false;\n+\n     startMonitorThread();\n   }\n \n@@ -173,6 +177,8 @@ public void registerMessageHandlerFactory(String type, MessageHandlerFactory fac\n           + factory.getMessageTypes());\n     }\n \n+    _isShuttingDown = false;\n+\n     MsgHandlerFactoryRegistryItem newItem =\n         new MsgHandlerFactoryRegistryItem(factory, threadpoolSize);\n     MsgHandlerFactoryRegistryItem prevItem = _hdlrFtyRegistry.putIfAbsent(type, newItem);\n@@ -386,6 +392,13 @@ public boolean scheduleTask(MessageTask task) {\n         if (!_taskMap.containsKey(taskId)) {\n           ExecutorService exeSvc = findExecutorServiceForMsg(message);\n \n+          if (exeSvc == null) {\n+            LOG.warn(String\n+                .format(\"Threadpool is null for type %s of message %s\", message.getMsgType(),\n+                    message.getMsgId()));\n+            return false;\n+          }\n+\n           LOG.info(\"Submit task: \" + taskId + \" to pool: \" + exeSvc);\n           Future<HelixTaskResult> future = exeSvc.submit(task);\n \n@@ -586,6 +599,8 @@ void init() {\n       _messageQueueMonitor.init();\n     }\n \n+    _isShuttingDown = false;\n+\n     // Re-init all existing factories\n     for (String msgType : _hdlrFtyRegistry.keySet()) {\n       MsgHandlerFactoryRegistryItem item = _hdlrFtyRegistry.get(msgType);\n@@ -649,6 +664,16 @@ public void onMessage(String instanceName, List<Message> messages,\n       // continue to process messages\n     }\n \n+    if (_isShuttingDown) {\n+      StringBuilder sb = new StringBuilder();\n+      for (Message message : messages) {\n+        sb.append(message.getMsgId() + \",\");\n+      }\n+      LOG.info(\n+          \"Helix task executor is shutting down, discard unprocessed messages : \" + sb.toString());\n+      return;\n+    }\n+\n     if (messages == null || messages.size() == 0) {\n       LOG.info(\"No Messages to process\");\n       return;\n@@ -953,6 +978,7 @@ private void removeMessageFromZk(HelixDataAccessor accessor, Message message,\n   @Override\n   public void shutdown() {\n     LOG.info(\"Shutting down HelixTaskExecutor\");\n+    _isShuttingDown = true;\n     _timer.cancel();\n \n     reset();"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/47d790e0c6ac388ee38b829bbc9311d21d001705",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/13fac7c77bb570631ff93e8ff83c5cdd2bcd903f",
        "message": "Fix NPE exception in CurrentStateOutput when getting currentstate for a task.",
        "bug_id": "helix_22",
        "file": [
            {
                "sha": "4ebef97bc60b7eb5eae56ac0fec5b9015b4c8b1c",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/CurrentStateOutput.java",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/47d790e0c6ac388ee38b829bbc9311d21d001705/helix-core/src/main/java/org/apache/helix/controller/stages/CurrentStateOutput.java",
                "raw_url": "https://github.com/apache/helix/raw/47d790e0c6ac388ee38b829bbc9311d21d001705/helix-core/src/main/java/org/apache/helix/controller/stages/CurrentStateOutput.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/CurrentStateOutput.java?ref=47d790e0c6ac388ee38b829bbc9311d21d001705",
                "patch": "@@ -373,9 +373,15 @@ private Message getStateMessage(String resourceName, Partition partition, String\n             if (!currentPartitionCount.containsKey(participant)) {\n               currentPartitionCount.put(participant, 0);\n             }\n-            String currState = participantMap.getValue().toString();\n-            if (participantMap.getValue() instanceof Message) {\n-              currState = ((Message) participantMap.getValue()).getToState();\n+\n+            Object curStateObj = participantMap.getValue();\n+            String currState = null;\n+            if (curStateObj != null) {\n+              if (curStateObj instanceof Message) {\n+                currState = ((Message) curStateObj).getToState();\n+              } else if (curStateObj instanceof String) {\n+                currState = curStateObj.toString();\n+              }\n             }\n             if ((currState != null && currState.equals(state)) || (currState == null && state == null)) {\n               currentPartitionCount.put(participant, currentPartitionCount.get(participant) + 1);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/44a1a7d11de373538e6d7229f06b2df5b03aa293",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/fd33bafd5ab80b665f79fa0acb00c2b66069ca4e",
        "message": "Fix BestPossibleExternalViewVerifier toString NPE",
        "bug_id": "helix_23",
        "file": [
            {
                "sha": "83492433a91d1d52a496c778c77a87f2434b60b9",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/44a1a7d11de373538e6d7229f06b2df5b03aa293/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "raw_url": "https://github.com/apache/helix/raw/44a1a7d11de373538e6d7229f06b2df5b03aa293/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java?ref=44a1a7d11de373538e6d7229f06b2df5b03aa293",
                "patch": "@@ -354,6 +354,6 @@ private void runStage(ClusterEvent event, Stage stage) throws Exception {\n   public String toString() {\n     String verifierName = getClass().getSimpleName();\n     return verifierName + \"(\" + _clusterName + \"@\" + _zkClient + \"@resources[\"\n-       + _resources != null ? Arrays.toString(_resources.toArray()) : \"\" + \"])\";\n+       + (_resources != null ? Arrays.toString(_resources.toArray()) : \"\") + \"])\";\n   }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/c49fa3d34332776ce4cb43a8a5fa0a16be863062",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/fe4a042b8136a5196f58c64e1cf5afa0695f03d7",
        "message": "Fix NPE in ClusterStateVerifier",
        "bug_id": "helix_24",
        "file": [
            {
                "sha": "264c3df5c3bcd03fcfaa774a2baef5cda132e41e",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/rebalancer/AutoRebalancer.java",
                "status": "modified",
                "additions": 1,
                "deletions": 3,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/c49fa3d34332776ce4cb43a8a5fa0a16be863062/helix-core/src/main/java/org/apache/helix/controller/rebalancer/AutoRebalancer.java",
                "raw_url": "https://github.com/apache/helix/raw/c49fa3d34332776ce4cb43a8a5fa0a16be863062/helix-core/src/main/java/org/apache/helix/controller/rebalancer/AutoRebalancer.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/rebalancer/AutoRebalancer.java?ref=c49fa3d34332776ce4cb43a8a5fa0a16be863062",
                "patch": "@@ -148,7 +148,6 @@ public IdealState computeNewIdealState(String resourceName, IdealState currentId\n     newIdealState.setRebalanceMode(RebalanceMode.FULL_AUTO);\n     newIdealState.getRecord().setListFields(newMapping.getListFields());\n \n-\n     boolean preferenceListChanged = false;\n     for (String partition : partitions) {\n       List<String> oldList = currentIdealState.getPreferenceList(partition);\n@@ -158,14 +157,13 @@ public IdealState computeNewIdealState(String resourceName, IdealState currentId\n         break;\n       }\n     }\n-    if (preferenceListChanged) {\n+    if (preferenceListChanged && _manager != null) {\n       HelixDataAccessor dataAccessor = _manager.getHelixDataAccessor();\n       PropertyKey.Builder keyBuilder = dataAccessor.keyBuilder();\n       currentIdealState.getRecord().setListFields(newIdealState.getRecord().getListFields());\n       dataAccessor.setProperty(keyBuilder.idealStates(resourceName), currentIdealState);\n     }\n \n-\n     return newIdealState;\n   }\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/019d6f4ddb21f0c9371fcf6f4e99504fa961c551",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/d9696cc16af8bdfc042c488fe3c28cb3b31413eb",
        "message": "Fix NPE if rebalance strategy is not specified in IS.",
        "bug_id": "helix_25",
        "file": [
            {
                "sha": "f943abfb2e0ff3d55c8164bc13cd31f71fefb33d",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/019d6f4ddb21f0c9371fcf6f4e99504fa961c551/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "raw_url": "https://github.com/apache/helix/raw/019d6f4ddb21f0c9371fcf6f4e99504fa961c551/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java?ref=019d6f4ddb21f0c9371fcf6f4e99504fa961c551",
                "patch": "@@ -66,7 +66,7 @@ public IdealState computeNewIdealState(String resourceName,\n     ZNRecord znRecord = clusterData.getCachedIdealMapping(resourceName);\n     if (znRecord != null) {\n       // TODO: only apply to legacy Auto-RebalanceStrategy at this time, need to apply to any strategy in future.\n-      if (currentIdealState.getRebalanceStrategy().equals(AutoRebalanceStrategy.class.getName())) {\n+      if (AutoRebalanceStrategy.class.getName().equals(currentIdealState.getRebalanceStrategy())) {\n         LOG.info(\"Use cached idealstate for \" + resourceName);\n         IdealState idealState = new IdealState(znRecord);\n         return idealState;"
            },
            {
                "sha": "2543d816aaee9187538591c23a18f0d41356d657",
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTask.java",
                "status": "modified",
                "additions": 8,
                "deletions": 1,
                "changes": 9,
                "blob_url": "https://github.com/apache/helix/blob/019d6f4ddb21f0c9371fcf6f4e99504fa961c551/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTask.java",
                "raw_url": "https://github.com/apache/helix/raw/019d6f4ddb21f0c9371fcf6f4e99504fa961c551/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTask.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTask.java?ref=019d6f4ddb21f0c9371fcf6f4e99504fa961c551",
                "patch": "@@ -214,6 +214,8 @@ private void removeMessageFromZk(HelixDataAccessor accessor, Message message) {\n     boolean success = accessor.removeProperty(msgKey);\n     if (!success) {\n       logger.warn(\"Failed to delete message \" + message.getId() + \" from zk!\");\n+    } else {\n+      logger.info(\"Delete message \" + message.getId() + \" from zk!\");\n     }\n   }\n \n@@ -225,6 +227,9 @@ private void forwardRelayMessages(HelixDataAccessor accessor, Message message,\n \n       // Ignore all relay messages if participant's session has changed.\n       if (!_manager.getSessionId().equals(message.getTgtSessionId())) {\n+        logger.info(\n+            \"Session id has been changed, ignore all relay messages attached with \" + message\n+                .getId());\n         return;\n       }\n \n@@ -234,14 +239,16 @@ private void forwardRelayMessages(HelixDataAccessor accessor, Message message,\n           msg.setRelayTime(taskCompletionTime);\n           if (msg.isExpired()) {\n             logger.info(\n-                \"Relay message expired, ignore it! \" + msg.getId() + \" to instance \" + instance);\n+                \"Relay message expired, ignore \" + msg.getId() + \" to instance \" + instance);\n             continue;\n           }\n           PropertyKey msgKey = keyBuilder.message(instance, msg.getId());\n           boolean success = accessor.getBaseDataAccessor()\n               .create(msgKey.getPath(), msg.getRecord(), AccessOption.PERSISTENT);\n           if (!success) {\n             logger.warn(\"Failed to send relay message \" + msg.getId() + \" to \" + instance);\n+          } else {\n+            logger.info(\"Send relay message \" + message.getId() + \" to \" + instance);\n           }\n         }\n       }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/04281faf0302fa7cfdbe81ec86325c043627489f",
        "message": "Fix NPE for get disabled partitions",
        "bug_id": "helix_26",
        "file": [
            {
                "sha": "0d540596080362f6b584fee4918094e877f4ba0b",
                "filename": "helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "status": "modified",
                "additions": 14,
                "deletions": 13,
                "changes": 27,
                "blob_url": "https://github.com/apache/helix/blob/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "raw_url": "https://github.com/apache/helix/raw/c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/model/InstanceConfig.java?ref=c0bef9a1c734f2396e9dc31c53dd047bbfd5dd61",
                "patch": "@@ -271,8 +271,9 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n   public List<String> getDisabledPartitions() {\n     List<String> oldDisabled =\n         _record.getListField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n-    if (!_record.getMapFields().containsKey(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        && oldDisabled == null) {\n+    Map<String, String> newDisabledMap =\n+        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n+    if (newDisabledMap == null && oldDisabled == null) {\n       return null;\n     }\n \n@@ -281,11 +282,11 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n       disabledPartitions.addAll(oldDisabled);\n     }\n \n-    for (String perResource : _record\n-        .getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name()).values()) {\n-      disabledPartitions.addAll(HelixUtil.deserializeByComma(perResource));\n+    if (newDisabledMap != null) {\n+      for (String perResource : newDisabledMap.values()) {\n+        disabledPartitions.addAll(HelixUtil.deserializeByComma(perResource));\n+      }\n     }\n-\n     return new ArrayList<String>(disabledPartitions);\n   }\n \n@@ -298,9 +299,10 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n     // TODO: Remove this logic getting data from list field when getDisabledParition() removed.\n     List<String> oldDisabled =\n         _record.getListField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n-    if ((!_record.getMapFields().containsKey(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        || !_record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-        .containsKey(resourceName)) && oldDisabled == null) {\n+    Map<String, String> newDisabledMap =\n+        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name());\n+    if ((newDisabledMap == null || !newDisabledMap.containsKey(resourceName))\n+        && oldDisabled == null) {\n       return null;\n     }\n \n@@ -309,10 +311,9 @@ public boolean getInstanceEnabledForPartition(String resource, String partition)\n       disabledPartitions.addAll(oldDisabled);\n     }\n \n-    disabledPartitions.addAll(HelixUtil.deserializeByComma(\n-        _record.getMapField(InstanceConfigProperty.HELIX_DISABLED_PARTITION.name())\n-            .get(resourceName)));\n-\n+    if (newDisabledMap != null) {\n+      disabledPartitions.addAll(HelixUtil.deserializeByComma(newDisabledMap.get(resourceName)));\n+    }\n     return new ArrayList<String>(disabledPartitions);\n   }\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/fe5062f5d7f230c41524d0d0ac66a955f4c3661f",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/f117e24522b0da3dc983f27faa3a427b156124a2",
        "message": "Fix NPE when first time call WorkflowRebalancer",
        "bug_id": "helix_27",
        "file": [
            {
                "sha": "95ee43f2ad84e999f8c2b17bbf4c0f1f98e44cd5",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/fe5062f5d7f230c41524d0d0ac66a955f4c3661f/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/fe5062f5d7f230c41524d0d0ac66a955f4c3661f/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=fe5062f5d7f230c41524d0d0ac66a955f4c3661f",
                "patch": "@@ -493,6 +493,11 @@ public void updateJobCounters(JobConfig jobConfig, TaskState to) {\n   }\n \n   private void updateJobGauges(JobConfig jobConfig, TaskState current) {\n+    // When first time for WorkflowRebalancer call, jobconfig may not ready.\n+    // Thus only check it for gauge.\n+    if (jobConfig == null) {\n+      return;\n+    }\n     String jobType = jobConfig.getJobType();\n     jobType = preProcessJobMonitor(jobType);\n     _perTypeJobMonitorMap.get(jobType).updateJobGauge(current);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/79301ad19871b1acb179436277b7f34683872b9c",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/8b7632ecec3e447bef5201bc1218e1dea2d45938",
        "message": "Adding check to avoid possible NPE when recording resource status.",
        "bug_id": "helix_28",
        "file": [
            {
                "sha": "41c73ed71f50ac069f65961a2ab7f3a1d5227878",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/79301ad19871b1acb179436277b7f34683872b9c/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/79301ad19871b1acb179436277b7f34683872b9c/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ResourceMonitor.java?ref=79301ad19871b1acb179436277b7f34683872b9c",
                "patch": "@@ -178,6 +178,9 @@ public void updateResource(ExternalView externalView, IdealState idealState, Sta\n       Map<String, String> idealRecord = idealState.getInstanceStateMap(partition);\n       Map<String, String> externalViewRecord = externalView.getStateMap(partition);\n \n+      if (idealRecord == null) {\n+        idealRecord = Collections.emptyMap();\n+      }\n       if (externalViewRecord == null) {\n         externalViewRecord = Collections.emptyMap();\n       }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/535986137b557f836c712e14c83f9fe923af4258",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/69f43016f231e428fc741988542e688865fa27f5",
        "message": "Fix a NPE in DelayedAutoRebalancer, adding more debug logs.",
        "bug_id": "helix_29",
        "file": [
            {
                "sha": "bbbdda08cafccbddd12f1ddce3740e20185fde4d",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "status": "modified",
                "additions": 14,
                "deletions": 4,
                "changes": 18,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/rebalancer/DelayedAutoRebalancer.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "patch": "@@ -72,6 +72,10 @@ public IdealState computeNewIdealState(String resourceName,\n \n     if (resourceConfig != null) {\n       userDefinedPreferenceList = resourceConfig.getPreferenceLists();\n+      if (!userDefinedPreferenceList.isEmpty()) {\n+        LOG.info(\"Using user defined preference list for partitions: \" + userDefinedPreferenceList\n+            .keySet());\n+      }\n     }\n \n     Set<String> liveEnabledNodes;\n@@ -100,7 +104,7 @@ public IdealState computeNewIdealState(String resourceName,\n           clusterData.getInstanceOfflineTimeMap(), clusterData.getLiveInstances().keySet(),\n           clusterData.getInstanceConfigMap(), delay, clusterConfig);\n \n-      Set<String> offlineOrDisabledInstances = new HashSet<String>(activeNodes);\n+      Set<String> offlineOrDisabledInstances = new HashSet<>(activeNodes);\n       offlineOrDisabledInstances.removeAll(liveEnabledNodes);\n       setRebalanceScheduler(currentIdealState, offlineOrDisabledInstances,\n           clusterData.getInstanceOfflineTimeMap(), clusterData.getLiveInstances().keySet(),\n@@ -169,7 +173,7 @@ public IdealState computeNewIdealState(String resourceName,\n       LOG.debug(\"currentMapping: \" + currentMapping);\n       LOG.debug(\"stateCountMap: \" + stateCountMap);\n       LOG.debug(\"liveEnabledNodes: \" + liveEnabledNodes);\n-      LOG.debug(\"ActiveNodes: \" + activeNodes);\n+      LOG.debug(\"activeNodes: \" + activeNodes);\n       LOG.debug(\"allNodes: \" + allNodes);\n       LOG.debug(\"maxPartition: \" + maxPartition);\n       LOG.debug(\"newIdealMapping: \" + newIdealMapping);\n@@ -305,11 +309,11 @@ private ZNRecord getFinalDelayedMapping(IdealState idealState, ZNRecord newIdeal\n       return newIdealMapping;\n     }\n     ZNRecord finalMapping = new ZNRecord(idealState.getResourceName());\n-    for (String partition : idealState.getPartitionSet()) {\n+    for (String partition : newIdealMapping.getListFields().keySet()) {\n       List<String> idealList = newIdealMapping.getListField(partition);\n       List<String> activeList = newActiveMapping.getListField(partition);\n \n-      List<String> liveList = new ArrayList<String>();\n+      List<String> liveList = new ArrayList<>();\n       int activeReplica = 0;\n       for (String ins : activeList) {\n         if (liveInstances.contains(ins)) {\n@@ -385,6 +389,12 @@ public ResourceAssignment computeBestPossiblePartitionState(ClusterDataCache cac\n \n       partitionMapping.addReplicaMap(partition, bestStateForPartition);\n     }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Best possible mapping for resource  \" + resource.getResourceName() + \": \"\n+          + partitionMapping);\n+    }\n+\n     return partitionMapping;\n   }\n "
            },
            {
                "sha": "52b7b288a8ac36b7f13335fb8c89e3242b8678a4",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/IntermediateStateCalcStage.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "patch": "@@ -240,7 +240,6 @@ private void chargePendingTransition(Resource resource, CurrentStateOutput curre\n       StateTransitionThrottleController throttleController, Set<Partition> partitionsNeedRecovery,\n       Set<Partition> partitionsNeedLoadbalance) {\n     String resourceName = resource.getResourceName();\n-    logger.info(\"Processing resource:\" + resourceName);\n \n     // check and charge pending transitions\n     for (Partition partition : resource.getPartitions()) {\n@@ -308,7 +307,7 @@ public int compare(Partition o1, Partition o2) {\n           intermediatePartitionStateMap, RebalanceType.RECOVERY_BALANCE);\n     }\n \n-    logger.info(String\n+    logger.debug(String\n         .format(\"needRecovery: %d, recoverybalanceThrottled: %d\", partitionsNeedRecovery.size(),\n             partitionRecoveryBalanceThrottled.size()));\n     return partitionRecoveryBalanceThrottled.size();"
            },
            {
                "sha": "c3b4942dbd97d555d8bcb40aa0276aa78aeb4036",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/common/ZkIntegrationTestBase.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "patch": "@@ -73,8 +73,8 @@ public void beforeSuite() throws Exception {\n \n     _gZkClient = new ZkClient(ZK_ADDR);\n     _gZkClient.setZkSerializer(new ZNRecordSerializer());\n-    _gSetupTool = new ClusterSetup(ZK_ADDR);\n-    _baseAccessor = new ZkBaseDataAccessor<ZNRecord>(_gZkClient);\n+    _gSetupTool = new ClusterSetup(_gZkClient);\n+    _baseAccessor = new ZkBaseDataAccessor<>(_gZkClient);\n   }\n \n   @AfterSuite"
            },
            {
                "sha": "fafd78c87a64b5aebefe9ba0bacbe383998ac018",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "status": "modified",
                "additions": 29,
                "deletions": 18,
                "changes": 47,
                "blob_url": "https://github.com/apache/helix/blob/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "raw_url": "https://github.com/apache/helix/raw/535986137b557f836c712e14c83f9fe923af4258/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/rebalancer/TestMixedModeAutoRebalance.java?ref=535986137b557f836c712e14c83f9fe923af4258",
                "patch": "@@ -25,11 +25,14 @@\n import java.util.List;\n import java.util.Map;\n import org.apache.helix.ConfigAccessor;\n+import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.controller.rebalancer.strategy.CrushRebalanceStrategy;\n import org.apache.helix.controller.rebalancer.strategy.MultiRoundCrushRebalanceStrategy;\n+import org.apache.helix.controller.rebalancer.util.RebalanceScheduler;\n import org.apache.helix.integration.common.ZkIntegrationTestBase;\n import org.apache.helix.integration.manager.ClusterControllerManager;\n import org.apache.helix.integration.manager.MockParticipantManager;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n import org.apache.helix.model.BuiltInStateModelDefinitions;\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.ResourceConfig;\n@@ -51,12 +54,11 @@\n   private final String CLUSTER_NAME = CLUSTER_PREFIX + \"_\" + CLASS_NAME;\n   private ClusterControllerManager _controller;\n \n-  private ClusterSetup _setupTool = null;\n   private List<MockParticipantManager> _participants = new ArrayList<>();\n   private int _replica = 3;\n   private HelixClusterVerifier _clusterVerifier;\n-  private List<String> _testDBs = new ArrayList<>();\n   private ConfigAccessor _configAccessor;\n+  private HelixDataAccessor _dataAccessor;\n \n   @BeforeClass\n   public void beforeClass() throws Exception {\n@@ -66,12 +68,11 @@ public void beforeClass() throws Exception {\n     if (_gZkClient.exists(namespace)) {\n       _gZkClient.deleteRecursive(namespace);\n     }\n-    _setupTool = new ClusterSetup(_gZkClient);\n-    _setupTool.addCluster(CLUSTER_NAME, true);\n+    _gSetupTool.addCluster(CLUSTER_NAME, true);\n \n     for (int i = 0; i < NUM_NODE; i++) {\n       String storageNodeName = PARTICIPANT_PREFIX + \"_\" + (START_PORT + i);\n-      _setupTool.addInstanceToCluster(CLUSTER_NAME, storageNodeName);\n+      _gSetupTool.addInstanceToCluster(CLUSTER_NAME, storageNodeName);\n \n       // start dummy participants\n       MockParticipantManager participant =\n@@ -91,24 +92,33 @@ public void beforeClass() throws Exception {\n     enablePersistBestPossibleAssignment(_gZkClient, CLUSTER_NAME, true);\n \n     _configAccessor = new ConfigAccessor(_gZkClient);\n+    _dataAccessor = new ZKHelixDataAccessor(CLUSTER_NAME, _baseAccessor);\n   }\n \n   @DataProvider(name = \"stateModels\")\n-  public static String [][] stateModels() {\n-    return new String[][] { {BuiltInStateModelDefinitions.MasterSlave.name()},\n-        {BuiltInStateModelDefinitions.OnlineOffline.name()},\n-        {BuiltInStateModelDefinitions.LeaderStandby.name()}\n+  public static Object [][] stateModels() {\n+    return new Object[][] { {BuiltInStateModelDefinitions.MasterSlave.name(), true},\n+        {BuiltInStateModelDefinitions.OnlineOffline.name(), true},\n+        {BuiltInStateModelDefinitions.LeaderStandby.name(), true},\n+        {BuiltInStateModelDefinitions.MasterSlave.name(), false},\n+        {BuiltInStateModelDefinitions.OnlineOffline.name(), false},\n+        {BuiltInStateModelDefinitions.LeaderStandby.name(), false},\n     };\n   }\n \n   @Test(dataProvider = \"stateModels\")\n-  public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n-      throws Exception {\n+  public void testUserDefinedPreferenceListsInFullAuto(\n+      String stateModel, boolean delayEnabled) throws Exception {\n     String db = \"Test-DB-\" + stateModel;\n-    createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n-        _replica, 0, CrushRebalanceStrategy.class.getName());\n+    if (delayEnabled) {\n+      createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n+          _replica - 1, 200, CrushRebalanceStrategy.class.getName());\n+    } else {\n+      createResourceWithDelayedRebalance(CLUSTER_NAME, db, stateModel, _PARTITIONS, _replica,\n+          _replica, 0, CrushRebalanceStrategy.class.getName());\n+    }\n     IdealState idealState =\n-        _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n+        _gSetupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n     Map<String, List<String>> userDefinedPreferenceLists = idealState.getPreferenceLists();\n     List<String> userDefinedPartitions = new ArrayList<>();\n     for (String partition : userDefinedPreferenceLists.keySet()) {\n@@ -125,6 +135,9 @@ public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n         new ResourceConfig.Builder(db).setPreferenceLists(userDefinedPreferenceLists).build();\n     _configAccessor.setResourceConfig(CLUSTER_NAME, db, resourceConfig);\n \n+    //TODO: Trigger rebalancer, remove this once Helix controller is listening on resource config changes.\n+    RebalanceScheduler.invokeRebalance(_dataAccessor, db);\n+\n     while (userDefinedPartitions.size() > 0) {\n       Thread.sleep(100);\n       Assert.assertTrue(_clusterVerifier.verify());\n@@ -136,7 +149,7 @@ public void testUserDefinedPreferenceListsInFullAuto(String stateModel)\n   private void verifyUserDefinedPreferenceLists(String db,\n       Map<String, List<String>> userDefinedPreferenceLists, List<String> userDefinedPartitions)\n       throws InterruptedException {\n-    IdealState is = _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n+    IdealState is = _gSetupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n     for (String p : userDefinedPreferenceLists.keySet()) {\n       List<String> userDefined = userDefinedPreferenceLists.get(p);\n       List<String> preferenceListInIs = is.getPreferenceList(p);\n@@ -163,9 +176,7 @@ private void removePartitionFromUserDefinedList(String db, List<String> userDefi\n     _configAccessor.setResourceConfig(CLUSTER_NAME, db, resourceConfig);\n \n     //TODO: Touch IS, remove this once Helix controller is listening on resource config changes.\n-    IdealState idealState =\n-        _setupTool.getClusterManagementTool().getResourceIdealState(CLUSTER_NAME, db);\n-    _setupTool.getClusterManagementTool().setResourceIdealState(CLUSTER_NAME, db, idealState);\n+    RebalanceScheduler.invokeRebalance(_dataAccessor, db);\n   }\n \n   @AfterClass"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/7355293aafe17ef95b3b4954e32294c6213f059b",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/41e65e1d11bbc22a9dfd281d3103dab85c9a29de",
        "message": "TaskUtil.getWorkflowCfg throws NPE if workflow doesn't exist.",
        "bug_id": "helix_30",
        "file": [
            {
                "sha": "bd8d9c633e07f1b8afd67d8fd16e12db9a003e45",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "status": "modified",
                "additions": 8,
                "deletions": 8,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java?ref=7355293aafe17ef95b3b4954e32294c6213f059b",
                "patch": "@@ -49,7 +49,6 @@\n import org.apache.helix.InstanceType;\n import org.apache.helix.PropertyKey;\n import org.apache.helix.PropertyPathBuilder;\n-import org.apache.helix.PropertyType;\n import org.apache.helix.ZNRecord;\n import org.apache.helix.manager.zk.ZKHelixAdmin;\n import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n@@ -222,7 +221,8 @@ public void start(Workflow flow) {\n    *\n    * Example:\n    *\n-   * WorkflowConfig currentWorkflowConfig = TaskUtil.getWorkflowCfg(_manager, workflow);\n+   * _driver = new TaskDriver ...\n+   * WorkflowConfig currentWorkflowConfig = _driver.getWorkflowCfg(_manager, workflow);\n    * WorkflowConfig.Builder configBuilder = new WorkflowConfig.Builder(currentWorkflowConfig);\n \n    * // make needed changes to the config here\n@@ -236,7 +236,7 @@ public void start(Workflow flow) {\n    */\n   public void updateWorkflow(String workflow, WorkflowConfig newWorkflowConfig) {\n     WorkflowConfig currentConfig =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, workflow);\n+        TaskUtil.getWorkflowCfg(_accessor, workflow);\n     if (currentConfig == null) {\n       throw new HelixException(\"Workflow \" + workflow + \" does not exist!\");\n     }\n@@ -270,7 +270,7 @@ public void createQueue(JobQueue queue) {\n   // TODO: need to make sure the queue is stopped or completed before flush the queue.\n   public void flushQueue(String queueName) {\n     WorkflowConfig config =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n     if (config == null) {\n       throw new IllegalArgumentException(\"Queue does not exist!\");\n     }\n@@ -339,7 +339,7 @@ public ZNRecord update(ZNRecord currentData) {\n    */\n   public void deleteJob(final String queueName, final String jobName) {\n     WorkflowConfig workflowCfg =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n \n     if (workflowCfg == null) {\n       throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n@@ -384,7 +384,7 @@ public void deleteJob(final String queueName, final String jobName) {\n    */\n   private void deleteJobFromScheduledQueue(final String queueName, final String jobName) {\n     WorkflowConfig workflowCfg =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n \n     if (workflowCfg == null) {\n       throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n@@ -710,7 +710,7 @@ public ZNRecord update(ZNRecord currentData) {\n   }\n \n   public WorkflowConfig getWorkflowConfig(String workflow) {\n-    return TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, workflow);\n+    return TaskUtil.getWorkflowCfg(_accessor, workflow);\n   }\n \n   public WorkflowContext getWorkflowContext(String workflow) {\n@@ -726,7 +726,7 @@ public JobContext getJobContext(String job) {\n   }\n \n   public void list(String resource) {\n-    WorkflowConfig wCfg = TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, resource);\n+    WorkflowConfig wCfg = TaskUtil.getWorkflowCfg(_accessor, resource);\n     if (wCfg == null) {\n       LOG.error(\"Workflow \" + resource + \" does not exist!\");\n       return;"
            },
            {
                "sha": "ca274d08fe4ccc3208c913ee38bbc3c1f2ec6dfa",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "status": "modified",
                "additions": 12,
                "deletions": 29,
                "changes": 41,
                "blob_url": "https://github.com/apache/helix/blob/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java?ref=7355293aafe17ef95b3b4954e32294c6213f059b",
                "patch": "@@ -30,7 +30,6 @@\n import java.util.concurrent.TimeUnit;\n \n import org.apache.helix.AccessOption;\n-import org.apache.helix.ConfigAccessor;\n import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixException;\n import org.apache.helix.HelixManager;\n@@ -40,7 +39,6 @@\n import org.apache.helix.model.CurrentState;\n import org.apache.helix.model.HelixConfigScope;\n import org.apache.helix.model.IdealState;\n-import org.apache.helix.model.ResourceAssignment;\n import org.apache.helix.model.builder.HelixConfigScopeBuilder;\n import org.apache.helix.store.HelixPropertyStore;\n import org.apache.log4j.Logger;\n@@ -98,21 +96,19 @@ public static JobConfig getJobCfg(HelixManager manager, String jobResource) {\n   /**\n    * Parses workflow resource configurations in Helix into a {@link WorkflowConfig} object.\n    *\n-   * @param cfgAccessor      Config accessor to access Helix configs\n-   * @param accessor         Accessor to access Helix configs\n-   * @param clusterName      Cluster name\n-   * @param workflowResource The name of the workflow resource.\n+   * @param accessor  Accessor to access Helix configs\n+   * @param workflow The name of the workflow.\n    * @return A {@link WorkflowConfig} object if Helix contains valid configurations for the\n    * workflow, null otherwise.\n    */\n-  public static WorkflowConfig getWorkflowCfg(ConfigAccessor cfgAccessor,\n-      HelixDataAccessor accessor, String clusterName, String workflowResource) {\n-    Map<String, String> workflowCfg =\n-        getResourceConfigMap(cfgAccessor, accessor, clusterName, workflowResource);\n+  public static WorkflowConfig getWorkflowCfg(HelixDataAccessor accessor, String workflow) {\n+    HelixProperty workflowCfg = getResourceConfig(accessor, workflow);\n     if (workflowCfg == null) {\n       return null;\n     }\n-    WorkflowConfig.Builder b = WorkflowConfig.Builder.fromMap(workflowCfg);\n+\n+    WorkflowConfig.Builder b =\n+        WorkflowConfig.Builder.fromMap(workflowCfg.getRecord().getSimpleFields());\n \n     return b.build();\n   }\n@@ -121,13 +117,12 @@ public static WorkflowConfig getWorkflowCfg(ConfigAccessor cfgAccessor,\n    * Parses workflow resource configurations in Helix into a {@link WorkflowConfig} object.\n    *\n    * @param manager          Helix manager object used to connect to Helix.\n-   * @param workflowResource The name of the workflow resource.\n+   * @param workflow The name of the workflow resource.\n    * @return A {@link WorkflowConfig} object if Helix contains valid configurations for the\n    * workflow, null otherwise.\n    */\n-  public static WorkflowConfig getWorkflowCfg(HelixManager manager, String workflowResource) {\n-    return getWorkflowCfg(manager.getConfigAccessor(), manager.getHelixDataAccessor(),\n-        manager.getClusterName(), workflowResource);\n+  public static WorkflowConfig getWorkflowCfg(HelixManager manager, String workflow) {\n+    return getWorkflowCfg(manager.getHelixDataAccessor(), workflow);\n   }\n \n   /**\n@@ -452,18 +447,6 @@ public static Workflow cloneWorkflow(HelixManager manager, String origWorkflowNa\n     return workflowBuilder.build();\n   }\n \n-  private static Map<String, String> getResourceConfigMap(ConfigAccessor cfgAccessor,\n-      HelixDataAccessor accessor, String clusterName, String resource) {\n-    HelixConfigScope scope = getResourceConfigScope(clusterName, resource);\n-\n-    List<String> cfgKeys = cfgAccessor.getKeys(scope);\n-    if (cfgKeys == null || cfgKeys.isEmpty()) {\n-      return null;\n-    }\n-\n-    return getResourceConfig(accessor, resource).getRecord().getSimpleFields();\n-  }\n-\n   private static HelixProperty getResourceConfig(HelixDataAccessor accessor, String resource) {\n     PropertyKey.Builder keyBuilder = accessor.keyBuilder();\n     return accessor.getProperty(keyBuilder.resourceConfig(resource));\n@@ -522,7 +505,7 @@ public static String getWorkflowContextKey(String resource) {\n     return Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, resource);\n   }\n \n-  public static PropertyKey getWorkflowConfigKey(HelixDataAccessor accessor, String resource) {\n-    return accessor.keyBuilder().resourceConfig(resource);\n+  public static PropertyKey getWorkflowConfigKey(HelixDataAccessor accessor, String workflow) {\n+    return accessor.keyBuilder().resourceConfig(workflow);\n   }\n }"
            },
            {
                "sha": "d83c5ebed765cf0c3ac85667d78e85cba4d1c961",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "raw_url": "https://github.com/apache/helix/raw/7355293aafe17ef95b3b4954e32294c6213f059b/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java?ref=7355293aafe17ef95b3b4954e32294c6213f059b",
                "patch": "@@ -47,6 +47,8 @@\n import org.apache.helix.task.TaskState;\n import org.apache.helix.task.TaskStateModelFactory;\n import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.task.Workflow;\n+import org.apache.helix.task.WorkflowConfig;\n import org.apache.helix.task.WorkflowContext;\n import org.apache.helix.tools.ClusterSetup;\n import org.apache.helix.tools.ClusterStateVerifier;\n@@ -367,6 +369,20 @@ public void deleteJobFromRecurrentQueueNotStarted() throws Exception {\n         String.format(\"%s_%s\", scheduledQueue, jobNames.get(JOB_COUNTS - 1)));\n   }\n \n+  @Test\n+  public void testGetNoExistWorkflowConfig() {\n+    String randomName = \"randomJob\";\n+    WorkflowConfig workflowConfig = _driver.getWorkflowConfig(randomName);\n+    Assert.assertNull(workflowConfig);\n+    JobConfig jobConfig = _driver.getJobConfig(randomName);\n+    Assert.assertNull(jobConfig);\n+    WorkflowContext workflowContext = _driver.getWorkflowContext(randomName);\n+    Assert.assertNull(workflowContext);\n+    JobContext jobContext = _driver.getJobContext(randomName);\n+    Assert.assertNull(jobContext);\n+\n+  }\n+\n   private void verifyJobDeleted(String queueName, String jobName) throws Exception {\n     HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n     PropertyKey.Builder keyBuilder = accessor.keyBuilder();"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/c35551c374a852d89b4ccbe5efd43cb395e33a68",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/96eb69186072b1386eea875ffb0fbdcba6070453",
        "message": "[HELIX-723] Remove null statement from AssignableInstanceManagerControllerSwitch\n\nController was set to null during development of the test and never got removed after finishing writing the test, which caused an NPE.\n\nChangelist:\n1. Remove an old null statement in the test",
        "bug_id": "helix_31",
        "file": [
            {
                "sha": "f07d6e3282120d1ae4844f6975def5a8a67ae0a7",
                "filename": "helix-core/src/test/java/org/apache/helix/task/TestAssignableInstanceManagerControllerSwitch.java",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/c35551c374a852d89b4ccbe5efd43cb395e33a68/helix-core/src/test/java/org/apache/helix/task/TestAssignableInstanceManagerControllerSwitch.java",
                "raw_url": "https://github.com/apache/helix/raw/c35551c374a852d89b4ccbe5efd43cb395e33a68/helix-core/src/test/java/org/apache/helix/task/TestAssignableInstanceManagerControllerSwitch.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/task/TestAssignableInstanceManagerControllerSwitch.java?ref=c35551c374a852d89b4ccbe5efd43cb395e33a68",
                "patch": "@@ -83,12 +83,10 @@ public void testControllerSwitch() throws InterruptedException {\n \n     // Stop the current controller\n     _controller.syncStop();\n-    _controller = null;\n     // Start a new controller\n     String newControllerName = CONTROLLER_PREFIX + \"_1\";\n-    ClusterControllerManager newController =\n-        new ClusterControllerManager(ZK_ADDR, CLUSTER_NAME, newControllerName);\n-    newController.syncStart();\n+    _controller = new ClusterControllerManager(ZK_ADDR, CLUSTER_NAME, newControllerName);\n+    _controller.syncStart();\n \n     // Generate a new AssignableInstanceManager\n     taskDataCache.refresh(accessor, resourceConfigMap);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/06a9350f2392a9dc845e54282a29eccc8267bdf5",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/edaf78e279e87f74a08355103b2ef1b427ae0012",
        "message": "Fix NPE in clusterstatusmonitor.\n\nShould check _oldDisabledPartitions for preventing null values.",
        "bug_id": "helix_32",
        "file": [
            {
                "sha": "e91f503fc8ef795291262298393ffba3fda42f16",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "status": "modified",
                "additions": 4,
                "deletions": 2,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/06a9350f2392a9dc845e54282a29eccc8267bdf5/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/06a9350f2392a9dc845e54282a29eccc8267bdf5/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=06a9350f2392a9dc845e54282a29eccc8267bdf5",
                "patch": "@@ -151,8 +151,10 @@ public long getDisabledInstancesGauge() {\n     }\n \n     // TODO : Get rid of this after old API removed.\n-    for (String instance : _oldDisabledPartitions.keySet()) {\n-      numDisabled += _oldDisabledPartitions.get(instance).size();\n+    for (List<String> partitions : _oldDisabledPartitions.values()) {\n+      if (partitions != null) {\n+        numDisabled += partitions.size();\n+      }\n     }\n \n     return numDisabled;"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/959966effa11f7cce0e054b6189c5e97130ae039",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/3768fc11cfe3be87131ce1743ea335e578c3d55e",
        "message": "Fix ZkClientMonitor bugs\n\nNPE check and thread-safe map for counter maps.",
        "bug_id": "helix_33",
        "file": [
            {
                "sha": "aa1a0738cc3415f53719043b81209c97d6402c55",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "status": "modified",
                "additions": 3,
                "deletions": 1,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "raw_url": "https://github.com/apache/helix/raw/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java?ref=959966effa11f7cce0e054b6189c5e97130ae039",
                "patch": "@@ -185,7 +185,9 @@ public void close() throws ZkInterruptedException {\n       }\n     } finally {\n       getEventLock().unlock();\n-      _monitor.unregister();\n+      if (_monitor != null) {\n+        _monitor.unregister();\n+      }\n       LOG.info(\"Closed zkclient\");\n     }\n   }"
            },
            {
                "sha": "5811d7ec316fc62a23c17649d7b8f2bdca761d21",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "status": "modified",
                "additions": 5,
                "deletions": 4,
                "changes": 9,
                "blob_url": "https://github.com/apache/helix/blob/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/959966effa11f7cce0e054b6189c5e97130ae039/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ZkClientMonitor.java?ref=959966effa11f7cce0e054b6189c5e97130ae039",
                "patch": "@@ -22,6 +22,7 @@\n import java.lang.management.ManagementFactory;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import javax.management.JMException;\n import javax.management.MBeanServer;\n import javax.management.ObjectName;\n@@ -62,10 +63,10 @@ public boolean match(String path) {\n   private long _writeCounter;\n   private long _readBytesCounter;\n   private long _writeBytesCounter;\n-  private Map<PredefinedPath, Long> _readCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _writeCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _readBytesCounterMap = new HashMap<PredefinedPath, Long>();\n-  private Map<PredefinedPath, Long> _writBytesCounterMap = new HashMap<PredefinedPath, Long>();\n+  private Map<PredefinedPath, Long> _readCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _writeCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _readBytesCounterMap = new ConcurrentHashMap<>();\n+  private Map<PredefinedPath, Long> _writBytesCounterMap = new ConcurrentHashMap<>();\n \n   public ZkClientMonitor(String tag) throws JMException {\n     tag = tag == null ? DEFAULT_TAG : tag;"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/0ad8af404908a54f7b98ee945bf2dda8e83f002f",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/8ba4c9c19981fffe3c958c6851e2b8b8bf90bfbb",
        "message": "TASK2.0: Job scheduling core pipeline fixes\n\nTask Framework 2.0 had stability issues and race conditions that weren't being handled correctly. Also, integration with RuntimeJobDag had some loopholes that needed to be fixed. This diff includes such fixes and improvements that makes it really show performance gains and cuts down on redundant computation.\nChangelist:\n1. Race condition when a job is enqueued, only the new JobConfig is updated and not the DAG\n    Add a two-way selective update which ensures consistency between JobConfigs and parent DAGs\n2. Moved where getNextJob() is called in scheduleJobs() in WorkflowDispatcher\n    This ensures that once a RuntimeJobDag is rebuilt, update for jobs happens in one pipeline run, which removes any extra delay or slowness\n3. Race condition where the job you got from getNextJob is for some reason not schedulable\n    This is due to deleting and enqueuing a job of the same name\n    RuntimeJobDag has the old job name, which conflicts with the dependency in the new DAG\n    This fixes the test: TestTaskRebalancerStopResume so that it does not enqueue a job of the same name\n4. JobRebalancer was throwing an NPE when calling processJobStatusUpdateAndAssignment()\n    This was sometimes making the Controller hang\n    Added a null check for JobConfig (job could have been deleted/purged)\n5. Fix bug with isWorkflowStopped\n    TargetState comparison was done in the opposite way\n    This fixes the test: TestRecurringJobQueue's testDeletingRecurrentQueueWithHistory()\n    Sometimes contexts do not get deleted cleanly but this does not affect correctness\n6. Add TestEnqueueJobs\n7. Fix unstable TestGetLastScheduledTaskExecInfo\n8. Other minor style fixes",
        "bug_id": "helix_34",
        "file": [
            {
                "sha": "5c29124e20096f62ac862dde55bb47c41904af02",
                "filename": "helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "status": "modified",
                "additions": 17,
                "deletions": 2,
                "changes": 19,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/common/caches/TaskDataCache.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -19,7 +19,6 @@\n  * under the License.\n  */\n \n-import com.google.common.base.Joiner;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -39,7 +38,6 @@\n import org.apache.helix.task.JobConfig;\n import org.apache.helix.task.JobContext;\n import org.apache.helix.task.RuntimeJobDag;\n-import org.apache.helix.task.Task;\n import org.apache.helix.task.TaskConstants;\n import org.apache.helix.task.WorkflowConfig;\n import org.apache.helix.task.WorkflowContext;\n@@ -128,6 +126,23 @@ public synchronized boolean refresh(HelixDataAccessor accessor,\n       if (!_jobConfigMap.containsKey(jobName) && newJobConfigs.get(jobName).getWorkflow() != null) {\n         workflowsUpdated.add(newJobConfigs.get(jobName).getWorkflow());\n       }\n+\n+      // Only for JobQueues when a new job is enqueued, there exists a race condition where only\n+      // JobConfig is updated and the RuntimeJobDag does not get updated because when the client\n+      // (TaskDriver) submits, it creates JobConfig ZNode first and modifies its parent JobDag next.\n+      // To ensure that they are both properly updated, check that workflow's DAG and existing\n+      // JobConfigs are consistent for JobQueues\n+      JobConfig jobConfig = newJobConfigs.get(jobName);\n+      if (_workflowConfigMap.containsKey(jobConfig.getWorkflow())) {\n+        WorkflowConfig workflowConfig = _workflowConfigMap.get(jobConfig.getWorkflow());\n+        // Check that the job's parent workflow's DAG contains this job\n+        if ((workflowConfig.isJobQueue() || !workflowConfig.isTerminable()) && !_runtimeJobDagMap\n+            .get(workflowConfig.getWorkflowId()).getAllNodes().contains(jobName)) {\n+          // Inconsistency between JobConfigs and DAGs found. Add the workflow to workflowsUpdated\n+          // to rebuild the RuntimeJobDag\n+          workflowsUpdated.add(jobConfig.getWorkflow());\n+        }\n+      }\n     }\n \n     // Removed jobs"
            },
            {
                "sha": "94af50dd119950bf0e2bb0496b36b04bce215ec1",
                "filename": "helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "status": "modified",
                "additions": 2,
                "deletions": 3,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -259,9 +259,8 @@ private void scheduleWorkflows(Map<String, Resource> resourceMap, WorkflowContro\n             String quotaType = getQuotaType(cache.getWorkflowConfig(workflowId));\n             restOfResources.remove(workflowId);\n             if (assignableInstanceManager.hasGlobalCapacity(quotaType)) {\n-              _workflowDispatcher\n-                  .assignWorkflow(workflowId, cache.getWorkflowConfig(workflowId), context,\n-                      currentStateOutput, bestPossibleOutput, resourceMap);\n+              _workflowDispatcher.assignWorkflow(workflowId, cache.getWorkflowConfig(workflowId),\n+                  context, currentStateOutput, bestPossibleOutput);\n             } else {\n               LogUtil.logInfo(logger, _eventId, String.format(\n                   \"Fail to schedule new jobs assignment for Workflow %s due to quota %s is full\","
            },
            {
                "sha": "78a74195094b4f4913c7da62ec82428f4a8e6ce9",
                "filename": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -1065,7 +1065,7 @@ private String getTaskId(JobConfig jobCfg, JobContext jobCtx, int partitionNum)\n    */\n   protected boolean isWorkflowStopped(WorkflowContext ctx, WorkflowConfig cfg) {\n     if (cfg.isRecurring()) {\n-      return cfg.getTargetState() == TargetState.START;\n+      return cfg.getTargetState() == TargetState.STOP;\n     }\n \n     for (String job : cfg.getJobDag().getAllNodes()) {"
            },
            {
                "sha": "6d8022962eb7a35f2df7494ed686dbab48e0c4a7",
                "filename": "helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/JobRebalancer.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -40,16 +40,22 @@ public ResourceAssignment computeBestPossiblePartitionState(\n       CurrentStateOutput currStateOutput) {\n     long startTime = System.currentTimeMillis();\n     final String jobName = resource.getResourceName();\n+    JobConfig jobConfig = clusterData.getJobConfig(jobName);\n+    if (jobConfig == null) {\n+      LOG.error(\n+          \"Job {}'s JobConfig is missing. This job might have been deleted or purged. Skipping status update and assignment!\",\n+          jobName);\n+      return buildEmptyAssignment(jobName, currStateOutput);\n+    }\n     LOG.debug(\"Computer Best Partition for job: \" + jobName);\n     if (_jobDispatcher == null) {\n       _jobDispatcher = new JobDispatcher();\n     }\n     _jobDispatcher.init(_manager);\n     _jobDispatcher.updateCache(clusterData);\n     _jobDispatcher.setClusterStatusMonitor(_clusterStatusMonitor);\n-    ResourceAssignment resourceAssignment = _jobDispatcher\n-        .processJobStatusUpdateAndAssignment(jobName, currStateOutput,\n-            clusterData.getWorkflowContext(clusterData.getJobConfig(jobName).getWorkflow()));\n+    ResourceAssignment resourceAssignment = _jobDispatcher.processJobStatusUpdateAndAssignment(\n+        jobName, currStateOutput, clusterData.getWorkflowContext(jobConfig.getWorkflow()));\n     LOG.debug(String.format(\"JobRebalancer computation takes %d ms for Job %s\",\n         System.currentTimeMillis() - startTime, jobName));\n     return resourceAssignment;"
            },
            {
                "sha": "c223a2947feb3a2cc96047849f969f23f9b4ce28",
                "filename": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "status": "modified",
                "additions": 4,
                "deletions": 8,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -20,26 +20,19 @@\n  */\n \n import java.util.ArrayDeque;\n-import java.util.Collections;\n import java.util.HashMap;\n-import java.util.LinkedList;\n import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.Queue;\n import java.util.Set;\n import java.util.HashSet;\n \n-import org.apache.helix.HelixException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-\n /**\n  * RuntimeJobDag is a job DAG that provides the job iterator functionality at runtime (when jobs are\n  * actually being assigned per job category). This is to support assignment of jobs based on their\n  * categories and quotas. RuntimeJobDag uses the list scheduling algorithm using ready-list and\n  * inflight-list to return jobs available for scheduling.\n- *\n  * NOTE: RuntimeJobDag is not thread-safe.\n  */\n public class RuntimeJobDag extends JobDag {\n@@ -125,11 +118,15 @@ public String getNextJob() {\n     }\n     // If list is empty, return null\n     if (_readyJobList.isEmpty()) {\n+\n       return null;\n     }\n     String nextJob = _readyJobList.poll();\n     _inflightJobList.add(nextJob);\n     _lastJob = nextJob;\n+\n+\n+\n     return nextJob;\n   }\n \n@@ -212,5 +209,4 @@ private void resetJobListAndDependencyMaps() {\n   public Set<String> getInflightJobList() {\n     return new HashSet<>(_inflightJobList);\n   }\n-\n }"
            },
            {
                "sha": "5da9fc5f080672219ca22b7faacbd7dc5e14b419",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "status": "modified",
                "additions": 5,
                "deletions": 6,
                "changes": 11,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -654,7 +654,7 @@ private static boolean cleanupIdealStateExtView(final HelixDataAccessor accessor\n    * @return True if remove success, otherwise false\n    */\n   protected static boolean removeWorkflow(final HelixDataAccessor accessor,\n-      final HelixPropertyStore propertyStore, String workflow, Set<String> jobs) {\n+      final HelixPropertyStore<ZNRecord> propertyStore, String workflow, Set<String> jobs) {\n     // clean up all jobs\n     for (String job : jobs) {\n       if (!removeJob(accessor, propertyStore, job)) {\n@@ -724,9 +724,9 @@ protected static boolean removeJobsFromWorkflow(final HelixDataAccessor dataAcce\n    * @return\n    */\n   protected static Set<String> getExpiredJobs(HelixDataAccessor dataAccessor,\n-      HelixPropertyStore propertyStore, WorkflowConfig workflowConfig,\n+      HelixPropertyStore<ZNRecord> propertyStore, WorkflowConfig workflowConfig,\n       WorkflowContext workflowContext) {\n-    Set<String> expiredJobs = new HashSet<String>();\n+    Set<String> expiredJobs = new HashSet<>();\n \n     if (workflowContext != null) {\n       Map<String, TaskState> jobStates = workflowContext.getJobStates();\n@@ -742,7 +742,7 @@ protected static boolean removeJobsFromWorkflow(final HelixDataAccessor dataAcce\n           continue;\n         }\n         long expiry = jobConfig.getExpiry();\n-        if (expiry == workflowConfig.DEFAULT_EXPIRY || expiry < 0) {\n+        if (expiry == WorkflowConfig.DEFAULT_EXPIRY || expiry < 0) {\n           expiry = workflowConfig.getExpiry();\n         }\n         if (jobContext != null && jobStates.get(job) == TaskState.COMPLETED) {\n@@ -822,7 +822,7 @@ public ZNRecord update(ZNRecord currentData) {\n   /**\n    * update workflow's property to remove jobs from JOB_STATES if there are already started.\n    */\n-  protected static boolean removeJobsState(final HelixPropertyStore propertyStore,\n+  protected static boolean removeJobsState(final HelixPropertyStore<ZNRecord> propertyStore,\n       final String workflow, final Set<String> jobs) {\n     String contextPath =\n         Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, workflow, TaskUtil.CONTEXT_NODE);\n@@ -983,7 +983,6 @@ public static boolean isJobStarted(String job, WorkflowContext workflowContext)\n    * @param workflowConfig\n    * @param workflowContext\n    */\n-\n   public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConfig,\n       WorkflowContext workflowContext, HelixManager manager,\n       RebalanceScheduler rebalanceScheduler) {"
            },
            {
                "sha": "51b21ebaa197cfe54a3b66e2f33bec7768f58bf8",
                "filename": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -174,7 +174,7 @@ public void updateWorkflowStatus(String workflow, WorkflowConfig workflowCfg, Wo\n \n   public void assignWorkflow(String workflow, WorkflowConfig workflowCfg,\n       WorkflowContext workflowCtx, CurrentStateOutput currentStateOutput,\n-      BestPossibleStateOutput bestPossibleOutput, Map<String, Resource> resourceMap) {\n+      BestPossibleStateOutput bestPossibleOutput) {\n     // Fetch workflow configuration and context\n     if (workflowCfg == null) {\n       // Already logged in status update.\n@@ -240,13 +240,13 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n     // Assign new jobs\n     while (nextJob != null) {\n       String job = nextJob;\n-      nextJob = jobDag.getNextJob();\n       TaskState jobState = workflowCtx.getJobState(job);\n       if (jobState != null && !jobState.equals(TaskState.NOT_STARTED)) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Job \" + job + \" is already started or completed.\");\n         }\n         processJob(job, currentStateOutput, bestPossibleOutput, workflowCtx);\n+        nextJob = jobDag.getNextJob();\n         continue;\n       }\n \n@@ -258,6 +258,9 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n         break;\n       }\n \n+      // TODO: Part of isJobReadyToSchedule() is already done by RuntimeJobDag. Because there is\n+      // some duplicate logic, consider refactoring. The check here and the ready-list in\n+      // RuntimeJobDag may cause conflicts.\n       // check ancestor job status\n       if (isJobReadyToSchedule(job, workflowCfg, workflowCtx, inCompleteAllJobCount, jobConfigMap,\n           clusterDataCache, clusterDataCache.getAssignableInstanceManager())) {\n@@ -288,6 +291,7 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n           scheduledJobs++;\n         }\n       }\n+      nextJob = jobDag.getNextJob();\n     }\n \n     long currentScheduledTime ="
            },
            {
                "sha": "2411b3901dcfad61c9fa5a1f6c0499906dacf4af",
                "filename": "helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/WorkflowRebalancer.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -54,7 +54,7 @@ public ResourceAssignment computeBestPossiblePartitionState(\n     _workflowDispatcher.updateWorkflowStatus(workflow, workflowCfg, workflowCtx, currStateOutput,\n         new BestPossibleStateOutput());\n     _workflowDispatcher.assignWorkflow(workflow, workflowCfg, workflowCtx, currStateOutput,\n-        new BestPossibleStateOutput(), new HashMap<String, Resource>());\n+        new BestPossibleStateOutput());\n \n     LOG.debug(String.format(\"WorkflowRebalancer computation takes %d ms for workflow %s\",\n         System.currentTimeMillis() - startTime, workflow));"
            },
            {
                "sha": "47b7cb8c52964c62105ac3b6666480da217afac8",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TaskTestUtil.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -206,7 +206,7 @@ public static Date getDateFromStartTime(String startTime)\n   }\n \n   public static JobQueue.Builder buildRecurrentJobQueue(String jobQueueName, int delayStart,\n-      int recurrenInSeconds, TargetState targetState) {\n+      int recurrenceInSeconds, TargetState targetState) {\n     WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder(jobQueueName);\n     workflowCfgBuilder.setExpiry(120000);\n     if (targetState != null) {\n@@ -218,7 +218,7 @@ public static Date getDateFromStartTime(String startTime)\n     cal.set(Calendar.SECOND, cal.get(Calendar.SECOND) + delayStart % 60);\n     cal.set(Calendar.MILLISECOND, 0);\n     ScheduleConfig scheduleConfig =\n-        ScheduleConfig.recurringFromDate(cal.getTime(), TimeUnit.SECONDS, recurrenInSeconds);\n+        ScheduleConfig.recurringFromDate(cal.getTime(), TimeUnit.SECONDS, recurrenceInSeconds);\n     workflowCfgBuilder.setScheduleConfig(scheduleConfig);\n     return new JobQueue.Builder(jobQueueName).setWorkflowConfig(workflowCfgBuilder.build());\n   }"
            },
            {
                "sha": "28ee51d19c7a063189a45c8b190495fed6899430",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "status": "added",
                "additions": 99,
                "deletions": 0,
                "changes": 99,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -0,0 +1,99 @@\n+package org.apache.helix.integration.task;\n+\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.task.JobConfig;\n+import org.apache.helix.task.JobQueue;\n+import org.apache.helix.task.TaskState;\n+import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.task.Workflow;\n+import org.apache.helix.task.WorkflowConfig;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+public class TestEnqueueJobs extends TaskTestBase {\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception {\n+    setSingleTestEnvironment();\n+    super.beforeClass();\n+  }\n+\n+  @Test\n+  public void testJobQueueAddingJobsOneByOne() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder().setWorkflowId(queueName).setParallelJobs(1);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    _driver.enqueueJob(queueName, \"JOB0\", jobBuilder);\n+    for (int i = 1; i < 5; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + (i - 1)),\n+          10000L, TaskState.COMPLETED);\n+      _driver.waitToStop(queueName, 5000L);\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+      _driver.resume(queueName);\n+    }\n+\n+    _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + 4),\n+        TaskState.COMPLETED);\n+  }\n+\n+  @Test\n+  public void testJobQueueAddingJobsAtSametime() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder =\n+        new WorkflowConfig.Builder().setWorkflowId(queueName).setParallelJobs(1);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+\n+    // Adding jobs\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    _driver.waitToStop(queueName, 5000L);\n+    for (int i = 0; i < 5; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+    _driver.resume(queueName);\n+\n+    _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + 4),\n+        TaskState.COMPLETED);\n+  }\n+\n+  @Test\n+  public void testJobSubmitGenericWorkflows() throws InterruptedException {\n+    String workflowName = TestHelper.getTestMethodName();\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2);\n+    Workflow.Builder builder = new Workflow.Builder(workflowName);\n+    for (int i = 0; i < 5; i++) {\n+      builder.addJob(\"JOB\" + i, jobBuilder);\n+    }\n+\n+    /**\n+     * Dependency visualization\n+     *               JOB0\n+     *\n+     *             /   |    \\\n+     *\n+     *         JOB1 <-JOB2   JOB4\n+     *\n+     *                 |     /\n+     *\n+     *                JOB3\n+     */\n+\n+    builder.addParentChildDependency(\"JOB0\", \"JOB1\");\n+    builder.addParentChildDependency(\"JOB0\", \"JOB2\");\n+    builder.addParentChildDependency(\"JOB0\", \"JOB4\");\n+    builder.addParentChildDependency(\"JOB1\", \"JOB2\");\n+    builder.addParentChildDependency(\"JOB2\", \"JOB3\");\n+    builder.addParentChildDependency(\"JOB4\", \"JOB3\");\n+    _driver.start(builder.build());\n+\n+    _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n+  }\n+}\n\\ No newline at end of file"
            },
            {
                "sha": "6d05d3848c91083ae807cfe9c3b974a9fa248221",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "status": "modified",
                "additions": 4,
                "deletions": 1,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -274,12 +274,15 @@ public void testDeletingRecurrentQueueWithHistory() throws Exception {\n \n     // Record all scheduled workflows\n     wCtx = TaskTestUtil.pollForWorkflowContext(_driver, queueName);\n-    List<String> scheduledWorkflows = new ArrayList<String>(wCtx.getScheduledWorkflows());\n+    List<String> scheduledWorkflows = new ArrayList<>(wCtx.getScheduledWorkflows());\n     final String lastScheduledWorkflow = wCtx.getLastScheduledSingleWorkflow();\n \n     // Delete recurrent workflow\n     _driver.delete(queueName);\n \n+    // Try to delete again to make sure things are cleaned up\n+    _driver.delete(queueName);\n+\n     // Wait until recurrent workflow and the last scheduled workflow are cleaned up\n     boolean result = TestHelper.verify(new TestHelper.Verifier() {\n       @Override public boolean verify() throws Exception {"
            },
            {
                "sha": "5f5c6a3c052570d9ab1f72cad5d053ee3151f6ff",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "status": "modified",
                "additions": 10,
                "deletions": 6,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -231,12 +231,16 @@ public void stopDeleteJobAndResumeNamedQueue() throws Exception {\n     currentJobNames.remove(deletedJob2);\n \n     // add job 3 back\n-    JobConfig.Builder job =\n-        new JobConfig.Builder().setCommand(MockTask.TASK_COMMAND)\n-            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(Sets.newHashSet(\"SLAVE\"));\n-    LOG.info(\"Enqueuing job: \" + deletedJob2);\n-    _driver.enqueueJob(queueName, deletedJob2, job);\n-    currentJobNames.add(deletedJob2);\n+    JobConfig.Builder job = new JobConfig.Builder().setCommand(MockTask.TASK_COMMAND)\n+        .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+        .setTargetPartitionStates(Sets.newHashSet(\"SLAVE\"));\n+\n+    // the name here MUST be unique in order to avoid conflicts with the old job cached in\n+    // RuntimeJobDag\n+    String newJob = deletedJob2 + \"_second\";\n+    LOG.info(\"Enqueuing job: \" + newJob);\n+    _driver.enqueueJob(queueName, newJob, job);\n+    currentJobNames.add(newJob);\n \n     // Ensure the jobs left are successful completed in the correct order\n     long preJobFinish = 0;"
            },
            {
                "sha": "a73f02d02009d3cd4258edf77aeadc8b5ffd72ac",
                "filename": "helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "raw_url": "https://github.com/apache/helix/raw/0ad8af404908a54f7b98ee945bf2dda8e83f002f/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java?ref=0ad8af404908a54f7b98ee945bf2dda8e83f002f",
                "patch": "@@ -60,8 +60,8 @@ public void testGetLastScheduledTaskExecInfo() throws InterruptedException {\n     List<Long> startTimesFastTasks = setupTasks(\"TestWorkflow_3\", 4, 10);\n     // API call needs to return the most recent timestamp (value at last index)\n     lastScheduledTaskTs = _driver.getLastScheduledTaskTimestamp(\"TestWorkflow_3\");\n-    execInfo = _driver.getLastScheduledTaskExecutionInfo(\"TestWorkflow_3\");\n     Thread.sleep(200); // Let the tasks run\n+    execInfo = _driver.getLastScheduledTaskExecutionInfo(\"TestWorkflow_3\");\n \n     Assert.assertEquals(startTimesFastTasks.get(startTimesFastTasks.size() - 1), lastScheduledTaskTs);\n     Assert.assertEquals(execInfo.getJobName(), \"TestWorkflow_3_job_0\");"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/9bf4437aa3ffe64d4cb983fea0a6b81162edeed9",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/215039b374ba1457d892d5f0c7ad758b393ed23a",
        "message": "Fix BestPossibleExternalViewVerifier toString NPE",
        "bug_id": "helix_35",
        "file": [
            {
                "sha": "83492433a91d1d52a496c778c77a87f2434b60b9",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/9bf4437aa3ffe64d4cb983fea0a6b81162edeed9/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "raw_url": "https://github.com/apache/helix/raw/9bf4437aa3ffe64d4cb983fea0a6b81162edeed9/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier/BestPossibleExternalViewVerifier.java?ref=9bf4437aa3ffe64d4cb983fea0a6b81162edeed9",
                "patch": "@@ -354,6 +354,6 @@ private void runStage(ClusterEvent event, Stage stage) throws Exception {\n   public String toString() {\n     String verifierName = getClass().getSimpleName();\n     return verifierName + \"(\" + _clusterName + \"@\" + _zkClient + \"@resources[\"\n-       + _resources != null ? Arrays.toString(_resources.toArray()) : \"\" + \"])\";\n+       + (_resources != null ? Arrays.toString(_resources.toArray()) : \"\") + \"])\";\n   }\n }"
            },
            {
                "sha": "185c2cae30cac7398908514f08c648838e3e2841",
                "filename": "helix-core/src/test/java/org/apache/helix/controller/Strategy/TestTopology.java",
                "status": "removed",
                "additions": 0,
                "deletions": 172,
                "changes": 172,
                "blob_url": "https://github.com/apache/helix/blob/215039b374ba1457d892d5f0c7ad758b393ed23a/helix-core/src/test/java/org/apache/helix/controller/Strategy/TestTopology.java",
                "raw_url": "https://github.com/apache/helix/raw/215039b374ba1457d892d5f0c7ad758b393ed23a/helix-core/src/test/java/org/apache/helix/controller/Strategy/TestTopology.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/controller/Strategy/TestTopology.java?ref=215039b374ba1457d892d5f0c7ad758b393ed23a",
                "patch": "@@ -1,172 +0,0 @@\n-package org.apache.helix.controller.Strategy;\n-\n-import org.apache.helix.HelixProperty;\n-import org.apache.helix.controller.rebalancer.topology.Node;\n-import org.apache.helix.controller.rebalancer.topology.Topology;\n-import org.apache.helix.model.ClusterConfig;\n-import org.apache.helix.model.InstanceConfig;\n-import org.apache.log4j.Logger;\n-import org.testng.Assert;\n-import org.testng.annotations.Test;\n-\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-public class TestTopology {\n-  private static Logger logger = Logger.getLogger(TestAutoRebalanceStrategy.class);\n-\n-  @Test\n-  public void testCreateClusterTopology() {\n-    ClusterConfig clusterConfig = new ClusterConfig(\"Test_Cluster\");\n-\n-    String topology = \"/Rack/Sub-Rack/Host/Instance\";\n-    clusterConfig.getRecord().getSimpleFields()\n-        .put(ClusterConfig.ClusterConfigProperty.TOPOLOGY.name(), topology);\n-    clusterConfig.getRecord().getSimpleFields()\n-        .put(ClusterConfig.ClusterConfigProperty.FAULT_ZONE_TYPE.name(), \"Sub-Rack\");\n-\n-    List<String> allNodes = new ArrayList<String>();\n-    List<String> liveNodes = new ArrayList<String>();\n-    Map<String, InstanceConfig> instanceConfigMap = new HashMap<String, InstanceConfig>();\n-\n-    Map<String, Integer> nodeToWeightMap = new HashMap<String, Integer>();\n-\n-    for (int i = 0; i < 100; i++) {\n-      String instance = \"localhost_\" + i;\n-      InstanceConfig config = new InstanceConfig(instance);\n-      String rack_id = \"rack_\" + i/25;\n-      String sub_rack_id = \"subrack-\" + i/5;\n-\n-      String domain =\n-          String.format(\"Rack=%s, Sub-Rack=%s, Host=%s\", rack_id, sub_rack_id, instance);\n-      config.setDomain(domain);\n-      config.setHostName(instance);\n-      config.setPort(\"9000\");\n-      allNodes.add(instance);\n-\n-      int weight = 0;\n-      if (i % 10 != 0) {\n-        liveNodes.add(instance);\n-        weight = 1000;\n-        if (i % 3 == 0) {\n-          // set random instance weight.\n-          weight = (i+1) * 100;\n-          config.setWeight(weight);\n-        }\n-      }\n-\n-      instanceConfigMap.put(instance, config);\n-\n-      if (!nodeToWeightMap.containsKey(rack_id)) {\n-        nodeToWeightMap.put(rack_id, 0);\n-      }\n-      nodeToWeightMap.put(rack_id, nodeToWeightMap.get(rack_id) + weight);\n-      if (!nodeToWeightMap.containsKey(sub_rack_id)) {\n-        nodeToWeightMap.put(sub_rack_id, 0);\n-      }\n-      nodeToWeightMap.put(sub_rack_id, nodeToWeightMap.get(sub_rack_id) + weight);\n-    }\n-\n-    Topology topo = new Topology(allNodes, liveNodes, instanceConfigMap, clusterConfig);\n-\n-    Assert.assertTrue(topo.getEndNodeType().equals(\"Instance\"));\n-    Assert.assertTrue(topo.getFaultZoneType().equals(\"Sub-Rack\"));\n-\n-    List<Node> faultZones = topo.getFaultZones();\n-    Assert.assertEquals(faultZones.size(), 20);\n-\n-    Node root = topo.getRootNode();\n-\n-    Assert.assertEquals(root.getChildrenCount(\"Rack\"), 4);\n-    Assert.assertEquals(root.getChildrenCount(\"Sub-Rack\"), 20);\n-    Assert.assertEquals(root.getChildrenCount(\"Host\"), 100);\n-    Assert.assertEquals(root.getChildrenCount(\"Instance\"), 100);\n-\n-\n-    // validate weights.\n-    for (Node rack : root.getChildren()) {\n-      Assert.assertEquals(rack.getWeight(), (long)nodeToWeightMap.get(rack.getName()));\n-      for (Node subRack : rack.getChildren()) {\n-        Assert.assertEquals(subRack.getWeight(), (long)nodeToWeightMap.get(subRack.getName()));\n-      }\n-    }\n-  }\n-\n-  @Test\n-  public void testCreateClusterTopologyWithDefaultTopology() {\n-    ClusterConfig clusterConfig = new ClusterConfig(\"Test_Cluster\");\n-\n-    List<String> allNodes = new ArrayList<String>();\n-    List<String> liveNodes = new ArrayList<String>();\n-    Map<String, InstanceConfig> instanceConfigMap = new HashMap<String, InstanceConfig>();\n-\n-    Map<String, Integer> nodeToWeightMap = new HashMap<String, Integer>();\n-\n-    for (int i = 0; i < 100; i++) {\n-      String instance = \"localhost_\" + i;\n-      InstanceConfig config = new InstanceConfig(instance);\n-      String zoneId = \"rack_\" + i / 10;\n-      config.setZoneId(zoneId);\n-      config.setHostName(instance);\n-      config.setPort(\"9000\");\n-      allNodes.add(instance);\n-\n-      int weight = 0;\n-      if (i % 10 != 0) {\n-        liveNodes.add(instance);\n-        weight = 1000;\n-        if (i % 3 == 0) {\n-          // set random instance weight.\n-          weight = (i + 1) * 100;\n-          config.setWeight(weight);\n-        }\n-      }\n-\n-      instanceConfigMap.put(instance, config);\n-\n-      if (!nodeToWeightMap.containsKey(zoneId)) {\n-        nodeToWeightMap.put(zoneId, 0);\n-      }\n-      nodeToWeightMap.put(zoneId, nodeToWeightMap.get(zoneId) + weight);\n-    }\n-\n-    Topology topo = new Topology(allNodes, liveNodes, instanceConfigMap, clusterConfig);\n-\n-    Assert.assertTrue(topo.getEndNodeType().equals(Topology.Types.INSTANCE.name()));\n-    Assert.assertTrue(topo.getFaultZoneType().equals(Topology.Types.ZONE.name()));\n-\n-    List<Node> faultZones = topo.getFaultZones();\n-    Assert.assertEquals(faultZones.size(), 10);\n-\n-    Node root = topo.getRootNode();\n-\n-    Assert.assertEquals(root.getChildrenCount(Topology.Types.ZONE.name()), 10);\n-    Assert.assertEquals(root.getChildrenCount(topo.getEndNodeType()), 100);\n-\n-    // validate weights.\n-    for (Node rack : root.getChildren()) {\n-      Assert.assertEquals(rack.getWeight(), (long) nodeToWeightMap.get(rack.getName()));\n-    }\n-  }\n-}"
            },
            {
                "sha": "4266408624999d6f2c88e65e5433810e28defec7",
                "filename": "helix-core/src/test/java/org/apache/helix/controller/strategy/TestTopology.java",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/9bf4437aa3ffe64d4cb983fea0a6b81162edeed9/helix-core/src/test/java/org/apache/helix/controller/strategy/TestTopology.java",
                "raw_url": "https://github.com/apache/helix/raw/9bf4437aa3ffe64d4cb983fea0a6b81162edeed9/helix-core/src/test/java/org/apache/helix/controller/strategy/TestTopology.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/controller/strategy/TestTopology.java?ref=9bf4437aa3ffe64d4cb983fea0a6b81162edeed9",
                "patch": "@@ -1,6 +1,5 @@\n-package org.apache.helix.controller.Strategy;\n+package org.apache.helix.controller.strategy;\n \n-import org.apache.helix.HelixProperty;\n import org.apache.helix.controller.rebalancer.topology.Node;\n import org.apache.helix.controller.rebalancer.topology.Topology;\n import org.apache.helix.model.ClusterConfig;\n@@ -34,7 +33,7 @@\n  */\n \n public class TestTopology {\n-  private static Logger logger = Logger.getLogger(TestTopology.class);\n+  private static Logger logger = Logger.getLogger(TestAutoRebalanceStrategy.class);\n \n   @Test\n   public void testCreateClusterTopology() {\n@@ -170,3 +169,4 @@ public void testCreateClusterTopologyWithDefaultTopology() {\n     }\n   }\n }\n+"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/dca1ed05bfccce69814fdb59b095d734d1c82de0",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/f5705dc9201716543c72427c004f1f64211e304e",
        "message": "Fix NPE when first time call WorkflowRebalancer",
        "bug_id": "helix_36",
        "file": [
            {
                "sha": "7f996c5a2896276675fb2be68ee1afc41bfe7fcb",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/dca1ed05bfccce69814fdb59b095d734d1c82de0/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/dca1ed05bfccce69814fdb59b095d734d1c82de0/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/mbeans/ClusterStatusMonitor.java?ref=dca1ed05bfccce69814fdb59b095d734d1c82de0",
                "patch": "@@ -463,6 +463,11 @@ public void updateJobCounters(JobConfig jobConfig, TaskState to) {\n   }\n \n   private void updateJobGauges(JobConfig jobConfig, TaskState current) {\n+    // When first time for WorkflowRebalancer call, jobconfig may not ready.\n+    // Thus only check it for gauge.\n+    if (jobConfig == null) {\n+      return;\n+    }\n     String jobType = jobConfig.getJobType();\n     jobType = preProcessJobMonitor(jobType);\n     _perTypeJobMonitorMap.get(jobType).updateJobGauge(current);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/90ef589aa47ef1726356ce5ea37e12d27372b342",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/0e4163f18c1274c0f77320698e9dfbf42314810d",
        "message": "[HELIX-699] Compare InstanceConfigs using their IDs in RoutingTable\n\nA possible race condition was causing a NPE on InstanceConfig.getHostName(). Instead of comparing hostnames and ports, we compare IDs, which are supposed to be concatenation of instance name, hostname, and port anyways and should always be set.",
        "bug_id": "helix_37",
        "file": [
            {
                "sha": "46cf4711a48c0fff5ef26ab66218eee134db8d04",
                "filename": "helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "status": "modified",
                "additions": 6,
                "deletions": 11,
                "changes": 17,
                "blob_url": "https://github.com/apache/helix/blob/90ef589aa47ef1726356ce5ea37e12d27372b342/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "raw_url": "https://github.com/apache/helix/raw/90ef589aa47ef1726356ce5ea37e12d27372b342/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/spectator/RoutingTable.java?ref=90ef589aa47ef1726356ce5ea37e12d27372b342",
                "patch": "@@ -464,23 +464,18 @@ boolean containsState(String state) {\n   private static Comparator<InstanceConfig> INSTANCE_CONFIG_COMPARATOR =\n       new Comparator<InstanceConfig>() {\n         @Override\n-        public int compare(InstanceConfig o1, InstanceConfig o2) {\n-          if (o1 == o2) {\n+        public int compare(InstanceConfig config1, InstanceConfig config2) {\n+          if (config1 == config2) {\n             return 0;\n           }\n-          if (o1 == null) {\n+          if (config1 == null) {\n             return -1;\n           }\n-          if (o2 == null) {\n+          if (config2 == null) {\n             return 1;\n           }\n-\n-          int compareTo = o1.getHostName().compareTo(o2.getHostName());\n-          if (compareTo == 0) {\n-            return o1.getPort().compareTo(o2.getPort());\n-          }\n-\n-          return compareTo;\n+          // IDs for InstanceConfigs are a concatenation of instance name, host, and port.\n+          return config1.getId().compareTo(config2.getId());\n         }\n       };\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/6d42db462bc65ed9f94f22ca6e2de83cb703ea87",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/d213c1a7b3fc310d38749f9555e5660858c37c3b",
        "message": "TaskUtil.getWorkflowCfg throws NPE if workflow doesn't exist.",
        "bug_id": "helix_38",
        "file": [
            {
                "sha": "b55d9d0a1011c1d0a6c2f05282a3e78217e7042a",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "status": "modified",
                "additions": 8,
                "deletions": 7,
                "changes": 15,
                "blob_url": "https://github.com/apache/helix/blob/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java?ref=6d42db462bc65ed9f94f22ca6e2de83cb703ea87",
                "patch": "@@ -222,7 +222,8 @@ public void start(Workflow flow) {\n    *\n    * Example:\n    *\n-   * WorkflowConfig currentWorkflowConfig = TaskUtil.getWorkflowCfg(_manager, workflow);\n+   * _driver = new TaskDriver ...\n+   * WorkflowConfig currentWorkflowConfig = _driver.getWorkflowCfg(_manager, workflow);\n    * WorkflowConfig.Builder configBuilder = new WorkflowConfig.Builder(currentWorkflowConfig);\n \n    * // make needed changes to the config here\n@@ -236,7 +237,7 @@ public void start(Workflow flow) {\n    */\n   public void updateWorkflow(String workflow, WorkflowConfig newWorkflowConfig) {\n     WorkflowConfig currentConfig =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, workflow);\n+        TaskUtil.getWorkflowCfg(_accessor, workflow);\n     if (currentConfig == null) {\n       throw new HelixException(\"Workflow \" + workflow + \" does not exist!\");\n     }\n@@ -270,7 +271,7 @@ public void createQueue(JobQueue queue) {\n   // TODO: need to make sure the queue is stopped or completed before flush the queue.\n   public void flushQueue(String queueName) {\n     WorkflowConfig config =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n     if (config == null) {\n       throw new IllegalArgumentException(\"Queue does not exist!\");\n     }\n@@ -339,7 +340,7 @@ public ZNRecord update(ZNRecord currentData) {\n    */\n   public void deleteJob(final String queueName, final String jobName) {\n     WorkflowConfig workflowCfg =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n \n     if (workflowCfg == null) {\n       throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n@@ -384,7 +385,7 @@ public void deleteJob(final String queueName, final String jobName) {\n    */\n   private void deleteJobFromScheduledQueue(final String queueName, final String jobName) {\n     WorkflowConfig workflowCfg =\n-        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+        TaskUtil.getWorkflowCfg(_accessor, queueName);\n \n     if (workflowCfg == null) {\n       throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n@@ -696,7 +697,7 @@ public ZNRecord update(ZNRecord currentData) {\n   }\n \n   public WorkflowConfig getWorkflowConfig(String workflow) {\n-    return TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, workflow);\n+    return TaskUtil.getWorkflowCfg(_accessor, workflow);\n   }\n \n   public WorkflowContext getWorkflowContext(String workflow) {\n@@ -712,7 +713,7 @@ public JobContext getJobContext(String job) {\n   }\n \n   public void list(String resource) {\n-    WorkflowConfig wCfg = TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, resource);\n+    WorkflowConfig wCfg = TaskUtil.getWorkflowCfg(_accessor, resource);\n     if (wCfg == null) {\n       LOG.error(\"Workflow \" + resource + \" does not exist!\");\n       return;"
            },
            {
                "sha": "ca274d08fe4ccc3208c913ee38bbc3c1f2ec6dfa",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "status": "modified",
                "additions": 12,
                "deletions": 29,
                "changes": 41,
                "blob_url": "https://github.com/apache/helix/blob/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java?ref=6d42db462bc65ed9f94f22ca6e2de83cb703ea87",
                "patch": "@@ -30,7 +30,6 @@\n import java.util.concurrent.TimeUnit;\n \n import org.apache.helix.AccessOption;\n-import org.apache.helix.ConfigAccessor;\n import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixException;\n import org.apache.helix.HelixManager;\n@@ -40,7 +39,6 @@\n import org.apache.helix.model.CurrentState;\n import org.apache.helix.model.HelixConfigScope;\n import org.apache.helix.model.IdealState;\n-import org.apache.helix.model.ResourceAssignment;\n import org.apache.helix.model.builder.HelixConfigScopeBuilder;\n import org.apache.helix.store.HelixPropertyStore;\n import org.apache.log4j.Logger;\n@@ -98,21 +96,19 @@ public static JobConfig getJobCfg(HelixManager manager, String jobResource) {\n   /**\n    * Parses workflow resource configurations in Helix into a {@link WorkflowConfig} object.\n    *\n-   * @param cfgAccessor      Config accessor to access Helix configs\n-   * @param accessor         Accessor to access Helix configs\n-   * @param clusterName      Cluster name\n-   * @param workflowResource The name of the workflow resource.\n+   * @param accessor  Accessor to access Helix configs\n+   * @param workflow The name of the workflow.\n    * @return A {@link WorkflowConfig} object if Helix contains valid configurations for the\n    * workflow, null otherwise.\n    */\n-  public static WorkflowConfig getWorkflowCfg(ConfigAccessor cfgAccessor,\n-      HelixDataAccessor accessor, String clusterName, String workflowResource) {\n-    Map<String, String> workflowCfg =\n-        getResourceConfigMap(cfgAccessor, accessor, clusterName, workflowResource);\n+  public static WorkflowConfig getWorkflowCfg(HelixDataAccessor accessor, String workflow) {\n+    HelixProperty workflowCfg = getResourceConfig(accessor, workflow);\n     if (workflowCfg == null) {\n       return null;\n     }\n-    WorkflowConfig.Builder b = WorkflowConfig.Builder.fromMap(workflowCfg);\n+\n+    WorkflowConfig.Builder b =\n+        WorkflowConfig.Builder.fromMap(workflowCfg.getRecord().getSimpleFields());\n \n     return b.build();\n   }\n@@ -121,13 +117,12 @@ public static WorkflowConfig getWorkflowCfg(ConfigAccessor cfgAccessor,\n    * Parses workflow resource configurations in Helix into a {@link WorkflowConfig} object.\n    *\n    * @param manager          Helix manager object used to connect to Helix.\n-   * @param workflowResource The name of the workflow resource.\n+   * @param workflow The name of the workflow resource.\n    * @return A {@link WorkflowConfig} object if Helix contains valid configurations for the\n    * workflow, null otherwise.\n    */\n-  public static WorkflowConfig getWorkflowCfg(HelixManager manager, String workflowResource) {\n-    return getWorkflowCfg(manager.getConfigAccessor(), manager.getHelixDataAccessor(),\n-        manager.getClusterName(), workflowResource);\n+  public static WorkflowConfig getWorkflowCfg(HelixManager manager, String workflow) {\n+    return getWorkflowCfg(manager.getHelixDataAccessor(), workflow);\n   }\n \n   /**\n@@ -452,18 +447,6 @@ public static Workflow cloneWorkflow(HelixManager manager, String origWorkflowNa\n     return workflowBuilder.build();\n   }\n \n-  private static Map<String, String> getResourceConfigMap(ConfigAccessor cfgAccessor,\n-      HelixDataAccessor accessor, String clusterName, String resource) {\n-    HelixConfigScope scope = getResourceConfigScope(clusterName, resource);\n-\n-    List<String> cfgKeys = cfgAccessor.getKeys(scope);\n-    if (cfgKeys == null || cfgKeys.isEmpty()) {\n-      return null;\n-    }\n-\n-    return getResourceConfig(accessor, resource).getRecord().getSimpleFields();\n-  }\n-\n   private static HelixProperty getResourceConfig(HelixDataAccessor accessor, String resource) {\n     PropertyKey.Builder keyBuilder = accessor.keyBuilder();\n     return accessor.getProperty(keyBuilder.resourceConfig(resource));\n@@ -522,7 +505,7 @@ public static String getWorkflowContextKey(String resource) {\n     return Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, resource);\n   }\n \n-  public static PropertyKey getWorkflowConfigKey(HelixDataAccessor accessor, String resource) {\n-    return accessor.keyBuilder().resourceConfig(resource);\n+  public static PropertyKey getWorkflowConfigKey(HelixDataAccessor accessor, String workflow) {\n+    return accessor.keyBuilder().resourceConfig(workflow);\n   }\n }"
            },
            {
                "sha": "d83c5ebed765cf0c3ac85667d78e85cba4d1c961",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "raw_url": "https://github.com/apache/helix/raw/6d42db462bc65ed9f94f22ca6e2de83cb703ea87/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestRecurringJobQueue.java?ref=6d42db462bc65ed9f94f22ca6e2de83cb703ea87",
                "patch": "@@ -47,6 +47,8 @@\n import org.apache.helix.task.TaskState;\n import org.apache.helix.task.TaskStateModelFactory;\n import org.apache.helix.task.TaskUtil;\n+import org.apache.helix.task.Workflow;\n+import org.apache.helix.task.WorkflowConfig;\n import org.apache.helix.task.WorkflowContext;\n import org.apache.helix.tools.ClusterSetup;\n import org.apache.helix.tools.ClusterStateVerifier;\n@@ -367,6 +369,20 @@ public void deleteJobFromRecurrentQueueNotStarted() throws Exception {\n         String.format(\"%s_%s\", scheduledQueue, jobNames.get(JOB_COUNTS - 1)));\n   }\n \n+  @Test\n+  public void testGetNoExistWorkflowConfig() {\n+    String randomName = \"randomJob\";\n+    WorkflowConfig workflowConfig = _driver.getWorkflowConfig(randomName);\n+    Assert.assertNull(workflowConfig);\n+    JobConfig jobConfig = _driver.getJobConfig(randomName);\n+    Assert.assertNull(jobConfig);\n+    WorkflowContext workflowContext = _driver.getWorkflowContext(randomName);\n+    Assert.assertNull(workflowContext);\n+    JobContext jobContext = _driver.getJobContext(randomName);\n+    Assert.assertNull(jobContext);\n+\n+  }\n+\n   private void verifyJobDeleted(String queueName, String jobName) throws Exception {\n     HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n     PropertyKey.Builder keyBuilder = accessor.keyBuilder();"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/10114cd0a201344c58bd9b1e51311d69011c5198",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/826d6c00832851124219f9d72da430e751e07300",
        "message": "Bug fix\n\n(1) HelixTaskExecutor checks whether MsgHandlerFactoryRegistryItem\nexists.\n(2) ZkHelixManager, onMessage callback might occur before\nsessionStartTime is set, which will cause NPE. Set the time first before\nregistering the message listener.",
        "bug_id": "helix_39",
        "file": [
            {
                "sha": "cded08603f8869b5142e68b5428f85fd0f25cf0d",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "raw_url": "https://github.com/apache/helix/raw/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=10114cd0a201344c58bd9b1e51311d69011c5198",
                "patch": "@@ -881,6 +881,8 @@ public void handleNewSession() throws Exception {\n       throw new HelixException(\"Cluster structure is not set up for cluster: \" + _clusterName);\n     }\n \n+    _sessionStartTime = System.currentTimeMillis();\n+\n     switch (_instanceType) {\n     case PARTICIPANT:\n       handleNewSessionAsParticipant();\n@@ -898,8 +900,6 @@ public void handleNewSession() throws Exception {\n       break;\n     }\n \n-    _sessionStartTime = System.currentTimeMillis();\n-\n     startTimerTasks();\n \n     /**"
            },
            {
                "sha": "717bbcf63345bcc5ceb5865768235573821b29b3",
                "filename": "helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "raw_url": "https://github.com/apache/helix/raw/10114cd0a201344c58bd9b1e51311d69011c5198/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/messaging/handling/HelixTaskExecutor.java?ref=10114cd0a201344c58bd9b1e51311d69011c5198",
                "patch": "@@ -881,16 +881,16 @@ public MessageHandler createMessageHandler(Message message, NotificationContext\n     String msgType = message.getMsgType().toString();\n \n     MsgHandlerFactoryRegistryItem item = _hdlrFtyRegistry.get(msgType);\n-    MessageHandlerFactory handlerFactory = item.factory();\n \n     // Fail to find a MessageHandlerFactory for the message\n     // we will keep the message and the message will be handled when\n     // the corresponding MessageHandlerFactory is registered\n-    if (handlerFactory == null) {\n+    if (item == null) {\n       LOG.warn(\"Fail to find message handler factory for type: \" + msgType + \" msgId: \"\n           + message.getMsgId());\n       return null;\n     }\n+    MessageHandlerFactory handlerFactory = item.factory();\n \n     // pass the executor to msg-handler since batch-msg-handler needs task-executor to schedule\n     // sub-msgs"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/6b6bb8f601099b4de5189172b050d5f1df2e2a41",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/1dc2aae0dbbf37e68cf68e6f72b171057ecaff4a",
        "message": "[Helix-624] Fix NPE in TestMessageService.TestMultiMessageCriteria",
        "bug_id": "helix_40",
        "file": [
            {
                "sha": "030a0c001f1db9b575c90bbc4e10f2820bacacb5",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestMessagingService.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/6b6bb8f601099b4de5189172b050d5f1df2e2a41/helix-core/src/test/java/org/apache/helix/integration/TestMessagingService.java",
                "raw_url": "https://github.com/apache/helix/raw/6b6bb8f601099b4de5189172b050d5f1df2e2a41/helix-core/src/test/java/org/apache/helix/integration/TestMessagingService.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestMessagingService.java?ref=6b6bb8f601099b4de5189172b050d5f1df2e2a41",
                "patch": "@@ -286,7 +286,7 @@ public void TestMultiMessageCriteria() throws Exception {\n     for (int i = 0; i < NODE_NR; i++) {\n       TestMessagingHandlerFactory factory = new TestMessagingHandlerFactory();\n       String hostDest = \"localhost_\" + (START_PORT + i);\n-      _participants[0].getMessagingService().registerMessageHandlerFactory(\n+      _participants[i].getMessagingService().registerMessageHandlerFactory(\n           factory.getMessageType(), factory);\n \n     }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/590f65cf9538435c89dfd71922479b281a159e60",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5",
        "message": "[HELIX-445] NPE in ZkPathDataDumpTask, rb=21504",
        "bug_id": "helix_41",
        "file": [
            {
                "sha": "67b28973bebcd2715011a32a986f0a1bc841c4b8",
                "filename": "helix-core/pom.xml",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/pom.xml",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/pom.xml?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -124,6 +124,11 @@ under the License.\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.mockito</groupId>\n+      <artifactId>mockito-all</artifactId>\n+      <scope>test</scope>\n+    </dependency>\n     <dependency>\n       <groupId>org.apache.commons</groupId>\n       <artifactId>commons-math</artifactId>"
            },
            {
                "sha": "f4e47a0e286e9ecc7a05a7b0feb95a86c7921523",
                "filename": "helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "status": "modified",
                "additions": 27,
                "deletions": 0,
                "changes": 27,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/PropertyKey.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/PropertyKey.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -408,6 +408,15 @@ public PropertyKey stateTransitionStatus(String instanceName, String sessionId)\n           sessionId);\n     }\n \n+    /**\n+     * Get a property key associated with {@link StatusUpdate} of an instance\n+     * @param instanceName\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey stateTransitionStatus(String instanceName) {\n+      return new PropertyKey(STATUSUPDATES, StatusUpdate.class, _clusterName, instanceName);\n+    }\n+\n     /**\n      * Used to get status update for a NON STATE TRANSITION type\n      * @param instanceName\n@@ -451,6 +460,16 @@ public PropertyKey stateTransitionErrors(String instanceName, String sessionId,\n           resourceName);\n     }\n \n+    /**\n+     * Get a property key associated with {@link Error} of an instance, session, and\n+     * resource\n+     * @param instanceName\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey stateTransitionErrors(String instanceName) {\n+      return new PropertyKey(ERRORS, Error.class, _clusterName, instanceName);\n+    }\n+\n     /**\n      * Used to get status update for a NON STATE TRANSITION type\n      * @param instanceName\n@@ -525,6 +544,14 @@ public PropertyKey controllerTaskStatus(String subPath, String recordName) {\n           recordName);\n     }\n \n+    /**\n+     * Get a property key associated with {@link StatusUpdate} of controller status updates\n+     * @return {@link PropertyKey}\n+     */\n+    public PropertyKey controllerTaskStatuses() {\n+      return new PropertyKey(STATUSUPDATES_CONTROLLER, StatusUpdate.class, _clusterName);\n+    }\n+\n     /**\n      * Get a property key associated with all {@link Message}s for the controller\n      * @return {@link PropertyKey}"
            },
            {
                "sha": "01bbaf3ead19afd0971831004f84c7a86e7f443c",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "status": "modified",
                "additions": 5,
                "deletions": 7,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -131,11 +131,9 @@\n    */\n   static class StatusDumpTask extends HelixTimerTask {\n     Timer _timer = null;\n-    final ZkClient zkclient;\n     final HelixManager helixController;\n \n-    public StatusDumpTask(ZkClient zkclient, HelixManager helixController) {\n-      this.zkclient = zkclient;\n+    public StatusDumpTask(HelixManager helixController) {\n       this.helixController = helixController;\n     }\n \n@@ -148,8 +146,8 @@ public void start() {\n       if (_timer == null) {\n         LOG.info(\"Start StatusDumpTask\");\n         _timer = new Timer(\"StatusDumpTimerTask\", true);\n-        _timer.scheduleAtFixedRate(new ZKPathDataDumpTask(helixController, zkclient,\n-            timeThresholdNoChange), initialDelay, period);\n+        _timer.scheduleAtFixedRate(new ZKPathDataDumpTask(helixController, timeThresholdNoChange),\n+            initialDelay, period);\n       }\n     }\n \n@@ -216,12 +214,12 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n       break;\n     case CONTROLLER:\n       _stateMachineEngine = null;\n-      _controllerTimerTasks.add(new StatusDumpTask(_zkclient, this));\n+      _controllerTimerTasks.add(new StatusDumpTask(this));\n \n       break;\n     case CONTROLLER_PARTICIPANT:\n       _stateMachineEngine = new HelixStateMachineEngine(this);\n-      _controllerTimerTasks.add(new StatusDumpTask(_zkclient, this));\n+      _controllerTimerTasks.add(new StatusDumpTask(this));\n       break;\n     case ADMINISTRATOR:\n     case SPECTATOR:"
            },
            {
                "sha": "a0190d2be24a3b9ee5992310023c38987c958524",
                "filename": "helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "status": "modified",
                "additions": 90,
                "deletions": 83,
                "changes": 173,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/monitoring/ZKPathDataDumpTask.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -19,36 +19,35 @@\n  * under the License.\n  */\n \n-import java.io.StringWriter;\n-import java.util.Date;\n import java.util.List;\n import java.util.TimerTask;\n \n+import org.apache.helix.BaseDataAccessor;\n import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n import org.apache.helix.PropertyType;\n import org.apache.helix.ZNRecord;\n import org.apache.helix.PropertyKey.Builder;\n import org.apache.helix.manager.zk.ZNRecordSerializer;\n-import org.apache.helix.manager.zk.ZkClient;\n import org.apache.helix.util.HelixUtil;\n import org.apache.log4j.Logger;\n import org.apache.zookeeper.data.Stat;\n-import org.codehaus.jackson.map.ObjectMapper;\n-import org.codehaus.jackson.map.SerializationConfig;\n+\n+import com.google.common.collect.Lists;\n \n public class ZKPathDataDumpTask extends TimerTask {\n-  static Logger logger = Logger.getLogger(ZKPathDataDumpTask.class);\n+  static Logger LOG = Logger.getLogger(ZKPathDataDumpTask.class);\n \n   private final int _thresholdNoChangeInMs;\n   private final HelixManager _manager;\n-  private final ZkClient _zkClient;\n+  private final ZNRecordSerializer _jsonSerializer;\n+\n+  public ZKPathDataDumpTask(HelixManager manager, int thresholdNoChangeInMs) {\n+    LOG.info(\"Init ZKPathDataDumpTask for cluster: \" + manager.getClusterName()\n+        + \", thresholdNoChangeInMs: \" + thresholdNoChangeInMs);\n \n-  public ZKPathDataDumpTask(HelixManager manager, ZkClient zkClient, int thresholdNoChangeInMs) {\n     _manager = manager;\n-    _zkClient = zkClient;\n-    logger.info(\"Scanning cluster statusUpdate \" + manager.getClusterName()\n-        + \" thresholdNoChangeInMs: \" + thresholdNoChangeInMs);\n+    _jsonSerializer = new ZNRecordSerializer();\n     _thresholdNoChangeInMs = thresholdNoChangeInMs;\n   }\n \n@@ -59,88 +58,96 @@ public void run() {\n     // We need to think if we should create per-instance log files that contains\n     // per-instance statusUpdates\n     // and errors\n-    logger.info(\"Scanning status updates ...\");\n-    try {\n-      HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n-      Builder keyBuilder = accessor.keyBuilder();\n-\n-      List<String> instances = accessor.getChildNames(keyBuilder.instanceConfigs());\n-      for (String instanceName : instances) {\n-        scanPath(HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instanceName,\n-            PropertyType.STATUSUPDATES), _thresholdNoChangeInMs);\n-        scanPath(HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instanceName,\n-            PropertyType.ERRORS), _thresholdNoChangeInMs * 3);\n-      }\n-      scanPath(HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n-          PropertyType.STATUSUPDATES_CONTROLLER), _thresholdNoChangeInMs);\n+    LOG.info(\"Scan statusUpdates and errors for cluster: \" + _manager.getClusterName()\n+        + \", by controller: \" + _manager);\n+    HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n+    Builder keyBuilder = accessor.keyBuilder();\n+    BaseDataAccessor<ZNRecord> baseAccessor = accessor.getBaseDataAccessor();\n+\n+    List<String> instances = accessor.getChildNames(keyBuilder.instanceConfigs());\n+    for (String instance : instances) {\n+      // dump participant status updates\n+      String statusUpdatePath =\n+          HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instance,\n+              PropertyType.STATUSUPDATES);\n+      dump(baseAccessor, statusUpdatePath, _thresholdNoChangeInMs);\n \n-      scanPath(HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n-          PropertyType.ERRORS_CONTROLLER), _thresholdNoChangeInMs * 3);\n-    } catch (Exception e) {\n-      logger.error(e);\n+      // dump participant errors\n+      String errorPath =\n+          HelixUtil.getInstancePropertyPath(_manager.getClusterName(), instance,\n+              PropertyType.ERRORS);\n+      dump(baseAccessor, errorPath, _thresholdNoChangeInMs * 3);\n     }\n+    // dump controller status updates\n+    String controllerStatusUpdatePath =\n+        HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n+            PropertyType.STATUSUPDATES_CONTROLLER);\n+    dump(baseAccessor, controllerStatusUpdatePath, _thresholdNoChangeInMs);\n+\n+    // dump controller errors\n+    String controllerErrorPath =\n+        HelixUtil.getControllerPropertyPath(_manager.getClusterName(),\n+            PropertyType.ERRORS_CONTROLLER);\n+    dump(baseAccessor, controllerErrorPath, _thresholdNoChangeInMs);\n   }\n \n-  void scanPath(String path, int thresholdNoChangeInMs) {\n-    logger.info(\"Scanning path \" + path);\n-    List<String> subPaths = _zkClient.getChildren(path);\n-    for (String subPath : subPaths) {\n-      try {\n-        String nextPath = path + \"/\" + subPath;\n-        List<String> subSubPaths = _zkClient.getChildren(nextPath);\n-        for (String subsubPath : subSubPaths) {\n-          try {\n-            checkAndDump(nextPath + \"/\" + subsubPath, thresholdNoChangeInMs);\n-          } catch (Exception e) {\n-            logger.error(e);\n-          }\n-        }\n-      } catch (Exception e) {\n-        logger.error(e);\n+  /**\n+   * Find paths of all leaf nodes under an ancestor path (exclusive)\n+   * @param accessor\n+   * @param ancestorPath\n+   * @return a list of paths\n+   */\n+  static List<String> scanPath(BaseDataAccessor<ZNRecord> accessor, String ancestorPath) {\n+    List<String> queue = Lists.newLinkedList();\n+    queue.add(ancestorPath);\n+\n+    // BFS\n+    List<String> leafPaths = Lists.newArrayList();\n+    while (!queue.isEmpty()) {\n+      String path = queue.remove(0);\n+      List<String> childNames = accessor.getChildNames(path, 0);\n+      if (childNames == null) {\n+        // path doesn't exist\n+        continue;\n+      }\n+      if (childNames.isEmpty() && !path.equals(ancestorPath)) {\n+        // leaf node, excluding ancestorPath\n+        leafPaths.add(path);\n+      }\n+      for (String childName : childNames) {\n+        String subPath = String.format(\"%s/%s\", path, childName);\n+        queue.add(subPath);\n       }\n     }\n+    return leafPaths;\n   }\n \n-  void checkAndDump(String path, int thresholdNoChangeInMs) {\n-    List<String> subPaths = _zkClient.getChildren(path);\n-    if (subPaths.size() == 0) {\n-      subPaths.add(\"\");\n+  void dump(BaseDataAccessor<ZNRecord> accessor, String ancestorPath, int threshold) {\n+    List<String> leafPaths = scanPath(accessor, ancestorPath);\n+    if (leafPaths.isEmpty()) {\n+      return;\n+    }\n+\n+    Stat[] stats = accessor.getStats(leafPaths, 0);\n+    List<String> dumpPaths = Lists.newArrayList();\n+    long now = System.currentTimeMillis();\n+    for (int i = 0; i < stats.length; i++) {\n+      Stat stat = stats[i];\n+      if ((now - stat.getMtime()) > threshold) {\n+        dumpPaths.add(leafPaths.get(i));\n+      }\n     }\n-    for (String subPath : subPaths) {\n-      String fullPath = subPath.length() > 0 ? path + \"/\" + subPath : path;\n-      Stat pathStat = _zkClient.getStat(fullPath);\n-\n-      long lastModifiedTimeInMs = pathStat.getMtime();\n-      long nowInMs = new Date().getTime();\n-      // logger.info(nowInMs + \" \" + lastModifiedTimeInMs + \" \" + fullPath);\n-\n-      // Check the last modified time\n-      if (nowInMs > lastModifiedTimeInMs) {\n-        long timeDiff = nowInMs - lastModifiedTimeInMs;\n-        if (timeDiff > thresholdNoChangeInMs) {\n-          logger.info(\"Dumping status update path \" + fullPath + \" \" + timeDiff + \"MS has passed\");\n-          _zkClient.setZkSerializer(new ZNRecordSerializer());\n-          ZNRecord record = _zkClient.readData(fullPath);\n-\n-          // dump the node content into log file\n-          ObjectMapper mapper = new ObjectMapper();\n-          SerializationConfig serializationConfig = mapper.getSerializationConfig();\n-          serializationConfig.set(SerializationConfig.Feature.INDENT_OUTPUT, true);\n-\n-          StringWriter sw = new StringWriter();\n-          try {\n-            mapper.writeValue(sw, record);\n-            logger.info(sw.toString());\n-          } catch (Exception e) {\n-            logger\n-                .warn(\n-                    \"Exception during serialization in ZKPathDataDumpTask.checkAndDump. This can mostly be ignored\",\n-                    e);\n-          }\n-          // Delete the leaf data\n-          _zkClient.deleteRecursive(fullPath);\n-        }\n+\n+    // dump\n+    LOG.info(\"Dump statusUpdates and errors records for pahts: \" + dumpPaths);\n+    List<ZNRecord> dumpRecords = accessor.get(dumpPaths, null, 0);\n+    for (ZNRecord record : dumpRecords) {\n+      if (record != null) {\n+        LOG.info(new String(_jsonSerializer.serialize(record)));\n       }\n     }\n+\n+    // clean up\n+    accessor.remove(dumpPaths, 0);\n   }\n }"
            },
            {
                "sha": "93ceedb0d425e26012f2b55707faa4100749555e",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "status": "modified",
                "additions": 14,
                "deletions": 27,
                "changes": 41,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestHelixCustomCodeRunner.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -21,6 +21,7 @@\n \n import java.util.Date;\n \n+import org.apache.helix.HelixDataAccessor;\n import org.apache.helix.HelixManager;\n import org.apache.helix.NotificationContext;\n import org.apache.helix.TestHelper;\n@@ -32,7 +33,6 @@\n import org.apache.helix.integration.manager.MockParticipantManager;\n import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n-import org.apache.helix.mock.participant.MockJobIntf;\n import org.apache.helix.model.LiveInstance;\n import org.apache.helix.participant.CustomCodeCallbackHandler;\n import org.apache.helix.participant.HelixCustomCodeRunner;\n@@ -62,30 +62,20 @@ public void onCallback(NotificationContext context) {\n \n   }\n \n-  class MockJob implements MockJobIntf {\n-    @Override\n-    public void doPreConnectJob(HelixManager manager) {\n-      try {\n-        // delay the start of the 1st participant\n-        // so there will be a leadership transfer from localhost_12919 to 12918\n-        if (manager.getInstanceName().equals(\"localhost_12918\")) {\n-          Thread.sleep(2000);\n-        }\n-\n-        HelixCustomCodeRunner customCodeRunner = new HelixCustomCodeRunner(manager, ZK_ADDR);\n-        customCodeRunner.invoke(_callback).on(ChangeType.LIVE_INSTANCE)\n-            .usingLeaderStandbyModel(\"TestParticLeader\").start();\n-      } catch (Exception e) {\n-        LOG.error(\"Exception do pre-connect job\", e);\n+  private void registerCustomCodeRunner(HelixManager manager) {\n+    try {\n+      // delay the start of the 1st participant\n+      // so there will be a leadership transfer from localhost_12919 to 12918\n+      if (manager.getInstanceName().equals(\"localhost_12918\")) {\n+        Thread.sleep(2000);\n       }\n-    }\n-\n-    @Override\n-    public void doPostConnectJob(HelixManager manager) {\n-      // TODO Auto-generated method stub\n \n+      HelixCustomCodeRunner customCodeRunner = new HelixCustomCodeRunner(manager, ZK_ADDR);\n+      customCodeRunner.invoke(_callback).on(ChangeType.LIVE_INSTANCE)\n+          .usingLeaderStandbyModel(\"TestParticLeader\").start();\n+    } catch (Exception e) {\n+      LOG.error(\"Exception do pre-connect job\", e);\n     }\n-\n   }\n \n   @Test\n@@ -109,10 +99,9 @@ public void testCustomCodeRunner() throws Exception {\n     for (int i = 0; i < _nodeNb; i++) {\n       String instanceName = \"localhost_\" + (_startPort + i);\n \n-      MockJob job = new MockJob();\n       participants[i] = new MockParticipantManager(ZK_ADDR, _clusterName, instanceName);\n \n-      job.doPreConnectJob(participants[i]);\n+      registerCustomCodeRunner(participants[i]);\n       participants[i].syncStart();\n     }\n     boolean result =\n@@ -125,9 +114,7 @@ public void testCustomCodeRunner() throws Exception {\n     _callback._isCallbackInvoked = false;\n \n     // add a new live instance\n-    // ZkClient zkClient = new ZkClient(ZK_ADDR);\n-    // zkClient.setZkSerializer(new ZNRecordSerializer());\n-    ZKHelixDataAccessor accessor =\n+    HelixDataAccessor accessor =\n         new ZKHelixDataAccessor(_clusterName, new ZkBaseDataAccessor<ZNRecord>(_gZkClient));\n     Builder keyBuilder = accessor.keyBuilder();\n "
            },
            {
                "sha": "cb6e186f9157aeb209efbb0e49f0209eb2dec70b",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestSchedulerMessage.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -393,7 +393,7 @@ public void testSchedulerMsg() throws Exception {\n       }\n     }\n     Thread.sleep(3000);\n-    ZKPathDataDumpTask dumpTask = new ZKPathDataDumpTask(manager, _gZkClient, 0);\n+    ZKPathDataDumpTask dumpTask = new ZKPathDataDumpTask(manager, 0);\n     dumpTask.run();\n \n     subPaths = _gZkClient.getChildren(controllerStatusPath);"
            },
            {
                "sha": "917be1741a266f099729f1dc7f355d9738a58098",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/manager/MockParticipantManager.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -28,7 +28,6 @@\n import org.apache.helix.manager.zk.ZkClient;\n import org.apache.helix.mock.participant.DummyProcess.DummyLeaderStandbyStateModelFactory;\n import org.apache.helix.mock.participant.DummyProcess.DummyOnlineOfflineStateModelFactory;\n-import org.apache.helix.mock.participant.MockJobIntf;\n import org.apache.helix.mock.participant.MockMSModelFactory;\n import org.apache.helix.mock.participant.MockSchemataModelFactory;\n import org.apache.helix.mock.participant.MockTransition;"
            },
            {
                "sha": "4b637a6abe322d2f26e782b4162a52cf314548e5",
                "filename": "helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "status": "removed",
                "additions": 0,
                "deletions": 28,
                "changes": 28,
                "blob_url": "https://github.com/apache/helix/blob/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "raw_url": "https://github.com/apache/helix/raw/8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/mock/participant/MockJobIntf.java?ref=8d5c27c139b7f5ce84f0a6dd8eaf3d5a48a866c5",
                "patch": "@@ -1,28 +0,0 @@\n-package org.apache.helix.mock.participant;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-import org.apache.helix.HelixManager;\n-\n-public interface MockJobIntf {\n-  public void doPreConnectJob(HelixManager manager);\n-\n-  public void doPostConnectJob(HelixManager manager);\n-}"
            },
            {
                "sha": "5f44b364e439fd8ceb1c14c4cd695eec83355056",
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestParticipantMonitor.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -96,10 +96,8 @@ public void onMBeanUnRegistered(MBeanServerConnection server,\n     }\n   }\n \n-  @Test(groups = {\n-    \"unitTest\"\n-  })\n-  public void TestReportData() throws InstanceNotFoundException, MalformedObjectNameException,\n+  @Test()\n+  public void testReportData() throws InstanceNotFoundException, MalformedObjectNameException,\n       NullPointerException, IOException, InterruptedException {\n     System.out.println(\"START TestParticipantMonitor\");\n     ParticipantMonitor monitor = new ParticipantMonitor();"
            },
            {
                "sha": "7a4a941851b34a4476901beb92729588baff0feb",
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "status": "modified",
                "additions": 2,
                "deletions": 4,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestStatCollector.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -23,10 +23,8 @@\n import org.testng.annotations.Test;\n \n public class TestStatCollector {\n-  @Test(groups = {\n-    \"unitTest\"\n-  })\n-  public void TestCollectData() {\n+  @Test()\n+  public void testCollectData() {\n     StatCollector collector = new StatCollector();\n \n     int nPoints = 100;"
            },
            {
                "sha": "a3d8ae346fe78e712db34b6098e66dae5b0d87e4",
                "filename": "helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "status": "added",
                "additions": 113,
                "deletions": 0,
                "changes": 113,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/monitoring/TestZKPathDataDumpTask.java?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -0,0 +1,113 @@\n+package org.apache.helix.monitoring;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import java.util.Date;\n+\n+import org.apache.helix.BaseDataAccessor;\n+import org.apache.helix.HelixDataAccessor;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.PropertyKey;\n+import org.apache.helix.TestHelper;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.ZkUnitTestBase;\n+import org.apache.helix.manager.zk.ZKHelixDataAccessor;\n+import org.apache.helix.manager.zk.ZkBaseDataAccessor;\n+import org.apache.helix.model.StatusUpdate;\n+import org.apache.helix.model.Error;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestZKPathDataDumpTask extends ZkUnitTestBase {\n+\n+  @Test\n+  public void test() throws Exception {\n+    String className = TestHelper.getTestClassName();\n+    String methodName = TestHelper.getTestMethodName();\n+    String clusterName = className + \"_\" + methodName;\n+    int n = 1;\n+\n+    System.out.println(\"START \" + clusterName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+    TestHelper.setupCluster(clusterName, ZK_ADDR, 12918, // participant port\n+        \"localhost\", // participant name prefix\n+        \"TestDB\", // resource name prefix\n+        1, // resources\n+        2, // partitions per resource\n+        n, // number of nodes\n+        1, // replicas\n+        \"MasterSlave\", true); // do rebalance\n+\n+    HelixDataAccessor accessor =\n+        new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor<ZNRecord>(_gZkClient));\n+    PropertyKey.Builder keyBuilder = accessor.keyBuilder();\n+    BaseDataAccessor<ZNRecord> baseAccessor = accessor.getBaseDataAccessor();\n+\n+    HelixManager manager = mock(HelixManager.class);\n+    when(manager.getHelixDataAccessor()).thenReturn(accessor);\n+    when(manager.getClusterName()).thenReturn(clusterName);\n+\n+    // run dump task without statusUpdates and errors, should not remove any existing statusUpdate/error paths\n+    ZKPathDataDumpTask task = new ZKPathDataDumpTask(manager, 0);\n+    task.run();\n+    PropertyKey controllerStatusUpdateKey = keyBuilder.controllerTaskStatuses();\n+    Assert.assertTrue(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    PropertyKey controllerErrorKey = keyBuilder.controllerTaskErrors();\n+    Assert.assertTrue(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    PropertyKey statusUpdateKey = keyBuilder.stateTransitionStatus(\"localhost_12918\");\n+    Assert.assertTrue(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    PropertyKey errorKey = keyBuilder.stateTransitionErrors(\"localhost_12918\");\n+\n+    // add participant status updates and errors\n+    statusUpdateKey =\n+        keyBuilder.stateTransitionStatus(\"localhost_12918\", \"session_0\", \"TestDB0\", \"TestDB0_0\");\n+    accessor.setProperty(statusUpdateKey, new StatusUpdate(new ZNRecord(\"statusUpdate\")));\n+    errorKey =\n+        keyBuilder.stateTransitionError(\"localhost_12918\", \"session_0\", \"TestDB0\", \"TestDB0_0\");\n+    accessor.setProperty(errorKey, new Error(new ZNRecord(\"error\")));\n+\n+    // add controller status updates and errors\n+    controllerStatusUpdateKey = keyBuilder.controllerTaskStatus(\"session_0\", \"TestDB\");\n+    accessor.setProperty(controllerStatusUpdateKey, new StatusUpdate(new ZNRecord(\"controllerStatusUpdate\")));\n+    controllerErrorKey = keyBuilder.controllerTaskError(\"TestDB_error\");\n+    accessor.setProperty(controllerErrorKey, new Error(new ZNRecord(\"controllerError\")));\n+\n+    // run dump task, should remove existing statusUpdate/error paths\n+    task.run();\n+    Assert.assertFalse(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    Assert.assertFalse(baseAccessor.exists(errorKey.getPath(), 0));\n+\n+    controllerStatusUpdateKey = keyBuilder.controllerTaskStatuses();\n+    Assert.assertTrue(baseAccessor.exists(controllerStatusUpdateKey.getPath(), 0));\n+    controllerErrorKey = keyBuilder.controllerTaskErrors();\n+    Assert.assertTrue(baseAccessor.exists(controllerErrorKey.getPath(), 0));\n+    statusUpdateKey = keyBuilder.stateTransitionStatus(\"localhost_12918\");\n+    Assert.assertTrue(baseAccessor.exists(statusUpdateKey.getPath(), 0));\n+    errorKey = keyBuilder.stateTransitionErrors(\"localhost_12918\");\n+\n+    System.out.println(\"END \" + clusterName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+  }\n+}"
            },
            {
                "sha": "1f6369d90a73c9ee71a89e3540ae72ff10e5198e",
                "filename": "pom.xml",
                "status": "modified",
                "additions": 5,
                "deletions": 0,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/590f65cf9538435c89dfd71922479b281a159e60/pom.xml",
                "raw_url": "https://github.com/apache/helix/raw/590f65cf9538435c89dfd71922479b281a159e60/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/pom.xml?ref=590f65cf9538435c89dfd71922479b281a159e60",
                "patch": "@@ -284,6 +284,11 @@ under the License.\n         <artifactId>testng</artifactId>\n         <version>6.0.1</version>\n       </dependency>\n+      <dependency>\n+        <groupId>org.mockito</groupId>\n+        <artifactId>mockito-all</artifactId>\n+        <version>1.9.5</version>\n+      </dependency>\n     </dependencies>\n   </dependencyManagement>\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/516faa0c504c807bbc9133694998f227e8e0d114",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/e924a4c4ee1f1c52dcf6b478bbc88d3050e9d0f8",
        "message": "[HELIX-587] Fix NPE in ClusterStateVerifier, rb=32344",
        "bug_id": "helix_42",
        "file": [
            {
                "sha": "473a4df1f0070584309b27be11fc687b4229fc1d",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "status": "modified",
                "additions": 12,
                "deletions": 4,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "raw_url": "https://github.com/apache/helix/raw/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ClusterStateVerifier.java?ref=516faa0c504c807bbc9133694998f227e8e0d114",
                "patch": "@@ -61,6 +61,7 @@\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.Partition;\n import org.apache.helix.model.Resource;\n+import org.apache.helix.task.TaskConstants;\n import org.apache.helix.util.ZKClientPool;\n import org.apache.log4j.Logger;\n \n@@ -255,15 +256,22 @@ static boolean verifyBestPossAndExtView(HelixDataAccessor accessor,\n       cache.refresh(accessor);\n \n       Map<String, IdealState> idealStates = cache.getIdealStates();\n-      if (idealStates == null) // || idealStates.isEmpty())\n-      {\n+      if (idealStates == null) {\n         // ideal state is null because ideal state is dropped\n         idealStates = Collections.emptyMap();\n       }\n \n+      // filter out all resources that use Task state model\n+      Iterator it = idealStates.entrySet().iterator();\n+      while (it.hasNext()) {\n+        Map.Entry<String, IdealState> pair = (Map.Entry<String, IdealState>)it.next();\n+        if (pair.getValue().getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)) {\n+          it.remove();\n+        }\n+      }\n+\n       Map<String, ExternalView> extViews = accessor.getChildValuesMap(keyBuilder.externalViews());\n-      if (extViews == null) // || extViews.isEmpty())\n-      {\n+      if (extViews == null) {\n         extViews = Collections.emptyMap();\n       }\n "
            },
            {
                "sha": "aed40884a04f24d09985e52d76a4640ef36eaa21",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "status": "modified",
                "additions": 10,
                "deletions": 4,
                "changes": 14,
                "blob_url": "https://github.com/apache/helix/blob/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "raw_url": "https://github.com/apache/helix/raw/516faa0c504c807bbc9133694998f227e8e0d114/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=516faa0c504c807bbc9133694998f227e8e0d114",
                "patch": "@@ -373,8 +373,7 @@ private JobQueue buildRecurrentJobQueue(String jobQueueName)\n   {\n     Map<String, String> cfgMap = new HashMap<String, String>();\n     cfgMap.put(WorkflowConfig.EXPIRY, String.valueOf(50000));\n-    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.getDefaultDateFormat().format(\n-        Calendar.getInstance().getTime()));\n+    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.getDefaultDateFormat().format(Calendar.getInstance().getTime()));\n     cfgMap.put(WorkflowConfig.RECURRENCE_INTERVAL, String.valueOf(60));\n     cfgMap.put(WorkflowConfig.RECURRENCE_UNIT, \"SECONDS\");\n     return (new JobQueue.Builder(jobQueueName).fromMap(cfgMap)).build();\n@@ -503,12 +502,19 @@ public void stopAndDeleteQueue() throws Exception {\n     String namespacedJob2 = String.format(\"%s_%s\", queueName,  job2Name);\n     TestUtil.pollForJobState(_manager, queueName, namespacedJob2, TaskState.COMPLETED);\n \n-    // Stop and delete queue\n+    // Stop queue\n     _driver.stop(queueName);\n+\n+    boolean result =\n+        ClusterStateVerifier.verifyByPolling(new ClusterStateVerifier.BestPossAndExtViewZkVerifier(\n+            ZK_ADDR, CLUSTER_NAME));\n+    Assert.assertTrue(result);\n+\n+    // Delete queue\n     _driver.delete(queueName);\n \n     // Wait until all status are cleaned up\n-    boolean result = TestHelper.verify(new TestHelper.Verifier() {\n+    result = TestHelper.verify(new TestHelper.Verifier() {\n       @Override public boolean verify() throws Exception {\n         HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n         PropertyKey.Builder keyBuilder = accessor.keyBuilder();"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/895cd9c14f071a62af59a7cc4d2627455a9eb9d1",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/49cb4ff8e08ef02b84378365cf4230c33371a3a7",
        "message": "fix NPE in ClusterSetup.main()",
        "bug_id": "helix_43",
        "file": [
            {
                "sha": "5d56a3eebbb2cca27e50ed595353fd18df15d397",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "status": "modified",
                "additions": 228,
                "deletions": 260,
                "changes": 488,
                "blob_url": "https://github.com/apache/helix/blob/895cd9c14f071a62af59a7cc4d2627455a9eb9d1/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "raw_url": "https://github.com/apache/helix/raw/895cd9c14f071a62af59a7cc4d2627455a9eb9d1/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/ClusterSetup.java?ref=895cd9c14f071a62af59a7cc4d2627455a9eb9d1",
                "patch": "@@ -12,7 +12,6 @@\n import org.apache.commons.cli.HelpFormatter;\n import org.apache.commons.cli.Option;\n import org.apache.commons.cli.OptionBuilder;\n-import org.apache.commons.cli.OptionGroup;\n import org.apache.commons.cli.Options;\n import org.apache.commons.cli.ParseException;\n import org.apache.log4j.Logger;\n@@ -33,42 +32,35 @@\n \n public class ClusterSetup\n {\n-  private static Logger logger = Logger.getLogger(ClusterSetup.class);\n-  public static final String zkServerAddress = \"zkSvr\";\n+  private static Logger      logger                = Logger.getLogger(ClusterSetup.class);\n+  public static final String zkServerAddress       = \"zkSvr\";\n \n   // List info about the cluster / DB/ Instances\n-  public static final String listClusters = \"listClusters\";\n-  public static final String listResourceGroups = \"listResourceGroups\";\n-  public static final String listInstances = \"listInstances\";\n+  public static final String listClusters          = \"listClusters\";\n+  public static final String listResourceGroups    = \"listResourceGroups\";\n+  public static final String listInstances         = \"listInstances\";\n \n   // Add and rebalance\n-  public static final String addCluster = \"addCluster\";\n-  public static final String addInstance = \"addNode\";\n-  public static final String addResourceGroup = \"addResourceGroup\";\n-  public static final String addStateModelDef = \"addStateModelDef\";\n-  public static final String addIdealState = \"addIdealState\";\n-  public static final String rebalance = \"rebalance\";\n+  public static final String addCluster            = \"addCluster\";\n+  public static final String addInstance           = \"addNode\";\n+  public static final String addResourceGroup      = \"addResourceGroup\";\n+  public static final String addStateModelDef      = \"addStateModelDef\";\n+  public static final String addIdealState         = \"addIdealState\";\n+  public static final String rebalance             = \"rebalance\";\n \n   // Query info (TBD in V2)\n-  public static final String listClusterInfo = \"listClusterInfo\";\n-  public static final String listInstanceInfo = \"listInstanceInfo\";\n+  public static final String listClusterInfo       = \"listClusterInfo\";\n+  public static final String listInstanceInfo      = \"listInstanceInfo\";\n   public static final String listResourceGroupInfo = \"listResourceGroupInfo\";\n-  public static final String listResourceInfo = \"listResourceInfo\";\n-  public static final String listStateModels = \"listStateModels\";\n-  public static final String listStateModel = \"listStateModel\";\n-  \n-\n-  // TODO: refactor\n-  // setup for file-based cluster manager\n-  // public static final String configFile = \"configFile\";\n+  public static final String listResourceInfo      = \"listResourceInfo\";\n+  public static final String listStateModels       = \"listStateModels\";\n+  public static final String listStateModel        = \"listStateModel\";\n \n   // enable / disable Instances\n-  public static final String enableInstance = \"enableInstance\";\n-\n-  public static final String help = \"help\";\n-\n-  static Logger _logger = Logger.getLogger(ClusterSetup.class);\n-  String _zkServerAddress;\n+  public static final String enableInstance        = \"enableInstance\";\n+  public static final String help                  = \"help\";\n+  static Logger              _logger               = Logger.getLogger(ClusterSetup.class);\n+  String                     _zkServerAddress;\n \n   public ClusterSetup(String zkServerAddress)\n   {\n@@ -78,23 +70,21 @@ public ClusterSetup(String zkServerAddress)\n   public void addCluster(String clusterName, boolean overwritePrevious)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n-    \n+\n     managementTool.addCluster(clusterName, overwritePrevious);\n     StateModelConfigGenerator generator = new StateModelConfigGenerator();\n-    addStateModelDef(clusterName, \"MasterSlave\",\n-        generator.generateConfigForMasterSlave());\n-    \n-    addStateModelDef(clusterName, \"LeaderStandby\",\n-        generator.generateConfigForLeaderStandby());\n-    \n-    addStateModelDef(clusterName, \"StorageSchemata\",\n-        generator.generateConfigForStorageSchemata());\n-    \n-    addStateModelDef(clusterName, \"OnlineOffline\",\n-        generator.generateConfigForOnlineOffline());\n+    addStateModelDef(clusterName, \"MasterSlave\", generator.generateConfigForMasterSlave());\n+\n+    addStateModelDef(clusterName, \"LeaderStandby\", generator.generateConfigForLeaderStandby());\n+\n+    addStateModelDef(clusterName, \"StorageSchemata\", generator.generateConfigForStorageSchemata());\n+\n+    addStateModelDef(clusterName, \"OnlineOffline\", generator.generateConfigForOnlineOffline());\n   }\n-  \n-  public void addCluster(String clusterName, boolean overwritePrevious, String stateModDefName, \n+\n+  public void addCluster(String clusterName,\n+                         boolean overwritePrevious,\n+                         String stateModDefName,\n                          ZNRecord stateModDef)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n@@ -138,10 +128,8 @@ public void addInstanceToCluster(String clusterName, String host, int port)\n     String InstanceId = host + \"_\" + port;\n     InstanceConfig.setId(InstanceId);\n     InstanceConfig.setSimpleField(InstanceConfigProperty.HOST.toString(), host);\n-    InstanceConfig\n-        .setSimpleField(InstanceConfigProperty.PORT.toString(), \"\" + port);\n-    InstanceConfig.setSimpleField(InstanceConfigProperty.ENABLED.toString(),\n-        true + \"\");\n+    InstanceConfig.setSimpleField(InstanceConfigProperty.PORT.toString(), \"\" + port);\n+    InstanceConfig.setSimpleField(InstanceConfigProperty.ENABLED.toString(), true + \"\");\n \n     managementTool.addInstance(clusterName, InstanceConfig);\n   }\n@@ -152,119 +140,124 @@ public ClusterManagementService getClusterManagementTool()\n     return new ZKClusterManagementTool(zkClient);\n   }\n \n-  public void addStateModelDef(String clusterName, String stateModelDef,\n-      ZNRecord record)\n+  public void addStateModelDef(String clusterName, String stateModelDef, ZNRecord record)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n     managementTool.addStateModelDef(clusterName, stateModelDef, record);\n   }\n \n   public void addResourceGroupToCluster(String clusterName,\n-      String resourceGroup, int numResources, String stateModelRef)\n+                                        String resourceGroup,\n+                                        int numResources,\n+                                        String stateModelRef)\n   {\n-    /*\n-    ClusterManagementService managementTool = getClusterManagementTool();\n-    managementTool.addResourceGroup(clusterName, resourceGroup, numResources,\n-        stateModelRef);\n-    */\n-    addResourceGroupToCluster(clusterName, resourceGroup, numResources, stateModelRef, \n+    addResourceGroupToCluster(clusterName,\n+                              resourceGroup,\n+                              numResources,\n+                              stateModelRef,\n                               IdealStateConfigProperty.AUTO.toString());\n   }\n-  \n+\n   public void addResourceGroupToCluster(String clusterName,\n-      String resourceGroup, int numResources, String stateModelRef, String idealStateMode)\n+                                        String resourceGroup,\n+                                        int numResources,\n+                                        String stateModelRef,\n+                                        String idealStateMode)\n   {\n     if (!idealStateMode.equalsIgnoreCase(IdealStateConfigProperty.CUSTOMIZED.toString()))\n     {\n       logger.info(\"ideal state mode is configured to auto mode\");\n       idealStateMode = IdealStateConfigProperty.AUTO.toString();\n     }\n     ClusterManagementService managementTool = getClusterManagementTool();\n-    managementTool.addResourceGroup(clusterName, resourceGroup, numResources,\n-        stateModelRef, idealStateMode);\n+    managementTool.addResourceGroup(clusterName,\n+                                    resourceGroup,\n+                                    numResources,\n+                                    stateModelRef,\n+                                    idealStateMode);\n   }\n-  \n-  public void dropResourceGroupToCluster(String clusterName,\n-      String resourceGroup)\n+\n+  public void dropResourceGroupToCluster(String clusterName, String resourceGroup)\n   {\n     ClusterManagementService managementTool = getClusterManagementTool();\n     managementTool.dropResourceGroup(clusterName, resourceGroup);\n   }\n \n-  public void rebalanceStorageCluster(String clusterName,\n-      String resourceGroupName, int replica)\n+  public void rebalanceStorageCluster(String clusterName, String resourceGroupName, int replica)\n   {\n-    replica --;\n+    replica--;\n     ClusterManagementService managementTool = getClusterManagementTool();\n     List<String> InstanceNames = managementTool.getInstancesInCluster(clusterName);\n \n-    ZNRecord dbIdealState = managementTool.getResourceGroupIdealState(\n-        clusterName, resourceGroupName);\n-    int partitions = Integer\n-        .parseInt(dbIdealState.getSimpleField(\"partitions\"));\n+    ZNRecord dbIdealState =\n+        managementTool.getResourceGroupIdealState(clusterName, resourceGroupName);\n+    int partitions = Integer.parseInt(dbIdealState.getSimpleField(\"partitions\"));\n \n     ZkClient zkClient = ZKClientPool.getZkClient(_zkServerAddress);\n     String idealStatePath = CMUtil.getIdealStatePath(clusterName, resourceGroupName);\n-    ZNRecord idealState = zkClient.<ZNRecord>readData(idealStatePath);\n+    ZNRecord idealState = zkClient.<ZNRecord> readData(idealStatePath);\n     String stateModelName = idealState.getSimpleField(\"state_model_def_ref\");\n     ZNRecord stateModDef = managementTool.getStateModelDef(clusterName, stateModelName);\n- \n+\n     if (stateModDef == null)\n     {\n       throw new ClusterManagerException(\"cannot find state model \" + stateModelName);\n     }\n     StateModelDefinition def = new StateModelDefinition(stateModDef);\n-    \n+\n     List<String> statePriorityList = def.getStatesPriorityList();\n-    \n+\n     String masterStateValue = null;\n     String slaveStateValue = null;\n-    \n-    for(String state : statePriorityList)\n+\n+    for (String state : statePriorityList)\n     {\n       String count = def.getNumInstancesPerState(state);\n-      if(count.equals(\"1\"))\n+      if (count.equals(\"1\"))\n       {\n-        if(masterStateValue != null)\n+        if (masterStateValue != null)\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         masterStateValue = state;\n       }\n-      else if(count.equalsIgnoreCase(\"R\"))\n+      else if (count.equalsIgnoreCase(\"R\"))\n       {\n-        if(slaveStateValue != null)\n+        if (slaveStateValue != null)\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         slaveStateValue = state;\n       }\n-      else if(count.equalsIgnoreCase(\"N\"))\n+      else if (count.equalsIgnoreCase(\"N\"))\n       {\n-        if(!(masterStateValue == null && slaveStateValue == null))\n+        if (!(masterStateValue == null && slaveStateValue == null))\n         {\n           throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n         }\n         replica = InstanceNames.size() - 1;\n         masterStateValue = slaveStateValue = state;\n       }\n     }\n-    if(masterStateValue == null && slaveStateValue == null)\n+    if (masterStateValue == null && slaveStateValue == null)\n     {\n       throw new ClusterManagerException(\"Invalid or unsupported state model definition\");\n     }\n-    \n-    if(masterStateValue == null)\n+\n+    if (masterStateValue == null)\n     {\n       masterStateValue = slaveStateValue;\n     }\n-    \n-    idealState = IdealStateCalculatorForStorageNode\n-        .calculateIdealState(InstanceNames, partitions, replica, resourceGroupName,\n-                             masterStateValue, slaveStateValue);\n+\n+    idealState =\n+        IdealStateCalculatorForStorageNode.calculateIdealState(InstanceNames,\n+                                                               partitions,\n+                                                               replica,\n+                                                               resourceGroupName,\n+                                                               masterStateValue,\n+                                                               slaveStateValue);\n     idealState.setSimpleFields(dbIdealState.getSimpleFields());\n-    managementTool.setResourceGroupIdealState(clusterName, resourceGroupName,\n-        idealState);\n+    managementTool.setResourceGroupIdealState(clusterName, resourceGroupName, idealState);\n   }\n \n   /**\n@@ -295,131 +288,145 @@ public static void printUsage(Options cliOptions)\n   @SuppressWarnings(\"static-access\")\n   private static Options constructCommandLineOptions()\n   {\n-    Option helpOption = OptionBuilder.withLongOpt(help)\n-        .withDescription(\"Prints command-line options info\").create();\n-\n-    Option zkServerOption = OptionBuilder.withLongOpt(zkServerAddress)\n-        .withDescription(\"Provide zookeeper address\").create();\n+    Option helpOption =\n+        OptionBuilder.withLongOpt(help)\n+                     .withDescription(\"Prints command-line options info\")\n+                     .create();\n+\n+    Option zkServerOption =\n+        OptionBuilder.withLongOpt(zkServerAddress)\n+                     .withDescription(\"Provide zookeeper address\")\n+                     .create();\n     zkServerOption.setArgs(1);\n     zkServerOption.setRequired(true);\n     zkServerOption.setArgName(\"ZookeeperServerAddress(Required)\");\n \n-    Option listClustersOption = OptionBuilder.withLongOpt(listClusters)\n-        .withDescription(\"List existing clusters\").create();\n+    Option listClustersOption =\n+        OptionBuilder.withLongOpt(listClusters).withDescription(\"List existing clusters\").create();\n     listClustersOption.setArgs(0);\n     listClustersOption.setRequired(false);\n \n-    Option listResourceGroupOption = OptionBuilder\n-        .withLongOpt(listResourceGroups)\n-        .withDescription(\"List resourceGroups hosted in a cluster\").create();\n+    Option listResourceGroupOption =\n+        OptionBuilder.withLongOpt(listResourceGroups)\n+                     .withDescription(\"List resourceGroups hosted in a cluster\")\n+                     .create();\n     listResourceGroupOption.setArgs(1);\n     listResourceGroupOption.setRequired(false);\n     listResourceGroupOption.setArgName(\"clusterName\");\n \n-    Option listInstancesOption = OptionBuilder.withLongOpt(listInstances)\n-        .withDescription(\"List Instances in a cluster\").create();\n+    Option listInstancesOption =\n+        OptionBuilder.withLongOpt(listInstances)\n+                     .withDescription(\"List Instances in a cluster\")\n+                     .create();\n     listInstancesOption.setArgs(1);\n     listInstancesOption.setRequired(false);\n     listInstancesOption.setArgName(\"clusterName\");\n \n-    Option addClusterOption = OptionBuilder.withLongOpt(addCluster)\n-        .withDescription(\"Add a new cluster\").create();\n+    Option addClusterOption =\n+        OptionBuilder.withLongOpt(addCluster).withDescription(\"Add a new cluster\").create();\n     addClusterOption.setArgs(1);\n     addClusterOption.setRequired(false);\n     addClusterOption.setArgName(\"clusterName\");\n \n-    Option addInstanceOption = OptionBuilder.withLongOpt(addInstance)\n-        .withDescription(\"Add a new Instance to a cluster\").create();\n+    Option addInstanceOption =\n+        OptionBuilder.withLongOpt(addInstance)\n+                     .withDescription(\"Add a new Instance to a cluster\")\n+                     .create();\n     addInstanceOption.setArgs(2);\n     addInstanceOption.setRequired(false);\n     addInstanceOption.setArgName(\"clusterName InstanceAddress(host:port)\");\n \n-    Option addResourceGroupOption = OptionBuilder.withLongOpt(addResourceGroup)\n-        .withDescription(\"Add a resourceGroup to a cluster\").create();\n+    Option addResourceGroupOption =\n+        OptionBuilder.withLongOpt(addResourceGroup)\n+                     .withDescription(\"Add a resourceGroup to a cluster\")\n+                     .create();\n     addResourceGroupOption.setArgs(4);\n     addResourceGroupOption.setRequired(false);\n-    addResourceGroupOption\n-        .setArgName(\"clusterName resourceGroupName partitionNo stateModelRef\");\n+    addResourceGroupOption.setArgName(\"clusterName resourceGroupName partitionNo stateModelRef\");\n \n-    Option addStateModelDefOption = OptionBuilder\n-        .withLongOpt(addStateModelDef)\n-        .withDescription(\"Add a State model to a cluster\").create();\n+    Option addStateModelDefOption =\n+        OptionBuilder.withLongOpt(addStateModelDef)\n+                     .withDescription(\"Add a State model to a cluster\")\n+                     .create();\n     addStateModelDefOption.setArgs(2);\n     addStateModelDefOption.setRequired(false);\n     addStateModelDefOption.setArgName(\"clusterName <filename>\");\n-    \n-    Option addIdealStateOption = OptionBuilder\n-        .withLongOpt(addIdealState)\n-        .withDescription(\"Add a State model to a cluster\").create();\n+\n+    Option addIdealStateOption =\n+        OptionBuilder.withLongOpt(addIdealState)\n+                     .withDescription(\"Add a State model to a cluster\")\n+                     .create();\n     addIdealStateOption.setArgs(3);\n     addIdealStateOption.setRequired(false);\n     addIdealStateOption.setArgName(\"clusterName reourceGroupName <filename>\");\n \n-    Option rebalanceOption = OptionBuilder.withLongOpt(rebalance)\n-        .withDescription(\"Rebalance a resourceGroup in a cluster\").create();\n+    Option rebalanceOption =\n+        OptionBuilder.withLongOpt(rebalance)\n+                     .withDescription(\"Rebalance a resourceGroup in a cluster\")\n+                     .create();\n     rebalanceOption.setArgs(3);\n     rebalanceOption.setRequired(false);\n     rebalanceOption.setArgName(\"clusterName resourceGroupName replicationNo\");\n \n-    Option InstanceInfoOption = OptionBuilder.withLongOpt(listInstanceInfo)\n-        .withDescription(\"Query info of a Instance in a cluster\").create();\n+    Option InstanceInfoOption =\n+        OptionBuilder.withLongOpt(listInstanceInfo)\n+                     .withDescription(\"Query info of a Instance in a cluster\")\n+                     .create();\n     InstanceInfoOption.setArgs(2);\n     InstanceInfoOption.setRequired(false);\n     InstanceInfoOption.setArgName(\"clusterName InstanceName\");\n \n-    Option clusterInfoOption = OptionBuilder.withLongOpt(listClusterInfo)\n-        .withDescription(\"Query info of a cluster\").create();\n+    Option clusterInfoOption =\n+        OptionBuilder.withLongOpt(listClusterInfo)\n+                     .withDescription(\"Query info of a cluster\")\n+                     .create();\n     clusterInfoOption.setArgs(1);\n     clusterInfoOption.setRequired(false);\n     clusterInfoOption.setArgName(\"clusterName\");\n \n-    Option resourceGroupInfoOption = OptionBuilder\n-        .withLongOpt(listResourceGroupInfo)\n-        .withDescription(\"Query info of a resourceGroup\").create();\n+    Option resourceGroupInfoOption =\n+        OptionBuilder.withLongOpt(listResourceGroupInfo)\n+                     .withDescription(\"Query info of a resourceGroup\")\n+                     .create();\n     resourceGroupInfoOption.setArgs(2);\n     resourceGroupInfoOption.setRequired(false);\n     resourceGroupInfoOption.setArgName(\"clusterName resourceGroupName\");\n \n-    Option partitionInfoOption = OptionBuilder.withLongOpt(listResourceInfo)\n-        .withDescription(\"Query info of a partition\").create();\n+    Option partitionInfoOption =\n+        OptionBuilder.withLongOpt(listResourceInfo)\n+                     .withDescription(\"Query info of a partition\")\n+                     .create();\n     partitionInfoOption.setArgs(2);\n     partitionInfoOption.setRequired(false);\n     partitionInfoOption.setArgName(\"clusterName partitionName\");\n \n-    Option enableInstanceOption = OptionBuilder.withLongOpt(enableInstance)\n-        .withDescription(\"Enable / disable a Instance\").create();\n+    Option enableInstanceOption =\n+        OptionBuilder.withLongOpt(enableInstance)\n+                     .withDescription(\"Enable / disable a Instance\")\n+                     .create();\n     enableInstanceOption.setArgs(3);\n     enableInstanceOption.setRequired(false);\n     enableInstanceOption.setArgName(\"clusterName InstanceName true/false\");\n-    \n-    Option listStateModelsOption = OptionBuilder.withLongOpt(listStateModels)\n-      .withDescription(\"Query info of state models in a cluster\").create();\n+\n+    Option listStateModelsOption =\n+        OptionBuilder.withLongOpt(listStateModels)\n+                     .withDescription(\"Query info of state models in a cluster\")\n+                     .create();\n     listStateModelsOption.setArgs(1);\n     listStateModelsOption.setRequired(false);\n     listStateModelsOption.setArgName(\"clusterName\");\n \n-    Option listStateModelOption = OptionBuilder.withLongOpt(listStateModel)\n-      .withDescription(\"Query info of a state model in a cluster\").create();\n+    Option listStateModelOption =\n+        OptionBuilder.withLongOpt(listStateModel)\n+                     .withDescription(\"Query info of a state model in a cluster\")\n+                     .create();\n     listStateModelOption.setArgs(2);\n     listStateModelOption.setRequired(false);\n     listStateModelOption.setArgName(\"clusterName stateModelName\");\n \n-\n-    // add an option group including either --zkSvr or --configFile\n-    /**\n-    Option fileOption = OptionBuilder.withLongOpt(configFile)\n-        .withDescription(\"Provide file to write states/messages\").create();\n-    fileOption.setArgs(1);\n-    fileOption.setRequired(true);\n-    fileOption.setArgName(\"File to write states/messages (Optional)\");\n-     **/\n-    OptionGroup optionGroup = new OptionGroup();\n-    optionGroup.addOption(zkServerOption);\n-    // optionGroup.addOption(fileOption);\n-\n     Options options = new Options();\n     options.addOption(helpOption);\n-    // options.addOption(zkServerOption);\n+    options.addOption(zkServerOption);\n     options.addOption(rebalanceOption);\n     options.addOption(addResourceGroupOption);\n     options.addOption(addClusterOption);\n@@ -438,26 +445,25 @@ private static Options constructCommandLineOptions()\n     options.addOption(listStateModelsOption);\n     options.addOption(listStateModelOption);\n \n-    options.addOptionGroup(optionGroup);\n-\n     return options;\n   }\n+\n   private static byte[] readFile(String filePath) throws IOException\n   {\n-    File file = new File(filePath); \n+    File file = new File(filePath);\n \n-    int size = (int)file.length(); \n-    byte[] bytes = new byte[size]; \n-    DataInputStream dis = new DataInputStream(new FileInputStream(file)); \n+    int size = (int) file.length();\n+    byte[] bytes = new byte[size];\n+    DataInputStream dis = new DataInputStream(new FileInputStream(file));\n     int read = 0;\n     int numRead = 0;\n-    while (read < bytes.length && \n-        (numRead = dis.read(bytes, read, bytes.length-read)) >= 0) \n+    while (read < bytes.length && (numRead = dis.read(bytes, read, bytes.length - read)) >= 0)\n     {\n       read = read + numRead;\n     }\n     return bytes;\n   }\n+\n   public static int processCommandLineArgs(String[] cliArgs) throws Exception\n   {\n     CommandLineParser cliParser = new GnuParser();\n@@ -467,54 +473,16 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     try\n     {\n       cmd = cliParser.parse(cliOptions, cliArgs);\n-    } catch (ParseException pe)\n+    }\n+    catch (ParseException pe)\n     {\n-      System.err\n-          .println(\"CommandLineClient: failed to parse command-line options: \"\n-              + pe.toString());\n+      System.err.println(\"CommandLineClient: failed to parse command-line options: \"\n+          + pe.toString());\n       printUsage(cliOptions);\n       System.exit(1);\n     }\n \n-    /**\n-    if (cmd.hasOption(configFile))\n-    {\n-      String file = cmd.getOptionValue(configFile);\n-\n-      // for temporary test only, will move to command line\n-      // create fake db names\n-      List<FileBasedClusterManager.DBParam> dbParams = new ArrayList<FileBasedClusterManager.DBParam>();\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"BizFollow\", 1));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"BizProfile\", 1));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"EspressoDB\", 10));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"MailboxDB\", 128));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"MyDB\", 8));\n-      dbParams.add(new FileBasedClusterManager.DBParam(\"schemata\", 1));\n-      String[] InstancesInfo =\n-      { \"localhost:8900\" };\n-\n-      // ClusterViewSerializer serializer = new ClusterViewSerializer(file);\n-      int replica = 0;\n-      ClusterView view = FileBasedClusterManager\n-          .generateStaticConfigClusterView(InstancesInfo, dbParams, replica);\n-\n-      // byte[] bytes;\n-      ClusterViewSerializer.serialize(view, new File(file));\n-      // System.out.println(new String(bytes));\n-\n-      ClusterView restoredView = ClusterViewSerializer.deserialize(new File(\n-          file));\n-      // System.out.println(restoredView);\n-\n-      byte[] bytes = ClusterViewSerializer.serialize(restoredView);\n-      // System.out.println(new String(bytes));\n-\n-      return 0;\n-    }\n-    **/\n-    \n-    ClusterSetup setupTool = new ClusterSetup(\n-        cmd.getOptionValue(zkServerAddress));\n+    ClusterSetup setupTool = new ClusterSetup(cmd.getOptionValue(zkServerAddress));\n \n     if (cmd.hasOption(addCluster))\n     {\n@@ -536,11 +504,9 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     {\n       String clusterName = cmd.getOptionValues(addResourceGroup)[0];\n       String resourceGroupName = cmd.getOptionValues(addResourceGroup)[1];\n-      int partitions = Integer\n-          .parseInt(cmd.getOptionValues(addResourceGroup)[2]);\n+      int partitions = Integer.parseInt(cmd.getOptionValues(addResourceGroup)[2]);\n       String stateModelRef = cmd.getOptionValues(addResourceGroup)[3];\n-      setupTool.addResourceGroupToCluster(clusterName, resourceGroupName,\n-          partitions, stateModelRef);\n+      setupTool.addResourceGroupToCluster(clusterName, resourceGroupName, partitions, stateModelRef);\n       return 0;\n     }\n \n@@ -549,15 +515,13 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n       String clusterName = cmd.getOptionValues(rebalance)[0];\n       String resourceGroupName = cmd.getOptionValues(rebalance)[1];\n       int replicas = Integer.parseInt(cmd.getOptionValues(rebalance)[2]);\n-      setupTool.rebalanceStorageCluster(clusterName, resourceGroupName,\n-          replicas);\n+      setupTool.rebalanceStorageCluster(clusterName, resourceGroupName, replicas);\n       return 0;\n     }\n \n     if (cmd.hasOption(listClusters))\n     {\n-      List<String> clusters = setupTool.getClusterManagementTool()\n-          .getClusters();\n+      List<String> clusters = setupTool.getClusterManagementTool().getClusters();\n \n       System.out.println(\"Existing clusters:\");\n       for (String cluster : clusters)\n@@ -570,30 +534,30 @@ public static int processCommandLineArgs(String[] cliArgs) throws Exception\n     if (cmd.hasOption(listResourceGroups))\n     {\n       String clusterName = cmd.getOptionValue(listResourceGroups);\n-      List<String> resourceGroupNames = setupTool.getClusterManagementTool()\n-          .getResourceGroupsInCluster(clusterName);\n+      List<String> resourceGroupNames =\n+          setupTool.getClusterManagementTool().getResourceGroupsInCluster(clusterName);\n \n       System.out.println(\"Existing resources in cluster \" + clusterName + \":\");\n       for (String resourceGroupName : resourceGroupNames)\n       {\n         System.out.println(resourceGroupName);\n       }\n       return 0;\n-    } \n-    else if(cmd.hasOption(listClusterInfo))\n+    }\n+    else if (cmd.hasOption(listClusterInfo))\n     {\n       String clusterName = cmd.getOptionValue(listClusterInfo);\n-      List<String> resourceGroupNames = setupTool.getClusterManagementTool()\n-          .getResourceGroupsInCluster(clusterName);\n-      List<String> Instances = setupTool.getClusterManagementTool()\n-        .getInstancesInCluster(clusterName);\n-      \n+      List<String> resourceGroupNames =\n+          setupTool.getClusterManagementTool().getResourceGroupsInCluster(clusterName);\n+      List<String> Instances =\n+          setupTool.getClusterManagementTool().getInstancesInCluster(clusterName);\n+\n       System.out.println(\"Existing resources in cluster \" + clusterName + \":\");\n       for (String resourceGroupName : resourceGroupNames)\n       {\n         System.out.println(resourceGroupName);\n       }\n-      \n+\n       System.out.println(\"Instances in cluster \" + clusterName + \":\");\n       for (String InstanceName : Instances)\n       {\n@@ -604,8 +568,8 @@ else if(cmd.hasOption(listClusterInfo))\n     else if (cmd.hasOption(listInstances))\n     {\n       String clusterName = cmd.getOptionValue(listInstances);\n-      List<String> Instances = setupTool.getClusterManagementTool()\n-          .getInstancesInCluster(clusterName);\n+      List<String> Instances =\n+          setupTool.getClusterManagementTool().getInstancesInCluster(clusterName);\n \n       System.out.println(\"Instances in cluster \" + clusterName + \":\");\n       for (String InstanceName : Instances)\n@@ -618,53 +582,54 @@ else if (cmd.hasOption(listInstanceInfo))\n     {\n       String clusterName = cmd.getOptionValues(listInstanceInfo)[0];\n       String instanceName = cmd.getOptionValues(listInstanceInfo)[1];\n-      ZNRecord record = setupTool.getClusterManagementTool().getInstanceConfig(clusterName, instanceName);\n-      \n+      ZNRecord record =\n+          setupTool.getClusterManagementTool().getInstanceConfig(clusterName, instanceName);\n+\n       String result = new String(new ZNRecordSerializer().serialize(record));\n       System.out.println(result);\n       return 0;\n-      \n-      // print out current states and\n-    } \n+    }\n     else if (cmd.hasOption(listResourceGroupInfo))\n     {\n       // print out partition number, db name and replication number\n       // Also the ideal states and current states\n       String clusterName = cmd.getOptionValues(listResourceGroupInfo)[0];\n       String resourceGroupName = cmd.getOptionValues(listResourceGroupInfo)[1];\n-      ZNRecord idealState = setupTool.getClusterManagementTool().getResourceGroupIdealState(clusterName, resourceGroupName);\n-      ZNRecord externalView = setupTool.getClusterManagementTool().getResourceGroupExternalView(clusterName, resourceGroupName);\n-      \n-      System.out.println(\"IdealState for \"+resourceGroupName+\":\");\n+      ZNRecord idealState =\n+          setupTool.getClusterManagementTool().getResourceGroupIdealState(clusterName,\n+                                                                          resourceGroupName);\n+      ZNRecord externalView =\n+          setupTool.getClusterManagementTool().getResourceGroupExternalView(clusterName,\n+                                                                            resourceGroupName);\n+\n+      System.out.println(\"IdealState for \" + resourceGroupName + \":\");\n       System.out.println(new String(new ZNRecordSerializer().serialize(idealState)));\n-      \n+\n       System.out.println();\n-      System.out.println(\"External view for \"+resourceGroupName+\":\");\n+      System.out.println(\"External view for \" + resourceGroupName + \":\");\n       System.out.println(new String(new ZNRecordSerializer().serialize(externalView)));\n       return 0;\n-      \n-    } \n+\n+    }\n     else if (cmd.hasOption(listResourceInfo))\n     {\n       // print out where the partition master / slaves locates\n-    } \n+    }\n     else if (cmd.hasOption(enableInstance))\n     {\n       String clusterName = cmd.getOptionValues(enableInstance)[0];\n       String instanceName = cmd.getOptionValues(enableInstance)[1];\n-      boolean enabled = Boolean.parseBoolean(cmd.getOptionValues(enableInstance)[1]\n-          .toLowerCase());\n+      boolean enabled = Boolean.parseBoolean(cmd.getOptionValues(enableInstance)[1].toLowerCase());\n \n-      setupTool.getClusterManagementTool().enableInstance(clusterName,\n-          instanceName, enabled);\n+      setupTool.getClusterManagementTool().enableInstance(clusterName, instanceName, enabled);\n       return 0;\n-    } \n-    else if(cmd.hasOption(listStateModels))\n+    }\n+    else if (cmd.hasOption(listStateModels))\n     {\n       String clusterName = cmd.getOptionValues(listStateModels)[0];\n-      \n-      List<String> stateModels =  setupTool.getClusterManagementTool()\n-      .getStateModelDefs(clusterName);\n+\n+      List<String> stateModels =\n+          setupTool.getClusterManagementTool().getStateModelDefs(clusterName);\n \n       System.out.println(\"Existing state models:\");\n       for (String stateModel : stateModels)\n@@ -677,36 +642,43 @@ else if (cmd.hasOption(listStateModel))\n     {\n       String clusterName = cmd.getOptionValues(listStateModel)[0];\n       String stateModel = cmd.getOptionValues(listStateModel)[1];\n-      ZNRecord record = setupTool.getClusterManagementTool().getStateModelDef(clusterName, stateModel);\n+      ZNRecord record =\n+          setupTool.getClusterManagementTool().getStateModelDef(clusterName, stateModel);\n       String result = new String(new ZNRecordSerializer().serialize(record));\n       System.out.println(result);\n       return 0;\n     }\n-    else if(cmd.hasOption(addStateModelDef))\n+    else if (cmd.hasOption(addStateModelDef))\n     {\n       String clusterName = cmd.getOptionValues(addStateModelDef)[0];\n       String stateModelFile = cmd.getOptionValues(addStateModelDef)[1];\n-      \n-      ZNRecord stateModelRecord = (ZNRecord)(new ZNRecordSerializer().deserialize(readFile(stateModelFile)));\n-      if(stateModelRecord.getId() == null || stateModelRecord.getId().length() == 0)\n+\n+      ZNRecord stateModelRecord =\n+          (ZNRecord) (new ZNRecordSerializer().deserialize(readFile(stateModelFile)));\n+      if (stateModelRecord.getId() == null || stateModelRecord.getId().length() == 0)\n       {\n         throw new IllegalArgumentException(\"ZNRecord for state model definition must have an id\");\n       }\n-      setupTool.getClusterManagementTool().addStateModelDef(clusterName, stateModelRecord.getId(), stateModelRecord);\n+      setupTool.getClusterManagementTool().addStateModelDef(clusterName,\n+                                                            stateModelRecord.getId(),\n+                                                            stateModelRecord);\n       return 0;\n     }\n-    else if(cmd.hasOption(addIdealState))\n+    else if (cmd.hasOption(addIdealState))\n     {\n       String clusterName = cmd.getOptionValues(addIdealState)[0];\n       String resourceGroupName = cmd.getOptionValues(addIdealState)[1];\n       String idealStateFile = cmd.getOptionValues(addIdealState)[2];\n-      \n-      ZNRecord idealStateRecord = (ZNRecord)(new ZNRecordSerializer().deserialize(readFile(idealStateFile)));\n-      if(idealStateRecord.getId() == null || !idealStateRecord.getId().equals(resourceGroupName))\n+\n+      ZNRecord idealStateRecord =\n+          (ZNRecord) (new ZNRecordSerializer().deserialize(readFile(idealStateFile)));\n+      if (idealStateRecord.getId() == null || !idealStateRecord.getId().equals(resourceGroupName))\n       {\n         throw new IllegalArgumentException(\"ideal state must have same id as resourceGroup name\");\n       }\n-      setupTool.getClusterManagementTool().setResourceGroupIdealState(clusterName, resourceGroupName, idealStateRecord);\n+      setupTool.getClusterManagementTool().setResourceGroupIdealState(clusterName,\n+                                                                      resourceGroupName,\n+                                                                      idealStateRecord);\n       return 0;\n     }\n     else if (cmd.hasOption(help))\n@@ -725,14 +697,10 @@ else if (cmd.hasOption(help))\n    */\n   public static void main(String[] args) throws Exception\n   {\n-    // For temporary test only, remove later\n-    // Logger.getRootLogger().setLevel(Level.ERROR);\n     if (args.length == 0)\n     {\n-      new ClusterSetup(\"localhost:2181\")\n-          .setupTestCluster(\"storage-integration-cluster\");\n-      new ClusterSetup(\"localhost:2181\")\n-          .setupTestCluster(\"relay-integration-cluster\");\n+      new ClusterSetup(\"localhost:2181\").setupTestCluster(\"storage-integration-cluster\");\n+      new ClusterSetup(\"localhost:2181\").setupTestCluster(\"relay-integration-cluster\");\n       System.exit(0);\n     }\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/2e71841696acf0df9f18ac620479a6478cd7a15d",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/5f0c543849e97dcf36f3b555174ad9c589eb77fd",
        "message": "fix potential NPE in queue size monitoring",
        "bug_id": "helix_44",
        "file": [
            {
                "sha": "155deb9d63d280fd1aa0bd451d12e7b6df16569a",
                "filename": "helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/2e71841696acf0df9f18ac620479a6478cd7a15d/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "raw_url": "https://github.com/apache/helix/raw/2e71841696acf0df9f18ac620479a6478cd7a15d/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java?ref=2e71841696acf0df9f18ac620479a6478cd7a15d",
                "patch": "@@ -415,7 +415,7 @@ public void onMessage(String instanceName,\n   {\n     logger.info(\"START: GenericClusterController.onMessage()\");\n     \n-    if (_msgQueueMonitor != null)\n+    if (_msgQueueMonitor != null && messages != null)\n     {\n       _msgQueueMonitor.addMessageQueueSize(messages.size());\n     }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/62f15af055aaa32d83b532232a580812cf2e732f",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/0380d58c68b7e7a90ff83f22088841c048cf52d9",
        "message": "DDS-3752: NPE in ClusterRepresentationUtil.getPropertyAsString()",
        "bug_id": "helix_45",
        "file": [
            {
                "sha": "214f6f17ed7a55166e23e5a80cb7a0cbfd202121",
                "filename": "helix-admin-webapp/src/main/java/com/linkedin/helix/webapp/resources/ClusterRepresentationUtil.java",
                "status": "modified",
                "additions": 10,
                "deletions": 2,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/62f15af055aaa32d83b532232a580812cf2e732f/helix-admin-webapp/src/main/java/com/linkedin/helix/webapp/resources/ClusterRepresentationUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/62f15af055aaa32d83b532232a580812cf2e732f/helix-admin-webapp/src/main/java/com/linkedin/helix/webapp/resources/ClusterRepresentationUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-admin-webapp/src/main/java/com/linkedin/helix/webapp/resources/ClusterRepresentationUtil.java?ref=62f15af055aaa32d83b532232a580812cf2e732f",
                "patch": "@@ -48,6 +48,8 @@\n \n public class ClusterRepresentationUtil\n {\n+  private static final ZNRecord EMPTY_ZNRECORD = new ZNRecord(\"EMPTY_ZNRECORD\");\n+\n   public static String getClusterPropertyAsString(ZkClient zkClient,\n                                                   String clusterName,\n                                                   PropertyKey propertyKey,\n@@ -138,7 +140,12 @@ public static String getPropertyAsString(ZkClient zkClient,\n     ZKHelixDataAccessor accessor =\n         new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor<ZNRecord>(zkClient));\n \n-    ZNRecord record = accessor.getProperty(propertyKey).getRecord();\n+    ZNRecord record = EMPTY_ZNRECORD;\n+    HelixProperty property = accessor.getProperty(propertyKey);\n+    if (property != null)\n+    {\n+      record = property.getRecord();\n+    }\n     return ObjectToJson(record);\n   }\n \n@@ -166,7 +173,8 @@ public static String ObjectToJson(Object object) throws JsonGenerationException,\n   public static HelixDataAccessor getClusterDataAccessor(ZkClient zkClient,\n                                                          String clusterName)\n   {\n-    return new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor<ZNRecord>(zkClient));\n+    return new ZKHelixDataAccessor(clusterName,\n+                                   new ZkBaseDataAccessor<ZNRecord>(zkClient));\n   }\n \n   public static <T extends Object> T JsonToObject(Class<T> clazz, String jsonString) throws JsonParseException,"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/b72ff29d1fc2845affb9ee943396424c5a7e5721",
        "message": "[Helix-612] Bump up the version of zkClient and zookeeper to avoid NPE",
        "bug_id": "helix_46",
        "file": [
            {
                "sha": "8143ca0c0cf131edc8f6379c68dd92a06a57cf5f",
                "filename": "helix-core/helix-core-0.6.6-SNAPSHOT.ivy",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/helix-core-0.6.6-SNAPSHOT.ivy",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/helix-core-0.6.6-SNAPSHOT.ivy",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/helix-core-0.6.6-SNAPSHOT.ivy?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -47,13 +47,13 @@ under the License.\n \t\n \t<dependencies>\n     <dependency org=\"log4j\" name=\"log4j\" rev=\"1.2.15\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n-    <dependency org=\"org.apache.zookeeper\" name=\"zookeeper\" rev=\"3.3.4\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/> \n+    <dependency org=\"org.apache.zookeeper\" name=\"zookeeper\" rev=\"3.4.6\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"org.codehaus.jackson\" name=\"jackson-core-asl\" rev=\"1.8.5\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"org.codehaus.jackson\" name=\"jackson-mapper-asl\" rev=\"1.8.5\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"commons-io\" name=\"commons-io\" rev=\"1.4\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"commons-cli\" name=\"commons-cli\" rev=\"1.2\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"commons-math\" name=\"commons-math\" rev=\"2.1\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n-    <dependency org=\"com.github.sgroschupf\" name=\"zkclient\" rev=\"0.1\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n+    <dependency org=\"com.101tec\" name=\"zkclient\" rev=\"0.5\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"com.google.guava\" name=\"guava\" rev=\"15.0\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"org.yaml\" name=\"snakeyaml\" rev=\"1.12\" conf=\"compile->compile(default);runtime->runtime(default);default->default\"/>\n     <dependency org=\"commons-logging\" name=\"commons-logging-api\" rev=\"1.1\" conf=\"compile->compile(*),master(*);runtime->runtime(*)\"/>"
            },
            {
                "sha": "0af60ed9ccec343f0564764a87629dbbcd53cb83",
                "filename": "helix-core/pom.xml",
                "status": "modified",
                "additions": 3,
                "deletions": 3,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/pom.xml",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/pom.xml?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -80,7 +80,7 @@ under the License.\n     <dependency>\n       <groupId>org.apache.zookeeper</groupId>\n       <artifactId>zookeeper</artifactId>\n-      <version>3.3.4</version>\n+      <version>3.4.6</version>\n       <exclusions>\n         <exclusion>\n           <groupId>junit</groupId>\n@@ -109,9 +109,9 @@ under the License.\n       <version>1.2</version>\n     </dependency>\n     <dependency>\n-      <groupId>com.github.sgroschupf</groupId>\n+      <groupId>com.101tec</groupId>\n       <artifactId>zkclient</artifactId>\n-      <version>0.1</version>\n+      <version>0.5</version>\n     </dependency>\n     <dependency>\n       <groupId>org.testng</groupId>"
            },
            {
                "sha": "8bf8a54eff6455c4afb5aaae99e63956a179c158",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -916,4 +916,8 @@ public ParticipantHealthReportCollector getHealthReportCollector() {\n     checkConnected();\n     return _participantHealthInfoCollector;\n   }\n+\n+  @Override\n+  public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+  }\n }"
            },
            {
                "sha": "e7884ced702800b6ebe5eea926dba3e13476949e",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkCallbackCache.java",
                "status": "modified",
                "additions": 3,
                "deletions": 0,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZkCallbackCache.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZkCallbackCache.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkCallbackCache.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -297,4 +297,7 @@ public void run() throws Exception {\n     }\n   }\n \n+  @Override\n+  public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+  }\n }"
            },
            {
                "sha": "48feacc7bb89854632040ba7bed25f6c17715127",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "status": "modified",
                "additions": 0,
                "deletions": 1,
                "changes": 1,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -143,7 +143,6 @@ public void close() throws ZkInterruptedException {\n            */\n           Thread.interrupted();\n           _connection.close();\n-          _connection = null;\n           /**\n            * restore interrupted status of current thread\n            */"
            },
            {
                "sha": "999c5e958ff2a057cf9af7cd0d83f96a491ee3a4",
                "filename": "helix-core/src/main/java/org/apache/helix/tools/ZKLogFormatter.java",
                "status": "modified",
                "additions": 1,
                "deletions": 4,
                "changes": 5,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/tools/ZKLogFormatter.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/main/java/org/apache/helix/tools/ZKLogFormatter.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/tools/ZKLogFormatter.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -22,7 +22,6 @@\n import java.beans.Introspector;\n import java.beans.PropertyDescriptor;\n import java.io.BufferedWriter;\n-import java.io.ByteArrayInputStream;\n import java.io.EOFException;\n import java.io.File;\n import java.io.FileInputStream;\n@@ -40,7 +39,6 @@\n import javax.xml.bind.annotation.adapters.HexBinaryAdapter;\n \n import org.apache.jute.BinaryInputArchive;\n-import org.apache.jute.InputArchive;\n import org.apache.jute.Record;\n import org.apache.log4j.Logger;\n import org.apache.zookeeper.KeeperException.NoNodeException;\n@@ -250,9 +248,8 @@ private static void readTransactionLog(String logfilepath) throws FileNotFoundEx\n       if (crcValue != crc.getValue()) {\n         throw new IOException(\"CRC doesn't match \" + crcValue + \" vs \" + crc.getValue());\n       }\n-      InputArchive iab = BinaryInputArchive.getArchive(new ByteArrayInputStream(bytes));\n       TxnHeader hdr = new TxnHeader();\n-      Record txn = SerializeUtils.deserializeTxn(iab, hdr);\n+      Record txn = SerializeUtils.deserializeTxn(bytes, hdr);\n       if (bw != null) {\n         bw.write(formatTransaction(hdr, txn));\n         bw.newLine();"
            },
            {
                "sha": "bc3d266ed97734dee1748786367de7fddb77d38d",
                "filename": "helix-core/src/test/java/org/apache/helix/TestZkClientWrapper.java",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/TestZkClientWrapper.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/TestZkClientWrapper.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/TestZkClientWrapper.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -85,6 +85,10 @@ public void handleStateChanged(KeeperState state) throws Exception {\n       public void handleNewSession() throws Exception {\n         System.out.println(\"In Old connection New session\");\n       }\n+\n+      @Override\n+      public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+      }\n     };\n \n     _zkClient.subscribeStateChanges(listener);"
            },
            {
                "sha": "6318b676e71e36237f0e97028dd5a320aa09d3c7",
                "filename": "helix-core/src/test/java/org/apache/helix/ZkTestHelper.java",
                "status": "modified",
                "additions": 8,
                "deletions": 0,
                "changes": 8,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/ZkTestHelper.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/ZkTestHelper.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/ZkTestHelper.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -95,6 +95,10 @@ public void handleNewSession() throws Exception {\n \n         LOG.info(\"handleNewSession. sessionId: \" + Long.toHexString(curZookeeper.getSessionId()));\n       }\n+\n+      @Override\n+      public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+      }\n     };\n \n     zkClient.subscribeStateChanges(listener);\n@@ -146,6 +150,10 @@ public void handleNewSession() throws Exception {\n         LOG.info(\"handleNewSession. sessionId: \" + Long.toHexString(curZookeeper.getSessionId()));\n         waitNewSession.countDown();\n       }\n+\n+      @Override\n+      public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+      }\n     };\n \n     zkClient.subscribeStateChanges(listener);"
            },
            {
                "sha": "83f3d30724ec6726db31235ac9f4b1d7601f2e38",
                "filename": "helix-core/src/test/java/org/apache/helix/ZkUnitTestBase.java",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/ZkUnitTestBase.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/ZkUnitTestBase.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/ZkUnitTestBase.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -225,6 +225,10 @@ public void handleStateChanged(KeeperState state) throws Exception {\n       public void handleNewSession() throws Exception {\n         LOG.info(\"In Old connection, new session\");\n       }\n+\n+      @Override\n+      public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+      }\n     };\n     zkClient.subscribeStateChanges(listener);\n     ZkConnection connection = ((ZkConnection) zkClient.getConnection());"
            },
            {
                "sha": "b567e4a50564ea0d9bbf460bb0e7b1cbb7a1b36a",
                "filename": "helix-core/src/test/java/org/apache/helix/manager/zk/TestZkFlapping.java",
                "status": "modified",
                "additions": 5,
                "deletions": 1,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/manager/zk/TestZkFlapping.java",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/helix-core/src/test/java/org/apache/helix/manager/zk/TestZkFlapping.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/manager/zk/TestZkFlapping.java?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -130,6 +130,10 @@ public void handleStateChanged(KeeperState state) throws Exception {\n     @Override\n     public void handleNewSession() throws Exception {\n     }\n+\n+    @Override\n+    public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+    }\n   }\n \n   @Test\n@@ -290,4 +294,4 @@ public boolean verify() throws Exception {\n \n     System.out.println(\"END \" + clusterName + \" at \" + new Date(System.currentTimeMillis()));\n   }\n-}\n\\ No newline at end of file\n+}"
            },
            {
                "sha": "004018ed8c4f0ade373fe1ba34d71398cd8c2d30",
                "filename": "recipes/rabbitmq-consumer-group/pom.xml",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/recipes/rabbitmq-consumer-group/pom.xml",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/recipes/rabbitmq-consumer-group/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/recipes/rabbitmq-consumer-group/pom.xml?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -83,9 +83,9 @@ under the License.\n       </exclusions>\n     </dependency>\n     <dependency>\n-      <groupId>com.github.sgroschupf</groupId>\n+      <groupId>com.101tec</groupId>\n       <artifactId>zkclient</artifactId>\n-      <version>0.1</version>\n+      <version>0.5</version>\n     </dependency>\n   </dependencies>\n   <build>"
            },
            {
                "sha": "5bc80a3bcdc888ee74618864cefe9097ce857dec",
                "filename": "recipes/rsync-replicated-file-system/pom.xml",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/recipes/rsync-replicated-file-system/pom.xml",
                "raw_url": "https://github.com/apache/helix/raw/308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5/recipes/rsync-replicated-file-system/pom.xml",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/recipes/rsync-replicated-file-system/pom.xml?ref=308c2cc6f45d9c942d9b4a8f52e4cf534528e2d5",
                "patch": "@@ -82,9 +82,9 @@ under the License.\n       <version>1.0</version>\n     </dependency>\n     <dependency>\n-      <groupId>com.github.sgroschupf</groupId>\n+      <groupId>com.101tec</groupId>\n       <artifactId>zkclient</artifactId>\n-      <version>0.1</version>\n+      <version>0.5</version>\n     </dependency>\n   </dependencies>\n   <build>"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/49ceac0e9449940546e37628780e5098ac4e8678",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/720e81999aada623ec24e3cb6e6e835aa12c3175",
        "message": "[HELIX-578] NPE while deleting a job from a recurrent job queue.",
        "bug_id": "helix_47",
        "file": [
            {
                "sha": "b8ca14130018aa2e2ce0c54679c98538a371f1ca",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "status": "modified",
                "additions": 79,
                "deletions": 19,
                "changes": 98,
                "blob_url": "https://github.com/apache/helix/blob/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java?ref=49ceac0e9449940546e37628780e5098ac4e8678",
                "patch": "@@ -281,17 +281,59 @@ public ZNRecord update(ZNRecord currentData) {\n \n   /** Delete a job from an existing named queue, the queue has to be stopped prior to this call */\n   public void deleteJob(final String queueName, final String jobName) {\n-    HelixProperty workflowConfig = _accessor.getProperty(_accessor.keyBuilder().resourceConfig(queueName));\n-    if (workflowConfig == null) {\n+    WorkflowConfig workflowCfg =\n+        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+\n+    if (workflowCfg == null) {\n       throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n     }\n-    boolean isTerminable =\n-        workflowConfig.getRecord().getBooleanField(WorkflowConfig.TERMINABLE, true);\n-    if (isTerminable) {\n+    if (workflowCfg.isTerminable()) {\n       throw new IllegalArgumentException(queueName + \" is not a queue!\");\n     }\n \n+    boolean isRecurringWorkflow =\n+        (workflowCfg.getScheduleConfig() != null && workflowCfg.getScheduleConfig().isRecurring());\n+\n+    if (isRecurringWorkflow) {\n+      WorkflowContext wCtx = TaskUtil.getWorkflowContext(_propertyStore, queueName);\n+\n+      String lastScheduledQueue = wCtx.getLastScheduledSingleWorkflow();\n+\n+      // delete the current scheduled one\n+      deleteJobFromScheduledQueue(lastScheduledQueue, jobName);\n+\n+      // Remove the job from the original queue template's DAG\n+      removeJobFromDag(queueName, jobName);\n+\n+      // delete the ideal state and resource config for the template job\n+      final String namespacedJobName = TaskUtil.getNamespacedJobName(queueName, jobName);\n+      _admin.dropResource(_clusterName, namespacedJobName);\n+\n+      // Delete the job template from property store\n+      String jobPropertyPath =\n+          Joiner.on(\"/\")\n+              .join(TaskConstants.REBALANCER_CONTEXT_ROOT, namespacedJobName);\n+      _propertyStore.remove(jobPropertyPath, AccessOption.PERSISTENT);\n+    } else {\n+      deleteJobFromScheduledQueue(queueName, jobName);\n+    }\n+  }\n+\n+\n+  /** delete a job from a scheduled (non-recurrent) queue.*/\n+  private void deleteJobFromScheduledQueue(final String queueName, final String jobName) {\n+    WorkflowConfig workflowCfg =\n+        TaskUtil.getWorkflowCfg(_cfgAccessor, _accessor, _clusterName, queueName);\n+\n+    if (workflowCfg == null) {\n+      throw new IllegalArgumentException(\"Queue \" + queueName + \" does not yet exist!\");\n+    }\n+\n     WorkflowContext wCtx = TaskUtil.getWorkflowContext(_propertyStore, queueName);\n+    if (wCtx != null && wCtx.getWorkflowState() == null) {\n+      throw new IllegalStateException(\"Queue \" + queueName + \" does not have a valid work state!\");\n+    }\n+\n     String workflowState =\n         (wCtx != null) ? wCtx.getWorkflowState().name() : TaskState.NOT_STARTED.name();\n \n@@ -300,7 +342,26 @@ public void deleteJob(final String queueName, final String jobName) {\n     }\n \n     // Remove the job from the queue in the DAG\n+    removeJobFromDag(queueName, jobName);\n+\n+    // delete the ideal state and resource config for the job\n+    final String namespacedJobName = TaskUtil.getNamespacedJobName(queueName, jobName);\n+    _admin.dropResource(_clusterName, namespacedJobName);\n+\n+    // update queue's property to remove job from JOB_STATES if it is already started.\n+    removeJobStateFromQueue(queueName, jobName);\n+\n+    // Delete the job from property store\n+    String jobPropertyPath =\n+        Joiner.on(\"/\")\n+            .join(TaskConstants.REBALANCER_CONTEXT_ROOT, namespacedJobName);\n+    _propertyStore.remove(jobPropertyPath, AccessOption.PERSISTENT);\n+  }\n+\n+  /** Remove the job name from the DAG from the queue configuration */\n+  private void removeJobFromDag(final String queueName, final String jobName) {\n     final String namespacedJobName = TaskUtil.getNamespacedJobName(queueName, jobName);\n+\n     DataUpdater<ZNRecord> updater = new DataUpdater<ZNRecord>() {\n       @Override\n       public ZNRecord update(ZNRecord currentData) {\n@@ -338,7 +399,7 @@ public ZNRecord update(ZNRecord currentData) {\n           currentData.setSimpleField(WorkflowConfig.DAG, jobDag.toJson());\n         } catch (Exception e) {\n           throw new IllegalStateException(\n-              \"Could not remove job \" + jobName + \" from queue \" + queueName, e);\n+              \"Could not remove job \" + jobName + \" from DAG of queue \" + queueName, e);\n         }\n         return currentData;\n       }\n@@ -347,17 +408,20 @@ public ZNRecord update(ZNRecord currentData) {\n     String path = _accessor.keyBuilder().resourceConfig(queueName).getPath();\n     boolean status = _accessor.getBaseDataAccessor().update(path, updater, AccessOption.PERSISTENT);\n     if (!status) {\n-      throw new IllegalArgumentException(\"Could not enqueue job\");\n+      throw new IllegalArgumentException(\n+          \"Could not remove job \" + jobName + \" from DAG of queue \" + queueName);\n     }\n+  }\n \n-    // delete the ideal state and resource config for the job\n-    _admin.dropResource(_clusterName, namespacedJobName);\n-\n-    // update queue's property to remove job from JOB_STATES if it is already started.\n+  /** update queue's property to remove job from JOB_STATES if it is already started.\n+   */\n+  private void removeJobStateFromQueue(final String queueName, final String jobName) {\n+    final String namespacedJobName = TaskUtil.getNamespacedJobName(queueName, jobName);\n     String queuePropertyPath =\n         Joiner.on(\"/\")\n             .join(TaskConstants.REBALANCER_CONTEXT_ROOT, queueName, TaskUtil.CONTEXT_NODE);\n-    updater = new DataUpdater<ZNRecord>() {\n+\n+    DataUpdater<ZNRecord> updater = new DataUpdater<ZNRecord>() {\n       @Override\n       public ZNRecord update(ZNRecord currentData) {\n         if (currentData != null) {\n@@ -369,13 +433,9 @@ public ZNRecord update(ZNRecord currentData) {\n         return currentData;\n       }\n     };\n-    _propertyStore.update(queuePropertyPath, updater, AccessOption.PERSISTENT);\n-\n-    // Delete the job from property store\n-    String jobPropertyPath =\n-        Joiner.on(\"/\")\n-            .join(TaskConstants.REBALANCER_CONTEXT_ROOT, namespacedJobName);\n-    _propertyStore.remove(jobPropertyPath, AccessOption.PERSISTENT);\n+    if (!_propertyStore.update(queuePropertyPath, updater, AccessOption.PERSISTENT)) {\n+      LOG.warn(\"Fail to remove job state for job \" + namespacedJobName + \" from queue \" + queueName);\n+    }\n   }\n \n   /** Adds a new job to the end an existing named queue */"
            },
            {
                "sha": "9f723631a08f0da00883da8fdce276dba80873f4",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "status": "modified",
                "additions": 114,
                "deletions": 1,
                "changes": 115,
                "blob_url": "https://github.com/apache/helix/blob/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "raw_url": "https://github.com/apache/helix/raw/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=49ceac0e9449940546e37628780e5098ac4e8678",
                "patch": "@@ -20,7 +20,9 @@\n  */\n \n import java.util.ArrayList;\n+import java.util.Calendar;\n import java.util.Collections;\n+import java.util.Date;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n@@ -51,6 +53,7 @@\n import org.apache.helix.task.TaskUtil;\n import org.apache.helix.task.Workflow;\n import org.apache.helix.task.WorkflowConfig;\n+import org.apache.helix.task.WorkflowContext;\n import org.apache.helix.tools.ClusterSetup;\n import org.apache.helix.tools.ClusterStateVerifier;\n import org.apache.log4j.Logger;\n@@ -254,6 +257,7 @@ public void stopAndResumeNamedQueue() throws Exception {\n     verifyJobNotInQueue(queueName, namespacedJob2);\n   }\n \n+\n   @Test\n   public void stopDeleteAndResumeNamedQueue() throws Exception {\n     String queueName = TestHelper.getTestMethodName();\n@@ -319,9 +323,19 @@ public void stopDeleteAndResumeNamedQueue() throws Exception {\n     LOG.info(\"Resuming job-queue: \" + queueName);\n     _driver.resume(queueName);\n \n-    // Ensure the jobs left are successful completed in the correct order\n     currentJobNames.remove(deletedJob1);\n     currentJobNames.remove(deletedJob2);\n+\n+    // add job 3 back\n+    JobConfig.Builder job =\n+        new JobConfig.Builder().setCommand(\"Reindex\")\n+            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setTargetPartitionStates(Sets.newHashSet(\"SLAVE\"));\n+    LOG.info(\"Enqueuing job: \" + deletedJob2);\n+    _driver.enqueueJob(queueName, deletedJob2, job);\n+    currentJobNames.add(deletedJob2);\n+\n+    // Ensure the jobs left are successful completed in the correct order\n     long preJobFinish = 0;\n     for (int i = 0; i < currentJobNames.size(); i++) {\n       String namedSpaceJobName = String.format(\"%s_%s\", queueName, currentJobNames.get(i));\n@@ -346,6 +360,105 @@ public void stopDeleteAndResumeNamedQueue() throws Exception {\n     }\n   }\n \n+  private JobQueue buildRecurrentJobQueue(String jobQueueName)\n+  {\n+    Map<String, String> cfgMap = new HashMap<String, String>();\n+    cfgMap.put(WorkflowConfig.EXPIRY, String.valueOf(50000));\n+    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.DEFAULT_DATE_FORMAT.format(\n+        Calendar.getInstance().getTime()));\n+    cfgMap.put(WorkflowConfig.RECURRENCE_INTERVAL, String.valueOf(60));\n+    cfgMap.put(WorkflowConfig.RECURRENCE_UNIT, \"SECONDS\");\n+    return (new JobQueue.Builder(jobQueueName).fromMap(cfgMap)).build();\n+  }\n+\n+  @Test\n+  public void stopDeleteAndResumeRecurrentNamedQueue() throws Exception {\n+    String queueName = TestHelper.getTestMethodName();\n+\n+    // Create a queue\n+    LOG.info(\"Starting job-queue: \" + queueName);\n+    JobQueue queue = buildRecurrentJobQueue(queueName);\n+    _driver.createQueue(queue);\n+\n+    // Create and Enqueue jobs\n+    List<String> currentJobNames = new ArrayList<String>();\n+    Map<String, String> commandConfig = ImmutableMap.of(TIMEOUT_CONFIG, String.valueOf(500));\n+    for (int i = 0; i <= 4; i++) {\n+      String targetPartition = (i == 0) ? \"MASTER\" : \"SLAVE\";\n+\n+      JobConfig.Builder job =\n+          new JobConfig.Builder().setCommand(\"Reindex\")\n+              .setJobCommandConfigMap(commandConfig)\n+              .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+              .setTargetPartitionStates(Sets.newHashSet(targetPartition));\n+      String jobName = targetPartition.toLowerCase() + \"Job\" + i;\n+      LOG.info(\"Enqueuing job: \" + jobName);\n+      _driver.enqueueJob(queueName, jobName, job);\n+      currentJobNames.add(i, jobName);\n+    }\n+\n+    WorkflowContext wCtx = TestUtil.pollForWorkflowContext(_manager, queueName);\n+    String scheduledQueue = wCtx.getLastScheduledSingleWorkflow();\n+\n+    // ensure job 1 is started before deleting it\n+    String deletedJob1 = currentJobNames.get(0);\n+    String namedSpaceDeletedJob1 = String.format(\"%s_%s\", scheduledQueue, deletedJob1);\n+    TestUtil.pollForJobState(_manager, scheduledQueue, namedSpaceDeletedJob1, TaskState.IN_PROGRESS);\n+\n+    // stop the queue\n+    LOG.info(\"Pausing job-queue: \" + scheduledQueue);\n+    _driver.stop(queueName);\n+    TestUtil.pollForJobState(_manager, scheduledQueue, namedSpaceDeletedJob1, TaskState.STOPPED);\n+    TestUtil.pollForWorkflowState(_manager, scheduledQueue, TaskState.STOPPED);\n+\n+    // delete the in-progress job (job 1) and verify it being deleted\n+    _driver.deleteJob(queueName, deletedJob1);\n+    verifyJobDeleted(queueName, namedSpaceDeletedJob1);\n+    verifyJobDeleted(scheduledQueue, namedSpaceDeletedJob1);\n+\n+    LOG.info(\"Resuming job-queue: \" + queueName);\n+    _driver.resume(queueName);\n+\n+    // ensure job 2 is started\n+    TestUtil.pollForJobState(_manager, scheduledQueue,\n+        String.format(\"%s_%s\", scheduledQueue, currentJobNames.get(1)), TaskState.IN_PROGRESS);\n+\n+    // stop the queue\n+    LOG.info(\"Pausing job-queue: \" + queueName);\n+    _driver.stop(queueName);\n+    TestUtil.pollForJobState(_manager, scheduledQueue,\n+        String.format(\"%s_%s\", scheduledQueue, currentJobNames.get(1)), TaskState.STOPPED);\n+    TestUtil.pollForWorkflowState(_manager, scheduledQueue, TaskState.STOPPED);\n+\n+    // Ensure job 3 is not started before deleting it\n+    String deletedJob2 = currentJobNames.get(2);\n+    String namedSpaceDeletedJob2 = String.format(\"%s_%s\", scheduledQueue, deletedJob2);\n+    TestUtil.pollForEmptyJobState(_manager, scheduledQueue, namedSpaceDeletedJob2);\n+\n+    // delete not-started job (job 3) and verify it being deleted\n+    _driver.deleteJob(queueName, deletedJob2);\n+    verifyJobDeleted(queueName, namedSpaceDeletedJob2);\n+    verifyJobDeleted(scheduledQueue, namedSpaceDeletedJob2);\n+\n+    LOG.info(\"Resuming job-queue: \" + queueName);\n+    _driver.resume(queueName);\n+\n+    // Ensure the jobs left are successful completed in the correct order\n+    currentJobNames.remove(deletedJob1);\n+    currentJobNames.remove(deletedJob2);\n+    long preJobFinish = 0;\n+    for (int i = 0; i < currentJobNames.size(); i++) {\n+      String namedSpaceJobName = String.format(\"%s_%s\", scheduledQueue, currentJobNames.get(i));\n+      TestUtil.pollForJobState(_manager, scheduledQueue, namedSpaceJobName, TaskState.COMPLETED);\n+\n+      JobContext jobContext = TaskUtil.getJobContext(_manager, namedSpaceJobName);\n+      long jobStart = jobContext.getStartTime();\n+      Assert.assertTrue(jobStart >= preJobFinish);\n+      preJobFinish = jobContext.getFinishTime();\n+    }\n+    // verify the job is not there for the next recurrence of queue schedule\n+  }\n+\n   private void verifyJobDeleted(String queueName, String jobName) throws Exception {\n     HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n     PropertyKey.Builder keyBuilder = accessor.keyBuilder();"
            },
            {
                "sha": "27e827a61f6fe00dfb6528681af60e425edf45bd",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestUtil.java",
                "status": "modified",
                "additions": 13,
                "deletions": 0,
                "changes": 13,
                "blob_url": "https://github.com/apache/helix/blob/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/test/java/org/apache/helix/integration/task/TestUtil.java",
                "raw_url": "https://github.com/apache/helix/raw/49ceac0e9449940546e37628780e5098ac4e8678/helix-core/src/test/java/org/apache/helix/integration/task/TestUtil.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestUtil.java?ref=49ceac0e9449940546e37628780e5098ac4e8678",
                "patch": "@@ -81,4 +81,17 @@ public boolean verify() throws Exception {\n     }, _default_timeout);\n     Assert.assertTrue(succeed);\n   }\n+\n+  public static WorkflowContext pollForWorkflowContext(HelixManager manager, String workflowResource)\n+      throws InterruptedException {\n+    // Wait for completion.\n+    long st = System.currentTimeMillis();\n+    WorkflowContext ctx;\n+    do {\n+      Thread.sleep(100);\n+      ctx = TaskUtil.getWorkflowContext(manager, workflowResource);\n+    } while (ctx == null && System.currentTimeMillis() < st + _default_timeout);\n+    Assert.assertNotNull(ctx);\n+    return ctx;\n+  }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/4909a51d78b519a4025a5f8112d1fa4782f30a5d",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/21535dfe9170c1f7d0a7933073df92a809373a2c",
        "message": "Fix disconnected zkConnection issue.\n\nOne issue is found that when zkConnection may be using an invalid zookeeper object (null). And related calls will get NPE error.\nAffected Helix components are ZKHelixManager, ZkHelixPropertyStore and other zk related classes.\nFor fixing this issue:\n1. Override retryUntilConnected() in Helix ZkClient to check the connection before trigger callbacks. This will prevent NPE. But user will still need to try-catch IllegalStateException, and re-create a ZkClient if necessary.\n2. For ZKHelixManager, implement handleSessionEstablishmentError to retry establishing a new connection. If retry fails, Helix invokes a user registered state handler.\n3. Add unit test for simulating connection error and test if error handler can recover the connection or trigger user registered callback.",
        "bug_id": "helix_48",
        "file": [
            {
                "sha": "b26f9d8bd88db2404c8da6c940aa6370803f1c25",
                "filename": "helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "raw_url": "https://github.com/apache/helix/raw/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java?ref=4909a51d78b519a4025a5f8112d1fa4782f30a5d",
                "patch": "@@ -25,6 +25,7 @@\n  * for zk-based cluster managers, the getZKXXX(..zkClient) that takes a zkClient parameter\n  *   are intended for session expiry test purpose\n  */\n+import org.apache.helix.manager.zk.HelixManagerStateListener;\n import org.apache.helix.manager.zk.ZKHelixManager;\n import org.apache.log4j.Logger;\n \n@@ -48,4 +49,19 @@ public static HelixManager getZKHelixManager(String clusterName, String instance\n     return new ZKHelixManager(clusterName, instanceName, type, zkAddr);\n   }\n \n+  /**\n+   * Construct a zk-based cluster manager that enforces all types (PARTICIPANT, CONTROLLER, and\n+   * SPECTATOR) to have a name\n+   * @param clusterName\n+   * @param instanceName\n+   * @param type\n+   * @param zkAddr\n+   * @param stateListener\n+   * @return a HelixManager backed by Zookeeper\n+   */\n+  public static HelixManager getZKHelixManager(String clusterName, String instanceName,\n+      InstanceType type, String zkAddr, HelixManagerStateListener stateListener) {\n+    return new ZKHelixManager(clusterName, instanceName, type, zkAddr, stateListener);\n+  }\n+\n }"
            },
            {
                "sha": "0277bfdab676f74aa23a9e6aceaddbb2eb4394fe",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "status": "added",
                "additions": 43,
                "deletions": 0,
                "changes": 43,
                "blob_url": "https://github.com/apache/helix/blob/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "raw_url": "https://github.com/apache/helix/raw/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java?ref=4909a51d78b519a4025a5f8112d1fa4782f30a5d",
                "patch": "@@ -0,0 +1,43 @@\n+package org.apache.helix.manager.zk;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import org.apache.helix.HelixManager;\n+\n+\n+public interface HelixManagerStateListener {\n+\n+  /**\n+   * Placeholder method for ensure backward compatible.\n+   * User will need to implement this method when Helix support async connecting to zookeeper.\n+   *\n+   * Invoked when the HelixManager connection to zookeeper is established\n+   * @param helixManager HelixManager that is successfully connected\n+   */\n+  void onConnected(HelixManager helixManager) throws Exception;\n+\n+  /**\n+   * Invoked when the HelixManager connection to zookeeper is disconnected\n+   *\n+   * @param helixManager HelixManager that fails to be connected\n+   * @param error connection error\n+   */\n+  void onDisconnected(HelixManager helixManager, Throwable error) throws Exception;\n+}"
            },
            {
                "sha": "43dc6a5c0d55c0331870ad9e8e5e6dd78a318975",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "status": "modified",
                "additions": 61,
                "deletions": 7,
                "changes": 68,
                "blob_url": "https://github.com/apache/helix/blob/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "raw_url": "https://github.com/apache/helix/raw/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=4909a51d78b519a4025a5f8112d1fa4782f30a5d",
                "patch": "@@ -80,15 +80,19 @@\n   public static final int FLAPPING_TIME_WINDOW = 300000; // Default to 300 sec\n   public static final int MAX_DISCONNECT_THRESHOLD = 5;\n   public static final String ALLOW_PARTICIPANT_AUTO_JOIN = \"allowParticipantAutoJoin\";\n+  private static final int DEFAULT_CONNECTION_ESTABLISHMENT_RETRY_TIMEOUT = 120000; // Default to 120 sec\n \n   protected final String _zkAddress;\n   private final String _clusterName;\n   private final String _instanceName;\n   private final InstanceType _instanceType;\n   private final int _sessionTimeout;\n+  private final int _clientConnectionTimeout;\n+  private final int _connectionRetryTimeout;\n   private final List<PreConnectCallback> _preConnectCallbacks;\n   protected final List<CallbackHandler> _handlers;\n   private final HelixManagerProperties _properties;\n+  private final HelixManagerStateListener _stateListener;\n \n   /**\n    * helix version#\n@@ -173,6 +177,11 @@ public void stop() {\n \n   public ZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddress) {\n+    this(clusterName, instanceName, instanceType, zkAddress, null);\n+  }\n+\n+  public ZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddress, HelixManagerStateListener stateListener) {\n \n     LOG.info(\"Create a zk-based cluster manager. zkSvr: \" + zkAddress + \", clusterName: \"\n         + clusterName + \", instanceName: \" + instanceName + \", type: \" + instanceType);\n@@ -201,6 +210,8 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n     _keyBuilder = new Builder(clusterName);\n     _messagingService = new DefaultMessagingService(this);\n \n+    _stateListener = stateListener;\n+\n     /**\n      * use system property if available\n      */\n@@ -212,8 +223,12 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n         getSystemPropertyAsInt(\"helixmanager.maxDisconnectThreshold\",\n             ZKHelixManager.MAX_DISCONNECT_THRESHOLD);\n \n-    _sessionTimeout =\n-        getSystemPropertyAsInt(\"zk.session.timeout\", ZkClient.DEFAULT_SESSION_TIMEOUT);\n+    _sessionTimeout = getSystemPropertyAsInt(\"zk.session.timeout\", ZkClient.DEFAULT_SESSION_TIMEOUT);\n+\n+    _clientConnectionTimeout = getSystemPropertyAsInt(\"zk.connection.timeout\", ZkClient.DEFAULT_CONNECTION_TIMEOUT);\n+\n+    _connectionRetryTimeout =\n+        getSystemPropertyAsInt(\"zk.connectionReEstablishment.timeout\", DEFAULT_CONNECTION_ESTABLISHMENT_RETRY_TIMEOUT);\n \n     /**\n      * instance type specific init\n@@ -470,7 +485,7 @@ void createClient() throws Exception {\n         ChainedPathZkSerializer.builder(new ZNRecordStreamingSerializer()).build();\n \n     _zkclient =\n-        new ZkClient(_zkAddress, _sessionTimeout, ZkClient.DEFAULT_CONNECTION_TIMEOUT, zkSerializer);\n+        new ZkClient(_zkAddress, _sessionTimeout, _clientConnectionTimeout, zkSerializer);\n \n     _baseDataAccessor = createBaseDataAccessor();\n \n@@ -581,6 +596,8 @@ public void disconnect() {\n         _participantManager = null;\n       }\n \n+      _helixPropertyStore = null;\n+\n       _zkclient.close();\n       _zkclient = null;\n       _sessionStartTime = null;\n@@ -812,9 +829,10 @@ public void handleStateChanged(KeeperState state) throws Exception {\n        */\n       _disconnectTimeHistory.add(System.currentTimeMillis());\n       if (isFlapping()) {\n-        LOG.error(\"instanceName: \" + _instanceName + \" is flapping. disconnect it. \"\n+        String errorMsg = \"instanceName: \" + _instanceName + \" is flapping. disconnect it. \"\n             + \" maxDisconnectThreshold: \" + _maxDisconnectThreshold + \" disconnects in \"\n-            + _flappingTimeWindowMs + \"ms.\");\n+            + _flappingTimeWindowMs + \"ms.\";\n+        LOG.error(errorMsg);\n \n         // Only disable the instance when it's instance type is PARTICIPANT\n         if (_instanceType.equals(InstanceType.PARTICIPANT)) {\n@@ -823,6 +841,9 @@ public void handleStateChanged(KeeperState state) throws Exception {\n           getClusterManagmentTool().enableInstance(_clusterName, _instanceName, false);\n         }\n         disconnect();\n+        if (_stateListener != null) {\n+          _stateListener.onDisconnected(this, new HelixException(errorMsg));\n+        }\n       }\n       break;\n     case Expired:\n@@ -919,12 +940,45 @@ public ParticipantHealthReportCollector getHealthReportCollector() {\n   }\n \n   @Override\n-  public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+  public void handleSessionEstablishmentError(Throwable error) throws Exception {\n+    LOG.warn(\"Handling Session Establishment Error. Try to reset connection.\", error);\n+    // Close currently disconnected ZkClient before cleanup\n+    if (_zkclient != null) {\n+      _zkclient.close();\n+    }\n+    // Cleanup ZKHelixManager\n+    disconnect();\n+    // Try to establish connections\n+    long operationStartTime = System.currentTimeMillis();\n+    while (!isConnected()) {\n+      try {\n+        connect();\n+        break;\n+      } catch (Exception e) {\n+        if (System.currentTimeMillis() - operationStartTime >= _connectionRetryTimeout) {\n+          break;\n+        }\n+        // If retry fails, use the latest exception.\n+        error = e;\n+        LOG.error(\"Fail to reset connection after session establishment error happens. Will retry.\", error);\n+        // Yield until next retry.\n+        Thread.yield();\n+      }\n+    }\n+\n+    if (!isConnected()) {\n+      LOG.error(\"Fail to reset connection after session establishment error happens.\", error);\n+      // retry failed, trigger error handler\n+      if (_stateListener != null) {\n+        _stateListener.onDisconnected(this, error);\n+      }\n+    } else {\n+      LOG.info(\"Connection is recovered.\");\n+    }\n   }\n \n   @Override\n   public Long getSessionStartTime() {\n     return _sessionStartTime;\n   }\n-\n }"
            },
            {
                "sha": "4bd2dd68174c28fefc300ca6ab0eb218aac9f1ea",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "status": "modified",
                "additions": 15,
                "deletions": 0,
                "changes": 15,
                "blob_url": "https://github.com/apache/helix/blob/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "raw_url": "https://github.com/apache/helix/raw/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java?ref=4909a51d78b519a4025a5f8112d1fa4782f30a5d",
                "patch": "@@ -431,6 +431,21 @@ public Object call() throws Exception {\n     });\n   }\n \n+  public <T> T retryUntilConnected(final Callable<T> callable) {\n+    final ZkConnection zkConnection = (ZkConnection) getConnection();\n+    return super.retryUntilConnected(new Callable<T>() {\n+      @Override\n+      public T call() throws Exception {\n+        // Validate that the connection is not null before trigger callback\n+        if (zkConnection == null || zkConnection.getZookeeper() == null) {\n+          throw new IllegalStateException(\n+              \"ZkConnection is in invalid state! Please close this ZkClient and create new client.\");\n+        }\n+        return callable.call();\n+      }\n+    });\n+  }\n+\n   private void checkDataSizeLimit(byte[] data) {\n     if (data != null && data.length > ZNRecord.SIZE_LIMIT) {\n       LOG.error(\"Data size larger than 1M, will not write to zk. Data (first 1k): \""
            },
            {
                "sha": "53fb831c35454e7f507b237dcb1555eed28e3374",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "status": "modified",
                "additions": 76,
                "deletions": 1,
                "changes": 77,
                "blob_url": "https://github.com/apache/helix/blob/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "raw_url": "https://github.com/apache/helix/raw/4909a51d78b519a4025a5f8112d1fa4782f30a5d/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java?ref=4909a51d78b519a4025a5f8112d1fa4782f30a5d",
                "patch": "@@ -31,10 +31,13 @@\n import org.apache.helix.InstanceType;\n import org.apache.helix.NotificationContext;\n import org.apache.helix.TestHelper;\n+import org.apache.helix.manager.zk.HelixManagerStateListener;\n+import org.apache.helix.manager.zk.ZKHelixManager;\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.Message;\n import org.apache.helix.participant.statemachine.StateModel;\n import org.apache.helix.participant.statemachine.StateModelFactory;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n import org.apache.helix.tools.ClusterSetup;\n import org.apache.helix.tools.ClusterStateVerifier;\n import org.apache.helix.tools.ClusterStateVerifier.BestPossAndExtViewZkVerifier;\n@@ -137,6 +140,79 @@ public void run() {\n     }\n   }\n \n+  @Test\n+  public void testZKDisconnectCallback() throws Exception {\n+    final int zkPort = TestHelper.getRandomPort();\n+    final String zkAddr = String.format(\"localhost:%d\", zkPort);\n+    final ZkServer zkServer = TestHelper.startZkServer(zkAddr);\n+\n+    String className = TestHelper.getTestClassName();\n+    String methodName = TestHelper.getTestMethodName();\n+    final String clusterName = className + \"_\" + methodName;\n+\n+    // Init flag to check if callback is triggered\n+    final AtomicReference<Boolean> flag = new AtomicReference<Boolean>(false);\n+\n+    // Setup cluster\n+    LOG.info(\"Setup clusters\");\n+    ClusterSetup clusterSetup = new ClusterSetup(zkAddr);\n+    clusterSetup.addCluster(clusterName, true);\n+    // For fast test, set short timeout\n+    System.setProperty(\"zk.connection.timeout\", \"2000\");\n+    System.setProperty(\"zk.connectionReEstablishment.timeout\", \"1000\");\n+\n+    // Registers and starts controller, register listener for disconnect handling\n+    LOG.info(\"Starts controller\");\n+    final ZKHelixManager controller =\n+        (ZKHelixManager) HelixManagerFactory.getZKHelixManager(clusterName, null, InstanceType.CONTROLLER, zkAddr,\n+            new HelixManagerStateListener() {\n+              @Override\n+              public void onConnected(HelixManager helixManager) throws Exception {\n+                return;\n+              }\n+\n+              @Override\n+              public void onDisconnected(HelixManager helixManager, Throwable error) throws Exception {\n+                Assert.assertEquals(helixManager.getClusterName(), clusterName);\n+                flag.getAndSet(true);\n+              }\n+            });\n+\n+    try {\n+      controller.connect();\n+      ZkHelixPropertyStore propertyStore = controller.getHelixPropertyStore();\n+\n+      // 1. shutdown zkServer and check if handler trigger callback\n+      zkServer.shutdown();\n+      // Retry will fail, and flag should be set within onDisconnected handler\n+      controller.handleSessionEstablishmentError(new Exception(\"For testing\"));\n+      Assert.assertTrue(flag.get());\n+\n+      try {\n+        propertyStore.get(\"/\", null, 0);\n+        Assert.fail(\"propertyStore should be disconnected.\");\n+      } catch (IllegalStateException e) {\n+        // Expected exception\n+        System.out.println(e.getMessage());\n+      }\n+\n+      // 2. restart zkServer and check if handler will recover connection\n+      flag.getAndSet(false);\n+      zkServer.start();\n+      // Retry will succeed, and flag should not be set\n+      controller.handleSessionEstablishmentError(new Exception(\"For testing\"));\n+      Assert.assertFalse(flag.get());\n+      // New propertyStore should be in good state\n+      propertyStore = controller.getHelixPropertyStore();\n+      propertyStore.get(\"/\", null, 0);\n+    } finally {\n+      controller.disconnect();\n+      zkServer.shutdown();\n+      System.clearProperty(\"zk.connection.timeout\");\n+      System.clearProperty(\"zk.connectionReEstablishment.timeout\");\n+    }\n+  }\n+\n   public static final class SimpleStateModel extends StateModel {\n \n     private final CountDownLatch latch;\n@@ -151,5 +227,4 @@ public void onBecomeOnlineFromOffline(Message message, NotificationContext conte\n       latch.countDown();\n     }\n   }\n-\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/3da3e319a4a821add6291c385dae41b633fad078",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/78ed261e7afea59c4898ec28caa77f0569e3b5f2",
        "message": "Fix disconnected zkConnection issue.\n\nOne issue is found that when zkConnection may be using an invalid zookeeper object (null). And related calls will get NPE error.\nAffected Helix components are ZKHelixManager, ZkHelixPropertyStore and other zk related classes.\nFor fixing this issue:\n1. Override retryUntilConnected() in Helix ZkClient to check the connection before trigger callbacks. This will prevent NPE. But user will still need to try-catch IllegalStateException, and re-create a ZkClient if necessary.\n2. For ZKHelixManager, implement handleSessionEstablishmentError to retry establishing a new connection. If retry fails, Helix invokes a user registered state handler.\n3. Add unit test for simulating connection error and test if error handler can recover the connection or trigger user registered callback.",
        "bug_id": "helix_49",
        "file": [
            {
                "sha": "b26f9d8bd88db2404c8da6c940aa6370803f1c25",
                "filename": "helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "status": "modified",
                "additions": 16,
                "deletions": 0,
                "changes": 16,
                "blob_url": "https://github.com/apache/helix/blob/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "raw_url": "https://github.com/apache/helix/raw/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/HelixManagerFactory.java?ref=3da3e319a4a821add6291c385dae41b633fad078",
                "patch": "@@ -25,6 +25,7 @@\n  * for zk-based cluster managers, the getZKXXX(..zkClient) that takes a zkClient parameter\n  *   are intended for session expiry test purpose\n  */\n+import org.apache.helix.manager.zk.HelixManagerStateListener;\n import org.apache.helix.manager.zk.ZKHelixManager;\n import org.apache.log4j.Logger;\n \n@@ -48,4 +49,19 @@ public static HelixManager getZKHelixManager(String clusterName, String instance\n     return new ZKHelixManager(clusterName, instanceName, type, zkAddr);\n   }\n \n+  /**\n+   * Construct a zk-based cluster manager that enforces all types (PARTICIPANT, CONTROLLER, and\n+   * SPECTATOR) to have a name\n+   * @param clusterName\n+   * @param instanceName\n+   * @param type\n+   * @param zkAddr\n+   * @param stateListener\n+   * @return a HelixManager backed by Zookeeper\n+   */\n+  public static HelixManager getZKHelixManager(String clusterName, String instanceName,\n+      InstanceType type, String zkAddr, HelixManagerStateListener stateListener) {\n+    return new ZKHelixManager(clusterName, instanceName, type, zkAddr, stateListener);\n+  }\n+\n }"
            },
            {
                "sha": "0277bfdab676f74aa23a9e6aceaddbb2eb4394fe",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "status": "added",
                "additions": 43,
                "deletions": 0,
                "changes": 43,
                "blob_url": "https://github.com/apache/helix/blob/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "raw_url": "https://github.com/apache/helix/raw/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/HelixManagerStateListener.java?ref=3da3e319a4a821add6291c385dae41b633fad078",
                "patch": "@@ -0,0 +1,43 @@\n+package org.apache.helix.manager.zk;\n+\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+import org.apache.helix.HelixManager;\n+\n+\n+public interface HelixManagerStateListener {\n+\n+  /**\n+   * Placeholder method for ensure backward compatible.\n+   * User will need to implement this method when Helix support async connecting to zookeeper.\n+   *\n+   * Invoked when the HelixManager connection to zookeeper is established\n+   * @param helixManager HelixManager that is successfully connected\n+   */\n+  void onConnected(HelixManager helixManager) throws Exception;\n+\n+  /**\n+   * Invoked when the HelixManager connection to zookeeper is disconnected\n+   *\n+   * @param helixManager HelixManager that fails to be connected\n+   * @param error connection error\n+   */\n+  void onDisconnected(HelixManager helixManager, Throwable error) throws Exception;\n+}"
            },
            {
                "sha": "670a65e4f009a5f925e59b4398f29883aa1bfc32",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "status": "modified",
                "additions": 61,
                "deletions": 7,
                "changes": 68,
                "blob_url": "https://github.com/apache/helix/blob/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "raw_url": "https://github.com/apache/helix/raw/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixManager.java?ref=3da3e319a4a821add6291c385dae41b633fad078",
                "patch": "@@ -82,15 +82,19 @@\n   public static final int FLAPPING_TIME_WINDOW = 300000; // Default to 300 sec\n   public static final int MAX_DISCONNECT_THRESHOLD = 5;\n   public static final String ALLOW_PARTICIPANT_AUTO_JOIN = \"allowParticipantAutoJoin\";\n+  private static final int DEFAULT_CONNECTION_ESTABLISHMENT_RETRY_TIMEOUT = 120000; // Default to 120 sec\n \n   protected final String _zkAddress;\n   private final String _clusterName;\n   private final String _instanceName;\n   private final InstanceType _instanceType;\n   private final int _sessionTimeout;\n+  private final int _clientConnectionTimeout;\n+  private final int _connectionRetryTimeout;\n   private final List<PreConnectCallback> _preConnectCallbacks;\n   protected final List<CallbackHandler> _handlers;\n   private final HelixManagerProperties _properties;\n+  private final HelixManagerStateListener _stateListener;\n \n   /**\n    * helix version#\n@@ -175,6 +179,11 @@ public void stop() {\n \n   public ZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n       String zkAddress) {\n+    this(clusterName, instanceName, instanceType, zkAddress, null);\n+  }\n+\n+  public ZKHelixManager(String clusterName, String instanceName, InstanceType instanceType,\n+      String zkAddress, HelixManagerStateListener stateListener) {\n \n     LOG.info(\"Create a zk-based cluster manager. zkSvr: \" + zkAddress + \", clusterName: \"\n         + clusterName + \", instanceName: \" + instanceName + \", type: \" + instanceType);\n@@ -203,6 +212,8 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n     _keyBuilder = new Builder(clusterName);\n     _messagingService = new DefaultMessagingService(this);\n \n+    _stateListener = stateListener;\n+\n     /**\n      * use system property if available\n      */\n@@ -214,8 +225,12 @@ public ZKHelixManager(String clusterName, String instanceName, InstanceType inst\n         getSystemPropertyAsInt(\"helixmanager.maxDisconnectThreshold\",\n             ZKHelixManager.MAX_DISCONNECT_THRESHOLD);\n \n-    _sessionTimeout =\n-        getSystemPropertyAsInt(\"zk.session.timeout\", ZkClient.DEFAULT_SESSION_TIMEOUT);\n+    _sessionTimeout = getSystemPropertyAsInt(\"zk.session.timeout\", ZkClient.DEFAULT_SESSION_TIMEOUT);\n+\n+    _clientConnectionTimeout = getSystemPropertyAsInt(\"zk.connection.timeout\", ZkClient.DEFAULT_CONNECTION_TIMEOUT);\n+\n+    _connectionRetryTimeout =\n+        getSystemPropertyAsInt(\"zk.connectionReEstablishment.timeout\", DEFAULT_CONNECTION_ESTABLISHMENT_RETRY_TIMEOUT);\n \n     /**\n      * instance type specific init\n@@ -471,7 +486,7 @@ void createClient() throws Exception {\n         ChainedPathZkSerializer.builder(new ZNRecordStreamingSerializer()).build();\n \n     _zkclient =\n-        new ZkClient(_zkAddress, _sessionTimeout, ZkClient.DEFAULT_CONNECTION_TIMEOUT, zkSerializer);\n+        new ZkClient(_zkAddress, _sessionTimeout, _clientConnectionTimeout, zkSerializer);\n \n     _baseDataAccessor = createBaseDataAccessor();\n \n@@ -582,6 +597,8 @@ public void disconnect() {\n         _participantManager = null;\n       }\n \n+      _helixPropertyStore = null;\n+\n       _zkclient.close();\n       _zkclient = null;\n       _sessionStartTime = null;\n@@ -813,9 +830,10 @@ public void handleStateChanged(KeeperState state) throws Exception {\n        */\n       _disconnectTimeHistory.add(System.currentTimeMillis());\n       if (isFlapping()) {\n-        LOG.error(\"instanceName: \" + _instanceName + \" is flapping. disconnect it. \"\n+        String errorMsg = \"instanceName: \" + _instanceName + \" is flapping. disconnect it. \"\n             + \" maxDisconnectThreshold: \" + _maxDisconnectThreshold + \" disconnects in \"\n-            + _flappingTimeWindowMs + \"ms.\");\n+            + _flappingTimeWindowMs + \"ms.\";\n+        LOG.error(errorMsg);\n \n         // Only disable the instance when it's instance type is PARTICIPANT\n         if (_instanceType.equals(InstanceType.PARTICIPANT)) {\n@@ -824,6 +842,9 @@ public void handleStateChanged(KeeperState state) throws Exception {\n           getClusterManagmentTool().enableInstance(_clusterName, _instanceName, false);\n         }\n         disconnect();\n+        if (_stateListener != null) {\n+          _stateListener.onDisconnected(this, new HelixException(errorMsg));\n+        }\n       }\n       break;\n     case Expired:\n@@ -920,12 +941,45 @@ public ParticipantHealthReportCollector getHealthReportCollector() {\n   }\n \n   @Override\n-  public void handleSessionEstablishmentError(Throwable var1) throws Exception {\n+  public void handleSessionEstablishmentError(Throwable error) throws Exception {\n+    LOG.warn(\"Handling Session Establishment Error. Try to reset connection.\", error);\n+    // Close currently disconnected ZkClient before cleanup\n+    if (_zkclient != null) {\n+      _zkclient.close();\n+    }\n+    // Cleanup ZKHelixManager\n+    disconnect();\n+    // Try to establish connections\n+    long operationStartTime = System.currentTimeMillis();\n+    while (!isConnected()) {\n+      try {\n+        connect();\n+        break;\n+      } catch (Exception e) {\n+        if (System.currentTimeMillis() - operationStartTime >= _connectionRetryTimeout) {\n+          break;\n+        }\n+        // If retry fails, use the latest exception.\n+        error = e;\n+        LOG.error(\"Fail to reset connection after session establishment error happens. Will retry.\", error);\n+        // Yield until next retry.\n+        Thread.yield();\n+      }\n+    }\n+\n+    if (!isConnected()) {\n+      LOG.error(\"Fail to reset connection after session establishment error happens.\", error);\n+      // retry failed, trigger error handler\n+      if (_stateListener != null) {\n+        _stateListener.onDisconnected(this, error);\n+      }\n+    } else {\n+      LOG.info(\"Connection is recovered.\");\n+    }\n   }\n \n   @Override\n   public Long getSessionStartTime() {\n     return _sessionStartTime;\n   }\n-\n }"
            },
            {
                "sha": "0a61e8212107c04e0325ced6ecdb585d73073ab1",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "status": "modified",
                "additions": 14,
                "deletions": 0,
                "changes": 14,
                "blob_url": "https://github.com/apache/helix/blob/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "raw_url": "https://github.com/apache/helix/raw/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZkClient.java?ref=3da3e319a4a821add6291c385dae41b633fad078",
                "patch": "@@ -437,4 +437,18 @@ public Object call() throws Exception {\n     });\n   }\n \n+  public <T> T retryUntilConnected(final Callable<T> callable) {\n+    final ZkConnection zkConnection = (ZkConnection) getConnection();\n+    return super.retryUntilConnected(new Callable<T>() {\n+      @Override\n+      public T call() throws Exception {\n+        // Validate that the connection is not null before trigger callback\n+        if (zkConnection == null || zkConnection.getZookeeper() == null) {\n+          throw new IllegalStateException(\n+              \"ZkConnection is in invalid state! Please close this ZkClient and create new client.\");\n+        }\n+        return callable.call();\n+      }\n+    });\n+  }\n }"
            },
            {
                "sha": "828860816810b14c0150e45e26be2ff56ad397a4",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "status": "modified",
                "additions": 76,
                "deletions": 1,
                "changes": 77,
                "blob_url": "https://github.com/apache/helix/blob/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "raw_url": "https://github.com/apache/helix/raw/3da3e319a4a821add6291c385dae41b633fad078/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/TestZkReconnect.java?ref=3da3e319a4a821add6291c385dae41b633fad078",
                "patch": "@@ -31,10 +31,13 @@\n import org.apache.helix.InstanceType;\n import org.apache.helix.NotificationContext;\n import org.apache.helix.TestHelper;\n+import org.apache.helix.manager.zk.HelixManagerStateListener;\n+import org.apache.helix.manager.zk.ZKHelixManager;\n import org.apache.helix.model.IdealState;\n import org.apache.helix.model.Message;\n import org.apache.helix.participant.statemachine.StateModel;\n import org.apache.helix.participant.statemachine.StateModelFactory;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n import org.apache.helix.tools.ClusterSetup;\n import org.apache.helix.tools.ClusterVerifiers.ClusterStateVerifier;\n import org.apache.helix.tools.ClusterVerifiers.ClusterStateVerifier.BestPossAndExtViewZkVerifier;\n@@ -137,6 +140,79 @@ public void run() {\n     }\n   }\n \n+  @Test\n+  public void testZKDisconnectCallback() throws Exception {\n+    final int zkPort = TestHelper.getRandomPort();\n+    final String zkAddr = String.format(\"localhost:%d\", zkPort);\n+    final ZkServer zkServer = TestHelper.startZkServer(zkAddr);\n+\n+    String className = TestHelper.getTestClassName();\n+    String methodName = TestHelper.getTestMethodName();\n+    final String clusterName = className + \"_\" + methodName;\n+\n+    // Init flag to check if callback is triggered\n+    final AtomicReference<Boolean> flag = new AtomicReference<Boolean>(false);\n+\n+    // Setup cluster\n+    LOG.info(\"Setup clusters\");\n+    ClusterSetup clusterSetup = new ClusterSetup(zkAddr);\n+    clusterSetup.addCluster(clusterName, true);\n+    // For fast test, set short timeout\n+    System.setProperty(\"zk.connection.timeout\", \"2000\");\n+    System.setProperty(\"zk.connectionReEstablishment.timeout\", \"1000\");\n+\n+    // Registers and starts controller, register listener for disconnect handling\n+    LOG.info(\"Starts controller\");\n+    final ZKHelixManager controller =\n+        (ZKHelixManager) HelixManagerFactory.getZKHelixManager(clusterName, null, InstanceType.CONTROLLER, zkAddr,\n+            new HelixManagerStateListener() {\n+              @Override\n+              public void onConnected(HelixManager helixManager) throws Exception {\n+                return;\n+              }\n+\n+              @Override\n+              public void onDisconnected(HelixManager helixManager, Throwable error) throws Exception {\n+                Assert.assertEquals(helixManager.getClusterName(), clusterName);\n+                flag.getAndSet(true);\n+              }\n+            });\n+\n+    try {\n+      controller.connect();\n+      ZkHelixPropertyStore propertyStore = controller.getHelixPropertyStore();\n+\n+      // 1. shutdown zkServer and check if handler trigger callback\n+      zkServer.shutdown();\n+      // Retry will fail, and flag should be set within onDisconnected handler\n+      controller.handleSessionEstablishmentError(new Exception(\"For testing\"));\n+      Assert.assertTrue(flag.get());\n+\n+      try {\n+        propertyStore.get(\"/\", null, 0);\n+        Assert.fail(\"propertyStore should be disconnected.\");\n+      } catch (IllegalStateException e) {\n+        // Expected exception\n+        System.out.println(e.getMessage());\n+      }\n+\n+      // 2. restart zkServer and check if handler will recover connection\n+      flag.getAndSet(false);\n+      zkServer.start();\n+      // Retry will succeed, and flag should not be set\n+      controller.handleSessionEstablishmentError(new Exception(\"For testing\"));\n+      Assert.assertFalse(flag.get());\n+      // New propertyStore should be in good state\n+      propertyStore = controller.getHelixPropertyStore();\n+      propertyStore.get(\"/\", null, 0);\n+    } finally {\n+      controller.disconnect();\n+      zkServer.shutdown();\n+      System.clearProperty(\"zk.connection.timeout\");\n+      System.clearProperty(\"zk.connectionReEstablishment.timeout\");\n+    }\n+  }\n+\n   public static final class SimpleStateModel extends StateModel {\n \n     private final CountDownLatch latch;\n@@ -151,5 +227,4 @@ public void onBecomeOnlineFromOffline(Message message, NotificationContext conte\n       latch.countDown();\n     }\n   }\n-\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/e94a9f5f90099a248181d6dc50314aec0e8d9512",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/516faa0c504c807bbc9133694998f227e8e0d114",
        "message": "[HELIX-589] Delete job API throws NPE if the job does not exist in last scheduled workflow",
        "bug_id": "helix_50",
        "file": [
            {
                "sha": "cb079cce61cdbaf67a32d38caf9c247b543c45c4",
                "filename": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "status": "modified",
                "additions": 24,
                "deletions": 26,
                "changes": 50,
                "blob_url": "https://github.com/apache/helix/blob/e94a9f5f90099a248181d6dc50314aec0e8d9512/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/e94a9f5f90099a248181d6dc50314aec0e8d9512/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java?ref=e94a9f5f90099a248181d6dc50314aec0e8d9512",
                "patch": "@@ -369,37 +369,35 @@ public ZNRecord update(ZNRecord currentData) {\n         JobDag jobDag = JobDag.fromJson(currentData.getSimpleField(WorkflowConfig.DAG));\n         Set<String> allNodes = jobDag.getAllNodes();\n         if (!allNodes.contains(namespacedJobName)) {\n-          throw new IllegalStateException(\"Could not delete job from queue \" + queueName + \", job \"\n-              + jobName + \" not exists\");\n-        }\n-\n-        String parent = null;\n-        String child = null;\n-        // remove the node from the queue\n-        for (String node : allNodes) {\n-          if (!node.equals(namespacedJobName)) {\n-            if (jobDag.getDirectChildren(node).contains(namespacedJobName)) {\n-              parent = node;\n-              jobDag.removeParentToChild(parent, namespacedJobName);\n-            } else if (jobDag.getDirectParents(node).contains(namespacedJobName)) {\n-              child = node;\n-              jobDag.removeParentToChild(namespacedJobName, child);\n+          LOG.warn(\"Could not delete job from queue \" + queueName + \", job \" + jobName + \" not exists\");\n+        } else {\n+          String parent = null;\n+          String child = null;\n+          // remove the node from the queue\n+          for (String node : allNodes) {\n+            if (!node.equals(namespacedJobName)) {\n+              if (jobDag.getDirectChildren(node).contains(namespacedJobName)) {\n+                parent = node;\n+                jobDag.removeParentToChild(parent, namespacedJobName);\n+              } else if (jobDag.getDirectParents(node).contains(namespacedJobName)) {\n+                child = node;\n+                jobDag.removeParentToChild(namespacedJobName, child);\n+              }\n             }\n           }\n-        }\n \n-        if (parent != null && child != null) {\n-          jobDag.addParentToChild(parent, child);\n-        }\n+          if (parent != null && child != null) {\n+            jobDag.addParentToChild(parent, child);\n+          }\n \n-        jobDag.removeNode(namespacedJobName);\n+          jobDag.removeNode(namespacedJobName);\n \n-        // Save the updated DAG\n-        try {\n-          currentData.setSimpleField(WorkflowConfig.DAG, jobDag.toJson());\n-        } catch (Exception e) {\n-          throw new IllegalStateException(\n-              \"Could not remove job \" + jobName + \" from DAG of queue \" + queueName, e);\n+          // Save the updated DAG\n+          try {\n+            currentData.setSimpleField(WorkflowConfig.DAG, jobDag.toJson());\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Could not remove job \" + jobName + \" from DAG of queue \" + queueName, e);\n+          }\n         }\n         return currentData;\n       }"
            },
            {
                "sha": "8a4467241089b5d68fdc078c0ba7d4a7ce3217af",
                "filename": "helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "status": "modified",
                "additions": 66,
                "deletions": 13,
                "changes": 79,
                "blob_url": "https://github.com/apache/helix/blob/e94a9f5f90099a248181d6dc50314aec0e8d9512/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "raw_url": "https://github.com/apache/helix/raw/e94a9f5f90099a248181d6dc50314aec0e8d9512/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/org/apache/helix/integration/task/TestTaskRebalancerStopResume.java?ref=e94a9f5f90099a248181d6dc50314aec0e8d9512",
                "patch": "@@ -220,8 +220,8 @@ public void stopAndResumeNamedQueue() throws Exception {\n \n     Set<String> slave = Sets.newHashSet(\"SLAVE\");\n     JobConfig.Builder job2 =\n-    new JobConfig.Builder().setCommand(\"Reindex\")\n-        .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(slave);\n+        new JobConfig.Builder().setCommand(\"Reindex\")\n+            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(slave);\n     String job2Name = \"slaveJob\";\n     LOG.info(\"Enqueuing job: \" + job2Name);\n     _driver.enqueueJob(queueName, job2Name, job2);\n@@ -315,9 +315,9 @@ public void stopDeleteJobAndResumeNamedQueue() throws Exception {\n     LOG.info(\"Pausing job-queue: \" + queueName);\n     _driver.stop(queueName);\n     TestUtil.pollForJobState(_manager,\n-                             queueName,\n-                             String.format(\"%s_%s\", queueName, currentJobNames.get(1)),\n-                             TaskState.STOPPED);\n+        queueName,\n+        String.format(\"%s_%s\", queueName, currentJobNames.get(1)),\n+        TaskState.STOPPED);\n     TestUtil.pollForWorkflowState(_manager, queueName, TaskState.STOPPED);\n \n     // Ensure job 3 is not started before deleting it\n@@ -373,7 +373,8 @@ private JobQueue buildRecurrentJobQueue(String jobQueueName)\n   {\n     Map<String, String> cfgMap = new HashMap<String, String>();\n     cfgMap.put(WorkflowConfig.EXPIRY, String.valueOf(50000));\n-    cfgMap.put(WorkflowConfig.START_TIME, WorkflowConfig.getDefaultDateFormat().format(Calendar.getInstance().getTime()));\n+    cfgMap.put(WorkflowConfig.START_TIME,\n+        WorkflowConfig.getDefaultDateFormat().format(Calendar.getInstance().getTime()));\n     cfgMap.put(WorkflowConfig.RECURRENCE_INTERVAL, String.valueOf(60));\n     cfgMap.put(WorkflowConfig.RECURRENCE_UNIT, \"SECONDS\");\n     return (new JobQueue.Builder(jobQueueName).fromMap(cfgMap)).build();\n@@ -467,6 +468,58 @@ public void stopDeleteJobAndResumeRecurrentQueue() throws Exception {\n     // verify the job is not there for the next recurrence of queue schedule\n   }\n \n+  @Test\n+  public void deleteJobFromRecurrentQueueNotStarted() throws Exception {\n+    String queueName = TestHelper.getTestMethodName();\n+\n+    // Create a queue\n+    LOG.info(\"Starting job-queue: \" + queueName);\n+    JobQueue queue = buildRecurrentJobQueue(queueName);\n+    _driver.createQueue(queue);\n+\n+    // create jobs\n+    List<JobConfig.Builder> jobs = new ArrayList<JobConfig.Builder>();\n+    List<String> jobNames = new ArrayList<String>();\n+    Map<String, String> commandConfig = ImmutableMap.of(TIMEOUT_CONFIG, String.valueOf(500));\n+\n+    final int JOB_COUNTS = 3;\n+\n+    for (int i = 0; i < JOB_COUNTS; i++) {\n+      String targetPartition = (i == 0) ? \"MASTER\" : \"SLAVE\";\n+\n+      JobConfig.Builder job =\n+          new JobConfig.Builder().setCommand(\"Reindex\").setJobCommandConfigMap(commandConfig)\n+              .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+              .setTargetPartitionStates(Sets.newHashSet(targetPartition));\n+      jobs.add(job);\n+      jobNames.add(targetPartition.toLowerCase() + \"Job\" + i);\n+    }\n+\n+    // enqueue all jobs except last one\n+    for (int i = 0; i < JOB_COUNTS - 1; ++i) {\n+      LOG.info(\"Enqueuing job: \" + jobNames.get(i));\n+      _driver.enqueueJob(queueName, jobNames.get(i), jobs.get(i));\n+    }\n+    String currentLastJob = jobNames.get(JOB_COUNTS - 2);\n+\n+    WorkflowContext wCtx = TestUtil.pollForWorkflowContext(_manager, queueName);\n+    String scheduledQueue = wCtx.getLastScheduledSingleWorkflow();\n+\n+    // ensure all jobs are finished\n+    String namedSpaceJob = String.format(\"%s_%s\", scheduledQueue, currentLastJob);\n+    TestUtil.pollForJobState(_manager, scheduledQueue, namedSpaceJob, TaskState.COMPLETED);\n+\n+    // enqueue the last job\n+    LOG.info(\"Enqueuing job: \" + jobNames.get(JOB_COUNTS - 1));\n+    _driver.enqueueJob(queueName, jobNames.get(JOB_COUNTS - 1), jobs.get(JOB_COUNTS - 1));\n+\n+    // remove the last job\n+    _driver.deleteJob(queueName, jobNames.get(JOB_COUNTS - 1));\n+\n+    // verify\n+    verifyJobDeleted(queueName, String.format(\"%s_%s\", scheduledQueue, jobNames.get(JOB_COUNTS - 1)));\n+  }\n+\n   @Test\n   public void stopAndDeleteQueue() throws Exception {\n     final String queueName = TestHelper.getTestMethodName();\n@@ -475,23 +528,23 @@ public void stopAndDeleteQueue() throws Exception {\n     System.out.println(\"START \" + queueName + \" at \" + new Date(System.currentTimeMillis()));\n     WorkflowConfig wfCfg\n         = new WorkflowConfig.Builder().setExpiry(2, TimeUnit.MINUTES)\n-                                      .setScheduleConfig(ScheduleConfig.recurringFromNow(TimeUnit.MINUTES, 1)).build();\n+        .setScheduleConfig(ScheduleConfig.recurringFromNow(TimeUnit.MINUTES, 1)).build();\n     JobQueue qCfg = new JobQueue.Builder(queueName).fromMap(wfCfg.getResourceConfigMap()).build();\n     _driver.createQueue(qCfg);\n \n     // Enqueue 2 jobs\n     Set<String> master = Sets.newHashSet(\"MASTER\");\n     JobConfig.Builder job1 =\n         new JobConfig.Builder().setCommand(\"Reindex\")\n-                               .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(master);\n+            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(master);\n     String job1Name = \"masterJob\";\n     LOG.info(\"Enqueuing job1: \" + job1Name);\n     _driver.enqueueJob(queueName, job1Name, job1);\n \n     Set<String> slave = Sets.newHashSet(\"SLAVE\");\n     JobConfig.Builder job2 =\n         new JobConfig.Builder().setCommand(\"Reindex\")\n-                               .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(slave);\n+            .setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB).setTargetPartitionStates(slave);\n     String job2Name = \"slaveJob\";\n     LOG.info(\"Enqueuing job2: \" + job2Name);\n     _driver.enqueueJob(queueName, job2Name, job2);\n@@ -522,10 +575,10 @@ public void stopAndDeleteQueue() throws Exception {\n         // check paths for resource-config, ideal-state, external-view, property-store\n         List<String> paths\n             = Lists.newArrayList(keyBuilder.resourceConfigs().getPath(),\n-                                 keyBuilder.idealStates().getPath(),\n-                                 keyBuilder.externalViews().getPath(),\n-                                 PropertyPathConfig.getPath(PropertyType.PROPERTYSTORE, CLUSTER_NAME)\n-                                     + TaskConstants.REBALANCER_CONTEXT_ROOT);\n+            keyBuilder.idealStates().getPath(),\n+            keyBuilder.externalViews().getPath(),\n+            PropertyPathConfig.getPath(PropertyType.PROPERTYSTORE, CLUSTER_NAME)\n+                + TaskConstants.REBALANCER_CONTEXT_ROOT);\n \n         for (String path : paths) {\n           List<String> childNames = accessor.getBaseDataAccessor().getChildNames(path, 0);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/173065e3a4e5af6f6d0d9b2cf5112ff61b980adb",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/7fc4a8af8a3e8c4acc2ad6c0b4f7f912cea0369f",
        "message": "Make map in NotificationContext synchronized\n\nOne issue we observed is that when batch messages enabled, it will have NPE in ZNRecord merge record.\nRace condition could be the root cause. The only place can have race condition is the current state update map in NotificationContext, which is passed as input for multiple sub tasks in BatchMessageHandler.",
        "bug_id": "helix_51",
        "file": [
            {
                "sha": "ae1e965cf29f7adc96016700572cad558dffe7b2",
                "filename": "helix-core/src/main/java/org/apache/helix/NotificationContext.java",
                "status": "modified",
                "additions": 2,
                "deletions": 1,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/173065e3a4e5af6f6d0d9b2cf5112ff61b980adb/helix-core/src/main/java/org/apache/helix/NotificationContext.java",
                "raw_url": "https://github.com/apache/helix/raw/173065e3a4e5af6f6d0d9b2cf5112ff61b980adb/helix-core/src/main/java/org/apache/helix/NotificationContext.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/NotificationContext.java?ref=173065e3a4e5af6f6d0d9b2cf5112ff61b980adb",
                "patch": "@@ -21,6 +21,7 @@\n \n import java.util.HashMap;\n import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n \n /**\n  * Metadata associated with a notification event and the current state of the cluster\n@@ -64,7 +65,7 @@ public void setEventName(String eventName) {\n    */\n   public NotificationContext(HelixManager manager) {\n     _manager = manager;\n-    _map = new HashMap<String, Object>();\n+    _map = new ConcurrentHashMap<String, Object>();\n   }\n \n   /**"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/1ee2ced4d2eb63d9a14d72672e3de5f8bda37405",
        "message": "add test case for handleNewSession(). add log for NPE caused by race condition in ZKHelixManager.disconnect(): zkconnection is close (null) but zkEventThread is still running",
        "bug_id": "helix_52",
        "file": [
            {
                "sha": "5cf5cb83142204fc76caf42b96604ce377218812",
                "filename": "helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "status": "modified",
                "additions": 6,
                "deletions": 0,
                "changes": 6,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/com/linkedin/helix/controller/GenericHelixController.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -437,6 +437,12 @@ public void onLiveInstanceChange(List<LiveInstance> liveInstances,\n   \n   void checkRebalancingTimer(HelixManager manager, List<IdealState> idealStates)\n   {\n+    if (manager.getConfigAccessor() == null)\n+    {\n+      logger.warn(manager.getInstanceName() + \" config accessor doesn't exist. should be in file-based mode.\");\n+      return;\n+    }\n+    \n     for(IdealState idealState : idealStates)\n     {\n       String resourceName = idealState.getResourceName();"
            },
            {
                "sha": "dff3b51c607e3bc5b56230006dbce3e01f6ef51b",
                "filename": "helix-core/src/main/java/com/linkedin/helix/manager/zk/ZKExceptionHandler.java",
                "status": "modified",
                "additions": 2,
                "deletions": 0,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/main/java/com/linkedin/helix/manager/zk/ZKExceptionHandler.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/main/java/com/linkedin/helix/manager/zk/ZKExceptionHandler.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/com/linkedin/helix/manager/zk/ZKExceptionHandler.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -29,6 +29,8 @@ private ZKExceptionHandler()\n \n   void handle(Exception e)\n   {\n+    logger.error(Thread.currentThread().getName() + \" isThreadInterruped: \" + Thread.currentThread().isInterrupted());\n+    \n     if (e instanceof ZkInterruptedException)\n     {\n       logger.warn(\"zk connection is interrupted, exception:\" + e);"
            },
            {
                "sha": "9681ea9768f464cbc49d417ec8f85dd690cf92fe",
                "filename": "helix-core/src/test/java/com/linkedin/helix/integration/TestStandAloneCMSessionExpiry.java",
                "status": "modified",
                "additions": 22,
                "deletions": 4,
                "changes": 26,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/TestStandAloneCMSessionExpiry.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/TestStandAloneCMSessionExpiry.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/com/linkedin/helix/integration/TestStandAloneCMSessionExpiry.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -65,7 +65,7 @@ public long getZkSessionId()\n   @Test()\n   public void testStandAloneCMSessionExpiry() throws Exception\n   {\n-    // Logger.getRootLogger().setLevel(Level.INFO);\n+    // Logger.getRootLogger().setLevel(Level.DEBUG);\n     System.out.println(\"RUN testStandAloneCMSessionExpiry() at \"\n         + new Date(System.currentTimeMillis()));\n \n@@ -110,12 +110,19 @@ public void testStandAloneCMSessionExpiry() throws Exception\n \n     // participant session expiry\n     ZkClusterManagerWithSessionExpiry manager =\n-        (ZkClusterManagerWithSessionExpiry) participants[0].getManager();\n+        (ZkClusterManagerWithSessionExpiry) participants[1].getManager();\n     long oldSessionId = manager.getZkSessionId();\n     manager.expireSession();\n     long newSessionId = manager.getZkSessionId();\n+    for (int i = 0; i < 100; i++)\n+    {\n+      if (newSessionId != oldSessionId)\n+      {\n+        break;\n+      }\n+      Thread.sleep(100);\n+    }\n     Assert.assertNotSame(newSessionId, oldSessionId);\n-\n     setupTool.addResourceToCluster(CLUSTER_NAME, \"TestDB1\", 10, \"MasterSlave\");\n     setupTool.rebalanceStorageCluster(CLUSTER_NAME, \"TestDB1\", 3);\n \n@@ -128,6 +135,14 @@ public void testStandAloneCMSessionExpiry() throws Exception\n     oldSessionId = controller.getZkSessionId();\n     controller.expireSession();\n     newSessionId = controller.getZkSessionId();\n+    for (int i = 0; i < 100; i++)\n+    {\n+      if (newSessionId != oldSessionId)\n+      {\n+        break;\n+      }\n+      Thread.sleep(100);\n+    }\n     Assert.assertNotSame(newSessionId, oldSessionId);\n     setupTool.addResourceToCluster(CLUSTER_NAME, \"TestDB2\", 8, \"MasterSlave\");\n     setupTool.rebalanceStorageCluster(CLUSTER_NAME, \"TestDB2\", 3);\n@@ -136,9 +151,12 @@ public void testStandAloneCMSessionExpiry() throws Exception\n         ClusterStateVerifier.verifyByPolling(new ClusterStateVerifier.BestPossAndExtViewZkVerifier(ZK_ADDR,\n                                                                                           CLUSTER_NAME));\n     Assert.assertTrue(result);\n-\n+    \n     // clean up\n+    System.out.println(\"Clean up ...\");\n+//    Logger.getRootLogger().setLevel(Level.DEBUG);\n     controller.disconnect();\n+    Thread.sleep(100);\n     for (int i = 0; i < NODE_NR; i++)\n     {\n       participants[i].syncStop();"
            },
            {
                "sha": "2c18551d8df4ed11b258638c47ecb3ddcb5dfbcb",
                "filename": "helix-core/src/test/java/com/linkedin/helix/integration/ZkIntegrationTestBase.java",
                "status": "modified",
                "additions": 49,
                "deletions": 19,
                "changes": 68,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/ZkIntegrationTestBase.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/ZkIntegrationTestBase.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/com/linkedin/helix/integration/ZkIntegrationTestBase.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -17,6 +17,8 @@\n \n import java.io.IOException;\n import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n \n import org.I0Itec.zkclient.IZkStateListener;\n import org.I0Itec.zkclient.ZkConnection;\n@@ -47,19 +49,19 @@\n \n public class ZkIntegrationTestBase\n {\n-  private static Logger LOG = Logger.getLogger(ZkIntegrationTestBase.class);\n+  private static Logger         LOG                       =\n+                                                              Logger.getLogger(ZkIntegrationTestBase.class);\n \n-  protected static ZkServer _zkServer;\n-  protected static ZkClient _gZkClient;\n+  protected static ZkServer     _zkServer;\n+  protected static ZkClient     _gZkClient;\n   protected static ClusterSetup _gSetupTool;\n \n-\n-  public static final String ZK_ADDR = \"localhost:2183\"; \n-  protected static final String CLUSTER_PREFIX = \"CLUSTER\";\n+  public static final String    ZK_ADDR                   = \"localhost:2183\";\n+  protected static final String CLUSTER_PREFIX            = \"CLUSTER\";\n   protected static final String CONTROLLER_CLUSTER_PREFIX = \"CONTROLLER_CLUSTER\";\n \n-  protected final String CONTROLLER_PREFIX = \"controller\";\n-  protected final String PARTICIPANT_PREFIX = \"localhost\";\n+  protected final String        CONTROLLER_PREFIX         = \"controller\";\n+  protected final String        PARTICIPANT_PREFIX        = \"localhost\";\n \n   @BeforeSuite\n   public void beforeSuite() throws Exception\n@@ -89,7 +91,8 @@ protected String getShortClassName()\n \n   protected String getCurrentLeader(ZkClient zkClient, String clusterName)\n   {\n-    ZKHelixDataAccessor accessor = new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor(zkClient));\n+    ZKHelixDataAccessor accessor =\n+        new ZKHelixDataAccessor(clusterName, new ZkBaseDataAccessor(zkClient));\n     Builder keyBuilder = accessor.keyBuilder();\n \n     LiveInstance leader = accessor.getProperty(keyBuilder.controllerLeader());\n@@ -102,7 +105,7 @@ protected String getCurrentLeader(ZkClient zkClient, String clusterName)\n \n   /**\n    * Stop current leader and returns the new leader\n-   *\n+   * \n    * @param zkClient\n    * @param clusterName\n    * @param startCMResultMap\n@@ -154,7 +157,7 @@ protected String stopCurrentLeader(ZkClient zkClient,\n \n   /**\n    * simulate session expiry\n-   *\n+   * \n    * @param zkConnection\n    * @throws IOException\n    * @throws InterruptedException\n@@ -188,7 +191,7 @@ public void process(WatchedEvent event)\n     LOG.info(\"After session expiry sessionId = \" + oldZookeeper.getSessionId());\n   }\n \n-  protected static void simulateSessionExpiry(ZkClient zkClient) throws IOException,\n+  public static void simulateSessionExpiry(final ZkClient zkClient) throws IOException,\n       InterruptedException\n   {\n     IZkStateListener listener = new IZkStateListener()\n@@ -208,7 +211,7 @@ public void handleNewSession() throws Exception\n     zkClient.subscribeStateChanges(listener);\n     ZkConnection connection = ((ZkConnection) zkClient.getConnection());\n     ZooKeeper oldZookeeper = connection.getZookeeper();\n-    LOG.info(\"Old sessionId = \" + oldZookeeper.getSessionId());\n+    LOG.info(\"Old sessionId = \" + Long.toHexString(oldZookeeper.getSessionId()));\n \n     Watcher watcher = new Watcher()\n     {\n@@ -219,25 +222,52 @@ public void process(WatchedEvent event)\n       }\n     };\n \n-    ZooKeeper newZookeeper =\n+    final ZooKeeper newZookeeper =\n         new ZooKeeper(connection.getServers(),\n                       oldZookeeper.getSessionTimeout(),\n                       watcher,\n                       oldZookeeper.getSessionId(),\n                       oldZookeeper.getSessionPasswd());\n-    LOG.info(\"New sessionId = \" + newZookeeper.getSessionId());\n+    LOG.info(\"New sessionId = \" + Long.toHexString(newZookeeper.getSessionId()));\n     // Thread.sleep(3000);\n+\n+    final CountDownLatch waitStart = new CountDownLatch(1);\n+    final CountDownLatch waitEnd = new CountDownLatch(1);\n+    new Thread(new Runnable()\n+    {\n+\n+      @Override\n+      public void run()\n+      {\n+        waitStart.countDown();\n+//        System.err.println(\"Start wait on expiring\");\n+        boolean ret =\n+            zkClient.waitForKeeperState(KeeperState.Expired,\n+                                        Integer.MAX_VALUE,\n+                                        TimeUnit.MILLISECONDS);\n+//        System.err.println(\"wait expire result: \" + ret);\n+        waitEnd.countDown();\n+      }\n+    }).start();\n+\n+    waitStart.await();\n     newZookeeper.close();\n-    Thread.sleep(15000);\n+\n+//    Thread.sleep(1000);\n+    waitEnd.await();\n+//    System.err.println(\"Start wait on connected\");\n+\n+    zkClient.waitUntilConnected();\n     connection = (ZkConnection) zkClient.getConnection();\n     oldZookeeper = connection.getZookeeper();\n-    LOG.info(\"After session expiry sessionId = \" + oldZookeeper.getSessionId());\n+//    System.err.println(\"zk: \" + oldZookeeper);\n+    LOG.info(\"After session expiry sessionId = \"\n+        + Long.toHexString(oldZookeeper.getSessionId()));\n   }\n \n   protected void enableHealthCheck(String clusterName)\n   {\n-    ConfigScope scope =\n-      new ConfigScopeBuilder().forCluster(clusterName).build();\n+    ConfigScope scope = new ConfigScopeBuilder().forCluster(clusterName).build();\n     new ConfigAccessor(_gZkClient).set(scope, \"healthChange\" + \".enabled\", \"\" + true);\n   }\n "
            },
            {
                "sha": "488f205d2f6c77fe69db1c20ec95ad5711a43aef",
                "filename": "helix-core/src/test/java/com/linkedin/helix/integration/ZkStandAloneCMTestBase.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/ZkStandAloneCMTestBase.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/integration/ZkStandAloneCMTestBase.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/com/linkedin/helix/integration/ZkStandAloneCMTestBase.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -29,7 +29,6 @@\n import com.linkedin.helix.TestHelper;\n import com.linkedin.helix.TestHelper.StartCMResult;\n import com.linkedin.helix.controller.HelixControllerMain;\n-import com.linkedin.helix.controller.restlet.ZKPropertyTransferServer;\n import com.linkedin.helix.manager.zk.ZNRecordSerializer;\n import com.linkedin.helix.manager.zk.ZkClient;\n import com.linkedin.helix.tools.ClusterSetup;\n@@ -148,6 +147,7 @@ public void afterClass() throws Exception\n       }\n     }\n \n+    Thread.sleep(100);\n     it = _startCMResultMap.entrySet().iterator();\n     while (it.hasNext())\n     {"
            },
            {
                "sha": "640d827e7c4ad0b865c24ed34fd89e0ba804926d",
                "filename": "helix-core/src/test/java/com/linkedin/helix/manager/zk/TestHandleNewSession.java",
                "status": "added",
                "additions": 91,
                "deletions": 0,
                "changes": 91,
                "blob_url": "https://github.com/apache/helix/blob/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/manager/zk/TestHandleNewSession.java",
                "raw_url": "https://github.com/apache/helix/raw/5a4a2b845ac8e9a08fed3585b40374a25d3a8d24/helix-core/src/test/java/com/linkedin/helix/manager/zk/TestHandleNewSession.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/test/java/com/linkedin/helix/manager/zk/TestHandleNewSession.java?ref=5a4a2b845ac8e9a08fed3585b40374a25d3a8d24",
                "patch": "@@ -0,0 +1,91 @@\n+package com.linkedin.helix.manager.zk;\n+\n+import java.util.Date;\n+\n+import org.I0Itec.zkclient.ZkConnection;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import com.linkedin.helix.InstanceType;\n+import com.linkedin.helix.TestHelper;\n+import com.linkedin.helix.integration.ZkIntegrationTestBase;\n+\n+public class TestHandleNewSession extends ZkIntegrationTestBase\n+{\n+  class TestZKHelixManager extends ZKHelixManager\n+  {\n+    public TestZKHelixManager(String clusterName,\n+                              String instanceName,\n+                              InstanceType instanceType,\n+                              String zkConnectString) throws Exception\n+    {\n+      super(clusterName, instanceName, instanceType, zkConnectString);\n+      // TODO Auto-generated constructor stub\n+    }\n+\n+    public ZkClient getZkClient()\n+    {\n+      return _zkClient;\n+    }\n+  }\n+\n+  @Test\n+  public void testHandleNewSession() throws Exception\n+  {\n+    // Logger.getRootLogger().setLevel(Level.INFO);\n+    System.out.println(\"START TestHandleNewSession at \"\n+        + new Date(System.currentTimeMillis()));\n+\n+    final String clusterName = \"TestHandleNewSession\";\n+    TestHelper.setupCluster(clusterName, ZK_ADDR, 12918, // participant port\n+                            \"localhost\", // participant name prefix\n+                            \"TestDB\", // resource name prefix\n+                            1, // resources\n+                            10, // partitions per resource\n+                            5, // number of nodes\n+                            3, // replicas\n+                            \"MasterSlave\",\n+                            true); // do rebalance\n+\n+    TestZKHelixManager manager =\n+        new TestZKHelixManager(clusterName,\n+                               \"localhost_12918\",\n+                               InstanceType.PARTICIPANT,\n+                               ZK_ADDR);\n+    manager.connect();\n+    final ZkClient zkclient = manager.getZkClient();\n+    String lastSessionId = manager.getSessionId();\n+    for (int i = 0; i < 3; i++)\n+    {\n+      ZkConnection zkConnection = ((ZkConnection) zkclient.getConnection());\n+      ZooKeeper zk = zkConnection.getZookeeper();\n+      System.out.println(zk);\n+\n+      simulateSessionExpiry(zkclient);\n+\n+      while (manager.getSessionId().equals(lastSessionId))\n+      {\n+        Thread.sleep(1000); // ZkHelixManager.handleNewSession() hasn't been called yet\n+      }\n+      String sessionId = manager.getSessionId();\n+      Assert.assertNotSame(sessionId, lastSessionId, \"session id should be changed after session expiry\");\n+      lastSessionId = sessionId;\n+      System.out.println(\"sessionId: \" + sessionId);\n+      Assert.assertFalse(sessionId.equals(\"0\"),\n+                         \"race condition in zhclient.handleNewSession(). sessionId is not returned yet.\");\n+      \n+      // TODO: need to test session expiry during handleNewSession()\n+      Thread.sleep(1000);   // wait ZKHelixManager.handleNewSession() to complete\n+    }\n+\n+    // Logger.getRootLogger().setLevel(Level.INFO);\n+    System.out.println(\"Disconnecting ...\");\n+    \n+    manager.disconnect(); \n+    \n+    System.out.println(\"END TestHandleNewSession at \"\n+        + new Date(System.currentTimeMillis()));\n+\n+  }\n+}"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/f87f68c5d7723cf7f4bdf7aa344fb0481a11fd12",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/57763e51527718d699d657ee78f03144a08984e4",
        "message": "Fix a possible NPE in HelixTaskExecutor. When no message handler factory\nis registered for a state model, it should return null.",
        "bug_id": "helix_53",
        "file": [
            {
                "sha": "62af5f17bf63f7b69646934cc4dceb632cf0ef98",
                "filename": "helix-core/src/main/java/com/linkedin/helix/participant/HelixStateMachineEngine.java",
                "status": "modified",
                "additions": 4,
                "deletions": 0,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/f87f68c5d7723cf7f4bdf7aa344fb0481a11fd12/helix-core/src/main/java/com/linkedin/helix/participant/HelixStateMachineEngine.java",
                "raw_url": "https://github.com/apache/helix/raw/f87f68c5d7723cf7f4bdf7aa344fb0481a11fd12/helix-core/src/main/java/com/linkedin/helix/participant/HelixStateMachineEngine.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/com/linkedin/helix/participant/HelixStateMachineEngine.java?ref=f87f68c5d7723cf7f4bdf7aa344fb0481a11fd12",
                "patch": "@@ -38,6 +38,10 @@\n   public StateModelFactory<? extends StateModel> getStateModelFactory(String stateModelName,\n       String factoryName)\n   {\n+    if(!_stateModelFactoryMap.containsKey(stateModelName))\n+    {\n+      return null;\n+    }\n     return _stateModelFactoryMap.get(stateModelName).get(factoryName);\n   }\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/812b83f0a69e055dc22a6f4cb4ec1c4ec1ff4572",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/470b514f3cc1f6d879938112bc862ab2ba22378d",
        "message": "Ignore instances with no instance configuration\n\nIgnore instances with no instance configuration when fetching the list\nof instances that have a specific tag.\n\nThe deletion order in ZKHelixAdmin#dropInstance deletes the instance\nconfiguration before deleting the instance itself. If this is\ninterrupted midway, the instance configuration is deleted but the\ninstance is present in the list of instances.\n\nWhen fetching the list of instances with a given tag, this means that\nif an instance has its configuration missing, the instance\nconfiguration will be null and the loop will exit with NPE. This patch\nadds a null check to avoid aborting the loop.",
        "bug_id": "helix_54",
        "file": [
            {
                "sha": "351c10ec12017b116d9a8d7b0f5ce4a9512c19f5",
                "filename": "helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/helix/blob/812b83f0a69e055dc22a6f4cb4ec1c4ec1ff4572/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "raw_url": "https://github.com/apache/helix/raw/812b83f0a69e055dc22a6f4cb4ec1c4ec1ff4572/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/helix-core/src/main/java/org/apache/helix/manager/zk/ZKHelixAdmin.java?ref=812b83f0a69e055dc22a6f4cb4ec1c4ec1ff4572",
                "patch": "@@ -602,7 +602,7 @@ private void createZKPaths(String clusterName) {\n \n     for (String instanceName : instances) {\n       InstanceConfig config = accessor.getProperty(keyBuilder.instanceConfig(instanceName));\n-      if (config.containsTag(tag)) {\n+      if (config != null && config.containsTag(tag)) {\n         result.add(instanceName);\n       }\n     }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/helix/commit/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
        "repo": "helix",
        "parent": "https://github.com/apache/helix/commit/08e5beced616e83400a1b3eab1f989343bded2b0",
        "message": "Fixed the following issues:\nDDS-2251: State transition priority list must be optional.\nDDS-2252: Initial State not honored; assumed to be OFFLINE always\nDDS-2248: customized ideal state doesn't honor non-alive/disabled instances and disabled resources (partitions), which in turn creates messages with null TgtSessionId and cause NPE on participant side\nDDS-2249: ideal state customized mode is broken\nAdded a new test case for customized ideal state",
        "bug_id": "helix_55",
        "file": [
            {
                "sha": "be34f93d4c27a5ccac814e31619bd32921b07bc8",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "status": "modified",
                "additions": 6,
                "deletions": 2,
                "changes": 8,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/agent/zk/ZKClusterManager.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -45,6 +45,7 @@\n import com.linkedin.clustermanager.messaging.handling.MessageHandlerFactory;\n import com.linkedin.clustermanager.model.CurrentState;\n import com.linkedin.clustermanager.model.LiveInstance;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n import com.linkedin.clustermanager.monitoring.ZKPathDataDumpTask;\n import com.linkedin.clustermanager.participant.DistClusterControllerElection;\n import com.linkedin.clustermanager.store.PropertyStore;\n@@ -464,7 +465,7 @@ private CallbackHandler createCallBackHandler(String path, Object listener,\n \n   /**\n    * This will be invoked when ever a new session is created<br/>\n-   * \n+   *\n    * case 1: the cluster manager was a participant carry over current state, add\n    * live instance, and invoke message listener; case 2: the cluster manager was\n    * controller and was a leader before do leader election, and if it becomes\n@@ -644,10 +645,13 @@ private void carryOverPreviousCurrentState()\n           logger.info(\"Carrying over old session:\" + previousSessionId\n               + \" resource \" + previousCurrentState.getId()\n               + \" to new session:\" + _sessionId);\n+          String stateModelDefRef = previousCurrentState.getStateModelDefRef();\n+          StateModelDefinition stateModel = _accessor.getProperty(StateModelDefinition.class, PropertyType.STATEMODELDEFS, stateModelDefRef);\n           for (String resourceKey : previousCurrentState\n               .getResourceKeyStateMap().keySet())\n           {\n-            previousCurrentState.setState(resourceKey, \"OFFLINE\");\n+\n+            previousCurrentState.setState(resourceKey, stateModel.getInitialState());\n           }\n           previousCurrentState.setSessionId(_sessionId);\n           _accessor.setProperty(PropertyType.CURRENTSTATES,"
            },
            {
                "sha": "9dba454a4ec89b3bdfee8d88ff641f3b03af5400",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "status": "modified",
                "additions": 87,
                "deletions": 16,
                "changes": 103,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/BestPossibleStateCalcStage.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -91,23 +91,26 @@ private BestPossibleStateOutput compute(ClusterDataCache cache,\n             currentStateOutput.getCurrentStateMap(resourceGroupName, resource);\n \n         Map<String, String> bestStateForResource;\n+        Set<String> disabledInstancesForResource\n+          = cache.getDisabledInstancesForResource(resource.toString());\n+\n         if (idealState.getIdealStateMode() == IdealStateModeProperty.CUSTOMIZED)\n         {\n-          // TODO add computerBestStateForResourceInCustomizedMode()\n-          //  e.g. exclude non-alive instance\n-          bestStateForResource = idealState.getInstanceStateMap(resource.getResourceKeyName());\n+          Map<String, String> idealStateMap = idealState.getInstanceStateMap(resource.getResourceKeyName());\n+          bestStateForResource = computeCustomizedBestStateForResource(cache, stateModelDef,\n+                                                                       idealStateMap,\n+                                                                       currentStateMap,\n+                                                                       disabledInstancesForResource);\n         }\n         else\n         {\n           List<String> instancePreferenceList\n             = getPreferenceList(cache, resource, idealState, stateModelDef);\n-          Set<String> disabledInstancesForResource\n-            = cache.getDisabledInstancesForResource(resource.toString());\n           bestStateForResource =\n-              computeBestStateForResource(cache, stateModelDef,\n-                                          instancePreferenceList,\n-                                          currentStateMap,\n-                                          disabledInstancesForResource);\n+              computeAutoBestStateForResource(cache, stateModelDef,\n+                                              instancePreferenceList,\n+                                              currentStateMap,\n+                                              disabledInstancesForResource);\n         }\n \n         output.setState(resourceGroupName, resource, bestStateForResource);\n@@ -116,11 +119,20 @@ private BestPossibleStateOutput compute(ClusterDataCache cache,\n     return output;\n   }\n \n-  private Map<String, String> computeBestStateForResource(ClusterDataCache cache,\n-  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  StateModelDefinition stateModelDef,\n-                                                          List<String> instancePreferenceList,\n-                                                          Map<String, String> currentStateMap,\n-                                                          Set<String> disabledInstancesForResource)\n+  /**\n+   * compute best state for resource in AUTO ideal state mode\n+   * @param cache\n+   * @param stateModelDef\n+   * @param instancePreferenceList\n+   * @param currentStateMap\n+   * @param disabledInstancesForResource\n+   * @return\n+   */\n+  private Map<String, String> computeAutoBestStateForResource(ClusterDataCache cache,\n+                                                              StateModelDefinition stateModelDef,\n+                                                              List<String> instancePreferenceList,\n+                                                              Map<String, String> currentStateMap,\n+                                                              Set<String> disabledInstancesForResource)\n   {\n     Map<String, String> instanceStateMap = new HashMap<String, String>();\n \n@@ -143,7 +155,7 @@ else if (disabledInstancesForResource.contains(instance))\n       }\n     }\n \n-    // ideal state is deleted or use customized ideal states\n+    // ideal state is deleted\n     if (instancePreferenceList == null)\n     {\n       return instanceStateMap;\n@@ -207,6 +219,65 @@ else if (\"R\".equals(num))\n     return instanceStateMap;\n   }\n \n+\n+  /**\n+   * compute best state for resource in CUSTOMIZED ideal state mode\n+   * @param cache\n+   * @param stateModelDef\n+   * @param idealStateMap\n+   * @param currentStateMap\n+   * @param disabledInstancesForResource\n+   * @return\n+   */\n+  private Map<String, String> computeCustomizedBestStateForResource(ClusterDataCache cache,\n+                                                                    StateModelDefinition stateModelDef,\n+                                                                    Map<String, String> idealStateMap,\n+                                                                    Map<String, String> currentStateMap,\n+                                                                    Set<String> disabledInstancesForResource)\n+  {\n+    Map<String, String> instanceStateMap = new HashMap<String, String>();\n+\n+    // if the ideal state is deleted, idealStateMap will be null/empty and\n+    // we should drop all resources.\n+    if (currentStateMap != null)\n+    {\n+      for (String instance : currentStateMap.keySet())\n+      {\n+        if (idealStateMap == null || !idealStateMap.containsKey(instance))\n+        {\n+          instanceStateMap.put(instance, \"DROPPED\");\n+        }\n+        else if (disabledInstancesForResource.contains(instance))\n+        {\n+          // if a node is disabled, put it into initial state (OFFLINE)\n+          instanceStateMap.put(instance, stateModelDef.getInitialState());\n+        }\n+      }\n+    }\n+\n+    // ideal state is deleted\n+    if (idealStateMap == null)\n+    {\n+      return instanceStateMap;\n+    }\n+\n+    Map<String, LiveInstance> liveInstancesMap = cache.getLiveInstances();\n+    for (String instance : idealStateMap.keySet())\n+    {\n+      boolean notInErrorState =\n+          currentStateMap == null || !\"ERROR\".equals(currentStateMap.get(instance));\n+\n+      if (liveInstancesMap.containsKey(instance) && notInErrorState\n+          && !disabledInstancesForResource.contains(instance))\n+      {\n+        instanceStateMap.put(instance, idealStateMap.get(instance));\n+      }\n+    }\n+\n+    return instanceStateMap;\n+  }\n+\n+\n   private List<String> getPreferenceList(ClusterDataCache cache, ResourceKey resource,\n                                          IdealState idealState,\n                                          StateModelDefinition stateModelDef)\n@@ -223,8 +294,8 @@ else if (\"R\".equals(num))\n     \t  list.add(instanceName);\n       }\n       return list;\n-\n     }\n+\n     return listField;\n   }\n }"
            },
            {
                "sha": "4e93dea8237b8c9a68a17a533c24067ada64042d",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "status": "modified",
                "additions": 16,
                "deletions": 12,
                "changes": 28,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/controller/stages/MessageSelectionStage.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -21,10 +21,10 @@\n   public void process(ClusterEvent event) throws Exception\n   {\n     ClusterDataCache cache = event.getAttribute(\"ClusterDataCache\");\n-    Map<String, ResourceGroup> resourceGroupMap = event\n-        .getAttribute(AttributeName.RESOURCE_GROUPS.toString());\n-    MessageGenerationOutput messageGenOutput = event\n-        .getAttribute(AttributeName.MESSAGES_ALL.toString());\n+    Map<String, ResourceGroup> resourceGroupMap =\n+        event.getAttribute(AttributeName.RESOURCE_GROUPS.toString());\n+    MessageGenerationOutput messageGenOutput =\n+        event.getAttribute(AttributeName.MESSAGES_ALL.toString());\n     if (cache == null || resourceGroupMap == null || messageGenOutput == null)\n     {\n       throw new StageException(\"Missing attributes in event:\" + event\n@@ -36,11 +36,12 @@ public void process(ClusterEvent event) throws Exception\n     for (String resourceGroupName : resourceGroupMap.keySet())\n     {\n       ResourceGroup resourceGroup = resourceGroupMap.get(resourceGroupName);\n-      StateModelDefinition stateModelDef = cache.getStateModelDef(resourceGroup.getStateModelDefRef());\n+      StateModelDefinition stateModelDef =\n+          cache.getStateModelDef(resourceGroup.getStateModelDefRef());\n       for (ResourceKey resource : resourceGroup.getResourceKeys())\n       {\n-        List<Message> messages = messageGenOutput.getMessages(\n-            resourceGroupName, resource);\n+        List<Message> messages =\n+            messageGenOutput.getMessages(resourceGroupName, resource);\n         List<Message> selectedMessages = selectMessages(messages, stateModelDef);\n         output.addMessages(resourceGroupName, resource, selectedMessages);\n       }\n@@ -49,22 +50,26 @@ public void process(ClusterEvent event) throws Exception\n   }\n \n   protected List<Message> selectMessages(List<Message> messages,\n-      StateModelDefinition stateModelDef)\n+                                         StateModelDefinition stateModelDef)\n   {\n     if (messages == null || messages.size() == 0)\n     {\n       return Collections.emptyList();\n     }\n-\n+    List<String> stateTransitionPriorityList =\n+        stateModelDef.getStateTransitionPriorityList();\n+    //todo change this and add validation logic so that state model constraints are not violated.\n+    if (stateTransitionPriorityList == null || stateTransitionPriorityList.isEmpty())\n+    {\n+      return messages;\n+    }\n     Set<String> possibleTransitions = new HashSet<String>();\n     for (Message message : messages)\n     {\n       String transition = message.getFromState() + \"-\" + message.getToState();\n       possibleTransitions.add(transition.toUpperCase());\n     }\n     String preferredTransition = null;\n-    List<String> stateTransitionPriorityList = stateModelDef\n-        .getStateTransitionPriorityList();\n \n     for (String transition : stateTransitionPriorityList)\n     {\n@@ -90,5 +95,4 @@ public void process(ClusterEvent event) throws Exception\n     return Collections.emptyList();\n   }\n \n-\n }"
            },
            {
                "sha": "f17bd2b00cbfb5539cbba733a33b32d26cac8e1d",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "status": "modified",
                "additions": 121,
                "deletions": 103,
                "changes": 224,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/messaging/handling/CMStateTransitionHandler.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -27,8 +27,7 @@\n \n public class CMStateTransitionHandler implements MessageHandler\n {\n-  private static Logger logger = Logger\n-      .getLogger(CMStateTransitionHandler.class);\n+  private static Logger logger = Logger.getLogger(CMStateTransitionHandler.class);\n   private final StateModel _stateModel;\n   StatusUpdateUtil _statusUpdateUtil;\n   private final StateModelParser _transitionMethodFinder;\n@@ -48,26 +47,28 @@ private boolean isNullOrEmpty(String data)\n \n   private boolean validateMessage(Message message)\n   {\n-    boolean isValid = isNullOrEmpty(message.getFromState())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getStateUnitKey())\n-        || isNullOrEmpty(message.getToState())\n-        || isNullOrEmpty(message.getStateModelDef());\n+    boolean isValid =\n+        isNullOrEmpty(message.getFromState()) || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getStateUnitKey())\n+            || isNullOrEmpty(message.getToState())\n+            || isNullOrEmpty(message.getStateModelDef());\n     return !isValid;\n   }\n \n-  private void prepareMessageExecution(ClusterManager manager, Message message)\n-      throws ClusterManagerException\n+  private void prepareMessageExecution(ClusterManager manager, Message message) throws ClusterManagerException\n   {\n     if (!validateMessage(message))\n     {\n-      String errorMessage = \"Invalid Message, ensure that message: \" + message\n-          + \" has all the required fields: \"\n-          + Arrays.toString(Message.Attributes.values());\n-\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, manager.getDataAccessor());\n+      String errorMessage =\n+          \"Invalid Message, ensure that message: \" + message\n+              + \" has all the required fields: \"\n+              + Arrays.toString(Message.Attributes.values());\n+\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 manager.getDataAccessor());\n       logger.error(errorMessage);\n       throw new ClusterManagerException(errorMessage);\n     }\n@@ -79,26 +80,24 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n     String fromState = message.getFromState();\n     String toState = message.getToState();\n \n-    List<StateModelDefinition> stateModelDefs = accessor.getChildValues(StateModelDefinition.class,\n-                                                                        PropertyType.STATEMODELDEFS);\n+    List<StateModelDefinition> stateModelDefs =\n+        accessor.getChildValues(StateModelDefinition.class, PropertyType.STATEMODELDEFS);\n \n-    String initStateValue = \"OFFLINE\";\n-    if (stateModelDefs != null)\n-    {\n-      StateModelDefinition stateModelDef = lookupStateModel(\n-          message.getStateModelDef(), stateModelDefs);\n+    StateModelDefinition stateModelDef =\n+        lookupStateModel(message.getStateModelDef(), stateModelDefs);\n \n-      if (stateModelDef != null)\n-      {\n-        initStateValue = stateModelDef.getInitialState();\n-      }\n+    String initStateValue;\n+    if (stateModelDef == null)\n+    {\n+      throw new ClusterManagerException(\"No State Model Defined for \"+ message.getStateModelDef());\n     }\n-\n-    CurrentState currentState = accessor.getProperty(CurrentState.class,\n-                                                     PropertyType.CURRENTSTATES,\n-                                                     instanceName,\n-                                                     manager.getSessionId(),\n-                                                     stateUnitGroup);\n+    initStateValue = stateModelDef.getInitialState();\n+    CurrentState currentState =\n+        accessor.getProperty(CurrentState.class,\n+                             PropertyType.CURRENTSTATES,\n+                             instanceName,\n+                             manager.getSessionId(),\n+                             stateUnitGroup);\n \n     // Set an empty current state record if it is null\n     if (currentState == null)\n@@ -113,10 +112,9 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n     }\n \n     /**\n-     * For resource unit that does not have a state, initialize it to OFFLINE\n-     * If current state does not have a state model def, set it.\n-     * Do the two updates together, otherwise controller may view a current state\n-     * with a NULL state model def\n+     * For resource unit that does not have a state, initialize it to OFFLINE If current\n+     * state does not have a state model def, set it. Do the two updates together,\n+     * otherwise controller may view a current state with a NULL state model def\n      */\n \n     CurrentState currentStateDelta = new CurrentState(stateUnitGroup);\n@@ -125,8 +123,8 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n       currentStateDelta.setState(stateUnitKey, initStateValue);\n       currentState.setState(stateUnitKey, initStateValue);\n \n-      logger.info(\"Setting initial state for partition: \" + stateUnitKey\n-          + \" to \" + initStateValue);\n+      logger.info(\"Setting initial state for partition: \" + stateUnitKey + \" to \"\n+          + initStateValue);\n     }\n \n     // Set the state model def to current state\n@@ -136,7 +134,7 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n       if (message.getStateModelDef() != null)\n       {\n         logger.info(\"Setting state model def on current state: \"\n-                   + message.getStateModelDef());\n+            + message.getStateModelDef());\n         currentStateDelta.setStateModelDefRef(message.getStateModelDef());\n       }\n     }\n@@ -148,29 +146,29 @@ private void prepareMessageExecution(ClusterManager manager, Message message)\n \n     // Verify the fromState and current state of the stateModel\n     String state = currentState.getState(stateUnitKey);\n-    if (!fromState.equals(\"*\") && (fromState == null || !fromState.equalsIgnoreCase(state)))\n+    if (!fromState.equals(\"*\")\n+        && (fromState == null || !fromState.equalsIgnoreCase(state)))\n     {\n-      String errorMessage = \"Current state of stateModel does not match the fromState in Message\"\n-          + \", Current State:\"\n-          + state\n-          + \", message expected:\"\n-          + fromState\n-          + \", partition: \"\n-          + message.getStateUnitKey()\n-          + \", from: \"\n-          + message.getMsgSrc()\n-          + \", to: \" + message.getTgtName();\n-\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, accessor);\n+      String errorMessage =\n+          \"Current state of stateModel does not match the fromState in Message\"\n+              + \", Current State:\" + state + \", message expected:\" + fromState\n+              + \", partition: \" + message.getStateUnitKey() + \", from: \"\n+              + message.getMsgSrc() + \", to: \" + message.getTgtName();\n+\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 accessor);\n       logger.error(errorMessage);\n       throw new ClusterManagerException(errorMessage);\n     }\n   }\n \n-  void postExecutionMessage(ClusterManager manager, Message message,\n-      NotificationContext context, CMTaskResult taskResult, Exception exception)\n-      throws InterruptedException\n+  void postExecutionMessage(ClusterManager manager,\n+                            Message message,\n+                            NotificationContext context,\n+                            CMTaskResult taskResult,\n+                            Exception exception) throws InterruptedException\n   {\n     ClusterDataAccessor accessor = manager.getDataAccessor();\n     try\n@@ -181,20 +179,20 @@ void postExecutionMessage(ClusterManager manager, Message message,\n \n       String fromState = message.getFromState();\n       String toState = message.getToState();\n-      CurrentState currentState = accessor.getProperty(CurrentState.class,\n-                                                       PropertyType.CURRENTSTATES,\n-                                                       instanceName,\n-                                                       manager.getSessionId(),\n-                                                       stateUnitGroup);\n+      CurrentState currentState =\n+          accessor.getProperty(CurrentState.class,\n+                               PropertyType.CURRENTSTATES,\n+                               instanceName,\n+                               manager.getSessionId(),\n+                               stateUnitGroup);\n \n       if (currentState != null)\n       {\n-//        map = currentState.getMapField(stateUnitKey);\n+        // map = currentState.getMapField(stateUnitKey);\n       }\n       else\n       {\n-        logger\n-            .warn(\"currentState is null. Storage node should be working with file based cluster manager.\");\n+        logger.warn(\"currentState is null. Storage node should be working with file based cluster manager.\");\n       }\n \n       // TODO verify that fromState is same as currentState this task\n@@ -213,22 +211,22 @@ void postExecutionMessage(ClusterManager manager, Message message,\n       }\n       else\n       {\n-        StateTransitionError error = new StateTransitionError(\n-            StateTransitionError.ErrorCode.INTERNAL, exception);\n+        StateTransitionError error =\n+            new StateTransitionError(StateTransitionError.ErrorCode.INTERNAL, exception);\n         _stateModel.rollbackOnError(message, context, error);\n         currentStateDelta.setState(stateUnitKey, \"ERROR\");\n         _stateModel.updateState(\"ERROR\");\n       }\n \n       currentStateDelta.setResourceGroup(stateUnitKey, message.getStateUnitGroup());\n \n-\n       if (taskResult.isSucess() && toState.equals(\"DROPPED\"))\n       {\n         // for \"OnOfflineToDROPPED\" message, we need to remove the resource key\n         // record from\n         // the current state of the instance because the resource key is dropped.\n-        ZNRecordDelta delta = new ZNRecordDelta(currentStateDelta.getRecord(), MERGEOPERATION.SUBSTRACT);\n+        ZNRecordDelta delta =\n+            new ZNRecordDelta(currentStateDelta.getRecord(), MERGEOPERATION.SUBSTRACT);\n         List<ZNRecordDelta> deltaList = new ArrayList<ZNRecordDelta>();\n         deltaList.add(delta);\n         CurrentState currentStateUpdate = new CurrentState(stateUnitGroup);\n@@ -248,22 +246,25 @@ void postExecutionMessage(ClusterManager manager, Message message,\n                                 manager.getSessionId(),\n                                 stateUnitGroup);\n       }\n-    } catch (Exception e)\n+    }\n+    catch (Exception e)\n     {\n       logger.error(\"Error when updating the state \", e);\n-      StateTransitionError error = new StateTransitionError(\n-          StateTransitionError.ErrorCode.FRAMEWORK, e);\n+      StateTransitionError error =\n+          new StateTransitionError(StateTransitionError.ErrorCode.FRAMEWORK, e);\n       _stateModel.rollbackOnError(message, context, error);\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class, e,\n-          \"Error when update the state \", accessor);\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 e,\n+                                 \"Error when update the state \",\n+                                 accessor);\n     }\n   }\n \n   // TODO: decide if handleMessage() should return a value CMTaskResult; this\n   // part need to integrate with\n   // send reply message\n-  public CMTaskResult handleMessageInternal(Message message,\n-      NotificationContext context)\n+  public CMTaskResult handleMessageInternal(Message message, NotificationContext context)\n   {\n     synchronized (_stateModel)\n     {\n@@ -273,13 +274,16 @@ public CMTaskResult handleMessageInternal(Message message,\n       String instanceName = manager.getInstanceName();\n       try\n       {\n-        _statusUpdateUtil.logInfo(message, CMStateTransitionHandler.class,\n-            \"Message handling task begin execute\", accessor);\n+        _statusUpdateUtil.logInfo(message,\n+                                  CMStateTransitionHandler.class,\n+                                  \"Message handling task begin execute\",\n+                                  accessor);\n         message.setExecuteStartTimeStamp(new Date().getTime());\n         try\n         {\n           prepareMessageExecution(manager, message);\n-        } catch (ClusterManagerException e)\n+        }\n+        catch (ClusterManagerException e)\n         {\n           taskResult.setSuccess(false);\n           taskResult.setMessage(e.getMessage());\n@@ -294,11 +298,11 @@ public CMTaskResult handleMessageInternal(Message message,\n         }\n         catch (Exception e)\n         {\n-          String errorMessage = \"Exception while executing a state transition task. \"\n-              + e;\n+          String errorMessage = \"Exception while executing a state transition task. \" + e;\n \n           // Hack: avoid throwing mock exception for testing code\n-          if (e instanceof InvocationTargetException && e.getCause().getMessage().startsWith(\"IGNORABLE\"))\n+          if (e instanceof InvocationTargetException\n+              && e.getCause().getMessage().startsWith(\"IGNORABLE\"))\n           {\n             logger.error(errorMessage + \". Cause:\" + e.getCause().getMessage());\n           }\n@@ -322,51 +326,64 @@ public CMTaskResult handleMessageInternal(Message message,\n       }\n       catch (InterruptedException e)\n       {\n-        _statusUpdateUtil.logError(message, CMStateTransitionHandler.class, e,\n-            \"State transition interrupted\", accessor);\n+        _statusUpdateUtil.logError(message,\n+                                   CMStateTransitionHandler.class,\n+                                   e,\n+                                   \"State transition interrupted\",\n+                                   accessor);\n         logger.info(\"Message \" + message.getMsgId() + \" is interrupted\");\n \n-        StateTransitionError error = new StateTransitionError(\n-            StateTransitionError.ErrorCode.FRAMEWORK, e);\n+        StateTransitionError error =\n+            new StateTransitionError(StateTransitionError.ErrorCode.FRAMEWORK, e);\n         _stateModel.rollbackOnError(message, context, error);\n         return taskResult;\n       }\n     }\n   }\n \n   private void invoke(ClusterDataAccessor accessor,\n-      NotificationContext context, CMTaskResult taskResult, Message message)\n-      throws IllegalAccessException, InvocationTargetException,\n+                      NotificationContext context,\n+                      CMTaskResult taskResult,\n+                      Message message) throws IllegalAccessException,\n+      InvocationTargetException,\n       InterruptedException\n   {\n     Method methodToInvoke = null;\n     String fromState = message.getFromState();\n     String toState = message.getToState();\n-    methodToInvoke = _transitionMethodFinder.getMethodForTransition(\n-        _stateModel.getClass(), fromState, toState, new Class[]\n-        { Message.class, NotificationContext.class });\n-    _statusUpdateUtil.logInfo(message, CMStateTransitionHandler.class,\n-        \"Message handling invoking\", accessor);\n+    methodToInvoke =\n+        _transitionMethodFinder.getMethodForTransition(_stateModel.getClass(),\n+                                                       fromState,\n+                                                       toState,\n+                                                       new Class[] { Message.class,\n+                                                           NotificationContext.class });\n+    _statusUpdateUtil.logInfo(message,\n+                              CMStateTransitionHandler.class,\n+                              \"Message handling invoking\",\n+                              accessor);\n     if (methodToInvoke != null)\n     {\n-      methodToInvoke.invoke(_stateModel, new Object[]\n-      { message, context });\n+      methodToInvoke.invoke(_stateModel, new Object[] { message, context });\n       taskResult.setSuccess(true);\n-    } else\n+    }\n+    else\n     {\n-      String errorMessage = \"Unable to find method for transition from \"\n-          + fromState + \" to \" + toState + \"in \" + _stateModel.getClass();\n+      String errorMessage =\n+          \"Unable to find method for transition from \" + fromState + \" to \" + toState\n+              + \"in \" + _stateModel.getClass();\n       logger.error(errorMessage);\n       taskResult.setSuccess(false);\n \n       System.out.println(errorMessage);\n-      _statusUpdateUtil.logError(message, CMStateTransitionHandler.class,\n-          errorMessage, accessor);\n+      _statusUpdateUtil.logError(message,\n+                                 CMStateTransitionHandler.class,\n+                                 errorMessage,\n+                                 accessor);\n     }\n   }\n \n   private StateModelDefinition lookupStateModel(String stateModelDefRef,\n-      List<StateModelDefinition> stateModelDefs)\n+                                                List<StateModelDefinition> stateModelDefs)\n   {\n     for (StateModelDefinition def : stateModelDefs)\n     {\n@@ -379,8 +396,9 @@ private StateModelDefinition lookupStateModel(String stateModelDefRef,\n   }\n \n   @Override\n-  public void handleMessage(Message message, NotificationContext context,\n-      Map<String, String> resultMap) throws InterruptedException\n+  public void handleMessage(Message message,\n+                            NotificationContext context,\n+                            Map<String, String> resultMap) throws InterruptedException\n   {\n     handleMessageInternal(message, context);\n "
            },
            {
                "sha": "0e43b79f6443013fa0427eed8c2bf0f5bbceafb8",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "status": "modified",
                "additions": 7,
                "deletions": 6,
                "changes": 13,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/model/StateModelDefinition.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -6,7 +6,6 @@\n \n import org.apache.log4j.Logger;\n \n-import com.linkedin.clustermanager.ClusterManagerException;\n import com.linkedin.clustermanager.ZNRecord;\n import com.linkedin.clustermanager.ZNRecordDecorator;\n \n@@ -117,11 +116,13 @@ public boolean isValid()\n       _logger.error(\"CurrentState does not contain StatesPriorityList, state model : \" + _record.getId());\n       return false;\n     }\n-    if(_record.getListField(StateModelDefinitionProperty.STATE_TRANSITION_PRIORITYLIST.toString()) == null)\n-    {\n-      _logger.error(\"CurrentState does not contain StateTransitionPriorityList, state model : \" + _record.getId());\n-      return false;\n-    }\n+\n+    // STATE_TRANSITION_PRIORITYLIST is optional\n+//    if(_record.getListField(StateModelDefinitionProperty.STATE_TRANSITION_PRIORITYLIST.toString()) == null)\n+//    {\n+//      _logger.error(\"CurrentState does not contain StateTransitionPriorityList, state model : \" + _record.getId());\n+//      return false;\n+//    }\n     return true;\n   }\n }"
            },
            {
                "sha": "e3941c367302c29fb1dc610957e8c6d3f28ffb7b",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "status": "modified",
                "additions": 1,
                "deletions": 2,
                "changes": 3,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/PropertiesReader.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -1,6 +1,5 @@\n package com.linkedin.clustermanager.tools;\n \n-import java.io.IOException;\n import java.io.InputStream;\n import java.util.Properties;\n \n@@ -21,7 +20,7 @@ public PropertiesReader(String propertyFileName)\n           .getResourceAsStream(propertyFileName);\n       _properties.load(stream);\n     }\n-    catch (IOException e)\n+    catch (Exception e)\n     {\n       String errMsg = \"could not open properties file:\" + propertyFileName;\n       // LOG.error(errMsg, e);"
            },
            {
                "sha": "60303ba3434f8732446f06635d39466b062fa687",
                "filename": "cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "status": "modified",
                "additions": 10,
                "deletions": 3,
                "changes": 13,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/main/java/com/linkedin/clustermanager/tools/TestExecutor.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -839,7 +839,7 @@ else if (_command._commandType == CommandType.VERIFY)\n             }\n             else\n             {\n-//              logger.debug(\"result:\" + result + \", diff:\" + diff);\n+//              logger.error(\"result:\" + result + \", diff:\" + diff);\n             }\n           }\n           else if (_command._commandType == CommandType.START)\n@@ -848,6 +848,7 @@ else if (_command._commandType == CommandType.START)\n             Thread thread = _command._nodeOpArg._thread;\n             thread.start();\n \n+            result = true;\n             _command._finishTimestamp = System.currentTimeMillis();\n             logger.info(\"result:\" + result + \", \" + _command.toString());\n             _testResults.put(_command, true);\n@@ -862,15 +863,16 @@ else if (_command._commandType == CommandType.STOP)\n             thread.interrupt();\n \n             // System.err.println(\"stop \" + _command._nodeOpArg._manager.getInstanceName());\n+            result = true;\n             _command._finishTimestamp = System.currentTimeMillis();\n             logger.info(\"result:\" + result + \", \" + _command.toString());\n             _testResults.put(_command, true);\n             break;\n           }\n           else\n           {\n-            logger.error(\"unsupport command\");\n-            break;\n+            throw new IllegalArgumentException(\"Unsupport command type (was \"\n+                                             + _command._commandType + \")\");\n           }\n \n           Thread.sleep(SLEEP_TIME);\n@@ -885,6 +887,11 @@ else if (_command._commandType == CommandType.STOP)\n       }\n       finally\n       {\n+        if (result == false)\n+        {\n+          _command._finishTimestamp = System.currentTimeMillis();\n+          logger.error(\"result:\" + result + \", diff: \" + diff);\n+        }\n         _countDown.countDown();\n       }\n     }"
            },
            {
                "sha": "2d54ef74a4b27296919389993d64bf944d97002c",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "status": "modified",
                "additions": 9,
                "deletions": 2,
                "changes": 11,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskExecutor.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -10,6 +10,8 @@\n import com.linkedin.clustermanager.messaging.handling.CMStateTransitionHandler;\n import com.linkedin.clustermanager.model.Message;\n import com.linkedin.clustermanager.model.Message.MessageType;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n+import com.linkedin.clustermanager.tools.StateModelConfigGenerator;\n \n public class TestCMTaskExecutor\n {\n@@ -36,8 +38,13 @@ public void testCMTaskExecutor() throws Exception\n     NotificationContext context;\n     executor.registerMessageHandlerFactory(\n         MessageType.TASK_REPLY.toString(), new AsyncCallbackService());\n-    String clusterName =\" testcluster\";\n-    context = new NotificationContext(new MockManager(clusterName));\n+    MockManager manager = new MockManager(\"testcluster\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMStateTransitionHandler handler = new CMStateTransitionHandler(stateModel);\n     executor.scheduleTask(message, handler, context);\n     while (!executor.isDone(msgId))"
            },
            {
                "sha": "59054b715fba37cffe05d2b0782bbfc71b7499b5",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "status": "modified",
                "additions": 27,
                "deletions": 11,
                "changes": 38,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestCMTaskHandler.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -1,5 +1,7 @@\n package com.linkedin.clustermanager;\n \n+import java.util.Date;\n+\n import org.testng.AssertJUnit;\n import org.testng.annotations.Test;\n \n@@ -10,14 +12,16 @@\n import com.linkedin.clustermanager.messaging.handling.CMTask;\n import com.linkedin.clustermanager.model.Message;\n import com.linkedin.clustermanager.model.Message.MessageType;\n+import com.linkedin.clustermanager.model.StateModelDefinition;\n+import com.linkedin.clustermanager.tools.StateModelConfigGenerator;\n \n public class TestCMTaskHandler\n {\n-  @Test ()\n+  @Test()\n   public void testInvocation() throws Exception\n   {\n-    System.out.println(\"START TestCMTaskHandler.testInvocation()\");\n-    Message message = new Message(MessageType.STATE_TRANSITION,\"Some unique id\");\n+    System.out.println(\"START TestCMTaskHandler.testInvocation() at \"+ new Date(System.currentTimeMillis()));\n+    Message message = new Message(MessageType.STATE_TRANSITION, \"Some unique id\");\n     message.setSrcName(\"cm-instance-0\");\n     message.setTgtSessionId(\"1234\");\n     message.setFromState(\"Offline\");\n@@ -30,20 +34,25 @@ public void testInvocation() throws Exception\n     MockStateModel stateModel = new MockStateModel();\n     NotificationContext context;\n     CMStateTransitionHandler stHandler = new CMStateTransitionHandler(stateModel);\n-    String clusterName=\"clusterName\";\n-    context = new NotificationContext(new MockManager(clusterName));\n+    MockManager manager = new MockManager(\"clusterName\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMTask handler;\n     handler = new CMTask(message, context, stHandler, null);\n     handler.call();\n     AssertJUnit.assertTrue(stateModel.stateModelInvoked);\n-    System.out.println(\"END TestCMTaskHandler.testInvocation()\");\n+    System.out.println(\"END TestCMTaskHandler.testInvocation() at \" + new Date(System.currentTimeMillis()));\n   }\n \n-  @Test ()\n+  @Test()\n   public void testInvocationAnnotated() throws Exception\n   {\n-    System.out.println(\"START TestCMTaskHandler.testInvocationAnnotated()\");\n-    Message message = new Message(MessageType.STATE_TRANSITION,\"Some unique id\");\n+    System.out.println(\"START TestCMTaskHandler.testInvocationAnnotated() at \" + new Date(System.currentTimeMillis()));\n+    Message message = new Message(MessageType.STATE_TRANSITION, \"Some unique id\");\n     message.setSrcName(\"cm-instance-0\");\n     message.setTgtSessionId(\"1234\");\n     message.setFromState(\"Offline\");\n@@ -55,14 +64,21 @@ public void testInvocationAnnotated() throws Exception\n     message.setStateModelDef(\"MasterSlave\");\n     MockStateModelAnnotated stateModel = new MockStateModelAnnotated();\n     NotificationContext context;\n-    context = new NotificationContext(new MockManager());\n+\n+    MockManager manager = new MockManager(\"clusterName\");\n+    ClusterDataAccessor accessor = manager.getDataAccessor();\n+    StateModelConfigGenerator generator = new StateModelConfigGenerator();\n+    StateModelDefinition stateModelDef = new StateModelDefinition(generator.generateConfigForMasterSlave());\n+    accessor.setProperty(PropertyType.STATEMODELDEFS, stateModelDef, \"MasterSlave\");\n+\n+    context = new NotificationContext(manager);\n     CMTask handler;\n     CMStateTransitionHandler stHandler = new CMStateTransitionHandler(stateModel);\n \n     handler = new CMTask(message, context, stHandler, null);\n     handler.call();\n     AssertJUnit.assertTrue(stateModel.stateModelInvoked);\n-    System.out.println(\"END TestCMTaskHandler.testInvocationAnnotated()\");\n+    System.out.println(\"END TestCMTaskHandler.testInvocationAnnotated() at \"+ new Date(System.currentTimeMillis()));\n   }\n \n }"
            },
            {
                "sha": "af5e541f3c846826d4260f7bc5ca152e0e96e228",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/TestHelper.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -378,19 +378,25 @@ else if (map1 != null && map2 == null)\n     return set;\n   }\n \n+  public static void verifyWithTimeout(String verifierName, Object... args)\n+  {\n+    verifyWithTimeout(verifierName, 30 * 1000, args);\n+  }\n+\n   /**\n    * generic method for verification with a timeout\n    * @param verifierName\n    * @param args\n    */\n-  public static void verifyWithTimeout(String verifierName, Object... args)\n+  public static void verifyWithTimeout(String verifierName, long timeout, Object... args)\n   {\n     final long sleepInterval = 1000;  // in ms\n+    final int loop = (int) (timeout / sleepInterval) + 1;\n     try\n     {\n       boolean result = false;\n       int i = 0;\n-      for (; i < 30; i++)\n+      for (; i < loop; i++)\n       {\n         Thread.sleep(sleepInterval);\n         // verifier should be static method\n@@ -483,7 +489,7 @@ public static boolean verifyBestPossAndExtViewExtended(String resourceGroupName,\n       }\n \n       BestPossibleStateOutput bestPossOutput =\n-        calcBestPossState(resourceGroupName, partitions, stateModelName, clusterName, accessor);\n+        TestHelper.calcBestPossState(resourceGroupName, partitions, stateModelName, clusterName, accessor);\n \n //      System.out.println(\"extView:\" + extView.getMapFields());\n //      System.out.println(\"BestPoss:\" + bestPossOutput);"
            },
            {
                "sha": "ecfbe64c661e94153c7ed872ae6fd0e27068c239",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "status": "modified",
                "additions": 2,
                "deletions": 2,
                "changes": 4,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMUsingDifferentParams.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -30,7 +30,7 @@ public void afterClass()\n   \t_zkClient.close();\n   }\n \n-  @Test (groups = {\"integrationTest\"})\n+  @Test ()\n   public void testCMUsingDifferentParams() throws Exception\n   {\n     System.out.println(\"START \" + getShortClassName() + \" at \"\n@@ -62,7 +62,7 @@ public void testCMUsingDifferentParams() throws Exception\n             }\n \n             TestDriver.startController(uniqTestName);\n-            TestDriver.verifyCluster(uniqTestName);\n+            TestDriver.verifyCluster(uniqTestName, 1000);\n             TestDriver.stopCluster(uniqTestName);\n \n             System.out.println(\"END \" + uniqTestName + \" at \""
            },
            {
                "sha": "aa944df8e312ceb67148c36022cf5286e4bc4583",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "status": "modified",
                "additions": 9,
                "deletions": 8,
                "changes": 17,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCMWithFailParticipant.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -13,28 +13,29 @@\n public class TestCMWithFailParticipant extends ZkIntegrationTestBase\n {\n   ZkClient _zkClient;\n-  @BeforeClass (groups = {\"integrationTest\"})\n+\n+  @BeforeClass ()\n   public void beforeClass() throws Exception\n   {\n   \t_zkClient = new ZkClient(ZK_ADDR);\n   \t_zkClient.setZkSerializer(new ZNRecordSerializer());\n   }\n-  \n-  \n+\n+\n \t@AfterClass\n   public void afterClass()\n   {\n   \t_zkClient.close();\n   }\n-\t\n-  @Test (groups = {\"integrationTest\"})\n+\n+  @Test ()\n   public void testCMWithFailParticipant() throws Exception\n   {\n     int numDb = 1;\n     int numPartitionsPerDb = 10;\n     int numNode = 5;\n     int replica = 3;\n-    \n+\n     String uniqTestName = \"TestFail_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n         + numNode + \"_r\" + replica;\n     System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n@@ -46,9 +47,9 @@ public void testCMWithFailParticipant() throws Exception\n       TestDriver.startDummyParticipant(uniqTestName, i);\n     }\n     TestDriver.startController(uniqTestName);\n-    \n+\n     TestDriver.stopDummyParticipant(uniqTestName, 2000, 0);\n-    TestDriver.verifyCluster(uniqTestName);\n+    TestDriver.verifyCluster(uniqTestName, 3000);\n     TestDriver.stopCluster(uniqTestName);\n \n     System.out.println(\"END \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));"
            },
            {
                "sha": "fd244d826967d02d88fa7444f544b6ce4b35979e",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "status": "modified",
                "additions": 42,
                "deletions": 4,
                "changes": 46,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestCustomIdealState.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -23,15 +23,14 @@ public void beforeClass() throws Exception\n   \t_zkClient.setZkSerializer(new ZNRecordSerializer());\n   }\n \n-\n \t@AfterClass\n   public void afterClass()\n   {\n   \t_zkClient.close();\n   }\n \n   @Test\n-  public void testCustomIdealState() throws Exception\n+  public void testBasic() throws Exception\n   {\n \n     int numDb = 2;\n@@ -40,7 +39,7 @@ public void testCustomIdealState() throws Exception\n     int replica = 3;\n \n     String uniqTestName = \"TestCustomIS_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n-        + numNode + \"_r\" + replica;\n+        + numNode + \"_r\" + replica + \"_basic\";\n     System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n \n     TestDriver.setupClusterWithoutRebalance(uniqTestName, _zkClient, numDb, numPartitionsPerDb, numNode, replica);\n@@ -52,12 +51,51 @@ public void testCustomIdealState() throws Exception\n     TestDriver.startController(uniqTestName);\n \n     TestDriver.setIdealState(uniqTestName, 2000, 50);\n+    TestDriver.verifyCluster(uniqTestName, 3000);\n \n-    TestDriver.verifyCluster(uniqTestName);\n     TestDriver.stopCluster(uniqTestName);\n \n+    System.out.println(\"STOP \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+  }\n+\n+  @Test\n+  public void testNonAliveInstances() throws Exception\n+  {\n+    int numDb = 2;\n+    int numPartitionsPerDb = 50;\n+    int numNode = 5;\n+    int replica = 3;\n+\n+    String uniqTestName = \"TestCustomIS_\" + \"db\" + numDb + \"_p\" + numPartitionsPerDb + \"_n\"\n+        + numNode + \"_r\" + replica + \"_nonalive\";\n+    System.out.println(\"START \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+\n+    TestDriver.setupClusterWithoutRebalance(uniqTestName, _zkClient, numDb, numPartitionsPerDb, numNode, replica);\n+\n+    for (int i = 0; i < numNode/2; i++)\n+    {\n+      TestDriver.startDummyParticipant(uniqTestName, i);\n+    }\n+\n+    TestDriver.startController(uniqTestName);\n+    TestDriver.setIdealState(uniqTestName, 0, 100);\n+\n+    // wait some time for customized ideal state being populated\n+    Thread.sleep(1000);\n+\n+    // start the rest of participants after ideal state is set\n+    for (int i = numNode/2; i < numNode; i++)\n+    {\n+      TestDriver.startDummyParticipant(uniqTestName, i);\n+    }\n+\n+    TestDriver.verifyCluster(uniqTestName, 4000);\n+\n+    TestDriver.stopCluster(uniqTestName);\n \n     System.out.println(\"STOP \" + uniqTestName + \" at \" + new Date(System.currentTimeMillis()));\n+\n   }\n \n+  // TODO add a test case that verify (in case of node failure) best possible state is a subset of ideal state\n }"
            },
            {
                "sha": "9ba90455e7c59dc851bf2153a3b66ec4cd99e06d",
                "filename": "cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "status": "modified",
                "additions": 16,
                "deletions": 65,
                "changes": 81,
                "blob_url": "https://github.com/apache/helix/blob/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "raw_url": "https://github.com/apache/helix/raw/7b28011e31c3cc4f8e79f4d5d8bb0933009750ff/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java",
                "contents_url": "https://api.github.com/repos/apache/helix/contents/cluster-manager-core/src/test/java/com/linkedin/clustermanager/integration/TestDriver.java?ref=7b28011e31c3cc4f8e79f4d5d8bb0933009750ff",
                "patch": "@@ -10,7 +10,6 @@\n import java.util.concurrent.ConcurrentHashMap;\n \n import org.apache.log4j.Logger;\n-import org.testng.AssertJUnit;\n \n import com.linkedin.clustermanager.ClusterManager;\n import com.linkedin.clustermanager.PropertyType;\n@@ -36,11 +35,7 @@\n public class TestDriver\n {\n   private static Logger LOG = Logger.getLogger(TestDriver.class);\n-  private static final String ZK_ADDR = ZkIntegrationTestBase.ZK_ADDR; // \"localhost:2183\";\n-  // private static final int DEFAULT_SESSION_TIMEOUT = 30000;\n-  // private static final int DEFAULT_CONNECTION_TIMEOUT = Integer.MAX_VALUE;\n-  // private static final ZkClient _zkClient = new ZkClient(ZK_ADDR, DEFAULT_SESSION_TIMEOUT,\n-  //    DEFAULT_CONNECTION_TIMEOUT, new ZNRecordSerializer());\n+  private static final String ZK_ADDR = ZkIntegrationTestBase.ZK_ADDR;\n \n   private static final String CLUSTER_PREFIX = \"TestDriver\";\n   private static final String STATE_MODEL = \"MasterSlave\";\n@@ -219,8 +214,10 @@ public static void startController(String uniqTestName, int[] nodeIds) throws Ex\n     }\n   }\n \n-  public static void verifyCluster(String uniqTestName) throws Exception\n+  public static void verifyCluster(String uniqTestName, long at) throws Exception\n   {\n+    Thread.sleep(at);\n+\n     if (!_testInfoMap.containsKey(uniqTestName))\n     {\n       String errMsg = \"test cluster hasn't been setup:\" + uniqTestName;\n@@ -231,47 +228,21 @@ public static void verifyCluster(String uniqTestName) throws Exception\n     String clusterName = testInfo._clusterName;\n     ZkClient zkClient = testInfo._zkClient;\n \n-    // verify external view\n-    String liveInstancePath = \"/\" + clusterName + \"/\"\n-        + PropertyType.LIVEINSTANCES.toString();\n-    List<String> liveInstances = zkClient.getChildren(liveInstancePath);\n-    String configInstancePath = \"/\" + clusterName + \"/\" + PropertyType.CONFIGS.toString();\n-    List<String> failInstances = zkClient.getChildren(configInstancePath);\n-    failInstances.removeAll(liveInstances);\n-\n-    List<TestCommand> commandList = new ArrayList<TestCommand>();\n \n     for (int i = 0; i < testInfo._numDb; i++)\n     {\n-      // String idealStatePath = \"/\" + clusterName + \"/\" + PropertyType.IDEALSTATES.toString()\n-      //    + \"/\" + TEST_DB_PREFIX + i;\n-      // ZNRecord idealState = _zkClient.<ZNRecord> readData(idealStatePath);\n       String dbName = TEST_DB_PREFIX + i;\n-      ZNRecord idealState = testInfo._idealStateMap.get(dbName);\n-\n-      ZNRecord externalView = calculateExternalViewFromIdealState(idealState, failInstances);\n-\n-      String externalViewPath = \"/\" + clusterName + \"/\"\n-          + PropertyType.EXTERNALVIEW.toString() + \"/\" + TEST_DB_PREFIX + i;\n-\n-      ZnodeOpArg arg = new ZnodeOpArg(externalViewPath, ZnodePropertyType.ZNODE, \"==\");\n-      TestCommand command = new TestCommand(CommandType.VERIFY, new TestTrigger(1000, 60 * 1000,\n-          externalView), arg);\n-      commandList.add(command);\n-    }\n-\n-    Map<TestCommand, Boolean> results = TestExecutor.executeTest(commandList, ZK_ADDR);\n-    for (Map.Entry<TestCommand, Boolean> entry : results.entrySet())\n-    {\n-      System.out.println(entry.getValue() + \":\" + entry.getKey());\n-      // LOG.info(entry.getValue() + \":\" + entry.getKey());\n-      AssertJUnit.assertTrue(entry.getValue());\n+      TestHelper.verifyWithTimeout(\"verifyBestPossAndExtViewExtended\",\n+                                   60 * 1000,\n+                                   dbName,\n+                                   testInfo._numPartitionsPerDb,\n+                                   \"MasterSlave\",\n+                                   TestHelper.<String>setOf(clusterName),\n+                                   zkClient,\n+                                   null,\n+                                   null,\n+                                   null);\n     }\n-\n-    // LOG.info(\"verify cluster:\" + clusterName + \", result:\" + result);\n-    // System.err.println(\"verify cluster:\" + clusterName + \", result:\" +\n-    // result);\n-    // TODO verify other states\n   }\n \n   public static void stopCluster(String uniqTestName) throws Exception\n@@ -331,7 +302,8 @@ public static void stopDummyParticipant(String uniqTestName, long at, int nodeId\n     {\n       String errMsg = \"Dummy participant:\" + failHost + \" seems not running\";\n       LOG.error(errMsg);\n-    } else\n+    }\n+    else\n     {\n       // System.err.println(\"try to stop participant: \" + result._manager.getInstanceName());\n       NodeOpArg arg = new NodeOpArg(result._manager, result._thread);\n@@ -342,7 +314,6 @@ public static void stopDummyParticipant(String uniqTestName, long at, int nodeId\n     }\n   }\n \n-\n   public static void setIdealState(String uniqTestName, long at, int percentage)\n   throws Exception\n   {\n@@ -400,26 +371,6 @@ public static void setIdealState(String uniqTestName, long at, int percentage)\n \n   }\n \n-  private static ZNRecord calculateExternalViewFromIdealState(ZNRecord idealState,\n-      List<String> failInstances)\n-  {\n-    ZNRecord externalView = new ZNRecord(idealState.getId());\n-\n-    // externalView.setId();\n-\n-    for (Map.Entry<String, Map<String, String>> mapEntry : idealState.getMapFields().entrySet())\n-    {\n-\n-      for (String failInstance : failInstances)\n-      {\n-        mapEntry.getValue().remove(failInstance);\n-      }\n-      externalView.setMapField(mapEntry.getKey(), mapEntry.getValue());\n-    }\n-\n-    return externalView;\n-  }\n-\n   private static List<String[]> findAllUnfinishPairs(ZNRecord cur, ZNRecord dest)\n   {\n     // find all (host, resource) pairs that haven't reached destination state"
            }
        ]
    }
]
