[
    {
        "commit": "https://github.com/apache/incubator-myriad/commit/4bce035ec8feff66f4804cc121c3051f5ecff4fa",
        "repo": "incubator-myriad",
        "parent": "https://github.com/apache/incubator-myriad/commit/79ba4a5f09c0bb59492a50bb8b310543fb372ead",
        "message": "[Myriad 188] - NodeManager switch to UNHEALTHY causes NPE on ResourceManager.\n\nJIRA:\n  [Myriad-188] https://issues.apache.org/jira/browse/MYRIAD-188\n  [Myriad-156] https://issues.apache.org/jira/browse/MYRIAD-156\n\nPull Request:\n  Closes #62\n\nAuthor:\n  darinj darinj@apache.org",
        "bug_id": "incubator-myriad_1",
        "file": [
            {
                "sha": "1dee5fa22862fec26c5b7ff1a0da49848e24a12f",
                "filename": "myriad-scheduler/src/main/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "status": "modified",
                "additions": 9,
                "deletions": 3,
                "changes": 12,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/main/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/main/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManager.java?ref=4bce035ec8feff66f4804cc121c3051f5ecff4fa",
                "patch": "@@ -70,6 +70,7 @@\n  */\n public class YarnNodeCapacityManager extends BaseInterceptor {\n   private static final Logger LOGGER = LoggerFactory.getLogger(YarnNodeCapacityManager.class);\n+\n   private final AbstractYarnScheduler yarnScheduler;\n   private final RMContext rmContext;\n   private final MyriadDriver myriadDriver;\n@@ -247,9 +248,14 @@ public void setNodeCapacity(RMNode rmNode, Resource newCapacity) {\n       rmNode.getTotalCapability().setVirtualCores(newCapacity.getVirtualCores());\n       LOGGER.debug(\"Setting capacity for node {} to {}\", rmNode.getHostName(), newCapacity);\n       // updates the scheduler with the new capacity for the NM.\n-      // the event is handled by the scheduler asynchronously\n-      rmContext.getDispatcher().getEventHandler().handle(new NodeResourceUpdateSchedulerEvent(rmNode, ResourceOption.newInstance(\n-          rmNode.getTotalCapability(), RMNode.OVER_COMMIT_TIMEOUT_MILLIS_DEFAULT)));\n+      synchronized (yarnScheduler) {\n+        if (yarnScheduler.getSchedulerNode(rmNode.getNodeID()) != null) {\n+          yarnScheduler.updateNodeResource(rmNode,\n+              ResourceOption.newInstance(rmNode.getTotalCapability(), RMNode.OVER_COMMIT_TIMEOUT_MILLIS_DEFAULT));\n+        } else {\n+          LOGGER.info(\"Yarn Scheduler doesn't have node {}, probably UNHEALTHY\", rmNode.getNodeID());\n+        }\n+      }\n     }\n   }\n "
            },
            {
                "sha": "c769999059734969564a42f26027c3be0249a6bc",
                "filename": "myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/FGSTestBaseSpec.groovy",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/FGSTestBaseSpec.groovy",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/FGSTestBaseSpec.groovy",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/FGSTestBaseSpec.groovy?ref=4bce035ec8feff66f4804cc121c3051f5ecff4fa",
                "patch": "@@ -33,6 +33,7 @@ import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNode\n import org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler\n import org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt\n import org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode\n+import org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode\n import org.apache.hadoop.yarn.util.resource.Resources\n import org.apache.mesos.Protos\n import org.apache.mesos.SchedulerDriver\n@@ -65,6 +66,7 @@ class FGSTestBaseSpec extends Specification {\n \n     def rmNodes = new ConcurrentHashMap<NodeId, RMNode>()\n \n+\n     RMNode getRMNode(int cpu, int mem, String host, Protos.SlaveID slaveId) {\n         RMNode rmNode = MockNodes.newNodeInfo(0, Resources.createResource(mem, cpu), 0, host)\n         if (rmNodes[rmNode.getNodeID()]) {\n@@ -80,18 +82,17 @@ class FGSTestBaseSpec extends Specification {\n \n     SchedulerNode getSchedulerNode(RMNode rmNode) {\n         SchedulerNode schedulerNode = new SchedulerNode(rmNode, false) {\n-\n             @Override\n             void reserveResource(SchedulerApplicationAttempt attempt, Priority priority, RMContainer container) {\n             }\n-\n             @Override\n             void unreserveResource(SchedulerApplicationAttempt attempt) {\n             }\n         }\n         return schedulerNode\n     }\n \n+\n     /******************* RMContext Related ****************/\n \n     def publisher = Mock(SystemMetricsPublisher) {}\n@@ -143,6 +144,8 @@ class FGSTestBaseSpec extends Specification {\n \n     AbstractYarnScheduler yarnScheduler = Mock(AbstractYarnScheduler) {\n         getRMContainer(_ as ContainerId) >> { ContainerId cid -> fgsContainers.get(cid).rmContainer }\n+        getSchedulerNode(_ as NodeId) >> { NodeId nodeId -> getSchedulerNode(rmNodes.get(nodeId)) }\n+        updateNodeResource(_ as RMNode, _ as ResourceOption) >> { }\n     }\n \n     FGSContainer getFGSContainer(RMNode node, int cid, int cpu, int mem, ContainerState state) {"
            },
            {
                "sha": "5d59c68eaa9c7cb111123cf9b9e7ff7e7fdd1659",
                "filename": "myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManagerSpec.groovy",
                "status": "modified",
                "additions": 3,
                "deletions": 2,
                "changes": 5,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManagerSpec.groovy",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/4bce035ec8feff66f4804cc121c3051f5ecff4fa/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManagerSpec.groovy",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/test/java/org/apache/myriad/scheduler/fgs/YarnNodeCapacityManagerSpec.groovy?ref=4bce035ec8feff66f4804cc121c3051f5ecff4fa",
                "patch": "@@ -19,6 +19,8 @@\n package org.apache.myriad.scheduler.fgs\n \n import org.apache.hadoop.yarn.api.records.ContainerState\n+import org.apache.hadoop.yarn.api.records.ResourceOption\n+import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNode\n import org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeResourceUpdateSchedulerEvent\n import org.apache.hadoop.yarn.util.resource.Resources\n import org.apache.mesos.Protos\n@@ -115,7 +117,7 @@ class YarnNodeCapacityManagerSpec extends FGSTestBaseSpec {\n         then:\n         zeroNM.getTotalCapability().getMemory() == 2048\n         zeroNM.getTotalCapability().getVirtualCores() == 2\n-        1 * rmContext.getDispatcher().getEventHandler().handle(_ as NodeResourceUpdateSchedulerEvent)\n+        1 * yarnScheduler.updateNodeResource( _ as RMNode, _ as ResourceOption)\n     }\n \n     YarnNodeCapacityManager getYarnNodeCapacityManager() {\n@@ -137,6 +139,5 @@ class YarnNodeCapacityManagerSpec extends FGSTestBaseSpec {\n         def taskUtils = new TaskUtils(cfg)\n         return new YarnNodeCapacityManager(registry, yarnScheduler, rmContext,\n                 myriadDriver, offerLifecycleManager, nodeStore, state, taskUtils)\n-\n     }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-myriad/commit/fceaf73013a38ba9e43e7f4ef1a258fbb96f09f1",
        "repo": "incubator-myriad",
        "parent": "https://github.com/apache/incubator-myriad/commit/981c4d24d8838d82deb4d82c8e38814f14fec877",
        "message": "This commit address Myriad-135, it is possible an offer may not conta\u2026 \u2026in a particular resource type, in which case an NPE occured.\n\nIn reviewing the code it was also discovered Myriad was only taking the first resource type offered instead of all resources of a type offered.  This meant if Myriad was running with role \"Hadoop\" and got an offer with cpu(Hadoop): 2 and cpu(*): 1, it would ignore the 1 cpu it could've taken from the * role.\n\nThis closes: #3\nReview: https://github.com/apache/incubator-myriad/pull/3",
        "bug_id": "incubator-myriad_2",
        "file": [
            {
                "sha": "1ca9ec0b6467c3cba7bde6b6e5d2179bc01d5a2b",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "status": "modified",
                "additions": 31,
                "deletions": 18,
                "changes": 49,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/fceaf73013a38ba9e43e7f4ef1a258fbb96f09f1/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/fceaf73013a38ba9e43e7f4ef1a258fbb96f09f1/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java?ref=fceaf73013a38ba9e43e7f4ef1a258fbb96f09f1",
                "patch": "@@ -64,6 +64,12 @@\n \n   private static final Lock driverOperationLock = new ReentrantLock();\n \n+  private static final String RESOURCES_CPU_KEY = \"cpus\";\n+  private static final String RESOURCES_MEM_KEY = \"mem\";\n+  private static final String RESOURCES_PORTS_KEY = \"ports\";\n+  private static final String RESOURCES_DISK_KEY = \"disk\";\n+\n+\n   @Inject\n   private SchedulerState schedulerState;\n \n@@ -155,7 +161,7 @@ public void onEvent(ResourceOffersEvent event, long sequence,\n         if (SchedulerUtils.isEligibleForFineGrainedScaling(offer.getHostname(), schedulerState)) {\n           if (LOGGER.isDebugEnabled()) {\n             LOGGER.debug(\"Picking an offer from slave with hostname {} for fine grained scaling.\",\n-                offer.getHostname());\n+                    offer.getHostname());\n           }\n           offerLifecycleMgr.addOffers(offer);\n         } else {\n@@ -175,22 +181,27 @@ private boolean matches(Offer offer, NodeTask taskToLaunch, Constraint constrain\n       return false;\n     }\n     Map<String, Object> results = new HashMap<String, Object>(5);\n+    //Assign default values to avoid NPE\n+    results.put(RESOURCES_CPU_KEY, Double.valueOf(0.0));\n+    results.put(RESOURCES_MEM_KEY, Double.valueOf(0.0));\n+    results.put(RESOURCES_DISK_KEY, Double.valueOf(0.0));\n+    results.put(RESOURCES_PORTS_KEY, Integer.valueOf(0));\n \n     for (Resource resource : offer.getResourcesList()) {\n       if (resourceEvaluators.containsKey(resource.getName())) {\n         resourceEvaluators.get(resource.getName()).eval(resource, results);\n       } else {\n         LOGGER.warn(\"Ignoring unknown resource type: {}\",\n-            resource.getName());\n+                resource.getName());\n       }\n     }\n-    double cpus = (Double) results.get(\"cpus\");\n-    double mem = (Double) results.get(\"mem\");\n-    int ports = (Integer) results.get(\"ports\");\n+    double cpus = (Double) results.get(RESOURCES_CPU_KEY);\n+    double mem = (Double) results.get(RESOURCES_MEM_KEY);\n+    int ports = (Integer) results.get(RESOURCES_PORTS_KEY);\n \n-    checkResource(cpus < 0, \"cpus\");\n-    checkResource(mem < 0, \"mem\");\n-    checkResource(ports < 0, \"port\");\n+    checkResource(cpus <= 0, RESOURCES_CPU_KEY);\n+    checkResource(mem <= 0, RESOURCES_MEM_KEY);\n+    checkResource(ports <= 0, RESOURCES_PORTS_KEY);\n \n     return checkAggregates(offer, taskToLaunch, ports, cpus, mem);\n   }\n@@ -243,7 +254,7 @@ private static Double scalarToDouble(Resource resource, String id) {\n       value = new Double(resource.getScalar().getValue());\n     } else {\n       LOGGER.error(id + \" resource was not a scalar: {}\", resource\n-          .getType().toString());\n+              .getType().toString());\n     }\n     return value;\n   }\n@@ -256,21 +267,23 @@ private static Double scalarToDouble(Resource resource, String id) {\n \n   static {\n     resourceEvaluators = new HashMap<String, EvalResources>(4);\n-    resourceEvaluators.put(\"cpus\", new EvalResources() {\n+    resourceEvaluators.put(RESOURCES_CPU_KEY, new EvalResources() {\n       public void eval(Resource resource, Map<String, Object> results) {\n-        results.put(\"cpus\", scalarToDouble(resource, \"cpus\"));\n+        results.put(RESOURCES_CPU_KEY, (Double) results.get(RESOURCES_CPU_KEY) +\n+                scalarToDouble(resource, RESOURCES_CPU_KEY));\n       }\n     });\n-    resourceEvaluators.put(\"mem\", new EvalResources() {\n+    resourceEvaluators.put(RESOURCES_MEM_KEY, new EvalResources() {\n       public void eval(Resource resource, Map<String, Object> results) {\n-        results.put(\"mem\", scalarToDouble(resource, \"mem\"));\n+        results.put(RESOURCES_MEM_KEY, (Double) results.get(RESOURCES_MEM_KEY) +\n+                scalarToDouble(resource, RESOURCES_MEM_KEY));\n       }\n     });\n-    resourceEvaluators.put(\"disk\", new EvalResources() {\n+    resourceEvaluators.put(RESOURCES_DISK_KEY, new EvalResources() {\n       public void eval(Resource resource, Map<String, Object> results) {\n       }\n     });\n-    resourceEvaluators.put(\"ports\", new EvalResources() {\n+    resourceEvaluators.put(RESOURCES_PORTS_KEY, new EvalResources() {\n       public void eval(Resource resource, Map<String, Object> results) {\n         int ports = 0;\n         if (resource.getType().equals(Value.Type.RANGES)) {\n@@ -280,13 +293,13 @@ public void eval(Resource resource, Map<String, Object> results) {\n               ports += range.getEnd() - range.getBegin() + 1;\n             }\n           }\n-\n         } else {\n           LOGGER.error(\"ports resource was not Ranges: {}\", resource\n-              .getType().toString());\n+                  .getType().toString());\n \n         }\n-        results.put(\"ports\", Integer.valueOf(ports));\n+        results.put(RESOURCES_PORTS_KEY, (Integer) results.get(RESOURCES_PORTS_KEY) +\n+                Integer.valueOf(ports));\n       }\n     });\n   }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-myriad/commit/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
        "repo": "incubator-myriad",
        "parent": "https://github.com/apache/incubator-myriad/commit/23e01ecd2106b48a3c0db87201aba81cfd61dd29",
        "message": "Additional changes for getting Myriad HA to work\n\n* Myriad Executor + NM (merged) now sends TASK_RUNNING and TASK_FINISHED messages to mesos for Mesos tasks\n  corresponding to yarn containers. This is independent of the RM.\n* Entire ExecutorInfo object for NM tasks is being preserved and recovered from the state store.\n  This is being done because mesos requires all tasks run on the same executor to have the same executor info\n  objects. The Myriad Executor + NM (merged) also runs tasks corresponding to yarn containers. These tasks also\n  need to be provided the same ExecutorInfo object. This ExecutorInfo object cannot be obtained across an RM restart\n  without being preserved into the state store. Made code changes to store ExecutorInfo into the scheduler state and\n  serialize and deserialize it to the state store.\n* Made sure that the RM's view of NM capacity is updated correctly after an RM restart. RM's view is not regenerated\n  atomically, so assumptions about data being available are not always true. Fixed a few NullPointerExceptions here.\n\nTesting done\n\n* Run a job with one node using Course Grain Scaling(CGS) and one flexed up node using Fine Grained Scaling(FGS).\n  On completion of the job kill RM. RM launches on another node. Delete output directory of first job and execute\n  same job again.\n  THis tests\n  1. That the RM successfully recovers the list of NM Tasks that it has launched before restart.\n  2. The executorInfo is stored and retrieved from the state store.\n\n* Run a long running job. Kill the RM while the job is running. RM launches on another node and the job continues\n  progress.\n  1. That the RM successfully recovers the list of NM Tasks that it has launched before restart.\n  2. The executorInfo is stored and retrieved from the state store.\n  3. RM recovers and job makes forward progress.",
        "bug_id": "incubator-myriad_3",
        "file": [
            {
                "sha": "a6d126a95ea1636853b7bb0908b49a5ea549da7e",
                "filename": "myriad-executor/src/main/java/com/ebay/myriad/executor/MyriadExecutorAuxService.java",
                "status": "modified",
                "additions": 27,
                "deletions": 1,
                "changes": 28,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-executor/src/main/java/com/ebay/myriad/executor/MyriadExecutorAuxService.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-executor/src/main/java/com/ebay/myriad/executor/MyriadExecutorAuxService.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-executor/src/main/java/com/ebay/myriad/executor/MyriadExecutorAuxService.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -20,12 +20,17 @@\n \n import java.nio.ByteBuffer;\n \n+import org.apache.hadoop.yarn.api.records.ContainerId;\n import org.apache.hadoop.yarn.server.api.ApplicationInitializationContext;\n import org.apache.hadoop.yarn.server.api.ApplicationTerminationContext;\n import org.apache.hadoop.yarn.server.api.AuxiliaryService;\n+import org.apache.hadoop.yarn.server.api.ContainerTerminationContext;\n \n import org.apache.mesos.MesosExecutorDriver;\n import org.apache.mesos.Protos.Status;\n+import org.apache.mesos.Protos.TaskState;\n+import org.apache.mesos.Protos.TaskStatus;\n+import org.apache.mesos.Protos;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -37,6 +42,9 @@\n \n   private static final Logger LOGGER = LoggerFactory.getLogger(MyriadExecutor.class);\n   private static final String SERVICE_NAME = \"myriad_service\";\n+  public static final String YARN_CONTAINER_TASK_ID_PREFIX = \"yarn_\";\n+\n+  private MesosExecutorDriver driver;\n \n   protected MyriadExecutorAuxService() {\n     super(SERVICE_NAME);\n@@ -48,7 +56,7 @@ protected void serviceStart() throws Exception {\n \n     new Thread(new Runnable() {\n       public void run() {\n-        MesosExecutorDriver driver = new MesosExecutorDriver(new MyriadExecutor());\n+        driver = new MesosExecutorDriver(new MyriadExecutor());\n         LOGGER.error(\"MyriadExecutor exit with status \" +\n         Integer.toString(driver.run() == Status.DRIVER_STOPPED ? 0 : 1));\n       }\n@@ -72,4 +80,22 @@ public ByteBuffer getMetaData() {\n     return null;\n   }\n \n+  @Override\n+  public void stopContainer(ContainerTerminationContext stopContainerContext) {\n+    sendStatus(stopContainerContext.getContainerId(), TaskState.TASK_FINISHED);\n+  }\n+\n+  private void sendStatus(ContainerId containerId, TaskState taskState) {\n+    Protos.TaskID taskId = Protos.TaskID.newBuilder()\n+      .setValue(YARN_CONTAINER_TASK_ID_PREFIX + containerId.toString())\n+      .build();\n+\n+    TaskStatus status = TaskStatus.newBuilder()\n+      .setTaskId(taskId)\n+      .setState(taskState)\n+      .build();\n+    driver.sendStatusUpdate(status);\n+    LOGGER.debug(\"Sent status \" + taskState + \" for taskId \" + taskId);\n+  }\n+\n }"
            },
            {
                "sha": "915bd2f8099cfc2f66b475d04979143e1f91c4e4",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/event/handlers/ResourceOffersEventHandler.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -94,6 +94,7 @@ public void onEvent(ResourceOffersEvent event, long sequence,\n                 schedulerState.getActiveTasks())) {\n               TaskInfo task = taskFactory.createTask(offer, pendingTaskId,\n                   taskToLaunch);\n+\n               List<OfferID> offerIds = new ArrayList<>();\n               offerIds.add(offer.getId());\n               List<TaskInfo> tasks = new ArrayList<>();\n@@ -104,6 +105,15 @@ public void onEvent(ResourceOffersEvent event, long sequence,\n               driver.launchTasks(offerIds, tasks);\n               launchedTaskId = pendingTaskId;\n \n+              // TODO (sdaingade) For every NM Task that we launch, we currently\n+              // need to backup the ExecutorInfo for that NM Task in the State Store.\n+              // Without this, we will not be able to launch tasks corresponding to yarn\n+              // containers. This is specially important in case the RM restarts.\n+              if (task.hasExecutor() && taskToLaunch.getExecutorInfo() == null) {\n+                  taskToLaunch.setExecutorInfo(task.getExecutor());\n+                  schedulerState.updateStateStore();\n+              }\n+\n               taskToLaunch.setHostname(offer.getHostname());\n               taskToLaunch.setSlaveId(offer.getSlaveId());\n               offerMatch = true;"
            },
            {
                "sha": "47393a4c45247e8e8e41b9696336c07729eb368f",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/NMHeartBeatHandler.java",
                "status": "modified",
                "additions": 11,
                "deletions": 49,
                "changes": 60,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/NMHeartBeatHandler.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/NMHeartBeatHandler.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/NMHeartBeatHandler.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -1,23 +1,20 @@\n package com.ebay.myriad.scheduler.fgs;\n \n-import com.ebay.myriad.executor.ContainerTaskStatusRequest;\n import com.ebay.myriad.scheduler.MyriadDriver;\n import com.ebay.myriad.scheduler.SchedulerUtils;\n import com.ebay.myriad.scheduler.TaskFactory;\n import com.ebay.myriad.scheduler.yarn.interceptor.BaseInterceptor;\n import com.ebay.myriad.scheduler.yarn.interceptor.InterceptorRegistry;\n import com.ebay.myriad.state.SchedulerState;\n-import com.google.gson.Gson;\n-import java.nio.charset.Charset;\n import java.util.ArrayList;\n import java.util.List;\n import javax.inject.Inject;\n-import org.apache.hadoop.yarn.api.records.ContainerId;\n import org.apache.hadoop.yarn.api.records.ContainerState;\n import org.apache.hadoop.yarn.api.records.ContainerStatus;\n import org.apache.hadoop.yarn.api.records.NodeId;\n import org.apache.hadoop.yarn.api.records.Resource;\n import org.apache.hadoop.yarn.server.resourcemanager.RMContext;\n+import org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainer;\n import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNode;\n import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEvent;\n import org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent;\n@@ -118,8 +115,10 @@ private void handleStatusUpdate(RMNodeEvent event, RMContext context) {\n     RMNode rmNode = context.getRMNodes().get(event.getNodeId());\n     String hostName = rmNode.getNodeID().getHost();\n \n-    nodeStore.getNode(hostName).snapshotRunningContainers();\n-    sendStatusUpdatesToMesosForCompletedContainers(statusEvent);\n+    Node host = nodeStore.getNode(hostName);\n+    if (host != null) {\n+      host.snapshotRunningContainers();\n+    }\n \n     // New capacity of the node =\n     // resources under use on the node (due to previous offers) +\n@@ -155,54 +154,17 @@ private Resource getResourcesUnderUse(RMNodeStatusEvent statusEvent) {\n     Resource usedResources = Resource.newInstance(0, 0);\n     for (ContainerStatus status : statusEvent.getContainers()) {\n       if (status.getState() == ContainerState.NEW || status.getState() == ContainerState.RUNNING) {\n-        Resources.addTo(usedResources, yarnScheduler.getRMContainer(status.getContainerId()).getAllocatedResource());\n+        RMContainer rmContainer = yarnScheduler.getRMContainer(status.getContainerId());\n+        // (sdaingade) This check is needed as RMContainer information may not be populated\n+        // immediately after a RM restart.\n+        if (rmContainer != null) {\n+          Resources.addTo(usedResources, rmContainer.getAllocatedResource());\n+        }\n       }\n     }\n     return usedResources;\n   }\n \n-  private void sendStatusUpdatesToMesosForCompletedContainers(RMNodeStatusEvent statusEvent) {\n-    // Send task update to Mesos\n-    Protos.SlaveID slaveId = nodeStore.getNode(statusEvent.getNodeId().getHost()).getSlaveId();\n-    for (ContainerStatus status : statusEvent.getContainers()) {\n-      ContainerId containerId = status.getContainerId();\n-      if (status.getState() == ContainerState.COMPLETE) {\n-        requestExecutorToSendTaskStatusUpdate(slaveId, containerId, Protos.TaskState.TASK_FINISHED);\n-      } else { // state == NEW | RUNNING\n-        requestExecutorToSendTaskStatusUpdate(slaveId, containerId, Protos.TaskState.TASK_RUNNING);\n-      }\n-    }\n-  }\n-\n-\n-  /**\n-   * sends a request to executor on the given slave to send back a status update\n-   * for the mesos task launched for this container.\n-   *\n-   * TODO(Santosh):\n-   *  Framework messages are unreliable. Try a NM auxiliary service that can help\n-   *  send out the status messages from NM itself. NM and MyriadExecutor would need\n-   *  to be merged into a single process.\n-   *\n-   * @param slaveId\n-   * @param containerId\n-   * @param taskState\n-   */\n-  private void requestExecutorToSendTaskStatusUpdate(Protos.SlaveID slaveId,\n-      ContainerId containerId,\n-      Protos.TaskState taskState) {\n-    final String mesosTaskId = ContainerTaskStatusRequest.YARN_CONTAINER_TASK_ID_PREFIX + containerId.toString();\n-    if (LOGGER.isDebugEnabled()) {\n-      LOGGER.debug(\"Sending out framework message requesting the executor to send {} status for task: {}\",\n-          taskState.name(), mesosTaskId);\n-    }\n-    ContainerTaskStatusRequest containerTaskStatusRequest = new ContainerTaskStatusRequest();\n-    containerTaskStatusRequest.setMesosTaskId(mesosTaskId);\n-    containerTaskStatusRequest.setState(taskState.name());\n-    myriadDriver.getDriver().sendFrameworkMessage(getExecutorId(slaveId), slaveId,\n-        new Gson().toJson(containerTaskStatusRequest).getBytes(Charset.defaultCharset()));\n-  }\n-\n   private Protos.ExecutorID getExecutorId(Protos.SlaveID slaveId) {\n     return Protos.ExecutorID.newBuilder().setValue(\n         TaskFactory.NMTaskFactoryImpl.EXECUTOR_PREFIX + slaveId.getValue()).build();"
            },
            {
                "sha": "12bbe736c95192f5c1f56685ba332f97057158bd",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "status": "modified",
                "additions": 5,
                "deletions": 2,
                "changes": 7,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/YarnNodeCapacityManager.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/scheduler/fgs/YarnNodeCapacityManager.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -12,6 +12,7 @@\n import java.util.HashSet;\n import java.util.List;\n import java.util.Set;\n+\n import javax.inject.Inject;\n import org.apache.hadoop.yarn.api.records.Container;\n import org.apache.hadoop.yarn.api.records.NodeId;\n@@ -196,7 +197,7 @@ private void handleContainerAllocation(RMNode rmNode) {\n   public void setNodeCapacity(RMNode rmNode, Resource newCapacity) {\n     rmNode.getTotalCapability().setMemory(newCapacity.getMemory());\n     rmNode.getTotalCapability().setVirtualCores(newCapacity.getVirtualCores());\n-\n+    LOGGER.info(\"Setting capacity for node {} to {}\", rmNode.getHostName(), newCapacity);\n     // updates the scheduler with the new capacity for the NM.\n     // the event is handled by the scheduler asynchronously\n     rmContext.getDispatcher().getEventHandler().handle(\n@@ -213,10 +214,12 @@ public void setNodeCapacity(RMNode rmNode, Resource newCapacity) {\n         Protos.TaskID taskId = Protos.TaskID.newBuilder()\n             .setValue(ContainerTaskStatusRequest.YARN_CONTAINER_TASK_ID_PREFIX + container.getId().toString()).build();\n \n+        // TODO (sdaingade) Remove ExecutorInfo from the Node object\n+        // as this is now cached in the NodeTask object in scheduler state.\n         Protos.ExecutorInfo executorInfo = node.getExecInfo();\n         if (executorInfo == null) {\n             executorInfo = Protos.ExecutorInfo.newBuilder(\n-                taskFactory.getExecutorInfoForSlave(offer.getSlaveId(), null))\n+                 state.getNodeTask(offer.getSlaveId()).getExecutorInfo())\n                 .setFrameworkId(offer.getFrameworkId()).build();\n             node.setExecInfo(executorInfo);\n         }"
            },
            {
                "sha": "8191eed6956394a931d16f8fe531be665d97094b",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/state/NodeTask.java",
                "status": "modified",
                "additions": 13,
                "deletions": 0,
                "changes": 13,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/NodeTask.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/NodeTask.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/state/NodeTask.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -32,6 +32,11 @@\n     @JsonProperty\n     private Protos.TaskStatus taskStatus;\n \n+    /**\n+     * Mesos executor for this node.\n+     */\n+    private Protos.ExecutorInfo executorInfo;\n+\n     public NodeTask(NMProfile profile) {\n         this.profile = profile;\n         this.hostname = \"\";\n@@ -68,4 +73,12 @@ public void setHostname(String hostname) {\n     public void setTaskStatus(Protos.TaskStatus taskStatus) {\n         this.taskStatus = taskStatus;\n     }\n+\n+    public Protos.ExecutorInfo getExecutorInfo() {\n+        return executorInfo;\n+    }\n+\n+    public void setExecutorInfo(Protos.ExecutorInfo executorInfo) {\n+        this.executorInfo = executorInfo;\n+    }\n }"
            },
            {
                "sha": "e27e976cf339e8843bbae67d99b77832d47ee4e0",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/state/SchedulerState.java",
                "status": "modified",
                "additions": 13,
                "deletions": 1,
                "changes": 14,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/SchedulerState.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/SchedulerState.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/state/SchedulerState.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -31,6 +31,8 @@\n import org.slf4j.LoggerFactory;\n \n import org.apache.mesos.Protos;\n+import org.apache.mesos.Protos.SlaveID;\n+\n import com.ebay.myriad.state.utils.StoreContext;\n import org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore;\n \n@@ -188,6 +190,16 @@ public void removeTask(Protos.TaskID taskId) {\n         return activeNodeTasks;\n     }\n \n+    public NodeTask getNodeTask(SlaveID slaveId) {\n+        for (Map.Entry<Protos.TaskID, NodeTask> entry : tasks.entrySet()) {\n+            if (entry.getValue().getSlaveId() != null &&\n+                entry.getValue().getSlaveId().equals(slaveId)) {\n+                return entry.getValue(); \n+            }\n+        }\n+        return null;\n+    }\n+\n     public Set<Protos.TaskID> getStagingTaskIds() {\n         return this.stagingTasks;\n     }\n@@ -226,7 +238,7 @@ public void setFrameworkId(Protos.FrameworkID newFrameworkId) {\n         updateStateStore();\n     }\n \n-    private void updateStateStore() {\n+    public void updateStateStore() {\n         if (!isMyriadStateStore()) {\n             return;\n         }"
            },
            {
                "sha": "3d8d57e2c3c804a93ab35b728660571bd01c3978",
                "filename": "myriad-scheduler/src/main/java/com/ebay/myriad/state/utils/ByteBufferSupport.java",
                "status": "modified",
                "additions": 30,
                "deletions": 0,
                "changes": 30,
                "blob_url": "https://github.com/apache/incubator-myriad/blob/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/utils/ByteBufferSupport.java",
                "raw_url": "https://github.com/apache/incubator-myriad/raw/0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a/myriad-scheduler/src/main/java/com/ebay/myriad/state/utils/ByteBufferSupport.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-myriad/contents/myriad-scheduler/src/main/java/com/ebay/myriad/state/utils/ByteBufferSupport.java?ref=0fa49c26bc0492ef4b69a85c219eab53f1cc7f0a",
                "patch": "@@ -116,13 +116,20 @@ public static ByteBuffer toByteBuffer(NodeTask nt) {\n     } else {\n       size += INT_SIZE;\n     }\n+    \n+    if (nt.getExecutorInfo() != null) {\n+        size += nt.getExecutorInfo().getSerializedSize() + INT_SIZE;\n+    } else {\n+        size += INT_SIZE;\n+    }\n \n     // Allocate and populate the buffer.\n     ByteBuffer bb = createBuffer(size);\n     putBytes(bb, profile);\n     putBytes(bb, hostname);\n     putBytes(bb, getSlaveBytes(nt));\n     putBytes(bb, getTaskBytes(nt));\n+    putBytes(bb, getExecutorInfoBytes(nt));\n     // Make sure the buffer is at the beginning\n     bb.rewind();\n     return bb;\n@@ -170,6 +177,7 @@ public static NodeTask toNodeTask(ByteBuffer bb) {\n       nt.setHostname(toString(bb));\n       nt.setSlaveId(toSlaveId(bb));\n       nt.setTaskStatus(toTaskStatus(bb));\n+      nt.setExecutorInfo(toExecutorInfo(bb));\n     }\n     return nt;\n   }\n@@ -182,6 +190,14 @@ public static NodeTask toNodeTask(ByteBuffer bb) {\n     }\n   }\n \n+  public static byte[] getExecutorInfoBytes(NodeTask nt) {\n+    if (nt.getExecutorInfo() != null) {\n+      return nt.getExecutorInfo().toByteArray();\n+    } else {\n+      return ZERO_BYTES;\n+    }\n+  }\n+\n   public static byte[] getSlaveBytes(NodeTask nt) {\n     if (nt.getSlaveId() != null) {\n       return nt.getSlaveId().toByteArray();\n@@ -272,6 +288,20 @@ public static NMProfile getProfile(ByteBuffer bb) {\n     }\n   }\n \n+  public static Protos.ExecutorInfo toExecutorInfo(ByteBuffer bb) {\n+    int size = bb.getInt();\n+    if (size > 0) {\n+      try {\n+        return Protos.ExecutorInfo.parseFrom(getBytes(bb, size));\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"ByteBuffer not in expected format,\" +\n+          \" failed to parse ExecutorInfo bytes\", e);\n+      }\n+    } else {\n+      return null;\n+    }\n+  }\n+\n   public static ByteBuffer fillBuffer(byte src[]) {\n     ByteBuffer bb = createBuffer(src.length);\n     bb.put(src);"
            }
        ]
    }
]
