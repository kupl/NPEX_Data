[
    {
        "commit": "https://github.com/apache/ambari-metrics/commit/ed51d8fd7ca8493312a953a1b64b49c001cdcd87",
        "repo": "ambari-metrics",
        "parent": "https://github.com/apache/ambari-metrics/commit/19125fc40d4d3efcf35de07381bdd55988a2254b",
        "message": "AMBARI-16949 Metrics Collector API shows NPE if we use wildcard (%25 for '%') for metric name (Jungtaek Lim via avijayan)",
        "bug_id": "ambari-metrics_1",
        "file": [
            {
                "sha": "bbd6d839ef71ed47ace28f6fdec452d214d6e073",
                "filename": "ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/PhoenixHBaseAccessor.java",
                "status": "modified",
                "additions": 19,
                "deletions": 3,
                "changes": 22,
                "blob_url": "https://github.com/apache/ambari-metrics/blob/ed51d8fd7ca8493312a953a1b64b49c001cdcd87/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/PhoenixHBaseAccessor.java",
                "raw_url": "https://github.com/apache/ambari-metrics/raw/ed51d8fd7ca8493312a953a1b64b49c001cdcd87/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/PhoenixHBaseAccessor.java",
                "contents_url": "https://api.github.com/repos/apache/ambari-metrics/contents/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/PhoenixHBaseAccessor.java?ref=ed51d8fd7ca8493312a953a1b64b49c001cdcd87",
                "patch": "@@ -850,7 +850,7 @@ private void appendMetricFromResultSet(TimelineMetrics metrics, Condition condit\n                                          Map<String, List<Function>> metricFunctions,\n                                          ResultSet rs) throws SQLException, IOException {\n     String metricName = rs.getString(\"METRIC_NAME\");\n-    List<Function> functions = metricFunctions.get(metricName);\n+    List<Function> functions = findMetricFunctions(metricFunctions, metricName);\n \n     // Apply aggregation function if present\n     if ((functions != null && !functions.isEmpty())) {\n@@ -990,7 +990,7 @@ private void appendAggregateMetricFromResultSet(TimelineMetrics metrics,\n       ResultSet rs) throws SQLException {\n \n     String metricName = rs.getString(\"METRIC_NAME\");\n-    List<Function> functions = metricFunctions.get(metricName);\n+    List<Function> functions = findMetricFunctions(metricFunctions, metricName);\n \n     for (Function aggregateFunction : functions) {\n       SingleValuedTimelineMetric metric;\n@@ -1027,7 +1027,7 @@ private void getLatestAggregateMetricRecords(Condition condition,\n       try {\n         rs = stmt.executeQuery();\n         while (rs.next()) {\n-          List<Function> functions = metricFunctions.get(metricName);\n+          List<Function> functions = findMetricFunctions(metricFunctions, metricName);\n           if (functions != null) {\n             for (Function f : functions) {\n               SingleValuedTimelineMetric metric =\n@@ -1108,6 +1108,22 @@ private void validateConditionIsNotEmpty(Condition condition) {\n     }\n   }\n \n+  private List<Function> findMetricFunctions(Map<String, List<Function>> metricFunctions,\n+      String metricName) {\n+    if (metricFunctions.containsKey(metricName)) {\n+      return metricFunctions.get(metricName);\n+    }\n+\n+    for (Map.Entry<String, List<Function>> nameToFunctions : metricFunctions.entrySet()) {\n+      String metricRegEx = nameToFunctions.getKey().replace(\"%\", \".*\");\n+      if (metricName.matches(metricRegEx)) {\n+        return nameToFunctions.getValue();\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n   public void saveHostAggregateRecords(Map<TimelineMetric, MetricHostAggregate> hostAggregateMap,\n                                        String phoenixTableName) throws SQLException {\n "
            }
        ]
    },
    {
        "commit": "https://github.com/apache/ambari-metrics/commit/5cbb82bac7bc02b9befef4dbd1262471f8767bf9",
        "repo": "ambari-metrics",
        "parent": "https://github.com/apache/ambari-metrics/commit/9eb55338f20ab2c2e70ec9b5383ba332981c7728",
        "message": "Revert \"AMBARI-9468. Support secure HDFS with AMS in distributed mode service (rlevas)\"\nReverting since this is a suspect for causing NPE failure when trying to Add Service.\nThis reverts commit e36b23166e4a40b456ded2bc72a7d045ad019175.",
        "bug_id": "ambari-metrics_2",
        "file": [
            {
                "sha": "4ec13dab2ef0817a2f1db095317d4f7298afb46a",
                "filename": "ambari-metrics-timelineservice/conf/unix/ambari-metrics-collector",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/ambari-metrics/blob/5cbb82bac7bc02b9befef4dbd1262471f8767bf9/ambari-metrics-timelineservice/conf/unix/ambari-metrics-collector",
                "raw_url": "https://github.com/apache/ambari-metrics/raw/5cbb82bac7bc02b9befef4dbd1262471f8767bf9/ambari-metrics-timelineservice/conf/unix/ambari-metrics-collector",
                "contents_url": "https://api.github.com/repos/apache/ambari-metrics/contents/ambari-metrics-timelineservice/conf/unix/ambari-metrics-collector?ref=5cbb82bac7bc02b9befef4dbd1262471f8767bf9",
                "patch": "@@ -228,7 +228,7 @@ case \"$1\" in\n         rm -f \"${PIDFILE}\" >/dev/null 2>&1\n     fi\n \n-    nohup \"${JAVA}\" \"-cp\" \"/usr/lib/ambari-metrics-collector/*:${COLLECTOR_CONF_DIR}\" ${AMS_COLLECTOR_OPTS} \"-Djava.net.preferIPv4Stack=true\" \"-Dams.log.dir=${AMS_COLLECTOR_LOG_DIR}\" \"-Dproc_${DAEMON_NAME}\" \"${CLASS}\" \"$@\" > $OUTFILE 2>&1 &\n+    nohup \"${JAVA}\" \"-cp\" \"/usr/lib/ambari-metrics-collector/*:${COLLECTOR_CONF_DIR}\" \"-Djava.net.preferIPv4Stack=true\" \"-Dams.log.dir=${AMS_COLLECTOR_LOG_DIR}\" \"-Dproc_${DAEMON_NAME}\" \"${CLASS}\" \"$@\" > $OUTFILE 2>&1 &\n     PID=$!\n     write_pidfile \"${PIDFILE}\"\n     sleep 2"
            }
        ]
    }
]
