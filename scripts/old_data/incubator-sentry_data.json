[
    {
        "commit": "https://github.com/apache/incubator-sentry/commit/924f0b038f351c26b1df72e21ad7e5dedbdb525e",
        "repo": "incubator-sentry",
        "parent": "https://github.com/apache/incubator-sentry/commit/6465503be6a4268f7ff4a2d787ecf4a4ad174988",
        "message": "SENTRY-337: When the parameter sentry.metastore.service.users isn't set or set empty, starting metastore will throw java.lang.NullPointerException (Guoquan Shen via Sravya Tirukkovalur)",
        "bug_id": "incubator-sentry_1",
        "file": [
            {
                "sha": "3a83895bc000c416686abf6e99c8652bb4d56a5f",
                "filename": "sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "status": "modified",
                "additions": 1,
                "deletions": 1,
                "changes": 2,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/924f0b038f351c26b1df72e21ad7e5dedbdb525e/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/924f0b038f351c26b1df72e21ad7e5dedbdb525e/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/conf/HiveAuthzConf.java?ref=924f0b038f351c26b1df72e21ad7e5dedbdb525e",
                "patch": "@@ -63,7 +63,7 @@\n     AUTHZ_UDF_WHITELIST(\"sentry.hive.udf.whitelist\", HIVE_UDF_WHITE_LIST),\n     AUTHZ_ALLOW_HIVE_IMPERSONATION(\"sentry.hive.allow.hive.impersonation\", \"false\"),\n     AUTHZ_ONFAILURE_HOOKS(\"sentry.hive.failure.hooks\", \"\"),\n-    AUTHZ_METASTORE_SERVICE_USERS(\"sentry.metastore.service.users\", \"\"),\n+    AUTHZ_METASTORE_SERVICE_USERS(\"sentry.metastore.service.users\", null),\n     AUTHZ_SYNC_ALTER_WITH_POLICY_STORE(\"sentry.hive.sync.alter\", \"true\"),\n     AUTHZ_SYNC_CREATE_WITH_POLICY_STORE(\"sentry.hive.sync.create\", \"false\"),\n     AUTHZ_SYNC_DROP_WITH_POLICY_STORE(\"sentry.hive.sync.drop\", \"true\"),"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-sentry/commit/71b889ad90a31ce992f587799f6f190a4a89bb3a",
        "repo": "incubator-sentry",
        "parent": "https://github.com/apache/incubator-sentry/commit/2ad16d05577ccef77b509da75c77bf040ba9b234",
        "message": "SENTRY-573: Fix NPE caused when rename op is applied on authzObject with no explicit permissions",
        "bug_id": "incubator-sentry_2",
        "file": [
            {
                "sha": "c362115ce6757f6bf8b7c2372bf76579783252b6",
                "filename": "sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "status": "modified",
                "additions": 15,
                "deletions": 8,
                "changes": 23,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/UpdateableAuthzPermissions.java?ref=71b889ad90a31ce992f587799f6f190a4a89bb3a",
                "patch": "@@ -17,6 +17,7 @@\n  */\n package org.apache.sentry.hdfs;\n \n+import java.util.Collection;\n import java.util.HashMap;\n import java.util.LinkedList;\n import java.util.List;\n@@ -127,15 +128,21 @@ private void applyPrivilegeUpdates(PermissionsUpdate update) {\n         String newAuthzObj = pUpdate.getAddPrivileges().keySet().iterator().next();\n         String oldAuthzObj = pUpdate.getDelPrivileges().keySet().iterator().next();\n         PrivilegeInfo privilegeInfo = perms.getPrivilegeInfo(oldAuthzObj);\n-        Map<String, FsAction> allPermissions = privilegeInfo.getAllPermissions();\n-        perms.delPrivilegeInfo(oldAuthzObj);\n-        perms.removeParentChildMappings(oldAuthzObj);\n-        PrivilegeInfo newPrivilegeInfo = new PrivilegeInfo(newAuthzObj);\n-        for (Map.Entry<String, FsAction> e : allPermissions.entrySet()) {\n-          newPrivilegeInfo.setPermission(e.getKey(), e.getValue());\n+        // The privilegeInfo object can be null if no explicit Privileges\n+        // have been granted on the object. For eg. If grants have been applied on\n+        // Db, but no explicit grants on Table.. then the authzObject associated\n+        // with the table will never exist.\n+        if (privilegeInfo != null) {\n+          Map<String, FsAction> allPermissions = privilegeInfo.getAllPermissions();\n+          perms.delPrivilegeInfo(oldAuthzObj);\n+          perms.removeParentChildMappings(oldAuthzObj);\n+          PrivilegeInfo newPrivilegeInfo = new PrivilegeInfo(newAuthzObj);\n+          for (Map.Entry<String, FsAction> e : allPermissions.entrySet()) {\n+            newPrivilegeInfo.setPermission(e.getKey(), e.getValue());\n+          }\n+          perms.addPrivilegeInfo(newPrivilegeInfo);\n+          perms.addParentChildMappings(newAuthzObj);\n         }\n-        perms.addPrivilegeInfo(newPrivilegeInfo);\n-        perms.addParentChildMappings(newAuthzObj);\n         return;\n       }\n       if (pUpdate.getAuthzObj().equals(PermissionsUpdate.ALL_AUTHZ_OBJ)) {"
            },
            {
                "sha": "ae7a9a210eeff33b10ab6abd6fd8732c6d5275ba",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "status": "modified",
                "additions": 10,
                "deletions": 0,
                "changes": 10,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/71b889ad90a31ce992f587799f6f190a4a89bb3a/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java?ref=71b889ad90a31ce992f587799f6f190a4a89bb3a",
                "patch": "@@ -655,6 +655,16 @@ public Void run() throws Exception {\n     verifyOnPath(\"/user/hive/warehouse\", FsAction.ALL, \"hbase\", true);\n     verifyOnAllSubDirs(\"/user/hive/warehouse/db1.db\", null, \"hbase\", false);\n \n+    // Verify table rename works\n+    stmt.execute(\"create table q1 (s string)\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q1\", FsAction.ALL, \"hbase\", true);\n+    stmt.execute(\"alter table q1 rename to q2\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q2\", FsAction.ALL, \"hbase\", true);\n+\n+    stmt.execute(\"create table q3 (s string)\");\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q3\", FsAction.ALL, \"hbase\", true);\n+    verifyOnAllSubDirs(\"/user/hive/warehouse/q2\", FsAction.ALL, \"hbase\", true);\n+\n     // Verify db privileges are propagated to tables\n     stmt.execute(\"grant select on database db1 to role p1_admin\");\n     verifyOnAllSubDirs(\"/user/hive/warehouse/db1.db/tbl1\", FsAction.READ_EXECUTE, \"hbase\", true);"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-sentry/commit/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465",
        "repo": "incubator-sentry",
        "parent": "https://github.com/apache/incubator-sentry/commit/3d3f96ca7939e687944f1426419db673f8797f3e",
        "message": "SENTRY-556: Remove NPE logging when Sentry Service is not reachable (Reviewed by: Lenni Kuff)",
        "bug_id": "incubator-sentry_3",
        "file": [
            {
                "sha": "c0889f2851b159afe8482ed3ee5485cdf4ab9e3e",
                "filename": "sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "status": "modified",
                "additions": 38,
                "deletions": 25,
                "changes": 63,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/c5cc86a802ba5e17e78df9ee7671ca42bb1fe465/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-hdfs/sentry-hdfs-namenode-plugin/src/main/java/org/apache/sentry/hdfs/SentryAuthorizationInfo.java?ref=c5cc86a802ba5e17e78df9ee7671ca42bb1fe465",
                "patch": "@@ -100,30 +100,34 @@ UpdateableAuthzPermissions getAuthzPermissions() {\n     return authzPermissions;\n   }\n \n-  private void update() {\n+  private boolean update() {\n     SentryAuthzUpdate updates = updater.getUpdates();\n-    UpdateableAuthzPaths newAuthzPaths = processUpdates(\n-        updates.getPathUpdates(), authzPaths);\n-    UpdateableAuthzPermissions newAuthzPerms = processUpdates(\n-        updates.getPermUpdates(), authzPermissions);\n-    // If there were any FULL updates the returned instance would be\n-    // different\n-    if ((newAuthzPaths != authzPaths)||(newAuthzPerms != authzPermissions)) {\n-      lock.writeLock().lock();\n-      try {\n-        authzPaths = newAuthzPaths;\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"FULL Updated paths seq Num [\" + authzPaths.getLastUpdatedSeqNum() + \"]\");\n-        }\n-        authzPermissions = newAuthzPerms;\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"FULL Updated perms seq Num [\" + authzPermissions.getLastUpdatedSeqNum() + \"]\");\n+    // Updates can be null if Sentry Service is un-reachable\n+    if (updates != null) {\n+      UpdateableAuthzPaths newAuthzPaths = processUpdates(\n+          updates.getPathUpdates(), authzPaths);\n+      UpdateableAuthzPermissions newAuthzPerms = processUpdates(\n+          updates.getPermUpdates(), authzPermissions);\n+      // If there were any FULL updates the returned instance would be\n+      // different\n+      if ((newAuthzPaths != authzPaths)||(newAuthzPerms != authzPermissions)) {\n+        lock.writeLock().lock();\n+        try {\n+          authzPaths = newAuthzPaths;\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"FULL Updated paths seq Num [\" + authzPaths.getLastUpdatedSeqNum() + \"]\");\n+          }\n+          authzPermissions = newAuthzPerms;\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"FULL Updated perms seq Num [\" + authzPermissions.getLastUpdatedSeqNum() + \"]\");\n+          }\n+        } finally {\n+          lock.writeLock().unlock();\n         }\n-      } finally {\n-        lock.writeLock().unlock();\n       }\n+      return true;\n     }\n-\n+    return false;\n   }\n \n   private <K extends Update, V extends Updateable<K>> V processUpdates(List<K> updates,\n@@ -143,6 +147,7 @@ private void update() {\n   }\n \n   public void run() {\n+    boolean success = false;\n     try {\n       // In case of previous preUpdate failure, we sleep for a retry wait \n       // interval we can do this because we are using a singledthreadedexecutor\n@@ -151,24 +156,32 @@ public void run() {\n       if (waitUntil > currTime) {\n         Thread.sleep(waitUntil - currTime);\n       }\n-      update();\n-      // we reset lastUpdate only on successful pulling\n-      lastUpdate = System.currentTimeMillis();\n-      waitUntil = lastUpdate;\n+      success = update();\n     } catch (Exception ex) {\n+      success = false;\n       LOG.warn(\"Failed to update, will retry in [{}]ms, error: \", \n           new Object[]{ retryWaitMillisec, ex.getMessage(), ex});\n+    }\n+    if (success) {\n+      // we reset lastUpdate only on successful pulling\n+      lastUpdate = System.currentTimeMillis();\n+      waitUntil = lastUpdate;\n+    } else {\n       waitUntil = System.currentTimeMillis() + retryWaitMillisec;\n     }\n   }\n \n   public void start() {\n     if (authzPaths != null) {\n+      boolean success = false;\n       try {\n-        update();\n+        success = update();\n       } catch (Exception ex) {\n+        success = false;\n         LOG.warn(\"Failed to do initial update, will retry in [{}]ms, error: \",\n             new Object[]{retryWaitMillisec, ex.getMessage(), ex});\n+      }\n+      if (!success) {\n         waitUntil = System.currentTimeMillis() + retryWaitMillisec;\n       }\n       executor = Executors.newSingleThreadScheduledExecutor("
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-sentry/commit/1e5826f85601319a2ef9c4bdab999ff1db697668",
        "repo": "incubator-sentry",
        "parent": "https://github.com/apache/incubator-sentry/commit/fa5f81c7734f8af8e1bdc669d6cbe2e5951e2bac",
        "message": "SENTRY-423: Hive command \"SHOW TABLE EXTENDED LIKE... \" failed with NPE (Chaoyu Tang via Prasad Mujumdar)",
        "bug_id": "incubator-sentry_4",
        "file": [
            {
                "sha": "0546e6a68eb67aabfc8e3974a67deb4a5a64bf94",
                "filename": "sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "status": "modified",
                "additions": 14,
                "deletions": 1,
                "changes": 15,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-binding/sentry-binding-hive/src/main/java/org/apache/sentry/binding/hive/HiveAuthzBindingHook.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668",
                "patch": "@@ -151,7 +151,6 @@ public ASTNode preAnalyze(HiveSemanticAnalyzerHookContext context, ASTNode ast)\n         break;\n       case HiveParser.TOK_DROPTABLE:\n       case HiveParser.TOK_DROPVIEW:\n-      case HiveParser.TOK_SHOW_TABLESTATUS:\n       case HiveParser.TOK_SHOW_CREATETABLE:\n       case HiveParser.TOK_ALTERTABLE_SERIALIZER:\n       case HiveParser.TOK_ALTERVIEW_ADDPARTS:\n@@ -166,6 +165,20 @@ public ASTNode preAnalyze(HiveSemanticAnalyzerHookContext context, ASTNode ast)\n       case HiveParser.TOK_ALTERINDEX_REBUILD:\n         currTab = extractTable((ASTNode)ast.getChild(0)); //type is not TOK_TABNAME\n         currDB = extractDatabase((ASTNode) ast.getChild(0));\n+      case HiveParser.TOK_SHOW_TABLESTATUS:\n+        currDB = extractDatabase((ASTNode)ast.getChild(0));\n+        int children = ast.getChildCount();\n+        for (int i = 1; i < children; i++) {\n+          ASTNode child = (ASTNode) ast.getChild(i);\n+          if (child.getToken().getType() == HiveParser.Identifier) {\n+            currDB = new Database(child.getText());\n+            break;\n+          }\n+        }\n+        //loosing the requested privileges for possible wildcard tables, since\n+        //further authorization will be done at the filter step and those unwanted will\n+        //eventually be filtered out from the output\n+        currTab = Table.ALL;\n         break;\n       case HiveParser.TOK_ALTERTABLE_RENAME:\n       case HiveParser.TOK_ALTERTABLE_PROPERTIES:"
            },
            {
                "sha": "89d7b2ac84fbd152ef22c5ce0a46af8c2a752ab8",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "status": "modified",
                "additions": 7,
                "deletions": 0,
                "changes": 7,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestOperations.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668",
                "patch": "@@ -326,6 +326,7 @@ public void testSelectAndInsertOnTable() throws Exception {\n   6. Describe tb1 : HiveOperation.DESCTABLE5.\n   7. HiveOperation.SHOWPARTITIONS\n   8. TODO: show functions?\n+  9. HiveOperation.SHOW_TABLESTATUS\n    */\n   @Test\n   public void testSelectOnTable() throws Exception {\n@@ -347,6 +348,7 @@ public void testSelectOnTable() throws Exception {\n     statement.executeQuery(\"SHOW indexes on tb1\");\n     statement.executeQuery(\"SHOW COLUMNS from tb1\");\n     statement.executeQuery(\"SHOW functions '.*'\");\n+    statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n \n     statement.executeQuery(\"DESCRIBE tb1\");\n     statement.executeQuery(\"DESCRIBE tb1 PARTITION (b=1)\");\n@@ -355,6 +357,7 @@ public void testSelectOnTable() throws Exception {\n     connection.close();\n \n     //Negative case\n+    adminCreate(DB2, tableName);\n     policyFile\n         .addPermissionsToRole(\"insert_db1_tb1\", privileges.get(\"insert_db1_tb1\"))\n         .addRolesToGroup(USERGROUP3, \"insert_db1_tb1\");\n@@ -363,6 +366,8 @@ public void testSelectOnTable() throws Exception {\n     statement = context.createStatement(connection);\n     statement.execute(\"Use \" + DB1);\n     context.assertSentrySemanticException(statement, \"select * from tb1\", semanticException);\n+    context.assertSentrySemanticException(statement,\n+        \"SHOW TABLE EXTENDED IN \" + DB2 + \" LIKE 'tb*'\", semanticException);\n \n     statement.close();\n     connection.close();\n@@ -379,6 +384,7 @@ public void testSelectOnTable() throws Exception {\n   6. HiveOperation.SHOWPARTITIONS\n   7. TODO: show functions?\n   8. TODO: lock, unlock, Show locks\n+  9. HiveOperation.SHOW_TABLESTATUS\n    */\n   @Test\n   public void testInsertOnTable() throws Exception {\n@@ -401,6 +407,7 @@ public void testInsertOnTable() throws Exception {\n     statement.executeQuery(\"SHOW COLUMNS from tb1\");\n     statement.executeQuery(\"SHOW functions '.*'\");\n     //statement.executeQuery(\"SHOW LOCKS tb1\");\n+    statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n \n     //NoViableAltException\n     //statement.executeQuery(\"SHOW transactions\");"
            },
            {
                "sha": "e103465ca8e7e71209383e4da696da4da6f2f59f",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "status": "modified",
                "additions": 62,
                "deletions": 0,
                "changes": 62,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/1e5826f85601319a2ef9c4bdab999ff1db697668/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hive/TestRuntimeMetadataRetrieval.java?ref=1e5826f85601319a2ef9c4bdab999ff1db697668",
                "patch": "@@ -250,6 +250,52 @@ public void testShowTables5() throws Exception {\n     statement.close();\n   }\n \n+  /**\n+   * Steps: 1. admin create db_1 and tb_1, tb_2, tb_3, tb_4 and table_5\n+   *        2. admin should see all tables except table_5 which does not match tb*\n+   *        3. user1 should only see the matched tables it has any level of privilege\n+   */\n+  @Test\n+  public void testShowTablesExtended() throws Exception {\n+    // tables visible to user1 (not access to tb_4\n+    String tableNames[] = {\"tb_1\", \"tb_2\", \"tb_3\", \"tb_4\", \"table_5\"};\n+    List<String> tableNamesValidation = new ArrayList<String>();\n+\n+    policyFile\n+        .addRolesToGroup(USERGROUP1, \"tab1_priv,tab2_priv,tab3_priv\")\n+        .addPermissionsToRole(\"tab1_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[0] + \"->action=select\")\n+        .addPermissionsToRole(\"tab2_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[1] + \"->action=insert\")\n+        .addPermissionsToRole(\"tab3_priv\", \"server=server1->db=\" + DB1 + \"->table=\"\n+            + tableNames[2] + \"->action=select\")\n+        .setUserGroupMapping(StaticUserGroup.getStaticMapping());\n+    writePolicyFile(policyFile);\n+\n+    String user1TableNames[] = {\"tb_1\", \"tb_2\", \"tb_3\"};\n+\n+    Connection connection = context.createConnection(ADMIN1);\n+    Statement statement = context.createStatement(connection);\n+    statement.execute(\"DROP DATABASE IF EXISTS \" + DB1 + \" CASCADE\");\n+    statement.execute(\"CREATE DATABASE \" + DB1);\n+    statement.execute(\"USE \" + DB1);\n+    createTabs(statement, DB1, tableNames);\n+    // Admin should see all tables except table_5, the one does not match the pattern\n+    ResultSet rs = statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n+    tableNamesValidation.addAll(Arrays.asList(tableNames).subList(0, 4));\n+    validateTablesInRs(rs, DB1, tableNamesValidation);\n+    statement.close();\n+\n+    connection = context.createConnection(USER1_1);\n+    statement = context.createStatement(connection);\n+    statement.execute(\"USE \" + DB1);\n+    // User1 should see tables with any level of access\n+    rs = statement.executeQuery(\"SHOW TABLE EXTENDED IN \" + DB1 + \" LIKE 'tb*'\");\n+    tableNamesValidation.addAll(Arrays.asList(user1TableNames));\n+    validateTablesInRs(rs, DB1, tableNamesValidation);\n+    statement.close();\n+  }\n+\n   /**\n    * Steps: 1. admin create few dbs\n    *        2. admin can do show databases\n@@ -359,4 +405,20 @@ private void validateTables(ResultSet rs, String dbName,\n     Assert.assertTrue(tableNames.toString(), tableNames.isEmpty());\n     rs.close();\n   }\n+\n+  // compare the tables in resultset with given array of table names\n+  // for some hive query like 'show table extended ...', the resultset does\n+  // not only contains tableName (See HIVE-8109)\n+  private void validateTablesInRs(ResultSet rs, String dbName,\n+      List<String> tableNames) throws SQLException {\n+    while (rs.next()) {\n+      String tableName = rs.getString(1);\n+      if (tableName.startsWith(\"tableName:\")) {\n+        Assert.assertTrue(\"Expected table \" + tableName.substring(10),\n+            tableNames.remove(tableName.substring(10).toLowerCase()));\n+      }\n+    }\n+    Assert.assertTrue(tableNames.toString(), tableNames.isEmpty());\n+    rs.close();\n+  }\n }"
            }
        ]
    },
    {
        "commit": "https://github.com/apache/incubator-sentry/commit/d96f95160fd3dfa30c27b82d09fb5cc2c348b483",
        "repo": "incubator-sentry",
        "parent": "https://github.com/apache/incubator-sentry/commit/8529f8e121144d715986a485abb204aa036caa19",
        "message": "SENTRY-1002: PathsUpdate.parsePath(path) will throw an NPE when parsing relative paths (Hao Hao via Lenni Kuff)\n\nChange-Id: I8882078abeed37c17734b04d09f6fb2b298861b9",
        "bug_id": "incubator-sentry_5",
        "file": [
            {
                "sha": "50ef112ff9ea9674d3b0bbc4279620e7a82f2d95",
                "filename": "sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "status": "modified",
                "additions": 19,
                "deletions": 4,
                "changes": 23,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-hdfs/sentry-hdfs-common/src/main/java/org/apache/sentry/hdfs/PathsUpdate.java?ref=d96f95160fd3dfa30c27b82d09fb5cc2c348b483",
                "patch": "@@ -23,13 +23,15 @@\n import java.util.LinkedList;\n import java.util.List;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n-\n import org.apache.sentry.hdfs.service.thrift.TPathChanges;\n import org.apache.sentry.hdfs.service.thrift.TPathsUpdate;\n import org.apache.commons.httpclient.util.URIUtil;\n import org.apache.commons.httpclient.URIException;\n import org.apache.commons.lang.StringUtils;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.conf.Configuration;\n \n import com.google.common.collect.Lists;\n \n@@ -42,7 +44,7 @@\n public class PathsUpdate implements Updateable.Update {\n \n   public static String ALL_PATHS = \"__ALL_PATHS__\";\n-\n+  private static final Configuration CONF = new Configuration();\n   private final TPathsUpdate tPathsUpdate;\n \n   public PathsUpdate() {\n@@ -89,6 +91,10 @@ public TPathsUpdate toThrift() {\n     return tPathsUpdate;\n   }\n \n+  @VisibleForTesting\n+  public static Configuration getConfiguration() {\n+    return CONF;\n+  }\n \n   /**\n    *\n@@ -106,9 +112,18 @@ public TPathsUpdate toThrift() {\n         return null;\n       }\n \n-      Preconditions.checkNotNull(uri.getScheme());\n+      String scheme = uri.getScheme();\n+      if (scheme == null) {\n+        // Use the default URI scheme only if the paths has no scheme.\n+        URI defaultUri = FileSystem.getDefaultUri(CONF);\n+        scheme = defaultUri.getScheme();\n+      }\n+\n+      // The paths without a scheme will be default to default scheme.\n+      Preconditions.checkNotNull(scheme);\n \n-      if(uri.getScheme().equalsIgnoreCase(\"hdfs\")) {\n+      // Non-HDFS paths will be skipped.\n+      if(scheme.equalsIgnoreCase(\"hdfs\")) {\n         return Lists.newArrayList(uri.getPath().split(\"^/\")[1]\n             .split(\"/\"));\n       } else {"
            },
            {
                "sha": "4d9e31cd9147511d6ee4becaf74e9c2a58d1f556",
                "filename": "sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "status": "modified",
                "additions": 73,
                "deletions": 5,
                "changes": 78,
                "blob_url": "https://github.com/apache/incubator-sentry/blob/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "raw_url": "https://github.com/apache/incubator-sentry/raw/d96f95160fd3dfa30c27b82d09fb5cc2c348b483/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java",
                "contents_url": "https://api.github.com/repos/apache/incubator-sentry/contents/sentry-tests/sentry-tests-hive/src/test/java/org/apache/sentry/tests/e2e/hdfs/TestHDFSIntegration.java?ref=d96f95160fd3dfa30c27b82d09fb5cc2c348b483",
                "patch": "@@ -51,13 +51,12 @@\n import org.apache.hadoop.fs.permission.AclStatus;\n import org.apache.hadoop.fs.permission.FsAction;\n import org.apache.hadoop.fs.permission.FsPermission;\n-import org.apache.hadoop.hdfs.DFSConfigKeys;\n-import org.apache.hadoop.hdfs.DFSTestUtil;\n-import org.apache.hadoop.hdfs.HdfsConfiguration;\n-import org.apache.hadoop.hdfs.MiniDFSCluster;\n+import org.apache.hadoop.hdfs.*;\n import org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream;\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n import org.apache.hadoop.io.LongWritable;\n import org.apache.hadoop.io.Text;\n import org.apache.hadoop.mapred.FileInputFormat;\n@@ -76,6 +75,7 @@\n import org.apache.hadoop.security.UserGroupInformation;\n import org.apache.sentry.binding.hive.SentryHiveAuthorizationTaskFactoryImpl;\n import org.apache.sentry.binding.hive.conf.HiveAuthzConf;\n+import org.apache.sentry.hdfs.PathsUpdate;\n import org.apache.sentry.hdfs.SentryAuthorizationProvider;\n import org.apache.sentry.provider.db.SentryAlreadyExistsException;\n import org.apache.sentry.provider.db.SimpleDBProviderBackend;\n@@ -101,6 +101,7 @@\n import com.google.common.collect.Maps;\n import com.google.common.io.Files;\n import com.google.common.io.Resources;\n+import org.apache.hadoop.hive.metastore.api.Table;\n \n public class TestHDFSIntegration {\n   \n@@ -140,13 +141,15 @@ public void reduce(Text key, Iterator<Long> values,\n \n   private static final int NUM_RETRIES = 10;\n   private static final int RETRY_WAIT = 1000;\n+  private static final String EXTERNAL_SENTRY_SERVICE = \"sentry.e2etest.external.sentry\";\n   private static final String DFS_NAMENODE_AUTHORIZATION_PROVIDER_KEY =\n       \"dfs.namenode.authorization.provider.class\";\n \n   private static MiniDFSCluster miniDFS;\n   private MiniMRClientCluster miniMR;\n   private static InternalHiveServer hiveServer2;\n   private static InternalMetastoreServer metastore;\n+  private static HiveMetaStoreClient hmsClient;\n \n   private static int sentryPort = -1;\n   protected static SentrySrv sentryServer;\n@@ -304,6 +307,7 @@ public void run() {\n           }\n         }.start();\n \n+        hmsClient = new HiveMetaStoreClient(hiveConf);\n         startHiveServer2(retries, hiveConf);\n         return null;\n       }\n@@ -1266,7 +1270,7 @@ public void testAllColumn() throws Throwable {\n     conn = hiveServer2.createConnection(StaticUserGroup.ADMIN1, StaticUserGroup.ADMIN1);\n     stmt = conn.createStatement();\n     stmt.execute(\"create database \" + dbName);\n-    stmt.execute(\"use \"+ dbName);\n+    stmt.execute(\"use \" + dbName);\n     stmt.execute(\"create table p1 (c1 string, c2 string) partitioned by (month int, day int)\");\n     stmt.execute(\"alter table p1 add partition (month=1, day=1)\");\n     loadDataTwoCols(stmt);\n@@ -1591,6 +1595,70 @@ private void verifyQuery(Statement stmt, String table, int n, int retry) throws\n     }\n   }\n \n+  /**\n+   * SENTRY-1002:\n+   * Ensure the paths with no scheme will not cause NPE during paths update.\n+   */\n+   @Test\n+   public void testMissingScheme() throws Throwable {\n+\n+     // In the local test environment, EXTERNAL_SENTRY_SERVICE is false,\n+     // set the default URI scheme to be hdfs.\n+     boolean testConfOff = new Boolean(System.getProperty(EXTERNAL_SENTRY_SERVICE, \"false\"));\n+     if (!testConfOff) {\n+       PathsUpdate.getConfiguration().set(\"fs.defaultFS\", \"hdfs:///\");\n+     }\n+\n+     tmpHDFSDir = new Path(\"/tmp/external\");\n+     if (!miniDFS.getFileSystem().exists(tmpHDFSDir)) {\n+       miniDFS.getFileSystem().mkdirs(tmpHDFSDir);\n+     }\n+\n+     Path partitionDir = new Path(\"/tmp/external/p1\");\n+     if (!miniDFS.getFileSystem().exists(partitionDir)) {\n+       miniDFS.getFileSystem().mkdirs(partitionDir);\n+     }\n+\n+     String dbName = \"db1\";\n+     String tblName = \"tab1\";\n+     dbNames = new String[]{dbName};\n+     roles = new String[]{\"admin_role\"};\n+     admin = StaticUserGroup.ADMIN1;\n+\n+     Connection conn;\n+     Statement stmt;\n+\n+     conn = hiveServer2.createConnection(\"hive\", \"hive\");\n+     stmt = conn.createStatement();\n+     stmt.execute(\"create role admin_role\");\n+     stmt.execute(\"grant all on server server1 to role admin_role\");\n+     stmt.execute(\"grant role admin_role to group \" + StaticUserGroup.ADMINGROUP);\n+     stmt.close();\n+     conn.close();\n+\n+     conn = hiveServer2.createConnection(StaticUserGroup.ADMIN1, StaticUserGroup.ADMIN1);\n+     stmt = conn.createStatement();\n+     stmt.execute(\"create database \" + dbName);\n+     stmt.execute(\"create external table \" + dbName + \".\" + tblName + \"(s string) location '/tmp/external/p1'\");\n+\n+     // Deep copy of table tab1\n+     Table tbCopy = hmsClient.getTable(dbName, tblName);\n+\n+     // Change the location of the table to strip the scheme.\n+     StorageDescriptor sd = hmsClient.getTable(dbName, tblName).getSd();\n+     sd.setLocation(\"/tmp/external\");\n+     tbCopy.setSd(sd);\n+\n+     // Alter table tab1 to be tbCopy which is at scheme-less location.\n+     // And the corresponding path will be updated to sentry server.\n+     hmsClient.alter_table(dbName, \"tab1\", tbCopy);\n+     Assert.assertEquals(hmsClient.getTable(dbName, tblName).getSd().getLocation(), \"/tmp/external\");\n+     verifyOnPath(\"/tmp/external\", FsAction.ALL, StaticUserGroup.HIVE, true);\n+\n+     stmt.close();\n+     conn.close();\n+   }\n+\n   private void loadData(Statement stmt) throws IOException, SQLException {\n     FSDataOutputStream f1 = miniDFS.getFileSystem().create(new Path(\"/tmp/f1.txt\"));\n     f1.writeChars(\"m1d1_t1\\n\");"
            }
        ]
    }
]
