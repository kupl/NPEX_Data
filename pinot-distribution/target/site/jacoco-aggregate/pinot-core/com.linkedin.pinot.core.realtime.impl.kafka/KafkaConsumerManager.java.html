<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>KafkaConsumerManager.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-distribution</a> &gt; <a href="../index.html" class="el_bundle">pinot-core</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.core.realtime.impl.kafka</a> &gt; <span class="el_source">KafkaConsumerManager.java</span></div><h1>KafkaConsumerManager.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.core.realtime.impl.kafka;

import com.google.common.util.concurrent.Uninterruptibles;
import java.util.HashMap;
import java.util.IdentityHashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import kafka.consumer.ConsumerIterator;
import kafka.javaapi.consumer.ConsumerConnector;
import org.apache.commons.lang3.tuple.ImmutableTriple;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


/**
 * Manager for Kafka consumers that reuses consumers and delays their shutdown.
 *
 * This is a workaround for the current realtime design flaw where any issue while flushing/committing offsets causes
 * duplicate or dropped events. Kafka consumption is driven by the controller, which assigns a realtime segment to the
 * servers; when a server is assigned a new realtime segment, it creates a Kafka consumer, consumes until it reaches a
 * threshold then flushes to disk, writes metadata to helix indicating the segment is completed, commits Kafka offsets
 * to ZK and then shuts down the consumer. The controller notices the metadata write and reassigns a segment to the
 * server, so that it can keep on consuming.
 *
 * This logic is flawed if committing Kafka offsets fails, at which time the committed state is unknown. The proper fix
 * would be to just keep on using that consumer and try committing our offsets later, but we recreate a new Kafka
 * consumer whenever we get a new segment and also keep the old consumer around, leading to half the events being
 * assigned, due to Kafka rebalancing the partitions between the two consumers (one of which is not actually reading
 * anything anymore). Because that logic is stateless and driven by Helix, there's no real clean way to keep the
 * consumer alive and pass it to the next segment.
 *
 * This class and long comment is to work around this issue by keeping the consumer alive for a little bit instead of
 * shutting it down immediately, so that the next segment assignment can pick up the same consumer. This way, even if
 * committing the offsets fails, we can still pick up the same consumer the next time we get a segment assigned to us
 * by the controller and hopefully commit our offsets the next time we flush to disk.
 *
 * This temporary code should be completely removed by the time we redesign the consumption to use the lower level
 * Kafka APIs.
 */
<span class="nc" id="L56">public class KafkaConsumerManager {</span>

<span class="nc" id="L58">  private static final Logger LOGGER = LoggerFactory.getLogger(KafkaConsumerManager.class);</span>
<span class="nc" id="L59">  private static final Long IN_USE = -1L;</span>
<span class="nc" id="L60">  private static final long CONSUMER_SHUTDOWN_DELAY_MILLIS = TimeUnit.SECONDS.toMillis(60); // One minute</span>
  private static final Map&lt;ImmutableTriple&lt;String, String, String&gt;, ConsumerAndIterator&gt;
<span class="nc" id="L62">      CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY = new HashMap&lt;&gt;();</span>
<span class="nc" id="L63">  private static final IdentityHashMap&lt;ConsumerAndIterator, Long&gt; CONSUMER_RELEASE_TIME = new IdentityHashMap&lt;&gt;();</span>

  public static ConsumerAndIterator acquireConsumerAndIteratorForConfig(KafkaHighLevelStreamProviderConfig config) {
<span class="nc" id="L66">    final ImmutableTriple&lt;String, String, String&gt; configKey =</span>
        new ImmutableTriple&lt;&gt;(config.getTopicName(), config.getGroupId(), config.getZkString());

<span class="nc" id="L69">    synchronized (KafkaConsumerManager.class) {</span>
      // If we have the consumer and it's not already acquired, return it, otherwise error out if it's already acquired
<span class="nc bnc" id="L71" title="All 2 branches missed.">      if (CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.containsKey(configKey)) {</span>
<span class="nc" id="L72">        ConsumerAndIterator consumerAndIterator = CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.get(configKey);</span>
<span class="nc bnc" id="L73" title="All 2 branches missed.">        if (CONSUMER_RELEASE_TIME.get(consumerAndIterator).equals(IN_USE)) {</span>
<span class="nc" id="L74">          throw new RuntimeException(&quot;Consumer/iterator &quot; + consumerAndIterator.getId() + &quot; already in use!&quot;);</span>
        } else {
<span class="nc" id="L76">          LOGGER.info(&quot;Reusing kafka consumer/iterator with id {}&quot;, consumerAndIterator.getId());</span>
<span class="nc" id="L77">          CONSUMER_RELEASE_TIME.put(consumerAndIterator, IN_USE);</span>
<span class="nc" id="L78">          return consumerAndIterator;</span>
        }
      }

<span class="nc" id="L82">      LOGGER.info(&quot;Creating new kafka consumer and iterator for topic {}&quot;, config.getTopicName());</span>

      // Create the consumer
<span class="nc" id="L85">      ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(config.getKafkaConsumerConfig());</span>

      // Create the iterator (can only be done once per consumer)
<span class="nc" id="L88">      ConsumerIterator&lt;byte[], byte[]&gt; iterator = consumer.createMessageStreams(config.getTopicMap(1)).</span>
          get(config.getTopicName()).get(0).iterator();

      // Mark both the consumer and iterator as acquired
<span class="nc" id="L92">      ConsumerAndIterator consumerAndIterator = new ConsumerAndIterator(consumer, iterator);</span>
<span class="nc" id="L93">      CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.put(configKey, consumerAndIterator);</span>
<span class="nc" id="L94">      CONSUMER_RELEASE_TIME.put(consumerAndIterator, IN_USE);</span>

<span class="nc" id="L96">      LOGGER.info(&quot;Created consumer/iterator with id {} for topic {}&quot;, consumerAndIterator.getId(),</span>
          config.getTopicName());

<span class="nc" id="L99">      return consumerAndIterator;</span>
<span class="nc" id="L100">    }</span>
  }

  public static void releaseConsumerAndIterator(final ConsumerAndIterator consumerAndIterator) {
<span class="nc" id="L104">    synchronized (KafkaConsumerManager.class) {</span>
      // Release the consumer, mark it for shutdown in the future
<span class="nc" id="L106">      final long releaseTime = System.currentTimeMillis() + CONSUMER_SHUTDOWN_DELAY_MILLIS;</span>
<span class="nc" id="L107">      CONSUMER_RELEASE_TIME.put(consumerAndIterator, releaseTime);</span>

<span class="nc" id="L109">      LOGGER.info(&quot;Marking consumer/iterator with id {} for release at {}&quot;, consumerAndIterator.getId(), releaseTime);</span>

      // Schedule the shutdown of the consumer
<span class="nc" id="L112">      new Thread() {</span>
        @Override
        public void run() {
          try {
            // Await the shutdown time
<span class="nc" id="L117">            Uninterruptibles.sleepUninterruptibly(CONSUMER_SHUTDOWN_DELAY_MILLIS, TimeUnit.MILLISECONDS);</span>

            // Shutdown all consumers that have not been re-acquired
<span class="nc" id="L120">            synchronized (KafkaConsumerManager.class) {</span>
<span class="nc" id="L121">              LOGGER.info(&quot;Executing release check for consumer/iterator {} at {}, scheduled at &quot;, consumerAndIterator.getId(),</span>
                  System.currentTimeMillis(), releaseTime);

<span class="nc" id="L124">              Iterator&lt;Map.Entry&lt;ImmutableTriple&lt;String, String, String&gt;, ConsumerAndIterator&gt;&gt; configIterator =</span>
                  CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.entrySet().iterator();

<span class="nc bnc" id="L127" title="All 2 branches missed.">              while (configIterator.hasNext()) {</span>
<span class="nc" id="L128">                Map.Entry&lt;ImmutableTriple&lt;String, String, String&gt;, ConsumerAndIterator&gt; entry = configIterator.next();</span>
<span class="nc" id="L129">                ConsumerAndIterator consumerAndIterator = entry.getValue();</span>

<span class="nc" id="L131">                final Long releaseTime = CONSUMER_RELEASE_TIME.get(consumerAndIterator);</span>
<span class="nc bnc" id="L132" title="All 4 branches missed.">                if (!releaseTime.equals(IN_USE) &amp;&amp; releaseTime &lt; System.currentTimeMillis()) {</span>
<span class="nc" id="L133">                  LOGGER.info(&quot;Releasing consumer/iterator {}&quot;, consumerAndIterator.getId());</span>

                  try {
<span class="nc" id="L136">                    consumerAndIterator.getConsumer().shutdown();</span>
<span class="nc" id="L137">                  } catch (Exception e) {</span>
<span class="nc" id="L138">                    LOGGER.warn(&quot;Caught exception while shutting down Kafka consumer with id {}&quot;, consumerAndIterator.getId(), e);</span>
<span class="nc" id="L139">                  }</span>

<span class="nc" id="L141">                  configIterator.remove();</span>
<span class="nc" id="L142">                  CONSUMER_RELEASE_TIME.remove(consumerAndIterator);</span>
                } else {
<span class="nc" id="L144">                  LOGGER.info(&quot;Not releasing consumer/iterator {}, it has been reacquired&quot;, consumerAndIterator.getId());</span>
                }
<span class="nc" id="L146">              }</span>
<span class="nc" id="L147">            }</span>
<span class="nc" id="L148">          } catch (Exception e) {</span>
<span class="nc" id="L149">            LOGGER.warn(&quot;Caught exception in release of consumer/iterator {}&quot;, e, consumerAndIterator);</span>
<span class="nc" id="L150">          }</span>
<span class="nc" id="L151">        }</span>
      }.start();
<span class="nc" id="L153">    }</span>
<span class="nc" id="L154">  }</span>

  public static void closeAllConsumers() {
    try {
      // Shutdown all consumers
<span class="nc" id="L159">      synchronized (KafkaConsumerManager.class) {</span>
<span class="nc" id="L160">        LOGGER.info(&quot;Trying to shutdown all the kafka consumers&quot;);</span>
<span class="nc" id="L161">        Iterator&lt;ConsumerAndIterator&gt; consumerIterator = CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.values().iterator();</span>

<span class="nc bnc" id="L163" title="All 2 branches missed.">        while (consumerIterator.hasNext()) {</span>
<span class="nc" id="L164">          ConsumerAndIterator consumerAndIterator = consumerIterator.next();</span>
<span class="nc" id="L165">          LOGGER.info(&quot;Trying to shutdown consumer/iterator {}&quot;, consumerAndIterator.getId());</span>
          try {
<span class="nc" id="L167">            consumerAndIterator.getConsumer().shutdown();</span>
<span class="nc" id="L168">          } catch (Exception e) {</span>
<span class="nc" id="L169">            LOGGER.warn(&quot;Caught exception while shutting down Kafka consumer with id {}&quot;, consumerAndIterator.getId(), e);</span>
<span class="nc" id="L170">          }</span>
<span class="nc" id="L171">          consumerIterator.remove();</span>
<span class="nc" id="L172">        }</span>
<span class="nc" id="L173">        CONSUMER_AND_ITERATOR_FOR_CONFIG_KEY.clear();</span>
<span class="nc" id="L174">        CONSUMER_RELEASE_TIME.clear();</span>
<span class="nc" id="L175">      }</span>
<span class="nc" id="L176">    } catch (Exception e) {</span>
<span class="nc" id="L177">      LOGGER.warn(&quot;Caught exception during shutting down all kafka consumers&quot;, e);</span>
<span class="nc" id="L178">    }</span>
<span class="nc" id="L179">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>