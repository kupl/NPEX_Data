<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>BaseChunkSingleValueReader.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-distribution</a> &gt; <a href="../index.html" class="el_bundle">pinot-core</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.core.io.reader.impl.v1</a> &gt; <span class="el_source">BaseChunkSingleValueReader.java</span></div><h1>BaseChunkSingleValueReader.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.core.io.reader.impl.v1;

import com.linkedin.pinot.core.io.compression.ChunkCompressorFactory;
import com.linkedin.pinot.core.io.compression.ChunkDecompressor;
import com.linkedin.pinot.core.io.reader.BaseSingleColumnSingleValueReader;
import com.linkedin.pinot.core.io.reader.impl.ChunkReaderContext;
import com.linkedin.pinot.core.segment.memory.PinotDataBuffer;
import java.io.IOException;
import java.nio.ByteBuffer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


/**
 * Abstract class implementation for {@link BaseSingleColumnSingleValueReader}.
 * Base class for the fixed and variable byte reader implementations.
 *
 */
public abstract class BaseChunkSingleValueReader extends BaseSingleColumnSingleValueReader&lt;ChunkReaderContext&gt; {
<span class="fc" id="L35">  private static final Logger LOGGER = LoggerFactory.getLogger(BaseChunkSingleValueReader.class);</span>

  protected static final int INT_SIZE = Integer.SIZE / Byte.SIZE;
  protected static final int LONG_SIZE = Long.SIZE / Byte.SIZE;
  protected static final int FLOAT_SIZE = Float.SIZE / Byte.SIZE;
  protected static final int DOUBLE_SIZE = Double.SIZE / Byte.SIZE;

  protected final PinotDataBuffer _dataBuffer;
  protected final PinotDataBuffer _dataHeader;
  protected final int _chunkSize;
  private final PinotDataBuffer _rawData;
  private final boolean _isCompressed;
  protected ChunkDecompressor _chunkDecompressor;

  protected final int _numDocsPerChunk;
  protected final int _numChunks;
  protected final int _lengthOfLongestEntry;

  /**
   * Constructor for the class.
   *
   * @param pinotDataBuffer Data buffer
   */
<span class="fc" id="L58">  public BaseChunkSingleValueReader(PinotDataBuffer pinotDataBuffer) {</span>
<span class="fc" id="L59">    _dataBuffer = pinotDataBuffer;</span>

<span class="fc" id="L61">    int headerOffset = 0;</span>
<span class="fc" id="L62">    int version = _dataBuffer.getInt(headerOffset);</span>
<span class="fc" id="L63">    headerOffset += INT_SIZE;</span>

<span class="fc" id="L65">    _numChunks = _dataBuffer.getInt(headerOffset);</span>
<span class="fc" id="L66">    headerOffset += INT_SIZE;</span>

<span class="fc" id="L68">    _numDocsPerChunk = _dataBuffer.getInt(headerOffset);</span>
<span class="fc" id="L69">    headerOffset += INT_SIZE;</span>

<span class="fc" id="L71">    _lengthOfLongestEntry = _dataBuffer.getInt(headerOffset);</span>
<span class="fc" id="L72">    headerOffset += INT_SIZE;</span>

<span class="fc" id="L74">    int dataHeaderStart = headerOffset;</span>
<span class="fc bfc" id="L75" title="All 2 branches covered.">    if (version &gt; 1) {</span>
<span class="fc" id="L76">      _dataBuffer.getInt(headerOffset); // Total docs</span>
<span class="fc" id="L77">      headerOffset += INT_SIZE;</span>

<span class="fc" id="L79">      ChunkCompressorFactory.CompressionType compressionType =</span>
          ChunkCompressorFactory.CompressionType.values()[_dataBuffer.getInt(headerOffset)];
<span class="fc" id="L81">      _chunkDecompressor = ChunkCompressorFactory.getDecompressor(compressionType);</span>
<span class="fc bfc" id="L82" title="All 2 branches covered.">      _isCompressed = !compressionType.equals(ChunkCompressorFactory.CompressionType.PASS_THROUGH);</span>

<span class="fc" id="L84">      headerOffset += INT_SIZE;</span>
<span class="fc" id="L85">      dataHeaderStart = _dataBuffer.getInt(headerOffset);</span>
<span class="fc" id="L86">    } else {</span>
<span class="fc" id="L87">      _isCompressed = true;</span>
<span class="fc" id="L88">      _chunkDecompressor = ChunkCompressorFactory.getDecompressor(ChunkCompressorFactory.CompressionType.SNAPPY);</span>
    }

<span class="fc" id="L91">    _chunkSize = (_lengthOfLongestEntry * _numDocsPerChunk);</span>

    // Slice out the header from the data buffer.
<span class="fc" id="L94">    int dataHeaderLength = _numChunks * INT_SIZE;</span>
<span class="fc" id="L95">    int rawDataStart = dataHeaderStart + dataHeaderLength;</span>
<span class="fc" id="L96">    _dataHeader = _dataBuffer.view(dataHeaderStart, rawDataStart);</span>

    // Useful for uncompressed data.
<span class="fc" id="L99">    _rawData = _dataBuffer.view(rawDataStart, _dataBuffer.size());</span>
<span class="fc" id="L100">  }</span>

  @Override
  public void close() {
    // Nothing to close here.
<span class="fc" id="L105">  }</span>

  /**
   * Helper method to get the chunk for a given row.
   * &lt;ul&gt;
   *   &lt;li&gt; If the chunk already exists in the reader context, returns the same. &lt;/li&gt;
   *   &lt;li&gt; Otherwise, loads the chunk for the row, and sets it in the reader context. &lt;/li&gt;
   * &lt;/ul&gt;
   * @param row Row for which to get the chunk
   * @param context Reader context
   * @return Chunk for the row
   */
  protected ByteBuffer getChunkForRow(int row, ChunkReaderContext context) {
<span class="fc" id="L118">    int chunkId = row / _numDocsPerChunk;</span>
<span class="fc bfc" id="L119" title="All 2 branches covered.">    if (context.getChunkId() == chunkId) {</span>
<span class="fc" id="L120">      return context.getChunkBuffer();</span>
    }

    int chunkSize;
<span class="fc" id="L124">    int chunkPosition = getChunkPosition(chunkId);</span>

    // Size of chunk can be determined using next chunks offset, or end of data buffer for last chunk.
<span class="fc bfc" id="L127" title="All 2 branches covered.">    if (chunkId == (_numChunks - 1)) { // Last chunk.</span>
<span class="fc" id="L128">      chunkSize = (int) (_dataBuffer.size() - chunkPosition);</span>
    } else {
<span class="fc" id="L130">      int nextChunkOffset = getChunkPosition(chunkId + 1);</span>
<span class="fc" id="L131">      chunkSize = nextChunkOffset - chunkPosition;</span>
    }

<span class="fc" id="L134">    ByteBuffer decompressedBuffer = context.getChunkBuffer();</span>
<span class="fc" id="L135">    decompressedBuffer.clear();</span>

    try {
<span class="fc" id="L138">      _chunkDecompressor.decompress(_dataBuffer.toDirectByteBuffer(chunkPosition, chunkSize), decompressedBuffer);</span>
<span class="nc" id="L139">    } catch (IOException e) {</span>
<span class="nc" id="L140">      LOGGER.error(&quot;Exception caught while decompressing data chunk&quot;, e);</span>
<span class="nc" id="L141">      throw new RuntimeException(e);</span>
<span class="fc" id="L142">    }</span>
<span class="fc" id="L143">    context.setChunkId(chunkId);</span>
<span class="fc" id="L144">    return decompressedBuffer;</span>
  }

  /**
   * Helper method to get the offset of the chunk in the data.
   *
   * @param chunkId Id of the chunk for which to return the position.
   * @return Position (offset) of the chunk in the data.
   */
  protected int getChunkPosition(int chunkId) {
<span class="fc" id="L154">    return _dataHeader.getInt(chunkId * INT_SIZE);</span>
  }

  /**
   * Method to determine if the data is compressed or not.
   *
   * @return True if data is compressed, false otherwise.
   */
  protected boolean isCompressed() {
<span class="fc" id="L163">    return (_isCompressed);</span>
  }

  /**
   * Returns a PinotDataBuffer containing the raw data.
   *
   * @return PinotDataBuffer containing raw data.
   */
  protected PinotDataBuffer getRawData() {
<span class="fc" id="L172">    return _rawData;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>