<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>ServerQueryExecutorV1Impl.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-distribution</a> &gt; <a href="../index.html" class="el_bundle">pinot-core</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.core.query.executor</a> &gt; <span class="el_source">ServerQueryExecutorV1Impl.java</span></div><h1>ServerQueryExecutorV1Impl.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.core.query.executor;

import com.google.common.base.Preconditions;
import com.linkedin.pinot.common.data.DataManager;
import com.linkedin.pinot.common.exception.QueryException;
import com.linkedin.pinot.common.metrics.ServerMeter;
import com.linkedin.pinot.common.metrics.ServerMetrics;
import com.linkedin.pinot.common.metrics.ServerQueryPhase;
import com.linkedin.pinot.common.query.QueryExecutor;
import com.linkedin.pinot.common.query.ServerQueryRequest;
import com.linkedin.pinot.common.query.context.TimerContext;
import com.linkedin.pinot.common.request.BrokerRequest;
import com.linkedin.pinot.common.request.InstanceRequest;
import com.linkedin.pinot.common.utils.CommonConstants;
import com.linkedin.pinot.common.utils.DataTable;
import com.linkedin.pinot.core.common.datatable.DataTableBuilder;
import com.linkedin.pinot.core.common.datatable.DataTableImplV2;
import com.linkedin.pinot.core.data.manager.offline.InstanceDataManager;
import com.linkedin.pinot.core.data.manager.offline.SegmentDataManager;
import com.linkedin.pinot.core.data.manager.offline.TableDataManager;
import com.linkedin.pinot.core.indexsegment.IndexSegment;
import com.linkedin.pinot.core.plan.Plan;
import com.linkedin.pinot.core.plan.maker.InstancePlanMakerImplV2;
import com.linkedin.pinot.core.plan.maker.PlanMaker;
import com.linkedin.pinot.core.query.config.QueryExecutorConfig;
import com.linkedin.pinot.core.query.exception.BadQueryRequestException;
import com.linkedin.pinot.core.query.pruner.SegmentPrunerService;
import com.linkedin.pinot.core.query.pruner.SegmentPrunerServiceImpl;
import com.linkedin.pinot.core.util.trace.TraceContext;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import org.apache.commons.configuration.Configuration;
import org.apache.commons.configuration.ConfigurationException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class ServerQueryExecutorV1Impl implements QueryExecutor {
<span class="fc" id="L58">  private static final Logger LOGGER = LoggerFactory.getLogger(ServerQueryExecutorV1Impl.class);</span>
  private static final boolean PRINT_QUERY_PLAN = false;

<span class="fc" id="L61">  private InstanceDataManager _instanceDataManager = null;</span>
<span class="fc" id="L62">  private SegmentPrunerService _segmentPrunerService = null;</span>
<span class="fc" id="L63">  private PlanMaker _planMaker = null;</span>
<span class="fc" id="L64">  private volatile boolean _isStarted = false;</span>
<span class="fc" id="L65">  private long _defaultTimeOutMs = CommonConstants.Server.DEFAULT_QUERY_EXECUTOR_TIMEOUT_MS;</span>
<span class="fc" id="L66">  private final Map&lt;String, Long&gt; _resourceTimeOutMsMap = new ConcurrentHashMap&lt;&gt;();</span>
  private ServerMetrics _serverMetrics;

<span class="fc" id="L69">  public ServerQueryExecutorV1Impl() {</span>
<span class="fc" id="L70">  }</span>

  @Override
  public void init(Configuration configuration, DataManager dataManager, ServerMetrics serverMetrics)
      throws ConfigurationException {
<span class="fc" id="L75">    _serverMetrics = serverMetrics;</span>
<span class="fc" id="L76">    _instanceDataManager = (InstanceDataManager) dataManager;</span>
<span class="fc" id="L77">    QueryExecutorConfig queryExecutorConfig = new QueryExecutorConfig(configuration);</span>
<span class="pc bpc" id="L78" title="1 of 2 branches missed.">    if (queryExecutorConfig.getTimeOut() &gt; 0) {</span>
<span class="fc" id="L79">      _defaultTimeOutMs = queryExecutorConfig.getTimeOut();</span>
    }
<span class="fc" id="L81">    LOGGER.info(&quot;Default timeout for query executor : {}&quot;, _defaultTimeOutMs);</span>
<span class="fc" id="L82">    LOGGER.info(&quot;Trying to build SegmentPrunerService&quot;);</span>
<span class="fc" id="L83">    _segmentPrunerService = new SegmentPrunerServiceImpl(queryExecutorConfig.getPrunerConfig());</span>
<span class="fc" id="L84">    LOGGER.info(&quot;Trying to build QueryPlanMaker&quot;);</span>
<span class="fc" id="L85">    _planMaker = new InstancePlanMakerImplV2(queryExecutorConfig);</span>
<span class="fc" id="L86">    LOGGER.info(&quot;Trying to build QueryExecutorTimer&quot;);</span>
<span class="fc" id="L87">  }</span>

  @Override
  public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService executorService) {
<span class="fc" id="L91">    TimerContext timerContext = queryRequest.getTimerContext();</span>
<span class="fc" id="L92">    TimerContext.Timer schedulerWaitTimer = timerContext.getPhaseTimer(ServerQueryPhase.SCHEDULER_WAIT);</span>
<span class="pc bpc" id="L93" title="1 of 2 branches missed.">    if (schedulerWaitTimer != null) {</span>
<span class="nc" id="L94">      schedulerWaitTimer.stopAndRecord();</span>
    }
<span class="fc" id="L96">    TimerContext.Timer queryProcessingTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PROCESSING);</span>

<span class="fc" id="L98">    InstanceRequest instanceRequest = queryRequest.getInstanceRequest();</span>
<span class="fc" id="L99">    long requestId = instanceRequest.getRequestId();</span>
<span class="fc" id="L100">    BrokerRequest brokerRequest = instanceRequest.getQuery();</span>
<span class="fc" id="L101">    LOGGER.debug(&quot;Incoming request Id: {}, query: {}&quot;, requestId, brokerRequest);</span>
<span class="fc" id="L102">    String tableName = brokerRequest.getQuerySource().getTableName();</span>
<span class="fc" id="L103">    TableDataManager tableDataManager = _instanceDataManager.getTableDataManager(tableName);</span>
<span class="pc bpc" id="L104" title="1 of 2 branches missed.">    Preconditions.checkState(tableDataManager != null, &quot;Failed to find data manager for table: {}&quot;, tableName);</span>
<span class="fc" id="L105">    List&lt;SegmentDataManager&gt; queryableSegmentDataManagerList =</span>
        acquireQueryableSegments(tableDataManager, instanceRequest);
<span class="fc" id="L107">    boolean enableTrace = instanceRequest.isEnableTrace();</span>
<span class="pc bpc" id="L108" title="1 of 2 branches missed.">    if (enableTrace) {</span>
<span class="nc" id="L109">      TraceContext.register(requestId);</span>
    }

<span class="fc" id="L112">    DataTable dataTable = null;</span>
    try {
<span class="fc" id="L114">      TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);</span>
<span class="fc" id="L115">      long totalRawDocs = pruneSegments(tableDataManager, queryableSegmentDataManagerList, queryRequest);</span>
<span class="fc" id="L116">      segmentPruneTimer.stopAndRecord();</span>

<span class="fc" id="L118">      int numSegmentsMatched = queryableSegmentDataManagerList.size();</span>
<span class="fc" id="L119">      queryRequest.setSegmentCountAfterPruning(numSegmentsMatched);</span>
<span class="fc" id="L120">      LOGGER.debug(&quot;Matched {} segments&quot;, numSegmentsMatched);</span>
<span class="pc bpc" id="L121" title="1 of 2 branches missed.">      if (numSegmentsMatched == 0) {</span>
<span class="nc" id="L122">        dataTable = DataTableBuilder.buildEmptyDataTable(brokerRequest);</span>
<span class="nc" id="L123">        Map&lt;String, String&gt; metadata = dataTable.getMetadata();</span>
<span class="nc" id="L124">        metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(totalRawDocs));</span>
<span class="nc" id="L125">        metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, &quot;0&quot;);</span>
<span class="nc" id="L126">        metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, &quot;0&quot;);</span>
<span class="nc" id="L127">        metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, &quot;0&quot;);</span>
<span class="nc" id="L128">      } else {</span>
<span class="fc" id="L129">        TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);</span>
<span class="fc" id="L130">        Plan globalQueryPlan =</span>
            _planMaker.makeInterSegmentPlan(queryableSegmentDataManagerList, brokerRequest, executorService,
                getResourceTimeOut(brokerRequest));
<span class="fc" id="L133">        planBuildTimer.stopAndRecord();</span>

        if (PRINT_QUERY_PLAN) {
          LOGGER.debug(&quot;***************************** Query Plan for Request {} ***********************************&quot;,
              instanceRequest.getRequestId());
          globalQueryPlan.print();
          LOGGER.debug(&quot;*********************************** End Query Plan ***********************************&quot;);
        }

<span class="fc" id="L142">        TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);</span>
<span class="fc" id="L143">        dataTable = globalQueryPlan.execute();</span>
<span class="fc" id="L144">        planExecTimer.stopAndRecord();</span>

        // Update the total docs in the metadata based on un-pruned segments.
<span class="fc" id="L147">        dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(totalRawDocs));</span>
      }
<span class="nc" id="L149">    } catch (Exception e) {</span>
<span class="nc" id="L150">      _serverMetrics.addMeteredQueryValue(brokerRequest, ServerMeter.QUERY_EXECUTION_EXCEPTIONS, 1);</span>

      // Do not log error for BadQueryRequestException because it's caused by bad query
<span class="nc bnc" id="L153" title="All 2 branches missed.">      if (e instanceof BadQueryRequestException) {</span>
<span class="nc" id="L154">        LOGGER.info(&quot;Caught BadQueryRequestException while processing requestId: {}, {}&quot;, requestId, e.getMessage());</span>
      } else {
<span class="nc" id="L156">        LOGGER.error(&quot;Exception processing requestId {}&quot;, requestId, e);</span>
      }

<span class="nc" id="L159">      dataTable = new DataTableImplV2();</span>
<span class="nc" id="L160">      dataTable.addException(QueryException.getException(QueryException.QUERY_EXECUTION_ERROR, e));</span>
    } finally {
<span class="pc bpc" id="L162" title="4 of 6 branches missed.">      for (SegmentDataManager segmentDataManager : queryableSegmentDataManagerList) {</span>
<span class="pc" id="L163">        tableDataManager.releaseSegment(segmentDataManager);</span>
<span class="pc" id="L164">      }</span>
<span class="pc bpc" id="L165" title="5 of 6 branches missed.">      if (enableTrace) {</span>
<span class="nc bnc" id="L166" title="All 6 branches missed.">        if (dataTable != null) {</span>
<span class="nc" id="L167">          dataTable.getMetadata().put(DataTable.TRACE_INFO_METADATA_KEY, TraceContext.getTraceInfo());</span>
        }
<span class="nc" id="L169">        TraceContext.unregister();</span>
      }
    }

<span class="fc" id="L173">    queryProcessingTimer.stopAndRecord();</span>
<span class="fc" id="L174">    long queryProcessingTime = queryProcessingTimer.getDurationMs();</span>
<span class="fc" id="L175">    dataTable.getMetadata().put(DataTable.TIME_USED_MS_METADATA_KEY, Long.toString(queryProcessingTime));</span>
<span class="fc" id="L176">    LOGGER.debug(&quot;Query processing time for request Id - {}: {}&quot;, requestId, queryProcessingTime);</span>
<span class="fc" id="L177">    LOGGER.debug(&quot;InstanceResponse for request Id - {}: {}&quot;, requestId, dataTable);</span>
<span class="fc" id="L178">    return dataTable;</span>
  }

  /**
   * Helper method to identify if a query is simple count(*) query without any predicates and group by's.
   *
   * @param brokerRequest Broker request for the query
   * @return True if simple count star query, false otherwise.
   */

  /**
   * Helper method to acquire segments that can be queried for the request.
   *
   * @param tableDataManager Table data manager
   * @param instanceRequest Instance request
   * @return List of segment data managers that can be queried.
   */
  private List&lt;SegmentDataManager&gt; acquireQueryableSegments(TableDataManager tableDataManager,
      final InstanceRequest instanceRequest) {
<span class="fc" id="L197">    LOGGER.debug(&quot;InstanceRequest contains {} segments&quot;, instanceRequest.getSearchSegmentsSize());</span>

<span class="pc bpc" id="L199" title="2 of 4 branches missed.">    if (tableDataManager == null || instanceRequest.getSearchSegmentsSize() == 0) {</span>
<span class="nc" id="L200">      return new ArrayList&lt;&gt;();</span>
    }
<span class="fc" id="L202">    List&lt;SegmentDataManager&gt; listOfQueryableSegments =</span>
        tableDataManager.acquireSegments(instanceRequest.getSearchSegments());
<span class="fc" id="L204">    LOGGER.debug(&quot;TableDataManager found {} segments before pruning&quot;, listOfQueryableSegments.size());</span>
<span class="fc" id="L205">    return listOfQueryableSegments;</span>
  }

  /**
   * Helper method to prune segments.
   *
   * @param tableDataManager Table data manager
   * @param segments List of segments to prune
   * @param serverQueryRequest Server query request
   * @return Total number of docs across all segments (including the ones that were pruned).
   */
  private long pruneSegments(TableDataManager tableDataManager, List&lt;SegmentDataManager&gt; segments,
      ServerQueryRequest serverQueryRequest) {
<span class="fc" id="L218">    long totalRawDocs = 0;</span>
<span class="fc" id="L219">    Iterator&lt;SegmentDataManager&gt; it = segments.iterator();</span>

<span class="fc bfc" id="L221" title="All 2 branches covered.">    while (it.hasNext()) {</span>
<span class="fc" id="L222">      SegmentDataManager segmentDataManager = it.next();</span>
<span class="fc" id="L223">      final IndexSegment indexSegment = segmentDataManager.getSegment();</span>
      // We need to compute the total raw docs for the table before any pruning.
<span class="fc" id="L225">      totalRawDocs += indexSegment.getSegmentMetadata().getTotalRawDocs();</span>
<span class="pc bpc" id="L226" title="1 of 2 branches missed.">      if (_segmentPrunerService.prune(indexSegment, serverQueryRequest)) {</span>
<span class="nc" id="L227">        it.remove();</span>
<span class="nc" id="L228">        tableDataManager.releaseSegment(segmentDataManager);</span>
      }
<span class="fc" id="L230">    }</span>
<span class="fc" id="L231">    return totalRawDocs;</span>
  }

  @Override
  public synchronized void shutDown() {
<span class="nc bnc" id="L236" title="All 2 branches missed.">    if (isStarted()) {</span>
<span class="nc" id="L237">      _isStarted = false;</span>
<span class="nc" id="L238">      LOGGER.info(&quot;QueryExecutor is shutDown!&quot;);</span>
    } else {
<span class="nc" id="L240">      LOGGER.warn(&quot;QueryExecutor is already shutDown, won't do anything!&quot;);</span>
    }
<span class="nc" id="L242">  }</span>

  @Override
  public boolean isStarted() {
<span class="nc" id="L246">    return _isStarted;</span>
  }

  @Override
  public synchronized void start() {
<span class="nc" id="L251">    _isStarted = true;</span>
<span class="nc" id="L252">    LOGGER.info(&quot;QueryExecutor is started!&quot;);</span>
<span class="nc" id="L253">  }</span>

  @Override
  public void updateResourceTimeOutInMs(String resource, long timeOutMs) {
<span class="nc" id="L257">    _resourceTimeOutMsMap.put(resource, timeOutMs);</span>
<span class="nc" id="L258">  }</span>

  private long getResourceTimeOut(BrokerRequest brokerRequest) {
    try {
<span class="fc" id="L262">      String resourceName = brokerRequest.getQuerySource().getTableName();</span>
<span class="pc bpc" id="L263" title="1 of 2 branches missed.">      if (_resourceTimeOutMsMap.containsKey(resourceName)) {</span>
<span class="nc" id="L264">        return _resourceTimeOutMsMap.get(resourceName);</span>
      }
<span class="nc" id="L266">    } catch (Exception e) {</span>
      // Return the default timeout value
<span class="nc" id="L268">      LOGGER.warn(&quot;Caught exception while obtaining resource timeout&quot;, e);</span>
<span class="fc" id="L269">    }</span>
<span class="fc" id="L270">    return _defaultTimeOutMs;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>