<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>HdfsSegmentFetcher.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-distribution</a> &gt; <a href="../index.html" class="el_bundle">pinot-common</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.common.segment.fetcher</a> &gt; <span class="el_source">HdfsSegmentFetcher.java</span></div><h1>HdfsSegmentFetcher.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.common.segment.fetcher;

import com.google.common.base.Strings;
import com.linkedin.pinot.common.utils.retry.RetryPolicies;
import com.linkedin.pinot.common.utils.retry.RetryPolicy;
import java.util.Collections;
import java.util.Set;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.security.UserGroupInformation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.io.IOException;
import java.util.concurrent.Callable;

import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.RETRY;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.RETRY_DEFAULT;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.RETRY_WAITIME_MS;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.RETRY_WAITIME_MS_DEFAULT;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.HdfsSegmentFetcher.HADOOP_CONF_PATH;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.HdfsSegmentFetcher.KEYTAB;
import static com.linkedin.pinot.common.utils.CommonConstants.SegmentFetcher.HdfsSegmentFetcher.PRINCIPLE;

<span class="nc" id="L42">public class HdfsSegmentFetcher implements SegmentFetcher {</span>

<span class="nc" id="L44">  private static final Logger LOGGER = LoggerFactory.getLogger(HdfsSegmentFetcher.class);</span>
<span class="nc" id="L45">  private FileSystem hadoopFS = null;</span>
<span class="nc" id="L46">  private int retryCount = RETRY_DEFAULT;</span>
<span class="nc" id="L47">  private int retryWaitMs = RETRY_WAITIME_MS_DEFAULT;</span>

  @Override
  public void init(org.apache.commons.configuration.Configuration configs) {
    try {
<span class="nc" id="L52">      retryCount = configs.getInt(RETRY, retryCount);</span>
<span class="nc" id="L53">      retryWaitMs = configs.getInt(RETRY_WAITIME_MS, retryWaitMs);</span>
<span class="nc" id="L54">      Configuration hadoopConf = getConf(configs.getString(HADOOP_CONF_PATH));</span>
<span class="nc" id="L55">      authenticate(hadoopConf, configs);</span>
<span class="nc" id="L56">      hadoopFS = FileSystem.get(hadoopConf);</span>
<span class="nc" id="L57">      LOGGER.info(&quot;successfully initialized hdfs segment fetcher&quot;);</span>
<span class="nc" id="L58">    } catch (Exception e) {</span>
<span class="nc" id="L59">      LOGGER.error(&quot;failed to initialized the hdfs segment fetcher&quot;, e);</span>
<span class="nc" id="L60">    }</span>
<span class="nc" id="L61">  }</span>

  private Configuration getConf(String hadoopConfPath) {
<span class="nc" id="L64">    Configuration hadoopConf = new Configuration();</span>
<span class="nc bnc" id="L65" title="All 2 branches missed.">    if (Strings.isNullOrEmpty(hadoopConfPath)) {</span>
<span class="nc" id="L66">      LOGGER.warn(&quot;no hadoop conf path is provided, will rely on default config&quot;);</span>
    } else {
<span class="nc" id="L68">      hadoopConf.addResource(new Path(hadoopConfPath, &quot;core-site.xml&quot;));</span>
<span class="nc" id="L69">      hadoopConf.addResource(new Path(hadoopConfPath, &quot;hdfs-site.xml&quot;));</span>
    }
<span class="nc" id="L71">    return hadoopConf;</span>
  }

  private void authenticate(Configuration hadoopConf, org.apache.commons.configuration.Configuration configs) {
<span class="nc" id="L75">    String principal = configs.getString(PRINCIPLE);</span>
<span class="nc" id="L76">    String keytab = configs.getString(KEYTAB);</span>
<span class="nc bnc" id="L77" title="All 4 branches missed.">    if (!Strings.isNullOrEmpty(principal) &amp;&amp; !Strings.isNullOrEmpty(keytab)) {</span>
<span class="nc" id="L78">      UserGroupInformation.setConfiguration(hadoopConf);</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">      if (UserGroupInformation.isSecurityEnabled()) {</span>
        try {
<span class="nc bnc" id="L81" title="All 4 branches missed.">          if (!UserGroupInformation.getCurrentUser().hasKerberosCredentials()</span>
              || !UserGroupInformation.getCurrentUser().getUserName().equals(principal)) {
<span class="nc" id="L83">            LOGGER.info(&quot;Trying to authenticate user [%s] with keytab [%s]..&quot;, principal, keytab);</span>
<span class="nc" id="L84">            UserGroupInformation.loginUserFromKeytab(principal, keytab);</span>
          }
        }
<span class="nc" id="L87">        catch (IOException e) {</span>
<span class="nc" id="L88">          throw new RuntimeException(String.format(&quot;Failed to authenticate user principal [%s] with keytab [%s]&quot;,</span>
                  principal, keytab), e);
<span class="nc" id="L90">        }</span>
      }
    }
<span class="nc" id="L93">  }</span>

  @Override
  public void fetchSegmentToLocal(final String uri, final File tempFile) throws Exception {
<span class="nc" id="L97">    LOGGER.debug(&quot;starting to fetch segment from hdfs&quot;);</span>
<span class="nc" id="L98">    final String tempFilePath = tempFile.getAbsolutePath();</span>
    try {
<span class="nc" id="L100">      final Path remoteFile = new Path(uri);</span>
<span class="nc" id="L101">      final Path localFile = new Path(tempFile.toURI());</span>

<span class="nc" id="L103">      RetryPolicy fixDelayRetryPolicy = RetryPolicies.fixedDelayRetryPolicy(retryCount, retryWaitMs);</span>
<span class="nc" id="L104">      fixDelayRetryPolicy.attempt(new Callable&lt;Boolean&gt;() {</span>
        @Override
        public Boolean call() throws Exception {
          try{
<span class="nc bnc" id="L108" title="All 2 branches missed.">            if (hadoopFS == null) {</span>
<span class="nc" id="L109">                throw new RuntimeException(&quot;hadoopFS client is not initialized when trying to copy files&quot;);</span>
              }
<span class="nc" id="L111">              long startMs = System.currentTimeMillis();</span>
<span class="nc" id="L112">              hadoopFS.copyToLocalFile(remoteFile, localFile);</span>
<span class="nc" id="L113">              LOGGER.debug(&quot;copied {} from hdfs to {} in local for size {}, take {} ms&quot;,</span>
                  uri, tempFilePath, tempFile.length(), System.currentTimeMillis() - startMs);
<span class="nc" id="L115">              return true;</span>
<span class="nc" id="L116">          } catch (IOException ex) {</span>
<span class="nc" id="L117">            LOGGER.warn(String.format(&quot;failed to fetch segment %s from hdfs, might retry&quot;, uri), ex);</span>
<span class="nc" id="L118">            return false;</span>
          }
        }
      });
<span class="nc" id="L122">    } catch (Exception ex) {</span>
<span class="nc" id="L123">      LOGGER.error(String.format(&quot;failed to fetch %s from hdfs to local %s&quot;, uri, tempFilePath), ex);</span>
<span class="nc" id="L124">      throw ex;</span>
<span class="nc" id="L125">    }</span>
<span class="nc" id="L126">  }</span>

  @Override
  public Set&lt;String&gt; getProtectedConfigKeys() {
<span class="nc" id="L130">    return Collections.&lt;String&gt;emptySet();</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>