<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>KafkaStreamMetadata.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-distribution</a> &gt; <a href="../index.html" class="el_bundle">pinot-common</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.common.metadata.stream</a> &gt; <span class="el_source">KafkaStreamMetadata.java</span></div><h1>KafkaStreamMetadata.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.common.metadata.stream;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import com.google.common.base.Splitter;
import com.linkedin.pinot.common.utils.CommonConstants;
import com.linkedin.pinot.common.utils.CommonConstants.Helix;
import com.linkedin.pinot.common.utils.CommonConstants.Helix.DataSource.Realtime.Kafka.ConsumerType;
import com.linkedin.pinot.common.utils.StringUtil;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import static com.linkedin.pinot.common.utils.EqualityUtils.hashCodeOf;
import static com.linkedin.pinot.common.utils.EqualityUtils.isEqual;
import static com.linkedin.pinot.common.utils.EqualityUtils.isNullOrNotSameClass;
import static com.linkedin.pinot.common.utils.EqualityUtils.isSameReference;


public class KafkaStreamMetadata implements StreamMetadata {
<span class="fc" id="L39">  private static final Logger LOGGER = LoggerFactory.getLogger(KafkaStreamMetadata.class);</span>

  private final String _kafkaTopicName;
<span class="fc" id="L42">  private final List&lt;ConsumerType&gt; _consumerTypes = new ArrayList&lt;&gt;(2);</span>
  private final String _zkBrokerUrl;
  private final String _bootstrapHosts;
  private final String _decoderClass;
  private String _consumerFactoryName;
  private final long _kafkaConnectionTimeoutMillis;
  private final int _kafkaFetchTimeoutMillis;
<span class="fc" id="L49">  private final Map&lt;String, String&gt; _decoderProperties = new HashMap&lt;String, String&gt;();</span>
<span class="fc" id="L50">  private final Map&lt;String, String&gt; _kafkaConsumerProperties = new HashMap&lt;String, String&gt;();</span>
<span class="fc" id="L51">  private final Map&lt;String, String&gt; _streamConfigMap = new HashMap&lt;String, String&gt;();</span>

  private static final long DEFAULT_KAFKA_CONNECTION_TIMEOUT_MILLIS = 30000L;
  private static final int DEFAULT_KAFKA_FETCH_TIMEOUT_MILLIS = 5000;

<span class="fc" id="L56">  public KafkaStreamMetadata(Map&lt;String, String&gt; streamConfigMap) {</span>
<span class="fc" id="L57">    _zkBrokerUrl =</span>
        streamConfigMap.get(StringUtil.join(&quot;.&quot;, Helix.DataSource.STREAM_PREFIX,
            Helix.DataSource.Realtime.Kafka.HighLevelConsumer.ZK_CONNECTION_STRING));

<span class="fc" id="L61">    final String bootstrapHostConfigKey = Helix.DataSource.STREAM_PREFIX + &quot;.&quot; + Helix.DataSource.Realtime.Kafka.KAFKA_BROKER_LIST;</span>
<span class="fc bfc" id="L62" title="All 2 branches covered.">    if (streamConfigMap.containsKey(bootstrapHostConfigKey)) {</span>
<span class="fc" id="L63">      _bootstrapHosts = streamConfigMap.get(bootstrapHostConfigKey);</span>
    } else {
<span class="fc" id="L65">      _bootstrapHosts = null;</span>
    }

<span class="fc" id="L68">    String consumerTypesCsv =streamConfigMap.get(StringUtil.join(&quot;.&quot;, Helix.DataSource.STREAM_PREFIX, Helix.DataSource.Realtime.Kafka.CONSUMER_TYPE));</span>
<span class="fc" id="L69">    Iterable&lt;String&gt; parts = Splitter.on(',').trimResults().split(consumerTypesCsv);</span>
<span class="fc bfc" id="L70" title="All 2 branches covered.">    for (String part : parts) {</span>
<span class="fc" id="L71">      _consumerTypes.add(ConsumerType.valueOf(part));</span>
<span class="fc" id="L72">    }</span>
<span class="pc bpc" id="L73" title="1 of 2 branches missed.">    if (_consumerTypes.isEmpty()) {</span>
<span class="nc" id="L74">      throw new RuntimeException(&quot;Empty consumer types: Must have 'highLevel' or 'simple'&quot;);</span>
    }
<span class="fc" id="L76">    Collections.sort(_consumerTypes);</span>

<span class="fc" id="L78">    _kafkaTopicName =</span>
        streamConfigMap.get(StringUtil.join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX,
            CommonConstants.Helix.DataSource.Realtime.Kafka.TOPIC_NAME));
<span class="fc" id="L81">    _decoderClass =</span>
        streamConfigMap.get(StringUtil.join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX,
            CommonConstants.Helix.DataSource.Realtime.Kafka.DECODER_CLASS));

<span class="fc" id="L85">    _consumerFactoryName = streamConfigMap.get(StringUtil</span>
        .join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX, Helix.DataSource.Realtime.Kafka.CONSUMER_FACTORY));
<span class="pc bpc" id="L87" title="1 of 2 branches missed.">    if (_consumerFactoryName == null) {</span>
<span class="fc" id="L88">      _consumerFactoryName = Helix.DataSource.Realtime.Kafka.ConsumerFactory.SIMPLE_CONSUMER_FACTORY_STRING;</span>
    }
<span class="fc" id="L90">    LOGGER.info(&quot;Setting consumer factory to {}&quot;, _consumerFactoryName);</span>

<span class="fc" id="L92">    final String kafkaConnectionTimeoutPropertyKey = StringUtil.join(&quot;.&quot;, Helix.DataSource.STREAM_PREFIX,</span>
        Helix.DataSource.Realtime.Kafka.KAFKA_CONNECTION_TIMEOUT_MILLIS);
    long kafkaConnectionTimeoutMillis;
<span class="pc bpc" id="L95" title="1 of 2 branches missed.">    if (streamConfigMap.containsKey(kafkaConnectionTimeoutPropertyKey)) {</span>
      try {
<span class="nc" id="L97">        kafkaConnectionTimeoutMillis = Long.parseLong(streamConfigMap.get(kafkaConnectionTimeoutPropertyKey));</span>
<span class="nc" id="L98">      } catch (Exception e) {</span>
<span class="nc" id="L99">        LOGGER.warn(&quot;Caught exception while parsing the Kafka connection timeout, defaulting to {} ms&quot;, e,</span>
            DEFAULT_KAFKA_CONNECTION_TIMEOUT_MILLIS);
<span class="nc" id="L101">        kafkaConnectionTimeoutMillis = DEFAULT_KAFKA_CONNECTION_TIMEOUT_MILLIS;</span>
<span class="nc" id="L102">      }</span>
    } else {
<span class="fc" id="L104">      kafkaConnectionTimeoutMillis = DEFAULT_KAFKA_CONNECTION_TIMEOUT_MILLIS;</span>
    }
<span class="fc" id="L106">    _kafkaConnectionTimeoutMillis = kafkaConnectionTimeoutMillis;</span>

<span class="fc" id="L108">    final String kafkaFetchTimeoutPropertyKey = StringUtil.join(&quot;.&quot;, Helix.DataSource.STREAM_PREFIX,</span>
        Helix.DataSource.Realtime.Kafka.KAFKA_FETCH_TIMEOUT_MILLIS);
    int kafkaFetchTimeoutMillis;
<span class="pc bpc" id="L111" title="1 of 2 branches missed.">    if (streamConfigMap.containsKey(kafkaFetchTimeoutPropertyKey)) {</span>
      try {
<span class="nc" id="L113">        kafkaFetchTimeoutMillis = Integer.parseInt(streamConfigMap.get(kafkaFetchTimeoutPropertyKey));</span>
<span class="nc" id="L114">      } catch (Exception e) {</span>
<span class="nc" id="L115">        LOGGER.warn(&quot;Caughe exception while parsing the Kafka fetch timeout, defaulting to {} ms&quot;, e,</span>
            DEFAULT_KAFKA_FETCH_TIMEOUT_MILLIS);
<span class="nc" id="L117">        kafkaFetchTimeoutMillis = DEFAULT_KAFKA_FETCH_TIMEOUT_MILLIS;</span>
<span class="nc" id="L118">      }</span>
    } else {
<span class="fc" id="L120">      kafkaFetchTimeoutMillis = DEFAULT_KAFKA_FETCH_TIMEOUT_MILLIS;</span>
    }
<span class="fc" id="L122">    _kafkaFetchTimeoutMillis = kafkaFetchTimeoutMillis;</span>

<span class="fc bfc" id="L124" title="All 2 branches covered.">    for (String key : streamConfigMap.keySet()) {</span>
<span class="fc bfc" id="L125" title="All 2 branches covered.">      if (key.startsWith(CommonConstants.Helix.DataSource.STREAM_PREFIX + &quot;.&quot;)) {</span>
<span class="fc" id="L126">        _streamConfigMap.put(key, streamConfigMap.get(key));</span>
      }
<span class="fc bfc" id="L128" title="All 2 branches covered.">      if (key.startsWith(StringUtil.join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX,</span>
          CommonConstants.Helix.DataSource.Realtime.Kafka.DECODER_PROPS_PREFIX))) {
<span class="fc" id="L130">        _decoderProperties.put(CommonConstants.Helix.DataSource.Realtime.Kafka.getDecoderPropertyKey(key),</span>
            streamConfigMap.get(key));
      }
<span class="fc bfc" id="L133" title="All 2 branches covered.">      if (key.startsWith(StringUtil.join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX,</span>
          Helix.DataSource.Realtime.Kafka.KAFKA_CONSUMER_PROPS_PREFIX))) {
<span class="fc" id="L135">        _kafkaConsumerProperties.put(CommonConstants.Helix.DataSource.Realtime.Kafka.getConsumerPropertyKey(key),</span>
            streamConfigMap.get(key));
      }
<span class="fc" id="L138">    }</span>
<span class="fc" id="L139">  }</span>

  public boolean hasHighLevelKafkaConsumerType() {
<span class="fc" id="L142">    return _consumerTypes.contains(ConsumerType.highLevel);</span>
  }

  public boolean hasSimpleKafkaConsumerType() {
<span class="fc" id="L146">    return _consumerTypes.contains(ConsumerType.simple);</span>
  }

  public long getKafkaConnectionTimeoutMillis() {
<span class="fc" id="L150">    return _kafkaConnectionTimeoutMillis;</span>
  }

  public int getKafkaFetchTimeoutMillis() {
<span class="nc" id="L154">    return _kafkaFetchTimeoutMillis;</span>
  }

  public String getKafkaTopicName() {
<span class="fc" id="L158">    return _kafkaTopicName;</span>
  }

  public List&lt;ConsumerType&gt; getConsumerTypes() {
<span class="nc" id="L162">    return _consumerTypes;</span>
  }

  public Map&lt;String, String&gt; getKafkaConfigs() {
<span class="nc" id="L166">    return _streamConfigMap;</span>
  }

  public String getZkBrokerUrl() {
<span class="fc" id="L170">    return _zkBrokerUrl;</span>
  }

  public String getDecoderClass() {
<span class="fc" id="L174">    return _decoderClass;</span>
  }

  public String getConsumerFactoryName() {
<span class="fc" id="L178">    return _consumerFactoryName;</span>
  }

  public Map&lt;String, String&gt; getDecoderProperties() {
<span class="fc" id="L182">    return _decoderProperties;</span>
  }

  public Map&lt;String, String&gt; getKafkaConsumerProperties() {
<span class="fc" id="L186">    return _kafkaConsumerProperties;</span>
  }

  @Override
  public String toString() {
<span class="nc" id="L191">    final StringBuilder result = new StringBuilder();</span>
<span class="nc" id="L192">    String newline = &quot;\n&quot;;</span>
<span class="nc" id="L193">    result.append(this.getClass().getName());</span>
<span class="nc" id="L194">    result.append(&quot; Object {&quot;);</span>
<span class="nc" id="L195">    result.append(newline);</span>
<span class="nc" id="L196">    String[] keys = _streamConfigMap.keySet().toArray(new String[0]);</span>
<span class="nc" id="L197">    Arrays.sort(keys);</span>
<span class="nc bnc" id="L198" title="All 2 branches missed.">    for (final String key : keys) {</span>
<span class="nc bnc" id="L199" title="All 2 branches missed.">      if (key.startsWith(StringUtil.join(&quot;.&quot;, CommonConstants.Helix.DataSource.STREAM_PREFIX,</span>
          CommonConstants.Helix.DataSource.KAFKA))) {
<span class="nc" id="L201">        result.append(&quot;  &quot;);</span>
<span class="nc" id="L202">        result.append(key);</span>
<span class="nc" id="L203">        result.append(&quot;: &quot;);</span>
<span class="nc" id="L204">        result.append(_streamConfigMap.get(key));</span>
<span class="nc" id="L205">        result.append(newline);</span>
      }
    }
<span class="nc" id="L208">    result.append(&quot;}&quot;);</span>

<span class="nc" id="L210">    return result.toString();</span>
  }

  @Override
  public boolean equals(Object o) {
<span class="fc bfc" id="L215" title="All 2 branches covered.">    if (isSameReference(this, o)) {</span>
<span class="fc" id="L216">      return true;</span>
    }

<span class="fc bfc" id="L219" title="All 2 branches covered.">    if (isNullOrNotSameClass(this, o)) {</span>
<span class="fc" id="L220">      return false;</span>
    }

<span class="fc" id="L223">    KafkaStreamMetadata that = (KafkaStreamMetadata) o;</span>

<span class="fc bfc" id="L225" title="All 14 branches covered.">    return isEqual(_kafkaTopicName, that._kafkaTopicName) &amp;&amp;</span>
        isEqual(_consumerTypes, that._consumerTypes) &amp;&amp;
        isEqual(_zkBrokerUrl, that._zkBrokerUrl) &amp;&amp;
        isEqual(_decoderClass, that._decoderClass) &amp;&amp;
        isEqual(_decoderProperties, that._decoderProperties) &amp;&amp;
        isEqual(_streamConfigMap, that._streamConfigMap) &amp;&amp;
        isEqual(_consumerFactoryName, that._consumerFactoryName);
  }

  @Override
  public int hashCode() {
<span class="fc" id="L236">    int result = hashCodeOf(_kafkaTopicName);</span>
<span class="fc" id="L237">    result = hashCodeOf(result, _consumerTypes);</span>
<span class="fc" id="L238">    result = hashCodeOf(result, _zkBrokerUrl);</span>
<span class="fc" id="L239">    result = hashCodeOf(result, _decoderClass);</span>
<span class="fc" id="L240">    result = hashCodeOf(result, _decoderProperties);</span>
<span class="fc" id="L241">    result = hashCodeOf(result, _streamConfigMap);</span>
<span class="fc" id="L242">    result = hashCodeOf(result, _consumerFactoryName);</span>
<span class="fc" id="L243">    return result;</span>
  }

  @Override
  public Map&lt;String, String&gt; toMap() {
<span class="nc" id="L248">    return _streamConfigMap;</span>
  }

  public String getBootstrapHosts() {
<span class="fc" id="L252">    return _bootstrapHosts;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>