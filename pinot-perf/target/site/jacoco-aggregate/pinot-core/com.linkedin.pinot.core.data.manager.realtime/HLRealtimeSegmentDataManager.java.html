<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>HLRealtimeSegmentDataManager.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-perf</a> &gt; <a href="../index.html" class="el_bundle">pinot-core</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.core.data.manager.realtime</a> &gt; <span class="el_source">HLRealtimeSegmentDataManager.java</span></div><h1>HLRealtimeSegmentDataManager.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.core.data.manager.realtime;

import com.google.common.util.concurrent.Uninterruptibles;
import com.linkedin.pinot.common.config.TableConfig;
import com.linkedin.pinot.common.data.Schema;
import com.linkedin.pinot.common.metadata.instance.InstanceZKMetadata;
import com.linkedin.pinot.common.metadata.segment.RealtimeSegmentZKMetadata;
import com.linkedin.pinot.common.metrics.ServerGauge;
import com.linkedin.pinot.common.metrics.ServerMeter;
import com.linkedin.pinot.common.metrics.ServerMetrics;
import com.linkedin.pinot.common.utils.CommonConstants.Segment.Realtime.Status;
import com.linkedin.pinot.common.utils.CommonConstants.Segment.SegmentType;
import com.linkedin.pinot.core.data.GenericRow;
import com.linkedin.pinot.core.data.extractors.FieldExtractorFactory;
import com.linkedin.pinot.core.data.extractors.PlainFieldExtractor;
import com.linkedin.pinot.core.indexsegment.IndexSegment;
import com.linkedin.pinot.core.indexsegment.columnar.ColumnarSegmentLoader;
import com.linkedin.pinot.core.indexsegment.generator.SegmentVersion;
import com.linkedin.pinot.core.realtime.StreamProvider;
import com.linkedin.pinot.core.realtime.StreamProviderConfig;
import com.linkedin.pinot.core.realtime.StreamProviderFactory;
import com.linkedin.pinot.core.realtime.converter.RealtimeSegmentConverter;
import com.linkedin.pinot.core.realtime.impl.RealtimeSegmentConfig;
import com.linkedin.pinot.core.realtime.impl.RealtimeSegmentImpl;
import com.linkedin.pinot.core.realtime.impl.kafka.KafkaHighLevelStreamProviderConfig;
import com.linkedin.pinot.core.segment.index.loader.IndexLoadingConfig;
import java.io.File;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.TimerTask;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import org.apache.commons.io.FileUtils;
import org.joda.time.DateTime;
import org.joda.time.DateTimeZone;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


public class HLRealtimeSegmentDataManager extends RealtimeSegmentDataManager {
<span class="fc" id="L58">  private static final Logger LOGGER = LoggerFactory.getLogger(HLRealtimeSegmentDataManager.class);</span>
  private final static long ONE_MINUTE_IN_MILLSEC = 1000 * 60;

  private final String tableName;
  private final String segmentName;
  private final Schema schema;
  private final PlainFieldExtractor extractor;
  private final RealtimeSegmentZKMetadata segmentMetatdaZk;

  private final StreamProviderConfig kafkaStreamProviderConfig;
  private final StreamProvider kafkaStreamProvider;
  private final File resourceDir;
  private final File resourceTmpDir;
  private final RealtimeSegmentImpl realtimeSegment;
  private final String tableStreamName;

<span class="fc" id="L74">  private final long start = System.currentTimeMillis();</span>
  private long segmentEndTimeThreshold;
<span class="fc" id="L76">  private AtomicLong lastUpdatedRawDocuments = new AtomicLong(0);</span>

<span class="fc" id="L78">  private volatile boolean keepIndexing = true;</span>
<span class="fc" id="L79">  private volatile boolean isShuttingDown = false;</span>

  private TimerTask segmentStatusTask;
  private final ServerMetrics serverMetrics;
  private final RealtimeTableDataManager notifier;
  private Thread indexingThread;

  private final String sortedColumn;
  private final List&lt;String&gt; invertedIndexColumns;
  private final List&lt;String&gt; noDictionaryColumns;
<span class="fc" id="L89">  private Logger segmentLogger = LOGGER;</span>
  private final SegmentVersion _segmentVersion;

  // An instance of this class exists only for the duration of the realtime segment that is currently being consumed.
  // Once the segment is committed, the segment is handled by OfflineSegmentDataManager
  public HLRealtimeSegmentDataManager(final RealtimeSegmentZKMetadata realtimeSegmentZKMetadata,
      final TableConfig tableConfig, InstanceZKMetadata instanceMetadata,
      final RealtimeTableDataManager realtimeTableDataManager, final String resourceDataDir,
      final IndexLoadingConfig indexLoadingConfig, final Schema schema, final ServerMetrics serverMetrics)
      throws Exception {
<span class="fc" id="L99">    super();</span>
<span class="fc" id="L100">    _segmentVersion = indexLoadingConfig.getSegmentVersion();</span>
<span class="fc" id="L101">    this.schema = schema;</span>
<span class="fc" id="L102">    this.extractor = FieldExtractorFactory.getPlainFieldExtractor(schema);</span>
<span class="fc" id="L103">    this.serverMetrics =serverMetrics;</span>
<span class="fc" id="L104">    this.segmentName = realtimeSegmentZKMetadata.getSegmentName();</span>
<span class="fc" id="L105">    this.tableName = tableConfig.getTableName();</span>

<span class="fc" id="L107">    List&lt;String&gt; sortedColumns = indexLoadingConfig.getSortedColumns();</span>
<span class="pc bpc" id="L108" title="1 of 2 branches missed.">    if (sortedColumns.isEmpty()) {</span>
<span class="nc" id="L109">      LOGGER.info(&quot;RealtimeDataResourceZKMetadata contains no information about sorted column for segment {}&quot;,</span>
          segmentName);
<span class="nc" id="L111">      this.sortedColumn = null;</span>
    } else {
<span class="fc" id="L113">      String firstSortedColumn = sortedColumns.get(0);</span>
<span class="pc bpc" id="L114" title="1 of 2 branches missed.">      if (this.schema.hasColumn(firstSortedColumn)) {</span>
<span class="fc" id="L115">        LOGGER.info(&quot;Setting sorted column name: {} from RealtimeDataResourceZKMetadata for segment {}&quot;,</span>
            firstSortedColumn, segmentName);
<span class="fc" id="L117">        this.sortedColumn = firstSortedColumn;</span>
      } else {
<span class="nc" id="L119">        LOGGER.warn(</span>
            &quot;Sorted column name: {} from RealtimeDataResourceZKMetadata is not existed in schema for segment {}.&quot;,
            firstSortedColumn, segmentName);
<span class="nc" id="L122">        this.sortedColumn = null;</span>
      }
    }

    // Inverted index columns
<span class="fc" id="L127">    Set&lt;String&gt; invertedIndexColumns = indexLoadingConfig.getInvertedIndexColumns();</span>
    // We need to add sorted column into inverted index columns because when we convert realtime in memory segment into
    // offline segment, we use sorted column's inverted index to maintain the order of the records so that the records
    // are sorted on the sorted column.
<span class="pc bpc" id="L131" title="1 of 2 branches missed.">    if (sortedColumn != null) {</span>
<span class="fc" id="L132">      invertedIndexColumns.add(sortedColumn);</span>
    }
<span class="fc" id="L134">    this.invertedIndexColumns = new ArrayList&lt;&gt;(invertedIndexColumns);</span>

<span class="fc" id="L136">    this.segmentMetatdaZk = realtimeSegmentZKMetadata;</span>

    // No DictionaryColumns
<span class="fc" id="L139">    noDictionaryColumns = new ArrayList&lt;&gt;(indexLoadingConfig.getNoDictionaryColumns());</span>

    // create and init stream provider config
    // TODO : ideally resourceMetatda should create and give back a streamProviderConfig
<span class="fc" id="L143">    this.kafkaStreamProviderConfig = new KafkaHighLevelStreamProviderConfig();</span>
<span class="fc" id="L144">    this.kafkaStreamProviderConfig.init(tableConfig, instanceMetadata, schema);</span>
<span class="fc" id="L145">    segmentLogger = LoggerFactory.getLogger(HLRealtimeSegmentDataManager.class.getName() +</span>
            &quot;_&quot; + segmentName +
            &quot;_&quot; + kafkaStreamProviderConfig.getStreamName()
    );
<span class="fc" id="L149">    segmentLogger.info(&quot;Created segment data manager with Sorted column:{}, invertedIndexColumns:{}&quot;, sortedColumn,</span>
        this.invertedIndexColumns);

<span class="fc" id="L152">    segmentEndTimeThreshold = start + kafkaStreamProviderConfig.getTimeThresholdToFlushSegment();</span>

<span class="fc" id="L154">    this.resourceDir = new File(resourceDataDir);</span>
<span class="fc" id="L155">    this.resourceTmpDir = new File(resourceDataDir, &quot;_tmp&quot;);</span>
<span class="fc bfc" id="L156" title="All 2 branches covered.">    if (!resourceTmpDir.exists()) {</span>
<span class="fc" id="L157">      resourceTmpDir.mkdirs();</span>
    }
    // create and init stream provider
<span class="fc" id="L160">    final String tableName = tableConfig.getTableName();</span>
<span class="fc" id="L161">    this.kafkaStreamProvider = StreamProviderFactory.buildStreamProvider();</span>
<span class="fc" id="L162">    this.kafkaStreamProvider.init(kafkaStreamProviderConfig, tableName, serverMetrics);</span>
<span class="fc" id="L163">    this.kafkaStreamProvider.start();</span>
<span class="fc" id="L164">    this.tableStreamName = tableName + &quot;_&quot; + kafkaStreamProviderConfig.getStreamName();</span>

    // lets create a new realtime segment
<span class="fc" id="L167">    segmentLogger.info(&quot;Started kafka stream provider&quot;);</span>
<span class="fc" id="L168">    final int capacity = kafkaStreamProviderConfig.getSizeThresholdToFlushSegment();</span>
<span class="fc" id="L169">    RealtimeSegmentConfig realtimeSegmentConfig = new RealtimeSegmentConfig.Builder().setSegmentName(segmentName)</span>
        .setStreamName(kafkaStreamProviderConfig.getStreamName())
        .setSchema(schema)
        .setCapacity(capacity)
        .setAvgNumMultiValues(indexLoadingConfig.getRealtimeAvgMultiValueCount())
        .setNoDictionaryColumns(indexLoadingConfig.getNoDictionaryColumns())
        .setInvertedIndexColumns(invertedIndexColumns)
        .setRealtimeSegmentZKMetadata(realtimeSegmentZKMetadata)
        .setOffHeap(indexLoadingConfig.isRealtimeOffheapAllocation())
        .setMemoryManager(getMemoryManager(realtimeTableDataManager.getConsumerDir(), segmentName,
            indexLoadingConfig.isRealtimeOffheapAllocation(), indexLoadingConfig.isDirectRealtimeOffheapAllocation(),
            serverMetrics))
        .setStatsHistory(realtimeTableDataManager.getStatsHistory())
        .build();
<span class="fc" id="L183">    realtimeSegment = new RealtimeSegmentImpl(realtimeSegmentConfig);</span>

<span class="fc" id="L185">    notifier = realtimeTableDataManager;</span>

<span class="fc" id="L187">    LOGGER.info(&quot;Starting consumption on realtime consuming segment {} maxRowCount {} maxEndTime {}&quot;,</span>
        segmentName, capacity, new DateTime(segmentEndTimeThreshold, DateTimeZone.UTC).toString());
<span class="fc" id="L189">    segmentStatusTask = new TimerTask() {</span>
      @Override
      public void run() {
<span class="fc" id="L192">        computeKeepIndexing();</span>
<span class="fc" id="L193">      }</span>
    };

    // start the indexing thread
<span class="fc" id="L197">    indexingThread = new Thread(new Runnable() {</span>
      @Override
      public void run() {
        // continue indexing until criteria is met
<span class="fc" id="L201">        boolean notFull = true;</span>
<span class="fc" id="L202">        long exceptionSleepMillis = 50L;</span>
<span class="fc" id="L203">        segmentLogger.info(&quot;Starting to collect rows&quot;);</span>

        do {
<span class="fc" id="L206">          GenericRow readRow = null;</span>
<span class="fc" id="L207">          GenericRow transformedRow = null;</span>
<span class="fc" id="L208">          GenericRow row = null;</span>
          try {
<span class="fc" id="L210">            readRow = GenericRow.createOrReuseRow(readRow);</span>
<span class="fc" id="L211">            readRow = kafkaStreamProvider.next(readRow);</span>
<span class="fc" id="L212">            row = readRow;</span>

<span class="fc bfc" id="L214" title="All 2 branches covered.">            if (readRow != null) {</span>
<span class="fc" id="L215">              transformedRow = GenericRow.createOrReuseRow(transformedRow);</span>
<span class="fc" id="L216">              transformedRow = extractor.transform(readRow, transformedRow);</span>
<span class="fc" id="L217">              row = transformedRow;</span>
<span class="fc" id="L218">              notFull = realtimeSegment.index(transformedRow);</span>
<span class="fc" id="L219">              exceptionSleepMillis = 50L;</span>
            }
<span class="fc" id="L221">          } catch (Exception e) {</span>
<span class="fc" id="L222">            segmentLogger.warn(&quot;Caught exception while indexing row, sleeping for {} ms, row contents {}&quot;,</span>
                exceptionSleepMillis, row, e);

            // Sleep for a short time as to avoid filling the logs with exceptions too quickly
<span class="fc" id="L226">            Uninterruptibles.sleepUninterruptibly(exceptionSleepMillis, TimeUnit.MILLISECONDS);</span>
<span class="fc" id="L227">            exceptionSleepMillis = Math.min(60000L, exceptionSleepMillis * 2);</span>
<span class="nc" id="L228">          } catch (Error e) {</span>
<span class="nc" id="L229">            segmentLogger.error(&quot;Caught error in indexing thread&quot;, e);</span>
<span class="nc" id="L230">            throw e;</span>
<span class="fc" id="L231">          }</span>
<span class="pc bpc" id="L232" title="1 of 6 branches missed.">        } while (notFull &amp;&amp; keepIndexing &amp;&amp; (!isShuttingDown));</span>

<span class="fc bfc" id="L234" title="All 2 branches covered.">        if (isShuttingDown) {</span>
<span class="fc" id="L235">          segmentLogger.info(&quot;Shutting down indexing thread!&quot;);</span>
<span class="fc" id="L236">          return;</span>
        }
        try {
          int numErrors, numConversions, numNulls, numNullCols;
<span class="pc bpc" id="L240" title="1 of 2 branches missed.">          if ((numErrors = extractor.getTotalErrors()) &gt; 0) {</span>
<span class="nc" id="L241">            serverMetrics.addMeteredTableValue(tableStreamName,</span>
                ServerMeter.ROWS_WITH_ERRORS, (long) numErrors);
          }
<span class="fc" id="L244">          Map&lt;String, Integer&gt; errorCount = extractor.getErrorCount();</span>
<span class="fc bfc" id="L245" title="All 2 branches covered.">          for (String column : errorCount.keySet()) {</span>
<span class="pc bpc" id="L246" title="1 of 2 branches missed.">            if ((numErrors = errorCount.get(column)) &gt; 0) {</span>
<span class="nc" id="L247">              segmentLogger.warn(&quot;Column {} had {} rows with errors&quot;, column, numErrors);</span>
            }
<span class="fc" id="L249">          }</span>
<span class="pc bpc" id="L250" title="1 of 2 branches missed.">          if ((numConversions = extractor.getTotalConversions()) &gt; 0) {</span>
<span class="nc" id="L251">            serverMetrics.addMeteredTableValue(tableStreamName,</span>
                ServerMeter.ROWS_NEEDING_CONVERSIONS, (long) numConversions);
<span class="nc" id="L253">            segmentLogger.info(&quot;{} rows needed conversions &quot;, numConversions);</span>
          }
<span class="pc bpc" id="L255" title="1 of 2 branches missed.">          if ((numNulls = extractor.getTotalNulls()) &gt; 0) {</span>
<span class="nc" id="L256">            serverMetrics.addMeteredTableValue(tableStreamName,</span>
                ServerMeter.ROWS_WITH_NULL_VALUES, (long) numNulls);
<span class="nc" id="L258">            segmentLogger.info(&quot;{} rows had null columns&quot;, numNulls);</span>
          }
<span class="pc bpc" id="L260" title="1 of 2 branches missed.">          if ((numNullCols = extractor.getTotalNullCols()) &gt; 0) {</span>
<span class="nc" id="L261">            serverMetrics.addMeteredTableValue(tableStreamName,</span>
                ServerMeter.COLUMNS_WITH_NULL_VALUES, (long) numNullCols);
<span class="nc" id="L263">            segmentLogger.info(&quot;{} columns had null values&quot;, numNullCols);</span>
          }
<span class="fc" id="L265">          segmentLogger.info(&quot;Indexing threshold reached, proceeding with index conversion&quot;);</span>
          // kill the timer first
<span class="fc" id="L267">          segmentStatusTask.cancel();</span>
<span class="fc" id="L268">          updateCurrentDocumentCountMetrics();</span>
<span class="fc" id="L269">          segmentLogger.info(&quot;Indexed {} raw events&quot;, realtimeSegment.getNumDocsIndexed());</span>
<span class="fc" id="L270">          File tempSegmentFolder = new File(resourceTmpDir, &quot;tmp-&quot; + String.valueOf(System.currentTimeMillis()));</span>

          // lets convert the segment now
<span class="fc" id="L273">          RealtimeSegmentConverter converter =</span>
              new RealtimeSegmentConverter(realtimeSegment, tempSegmentFolder.getAbsolutePath(), schema,
                  realtimeSegmentZKMetadata.getTableName(), realtimeSegmentZKMetadata.getSegmentName(), sortedColumn,
                  HLRealtimeSegmentDataManager.this.invertedIndexColumns,
                  noDictionaryColumns, null/*StarTreeIndexSpec*/); // Star tree not supported for HLC.

<span class="fc" id="L279">          segmentLogger.info(&quot;Trying to build segment&quot;);</span>
<span class="fc" id="L280">          final long buildStartTime = System.nanoTime();</span>
<span class="fc" id="L281">          converter.build(_segmentVersion, serverMetrics);</span>
<span class="fc" id="L282">          final long buildEndTime = System.nanoTime();</span>
<span class="fc" id="L283">          segmentLogger.info(&quot;Built segment in {} ms&quot;,</span>
              TimeUnit.MILLISECONDS.convert((buildEndTime - buildStartTime), TimeUnit.NANOSECONDS));
<span class="fc" id="L285">          File destDir = new File(resourceDataDir, realtimeSegmentZKMetadata.getSegmentName());</span>
<span class="fc" id="L286">          FileUtils.deleteQuietly(destDir);</span>
<span class="fc" id="L287">          FileUtils.moveDirectory(tempSegmentFolder.listFiles()[0], destDir);</span>

<span class="fc" id="L289">          FileUtils.deleteQuietly(tempSegmentFolder);</span>
<span class="fc" id="L290">          long segStartTime = realtimeSegment.getMinTime();</span>
<span class="fc" id="L291">          long segEndTime = realtimeSegment.getMaxTime();</span>

<span class="fc" id="L293">          TimeUnit timeUnit = schema.getTimeFieldSpec().getOutgoingGranularitySpec().getTimeType();</span>
<span class="fc" id="L294">          IndexSegment segment =</span>
              ColumnarSegmentLoader.load(new File(resourceDir, segmentMetatdaZk.getSegmentName()), indexLoadingConfig);

<span class="fc" id="L297">          segmentLogger.info(&quot;Committing Kafka offsets&quot;);</span>
<span class="fc" id="L298">          boolean commitSuccessful = false;</span>
          try {
<span class="fc" id="L300">            kafkaStreamProvider.commit();</span>
<span class="fc" id="L301">            commitSuccessful = true;</span>
<span class="fc" id="L302">            kafkaStreamProvider.shutdown();</span>
<span class="fc" id="L303">            segmentLogger.info(&quot;Successfully committed Kafka offsets, consumer release requested.&quot;);</span>
<span class="fc" id="L304">          } catch (Throwable e) {</span>
            // If we got here, it means that either the commit or the shutdown failed. Considering that the
            // KafkaConsumerManager delays shutdown and only adds the consumer to be released in a deferred way, this
            // likely means that writing the Kafka offsets failed.
            //
            // The old logic (mark segment as done, then commit offsets and shutdown the consumer immediately) would die
            // in a terrible way, leaving the consumer open and causing us to only get half the records from that point
            // on. In this case, because we keep the consumer open for a little while, we should be okay if the
            // controller reassigns us a new segment before the consumer gets released. Hopefully by the next time that
            // we get to committing the offsets, the transient ZK failure that caused the write to fail will not
            // happen again and everything will be good.
            //
            // Several things can happen:
            // - The controller reassigns us a new segment before we release the consumer (KafkaConsumerManager will
            //   keep the consumer open for about a minute, which should be enough time for the controller to reassign
            //   us a new segment) and the next time we close the segment the offsets commit successfully; we're good.
            // - The controller reassigns us a new segment, but after we released the consumer (if the controller was
            //   down or there was a ZK failure on writing the Kafka offsets but not the Helix state). We lose whatever
            //   data was in this segment. Not good.
            // - The server crashes after this comment and before we mark the current segment as done; if the Kafka
            //   offsets didn't get written, then when the server restarts it'll start consuming the current segment
            //   from the previously committed offsets; we're good.
            // - The server crashes after this comment, the Kafka offsets were written but the segment wasn't marked as
            //   done in Helix, but we got a failure (or not) on the commit; we lose whatever data was in this segment
            //   if we restart the server (not good). If we manually mark the segment as done in Helix by editing the
            //   state in ZK, everything is good, we'll consume a new segment that starts from the correct offsets.
            //
            // This is still better than the previous logic, which would have these failure modes:
            // - Consumer was left open and the controller reassigned us a new segment; consume only half the events
            //   (because there are two consumers and Kafka will try to rebalance partitions between those two)
            // - We got a segment assigned to us before we got around to committing the offsets, reconsume the data that
            //   we got in this segment again, as we're starting consumption from the previously committed offset (eg.
            //   duplicate data).
            //
            // This is still not very satisfactory, which is why this part is due for a redesign.
            //
            // Assuming you got here because the realtime offset commit metric has fired, check the logs to determine
            // which of the above scenarios happened. If you're in one of the good scenarios, then there's nothing to
            // do. If you're not, then based on how critical it is to get those rows back, then your options are:
            // - Wipe the realtime table and reconsume everything (mark the replica as disabled so that clients don't
            //   see query results from partially consumed data, then re-enable it when this replica has caught up)
            // - Accept that those rows are gone in this replica and move on (they'll be replaced by good offline data
            //   soon anyway)
            // - If there's a replica that has consumed properly, you could shut it down, copy its segments onto this
            //   replica, assign a new consumer group id to this replica, rename the copied segments and edit their
            //   metadata to reflect the new consumer group id, copy the Kafka offsets from the shutdown replica onto
            //   the new consumer group id and then restart both replicas. This should get you the missing rows.

<span class="fc" id="L352">            segmentLogger.error(&quot;FATAL: Exception committing or shutting down consumer commitSuccessful={}&quot;,</span>
                commitSuccessful, e);
<span class="fc" id="L354">            serverMetrics.addMeteredTableValue(tableName, ServerMeter.REALTIME_OFFSET_COMMIT_EXCEPTIONS, 1L);</span>
<span class="pc bpc" id="L355" title="1 of 2 branches missed.">            if (!commitSuccessful) {</span>
<span class="fc" id="L356">              kafkaStreamProvider.shutdown();</span>
            }
<span class="fc" id="L358">          }</span>

          try {
<span class="fc" id="L361">            segmentLogger.info(&quot;Marking current segment as completed in Helix&quot;);</span>
<span class="fc" id="L362">            RealtimeSegmentZKMetadata metadataToOverwrite = new RealtimeSegmentZKMetadata();</span>
<span class="fc" id="L363">            metadataToOverwrite.setTableName(realtimeSegmentZKMetadata.getTableName());</span>
<span class="fc" id="L364">            metadataToOverwrite.setSegmentName(realtimeSegmentZKMetadata.getSegmentName());</span>
<span class="fc" id="L365">            metadataToOverwrite.setSegmentType(SegmentType.OFFLINE);</span>
<span class="fc" id="L366">            metadataToOverwrite.setStatus(Status.DONE);</span>
<span class="fc" id="L367">            metadataToOverwrite.setStartTime(segStartTime);</span>
<span class="fc" id="L368">            metadataToOverwrite.setEndTime(segEndTime);</span>
<span class="fc" id="L369">            metadataToOverwrite.setTimeUnit(timeUnit);</span>
<span class="fc" id="L370">            metadataToOverwrite.setTotalRawDocs(realtimeSegment.getNumDocsIndexed());</span>
<span class="fc" id="L371">            notifier.notifySegmentCommitted(metadataToOverwrite, segment);</span>
<span class="fc" id="L372">            segmentLogger.info(&quot;Completed write of segment completion to Helix, waiting for controller to assign a new segment&quot;);</span>
<span class="nc" id="L373">          } catch (Exception e) {</span>
<span class="nc bnc" id="L374" title="All 2 branches missed.">            if (commitSuccessful) {</span>
<span class="nc" id="L375">              segmentLogger.error(&quot;Offsets were committed to Kafka but we were unable to mark this segment as completed in Helix. Manually mark the segment as completed in Helix; restarting this instance will result in data loss.&quot;, e);</span>
            } else {
<span class="nc" id="L377">              segmentLogger.warn(&quot;Caught exception while marking segment as completed in Helix. Offsets were not written, restarting the instance should be safe.&quot;, e);</span>
            }
<span class="fc" id="L379">          }</span>
<span class="nc" id="L380">        } catch (Exception e) {</span>
<span class="nc" id="L381">          segmentLogger.error(&quot;Caught exception in the realtime indexing thread&quot;, e);</span>
<span class="fc" id="L382">        }</span>
<span class="fc" id="L383">      }</span>
    });

<span class="fc" id="L386">    indexingThread.start();</span>
<span class="fc" id="L387">    serverMetrics.addValueToTableGauge(tableName, ServerGauge.SEGMENT_COUNT, 1L);</span>
<span class="fc" id="L388">    segmentLogger.debug(&quot;scheduling keepIndexing timer check&quot;);</span>
    // start a schedule timer to keep track of the segment
<span class="fc" id="L390">    TimerService.timer.schedule(segmentStatusTask, ONE_MINUTE_IN_MILLSEC, ONE_MINUTE_IN_MILLSEC);</span>
<span class="fc" id="L391">    segmentLogger.info(&quot;finished scheduling keepIndexing timer check&quot;);</span>
<span class="fc" id="L392">  }</span>

  @Override
  public IndexSegment getSegment() {
<span class="fc" id="L396">    return realtimeSegment;</span>
  }

  @Override
  public String getSegmentName() {
<span class="fc" id="L401">    return segmentName;</span>
  }

  private void computeKeepIndexing() {
<span class="pc bpc" id="L405" title="1 of 2 branches missed.">    if (keepIndexing) {</span>
<span class="fc" id="L406">      segmentLogger.debug(&quot;Current indexed {} raw events&quot;, realtimeSegment.getNumDocsIndexed());</span>
<span class="pc bpc" id="L407" title="2 of 4 branches missed.">      if ((System.currentTimeMillis() &gt;= segmentEndTimeThreshold)</span>
          || realtimeSegment.getNumDocsIndexed() &gt;= kafkaStreamProviderConfig.getSizeThresholdToFlushSegment()) {
<span class="nc bnc" id="L409" title="All 2 branches missed.">        if (realtimeSegment.getNumDocsIndexed() == 0) {</span>
<span class="nc" id="L410">          segmentLogger.info(&quot;no new events coming in, extending the end time by another hour&quot;);</span>
<span class="nc" id="L411">          segmentEndTimeThreshold =</span>
              System.currentTimeMillis() + kafkaStreamProviderConfig.getTimeThresholdToFlushSegment();
<span class="nc" id="L413">          return;</span>
        }
<span class="nc" id="L415">        segmentLogger.info(</span>
            &quot;Stopped indexing due to reaching segment limit: {} raw documents indexed, segment is aged {} minutes&quot;,
            realtimeSegment.getNumDocsIndexed(), ((System.currentTimeMillis() - start) / (ONE_MINUTE_IN_MILLSEC)));
<span class="nc" id="L418">        keepIndexing = false;</span>
      }
    }
<span class="fc" id="L421">    updateCurrentDocumentCountMetrics();</span>
<span class="fc" id="L422">  }</span>

  private void updateCurrentDocumentCountMetrics() {
<span class="fc" id="L425">    int currentRawDocs = realtimeSegment.getNumDocsIndexed();</span>
<span class="fc" id="L426">    serverMetrics.addValueToTableGauge(tableName, ServerGauge.DOCUMENT_COUNT, (currentRawDocs - lastUpdatedRawDocuments.get()));</span>
<span class="fc" id="L427">    lastUpdatedRawDocuments.set(currentRawDocs);</span>
<span class="fc" id="L428">  }</span>

  @Override
  public void destroy() {
<span class="fc" id="L432">    LOGGER.info(&quot;Trying to shutdown RealtimeSegmentDataManager : {}!&quot;, this.segmentName);</span>
<span class="fc" id="L433">    isShuttingDown = true;</span>
    try {
<span class="fc" id="L435">      kafkaStreamProvider.shutdown();</span>
<span class="nc" id="L436">    } catch (Exception e) {</span>
<span class="nc" id="L437">      LOGGER.error(&quot;Failed to shutdown kafka stream provider!&quot;, e);</span>
<span class="fc" id="L438">    }</span>
<span class="fc" id="L439">    keepIndexing = false;</span>
<span class="fc" id="L440">    segmentStatusTask.cancel();</span>
<span class="fc" id="L441">    realtimeSegment.destroy();</span>
<span class="fc" id="L442">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>