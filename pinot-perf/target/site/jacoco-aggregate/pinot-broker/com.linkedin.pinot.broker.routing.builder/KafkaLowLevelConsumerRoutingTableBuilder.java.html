<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>KafkaLowLevelConsumerRoutingTableBuilder.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-perf</a> &gt; <a href="../index.html" class="el_bundle">pinot-broker</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.broker.routing.builder</a> &gt; <span class="el_source">KafkaLowLevelConsumerRoutingTableBuilder.java</span></div><h1>KafkaLowLevelConsumerRoutingTableBuilder.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.linkedin.pinot.broker.routing.builder;

import com.linkedin.pinot.common.config.TableConfig;
import com.linkedin.pinot.common.utils.CommonConstants;
import com.linkedin.pinot.common.utils.SegmentName;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.SortedSet;
import org.apache.commons.configuration.Configuration;
import org.apache.helix.ZNRecord;
import org.apache.helix.model.ExternalView;
import org.apache.helix.model.InstanceConfig;
import org.apache.helix.store.zk.ZkHelixPropertyStore;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


/**
 * Routing table builder for the Kafka low level consumer.
 */
<span class="fc" id="L39">public class KafkaLowLevelConsumerRoutingTableBuilder extends GeneratorBasedRoutingTableBuilder {</span>
<span class="fc" id="L40">  private static final Logger LOGGER = LoggerFactory.getLogger(KafkaLowLevelConsumerRoutingTableBuilder.class);</span>

<span class="fc" id="L42">  private int _targetNumServersPerQuery = 8;</span>

  @Override
  public void init(Configuration configuration, TableConfig tableConfig, ZkHelixPropertyStore&lt;ZNRecord&gt; propertyStore) {
    // TODO jfim This is a broker-level configuration for now, until we refactor the configuration of the routing table to allow per-table routing settings
<span class="pc bpc" id="L47" title="1 of 2 branches missed.">    if (configuration.containsKey(&quot;realtimeTargetServerCountPerQuery&quot;)) {</span>
<span class="nc" id="L48">      final String targetServerCountPerQuery = configuration.getString(&quot;realtimeTargetServerCountPerQuery&quot;);</span>
      try {
<span class="nc" id="L50">        _targetNumServersPerQuery = Integer.parseInt(targetServerCountPerQuery);</span>
<span class="nc" id="L51">        LOGGER.info(&quot;Using realtime target server count of {}&quot;, _targetNumServersPerQuery);</span>
<span class="nc" id="L52">      } catch (Exception e) {</span>
<span class="nc" id="L53">        LOGGER.warn(</span>
            &quot;Could not get the realtime target server count per query from configuration value {}, keeping default value {}&quot;,
            targetServerCountPerQuery, _targetNumServersPerQuery, e);
<span class="nc" id="L56">      }</span>
<span class="nc" id="L57">    } else {</span>
<span class="fc" id="L58">      LOGGER.info(&quot;Using default value for realtime target server count of {}&quot;, _targetNumServersPerQuery);</span>
    }
<span class="fc" id="L60">  }</span>

  @Override
  protected RoutingTableGenerator buildRoutingTableGenerator() {
<span class="fc" id="L64">    return new KafkaLowLevelConsumerRoutingTableGenerator();</span>
  }

<span class="fc" id="L67">  private class KafkaLowLevelConsumerRoutingTableGenerator extends BaseRoutingTableGenerator {</span>
    // We build the routing table based off the external view here. What we want to do is to make sure that we uphold
    // the guarantees clients expect (no duplicate records, eventual consistency) and spreading the load as equally as
    // possible between the servers.
    //
    // Each Kafka partition contains a fraction of the data, so we need to make sure that we query all partitions.
    // Because in certain unlikely degenerate scenarios, we can consume overlapping data until segments are flushed (at
    // which point the overlapping data is discarded during the reconciliation process with the controller), we need to
    // ensure that the query that is sent has only one partition in CONSUMING state in order to avoid duplicate records.
    //
    // The upstream code in BaseRoutingTableGenerator will generate routing tables based on taking a subset of servers
    // if the cluster is large enough as well as ensure that the best routing tables are used for routing.

<span class="fc" id="L80">    private Map&lt;String, List&lt;String&gt;&gt; _segmentToServersMap = new HashMap&lt;&gt;();</span>

<span class="fc" id="L82">    public KafkaLowLevelConsumerRoutingTableGenerator() {</span>
<span class="fc" id="L83">      super(_targetNumServersPerQuery);</span>
<span class="fc" id="L84">    }</span>

    @Override
    public void init(ExternalView externalView, List&lt;InstanceConfig&gt; instanceConfigList) {
      // 1. Gather all segments and group them by Kafka partition, sorted by sequence number
<span class="fc" id="L89">      Map&lt;String, SortedSet&lt;SegmentName&gt;&gt; sortedSegmentsByKafkaPartition =</span>
          KafkaLowLevelRoutingTableBuilderUtil.getSortedSegmentsByKafkaPartition(externalView);

      // 2. Ensure that for each Kafka partition, we have at most one Helix partition (Pinot segment) in consuming state
<span class="fc" id="L93">      Map&lt;String, SegmentName&gt; allowedSegmentInConsumingStateByKafkaPartition =</span>
          KafkaLowLevelRoutingTableBuilderUtil.getAllowedConsumingStateSegments(externalView,
              sortedSegmentsByKafkaPartition);

      // 3. Sort all the segments to be used during assignment in ascending order of replicas

      // PriorityQueue throws IllegalArgumentException when given a size of zero
<span class="fc" id="L100">      RoutingTableInstancePruner instancePruner = new RoutingTableInstancePruner(instanceConfigList);</span>

<span class="fc bfc" id="L102" title="All 2 branches covered.">      for (Map.Entry&lt;String, SortedSet&lt;SegmentName&gt;&gt; entry : sortedSegmentsByKafkaPartition.entrySet()) {</span>
<span class="fc" id="L103">        String kafkaPartition = entry.getKey();</span>
<span class="fc" id="L104">        SortedSet&lt;SegmentName&gt; segmentNames = entry.getValue();</span>

        // The only segment name which is allowed to be in CONSUMING state or null
<span class="fc" id="L107">        SegmentName validConsumingSegment = allowedSegmentInConsumingStateByKafkaPartition.get(kafkaPartition);</span>

<span class="fc bfc" id="L109" title="All 2 branches covered.">        for (SegmentName segmentName : segmentNames) {</span>
<span class="fc" id="L110">          List&lt;String&gt; validServers = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L111">          String segmentNameStr = segmentName.getSegmentName();</span>
<span class="fc" id="L112">          Map&lt;String, String&gt; externalViewState = externalView.getStateMap(segmentNameStr);</span>

<span class="fc bfc" id="L114" title="All 2 branches covered.">          for (Map.Entry&lt;String, String&gt; instanceAndStateEntry : externalViewState.entrySet()) {</span>
<span class="fc" id="L115">            String instance = instanceAndStateEntry.getKey();</span>
<span class="fc" id="L116">            String state = instanceAndStateEntry.getValue();</span>

            // Skip pruned replicas (shutting down or otherwise disabled)
<span class="fc bfc" id="L119" title="All 2 branches covered.">            if (instancePruner.isInactive(instance)) {</span>
<span class="fc" id="L120">              continue;</span>
            }

            // Replicas in ONLINE state are always allowed
<span class="fc bfc" id="L124" title="All 2 branches covered.">            if (state.equalsIgnoreCase(</span>
                CommonConstants.Helix.StateModel.RealtimeSegmentOnlineOfflineStateModel.ONLINE)) {
<span class="fc" id="L126">              validServers.add(instance);</span>
<span class="fc" id="L127">              continue;</span>
            }

            // Replicas in CONSUMING state are only allowed on the last segment
<span class="pc bpc" id="L131" title="2 of 4 branches missed.">            if (state.equalsIgnoreCase(</span>
                CommonConstants.Helix.StateModel.RealtimeSegmentOnlineOfflineStateModel.CONSUMING)
                &amp;&amp; segmentName.equals(validConsumingSegment)) {
<span class="fc" id="L134">              validServers.add(instance);</span>
            }
<span class="fc" id="L136">          }</span>

<span class="fc bfc" id="L138" title="All 2 branches covered.">          if (!validServers.isEmpty()) {</span>
<span class="fc" id="L139">            _segmentToServersMap.put(segmentNameStr, validServers);</span>
          }

          // If this segment is the segment allowed in CONSUMING state, don't process segments after it in that Kafka
          // partition
<span class="fc bfc" id="L144" title="All 2 branches covered.">          if (segmentName.equals(validConsumingSegment)) {</span>
<span class="fc" id="L145">            break;</span>
          }
<span class="fc" id="L147">        }</span>
<span class="fc" id="L148">      }</span>
<span class="fc" id="L149">    }</span>

    @Override
    protected Map&lt;String, List&lt;String&gt;&gt; getSegmentToServersMap() {
<span class="fc" id="L153">      return _segmentToServersMap;</span>
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>