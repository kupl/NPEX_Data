<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>ValidationManager.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">pinot-tools</a> &gt; <a href="../index.html" class="el_bundle">pinot-controller</a> &gt; <a href="index.source.html" class="el_package">com.linkedin.pinot.controller.validation</a> &gt; <span class="el_source">ValidationManager.java</span></div><h1>ValidationManager.java</h1><pre class="source lang-java linenums">/**
 * Copyright (C) 2014-2016 LinkedIn Corp. (pinot-core@linkedin.com)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.linkedin.pinot.controller.validation;

import com.linkedin.pinot.common.config.TableConfig;
import com.linkedin.pinot.common.config.TableNameBuilder;
import com.linkedin.pinot.common.metadata.ZKMetadataProvider;
import com.linkedin.pinot.common.metadata.segment.OfflineSegmentZKMetadata;
import com.linkedin.pinot.common.metadata.segment.RealtimeSegmentZKMetadata;
import com.linkedin.pinot.common.metadata.stream.KafkaStreamMetadata;
import com.linkedin.pinot.common.metrics.ValidationMetrics;
import com.linkedin.pinot.common.utils.CommonConstants.Helix.TableType;
import com.linkedin.pinot.common.utils.HLCSegmentName;
import com.linkedin.pinot.common.utils.LLCSegmentName;
import com.linkedin.pinot.common.utils.SegmentName;
import com.linkedin.pinot.common.utils.helix.HelixHelper;
import com.linkedin.pinot.common.utils.time.TimeUtils;
import com.linkedin.pinot.controller.ControllerConf;
import com.linkedin.pinot.controller.helix.core.PinotHelixResourceManager;
import com.linkedin.pinot.controller.helix.core.PinotHelixSegmentOnlineOfflineStateModelGenerator;
import com.linkedin.pinot.controller.helix.core.realtime.PinotLLCRealtimeSegmentManager;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;
import org.apache.helix.ZNRecord;
import org.apache.helix.model.IdealState;
import org.apache.helix.store.zk.ZkHelixPropertyStore;
import org.joda.time.Duration;
import org.joda.time.Interval;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


/**
 * Manages the segment validation metrics, to ensure that all offline segments are contiguous (no missing segments) and
 * that the offline push delay isn't too high.
 */

public class ValidationManager {
<span class="fc" id="L62">  private static final Logger LOGGER = LoggerFactory.getLogger(ValidationManager.class);</span>
  private final ValidationMetrics _validationMetrics;
  private final ScheduledExecutorService _executorService;
  private final PinotHelixResourceManager _pinotHelixResourceManager;
  private final long _validationIntervalSeconds;
  private final boolean _autoCreateOnError;
  private final PinotLLCRealtimeSegmentManager _llcRealtimeSegmentManager;

  /**
   * Constructs the validation manager.
   * @param validationMetrics The validation metrics utility used to publish the metrics.
   * @param pinotHelixResourceManager The resource manager used to interact with Helix
   * @param config
   * @param llcRealtimeSegmentManager
   */
  public ValidationManager(ValidationMetrics validationMetrics, PinotHelixResourceManager pinotHelixResourceManager,
<span class="fc" id="L78">      ControllerConf config, PinotLLCRealtimeSegmentManager llcRealtimeSegmentManager) {</span>
<span class="fc" id="L79">    _validationMetrics = validationMetrics;</span>
<span class="fc" id="L80">    _pinotHelixResourceManager = pinotHelixResourceManager;</span>
<span class="fc" id="L81">    _validationIntervalSeconds = config.getValidationControllerFrequencyInSeconds();</span>
<span class="fc" id="L82">    _autoCreateOnError = true;</span>
<span class="fc" id="L83">    _llcRealtimeSegmentManager = llcRealtimeSegmentManager;</span>

<span class="fc" id="L85">    _executorService = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() {</span>
      @Override
      public Thread newThread(Runnable runnable) {
<span class="fc" id="L88">        Thread thread = new Thread(runnable);</span>
<span class="fc" id="L89">        thread.setName(&quot;PinotValidationManagerExecutorService&quot;);</span>
<span class="fc" id="L90">        return thread;</span>
      }
    });
<span class="fc" id="L93">  }</span>

  /**
   * Starts the validation manager.
   */
  public void start() {
<span class="fc" id="L99">    LOGGER.info(&quot;Starting validation manager&quot;);</span>

    // Set up an executor that executes validation tasks periodically
<span class="fc" id="L102">    _executorService.scheduleWithFixedDelay(new Runnable() {</span>
      @Override
      public void run() {
        try {
<span class="nc" id="L106">          runValidation();</span>
<span class="nc" id="L107">        } catch (Exception e) {</span>
<span class="nc" id="L108">          LOGGER.warn(&quot;Caught exception while running validation&quot;, e);</span>
<span class="nc" id="L109">        }</span>
<span class="nc" id="L110">      }</span>
    }, 120, _validationIntervalSeconds, TimeUnit.SECONDS);
<span class="fc" id="L112">  }</span>

  /**
   * Stops the validation manager.
   */
  public void stop() {
    // Shut down the executor
<span class="fc" id="L119">    _executorService.shutdown();</span>
<span class="fc" id="L120">  }</span>

  /**
   * Runs a validation pass over the currently loaded tables.
   */
  public void runValidation() {
<span class="nc bnc" id="L126" title="All 2 branches missed.">    if (!_pinotHelixResourceManager.isLeader()) {</span>
<span class="nc" id="L127">      _validationMetrics.unregisterAllMetrics();</span>
<span class="nc" id="L128">      LOGGER.info(&quot;Skipping validation, not leader!&quot;);</span>
<span class="nc" id="L129">      return;</span>
    }

<span class="nc" id="L132">    LOGGER.info(&quot;Starting validation&quot;);</span>
    // Fetch the list of tables
<span class="nc" id="L134">    List&lt;String&gt; allTableNames = _pinotHelixResourceManager.getAllTables();</span>
<span class="nc" id="L135">    ZkHelixPropertyStore&lt;ZNRecord&gt; propertyStore = _pinotHelixResourceManager.getPropertyStore();</span>

<span class="nc bnc" id="L137" title="All 2 branches missed.">    for (String tableNameWithType : allTableNames) {</span>
<span class="nc" id="L138">      _pinotHelixResourceManager.rebuildBrokerResourceFromHelixTags(tableNameWithType);</span>
<span class="nc" id="L139">      LOGGER.info(&quot;Starting to validate table: {}&quot;, tableNameWithType);</span>

      // For each table, fetch the metadata for all its segments
<span class="nc" id="L142">      TableType tableType = TableNameBuilder.getTableTypeFromTableName(tableNameWithType);</span>
<span class="nc bnc" id="L143" title="All 2 branches missed.">      if (tableType == TableType.OFFLINE) {</span>
<span class="nc" id="L144">        validateOfflineSegmentPush(propertyStore, tableNameWithType);</span>
      } else {
<span class="nc" id="L146">        List&lt;RealtimeSegmentZKMetadata&gt; realtimeSegmentZKMetadataList =</span>
            ZKMetadataProvider.getRealtimeSegmentZKMetadataListForTable(propertyStore, tableNameWithType);
<span class="nc" id="L148">        boolean countHLCSegments = true;  // false if this table has ONLY LLC segments (i.e. fully migrated)</span>
<span class="nc" id="L149">        TableConfig tableConfig = null;</span>
<span class="nc" id="L150">        KafkaStreamMetadata streamMetadata = null;</span>
        try {
<span class="nc" id="L152">          tableConfig = _pinotHelixResourceManager.getRealtimeTableConfig(tableNameWithType);</span>
<span class="nc bnc" id="L153" title="All 2 branches missed.">          if (tableConfig == null) {</span>
<span class="nc" id="L154">            continue;</span>
          }
<span class="nc" id="L156">          streamMetadata = new KafkaStreamMetadata(tableConfig.getIndexingConfig().getStreamConfigs());</span>
<span class="nc bnc" id="L157" title="All 4 branches missed.">          if (streamMetadata.hasSimpleKafkaConsumerType() &amp;&amp; !streamMetadata.hasHighLevelKafkaConsumerType()) {</span>
<span class="nc" id="L158">            countHLCSegments = false;</span>
          }
          // Update the gauge to contain the total document count in the segments
<span class="nc" id="L161">          _validationMetrics.updateTotalDocumentCountGauge(tableNameWithType,</span>
              computeRealtimeTotalDocumentInSegments(realtimeSegmentZKMetadataList, countHLCSegments));
<span class="nc bnc" id="L163" title="All 2 branches missed.">          if (streamMetadata.hasSimpleKafkaConsumerType()) {</span>
<span class="nc" id="L164">            validateLLCSegments(tableNameWithType, tableConfig);</span>
          }
<span class="nc" id="L166">        } catch (Exception e) {</span>
<span class="nc bnc" id="L167" title="All 2 branches missed.">          if (tableConfig == null) {</span>
<span class="nc" id="L168">            LOGGER.warn(&quot;Cannot get realtime table config for table: {}&quot;, tableNameWithType);</span>
<span class="nc bnc" id="L169" title="All 2 branches missed.">          } else if (streamMetadata == null) {</span>
<span class="nc" id="L170">            LOGGER.warn(&quot;Cannot get stream config for table: {}&quot;, tableNameWithType);</span>
          } else {
<span class="nc" id="L172">            LOGGER.error(&quot;Exception while validating table: {}&quot;, tableNameWithType, e);</span>
          }
<span class="nc" id="L174">        }</span>
      }
<span class="nc" id="L176">    }</span>
<span class="nc" id="L177">    LOGGER.info(&quot;Validation completed&quot;);</span>
<span class="nc" id="L178">  }</span>

  // For LLC segments, validate that there is at least one segment in CONSUMING state for every partition.
  void validateLLCSegments(final String realtimeTableName, TableConfig tableConfig) {
<span class="fc" id="L182">    LOGGER.info(&quot;Validating LLC Segments for {}&quot;, realtimeTableName);</span>
<span class="fc" id="L183">    Map&lt;String, String&gt; streamConfigs = tableConfig.getIndexingConfig().getStreamConfigs();</span>
<span class="fc" id="L184">    ZNRecord partitionAssignment = _llcRealtimeSegmentManager.getKafkaPartitionAssignment(realtimeTableName);</span>
<span class="pc bpc" id="L185" title="1 of 2 branches missed.">    if (partitionAssignment == null) {</span>
<span class="nc" id="L186">      LOGGER.warn(&quot;No partition assignment found for table {}&quot;, realtimeTableName);</span>
<span class="nc" id="L187">      return;</span>
    }
<span class="fc" id="L189">    Map&lt;String, List&lt;String&gt;&gt; partitionToHostsMap = partitionAssignment.getListFields();</span>
    // Keep a set of kafka partitions, and remove the partition when we find a segment in CONSUMING state in
    // that partition.
<span class="fc" id="L192">    Set&lt;Integer&gt; nonConsumingKafkaPartitions = new HashSet&lt;&gt;(partitionToHostsMap.size());</span>
<span class="fc bfc" id="L193" title="All 2 branches covered.">    for (String partitionStr : partitionToHostsMap.keySet()) {</span>
<span class="fc" id="L194">      nonConsumingKafkaPartitions.add(Integer.valueOf(partitionStr));</span>
<span class="fc" id="L195">    }</span>

<span class="fc" id="L197">    IdealState idealState =</span>
        HelixHelper.getTableIdealState(_pinotHelixResourceManager.getHelixZkManager(), realtimeTableName);
<span class="pc bpc" id="L199" title="1 of 2 branches missed.">    if (!idealState.isEnabled()) {</span>
      // No validation to be done.
<span class="nc" id="L201">      LOGGER.info(&quot;Skipping validation for {} since it is disabled&quot;, realtimeTableName);</span>
<span class="nc" id="L202">      return;</span>
    }
    // Walk through all segments in the idealState, looking for one instance that is in CONSUMING state. If we find one
    // remove the kafka partition that the segment belongs to, from the kafka partition set.
    // Make sure that there are at least some LLC segments in place. If there are no LLC segments, it is possible
    // that this table is in the process of being disabled for LLC
<span class="fc" id="L208">    Set&lt;String&gt; segmentIds = idealState.getPartitionSet();</span>
<span class="fc" id="L209">    List&lt;String&gt; llcSegments = new ArrayList&lt;&gt;(segmentIds.size());</span>
<span class="fc bfc" id="L210" title="All 2 branches covered.">    for (String segmentId : segmentIds) {</span>
<span class="pc bpc" id="L211" title="1 of 2 branches missed.">      if (SegmentName.isLowLevelConsumerSegmentName(segmentId)) {</span>
<span class="fc" id="L212">        llcSegments.add(segmentId);</span>
<span class="fc" id="L213">        Map&lt;String, String&gt; stateMap = idealState.getInstanceStateMap(segmentId);</span>
<span class="fc" id="L214">        Iterator&lt;String&gt; iterator = stateMap.values().iterator();</span>
        // If there is at least one instance in CONSUMING state, we are good.
<span class="fc" id="L216">        boolean foundConsuming = false;</span>
<span class="fc bfc" id="L217" title="All 4 branches covered.">        while (iterator.hasNext() &amp;&amp; !foundConsuming) {</span>
<span class="fc" id="L218">          String stateString = iterator.next();</span>
<span class="fc bfc" id="L219" title="All 2 branches covered.">          if (stateString.equals(PinotHelixSegmentOnlineOfflineStateModelGenerator.CONSUMING_STATE)) {</span>
<span class="fc" id="L220">            LOGGER.info(&quot;Found CONSUMING segment {}&quot;, segmentId);</span>
<span class="fc" id="L221">            foundConsuming = true;</span>
          }
<span class="fc" id="L223">        }</span>
<span class="fc bfc" id="L224" title="All 2 branches covered.">        if (foundConsuming) {</span>
<span class="fc" id="L225">          LLCSegmentName llcSegmentName = new LLCSegmentName(segmentId);</span>
<span class="fc" id="L226">          nonConsumingKafkaPartitions.remove(llcSegmentName.getPartitionId());</span>
        }
      }
<span class="fc" id="L229">    }</span>

    // Kafka partition set now has all the partitions that do not have any segments in CONSUMING state.
<span class="pc bpc" id="L232" title="1 of 2 branches missed.">    if (!llcSegments.isEmpty()) {</span>
      // Raise the metric only if there is at least one llc segment in the idealstate.
<span class="fc" id="L234">      _validationMetrics.updateNonConsumingPartitionCountMetric(realtimeTableName, nonConsumingKafkaPartitions.size());</span>
      // Recreate a segment for the partitions that are missing one.
<span class="fc bfc" id="L236" title="All 2 branches covered.">      for (Integer kafkaPartition : nonConsumingKafkaPartitions) {</span>
<span class="fc" id="L237">        LOGGER.warn(&quot;Table {}, kafka partition {} has no segments in CONSUMING state (out of {} llc segments)&quot;,</span>
            realtimeTableName, kafkaPartition, llcSegments.size());
<span class="fc" id="L239">      }</span>
<span class="pc bpc" id="L240" title="1 of 2 branches missed.">      if (_autoCreateOnError) {</span>
<span class="nc" id="L241">        _llcRealtimeSegmentManager.createConsumingSegment(realtimeTableName, nonConsumingKafkaPartitions, llcSegments,</span>
            tableConfig);
<span class="nc" id="L243">        _llcRealtimeSegmentManager.completeCommittingSegments(realtimeTableName, llcSegments);</span>
      }
    }
    // Make this call after other validations (so that we verify that we are consistent against the existing partition
    // assignment). This call may end up changing the kafka partition assignment for the table.
<span class="fc" id="L248">    _llcRealtimeSegmentManager.updateKafkaPartitionsIfNecessary(tableConfig);</span>
<span class="fc" id="L249">  }</span>

  // For offline segment pushes, validate that there are no missing segments, and update metrics
  private void validateOfflineSegmentPush(ZkHelixPropertyStore&lt;ZNRecord&gt; propertyStore, String offlineTableName) {
<span class="nc" id="L253">    List&lt;OfflineSegmentZKMetadata&gt; offlineSegmentZKMetadataList =</span>
        ZKMetadataProvider.getOfflineSegmentZKMetadataListForTable(propertyStore, offlineTableName);

    // Compute the missing segments if there are at least two
<span class="nc" id="L257">    int numMissingSegments = 0;</span>
<span class="nc" id="L258">    int numSegments = offlineSegmentZKMetadataList.size();</span>
<span class="nc bnc" id="L259" title="All 2 branches missed.">    if (numSegments &gt;= 2) {</span>
<span class="nc" id="L260">      List&lt;Interval&gt; segmentIntervals = new ArrayList&lt;&gt;(numSegments);</span>
<span class="nc" id="L261">      Duration timeGranularity = null;</span>
<span class="nc bnc" id="L262" title="All 2 branches missed.">      for (OfflineSegmentZKMetadata offlineSegmentZKMetadata : offlineSegmentZKMetadataList) {</span>
<span class="nc" id="L263">        Interval timeInterval = offlineSegmentZKMetadata.getTimeInterval();</span>
<span class="nc bnc" id="L264" title="All 6 branches missed.">        if (timeInterval != null &amp;&amp; TimeUtils.timeValueInValidRange(timeInterval.getStartMillis())</span>
            &amp;&amp; TimeUtils.timeValueInValidRange(timeInterval.getEndMillis())) {
<span class="nc" id="L266">          segmentIntervals.add(timeInterval);</span>
<span class="nc" id="L267">          timeGranularity = offlineSegmentZKMetadata.getTimeGranularity();</span>
        }
<span class="nc" id="L269">      }</span>
<span class="nc" id="L270">      List&lt;Interval&gt; missingIntervals = computeMissingIntervals(segmentIntervals, timeGranularity);</span>
<span class="nc bnc" id="L271" title="All 2 branches missed.">      for (Interval missingInterval : missingIntervals) {</span>
<span class="nc" id="L272">        LOGGER.warn(&quot;Missing data in table {} for time interval {}&quot;, offlineTableName, missingInterval);</span>
<span class="nc" id="L273">      }</span>
<span class="nc" id="L274">      numMissingSegments = missingIntervals.size();</span>
    }
    // Update the gauge that contains the number of missing segments
<span class="nc" id="L277">    _validationMetrics.updateMissingSegmentCountGauge(offlineTableName, numMissingSegments);</span>

    // Compute the max segment end time and max segment push time
<span class="nc" id="L280">    long maxSegmentEndTime = Long.MIN_VALUE;</span>
<span class="nc" id="L281">    long maxSegmentPushTime = Long.MIN_VALUE;</span>

<span class="nc bnc" id="L283" title="All 2 branches missed.">    for (OfflineSegmentZKMetadata offlineSegmentZKMetadata : offlineSegmentZKMetadataList) {</span>
<span class="nc" id="L284">      Interval segmentInterval = offlineSegmentZKMetadata.getTimeInterval();</span>

<span class="nc bnc" id="L286" title="All 4 branches missed.">      if (segmentInterval != null &amp;&amp; maxSegmentEndTime &lt; segmentInterval.getEndMillis()) {</span>
<span class="nc" id="L287">        maxSegmentEndTime = segmentInterval.getEndMillis();</span>
      }

<span class="nc" id="L290">      long segmentPushTime = offlineSegmentZKMetadata.getPushTime();</span>
<span class="nc" id="L291">      long segmentRefreshTime = offlineSegmentZKMetadata.getRefreshTime();</span>
<span class="nc" id="L292">      long segmentUpdateTime = Math.max(segmentPushTime, segmentRefreshTime);</span>

<span class="nc bnc" id="L294" title="All 2 branches missed.">      if (maxSegmentPushTime &lt; segmentUpdateTime) {</span>
<span class="nc" id="L295">        maxSegmentPushTime = segmentUpdateTime;</span>
      }
<span class="nc" id="L297">    }</span>

    // Update the gauges that contain the delay between the current time and last segment end time
<span class="nc" id="L300">    _validationMetrics.updateOfflineSegmentDelayGauge(offlineTableName, maxSegmentEndTime);</span>
<span class="nc" id="L301">    _validationMetrics.updateLastPushTimeGauge(offlineTableName, maxSegmentPushTime);</span>
    // Update the gauge to contain the total document count in the segments
<span class="nc" id="L303">    _validationMetrics.updateTotalDocumentCountGauge(offlineTableName,</span>
        computeOfflineTotalDocumentInSegments(offlineSegmentZKMetadataList));
    // Update the gauge to contain the total number of segments for this table
<span class="nc" id="L306">    _validationMetrics.updateSegmentCountGauge(offlineTableName, numSegments);</span>
<span class="nc" id="L307">  }</span>

  public static long computeOfflineTotalDocumentInSegments(
      List&lt;OfflineSegmentZKMetadata&gt; offlineSegmentZKMetadataList) {
<span class="nc" id="L311">    long numTotalDocs = 0;</span>
<span class="nc bnc" id="L312" title="All 2 branches missed.">    for (OfflineSegmentZKMetadata offlineSegmentZKMetadata : offlineSegmentZKMetadataList) {</span>
<span class="nc" id="L313">      numTotalDocs += offlineSegmentZKMetadata.getTotalRawDocs();</span>
<span class="nc" id="L314">    }</span>
<span class="nc" id="L315">    return numTotalDocs;</span>
  }

  public static long computeRealtimeTotalDocumentInSegments(
      List&lt;RealtimeSegmentZKMetadata&gt; realtimeSegmentZKMetadataList, boolean countHLCSegments) {
<span class="fc" id="L320">    long numTotalDocs = 0;</span>

<span class="fc" id="L322">    String groupId = &quot;&quot;;</span>
<span class="fc bfc" id="L323" title="All 2 branches covered.">    for (RealtimeSegmentZKMetadata realtimeSegmentZKMetadata : realtimeSegmentZKMetadataList) {</span>
<span class="fc" id="L324">      String segmentName = realtimeSegmentZKMetadata.getSegmentName();</span>
<span class="fc bfc" id="L325" title="All 2 branches covered.">      if (SegmentName.isHighLevelConsumerSegmentName(segmentName)) {</span>
<span class="fc bfc" id="L326" title="All 2 branches covered.">        if (countHLCSegments) {</span>
<span class="fc" id="L327">          HLCSegmentName hlcSegmentName = new HLCSegmentName(segmentName);</span>
<span class="fc" id="L328">          String segmentGroupIdName = hlcSegmentName.getGroupId();</span>

<span class="fc bfc" id="L330" title="All 2 branches covered.">          if (groupId.isEmpty()) {</span>
<span class="fc" id="L331">            groupId = segmentGroupIdName;</span>
          }
          // Discard all segments with different groupids as they are replicas
<span class="pc bpc" id="L334" title="1 of 4 branches missed.">          if (groupId.equals(segmentGroupIdName) &amp;&amp; realtimeSegmentZKMetadata.getTotalRawDocs() &gt;= 0) {</span>
<span class="fc" id="L335">            numTotalDocs += realtimeSegmentZKMetadata.getTotalRawDocs();</span>
          }
<span class="fc" id="L337">        }</span>
      } else {
        // Low level segments
<span class="pc bpc" id="L340" title="1 of 2 branches missed.">        if (!countHLCSegments) {</span>
<span class="fc" id="L341">          numTotalDocs += realtimeSegmentZKMetadata.getTotalRawDocs();</span>
        }
      }
<span class="fc" id="L344">    }</span>

<span class="fc" id="L346">    return numTotalDocs;</span>
  }

  /**
   * Computes a list of missing intervals, given a list of existing intervals and the expected frequency of the
   * intervals.
   *
   * @param segmentIntervals The list of existing intervals
   * @param frequency The expected interval frequency
   * @return The list of missing intervals
   */
  public static List&lt;Interval&gt; computeMissingIntervals(List&lt;Interval&gt; segmentIntervals, Duration frequency) {
    // Sanity check for frequency
<span class="pc bpc" id="L359" title="1 of 2 branches missed.">    if (frequency == null) {</span>
<span class="nc" id="L360">      return Collections.emptyList();</span>
    }

    // Default segment granularity to day level if its small than hours.
<span class="fc bfc" id="L364" title="All 2 branches covered.">    if (frequency.getMillis() &lt; Duration.standardHours(1).getMillis()) {</span>
<span class="fc" id="L365">      frequency = Duration.standardDays(1);</span>
    }

    // If there are less than two segments, none can be missing
<span class="pc bpc" id="L369" title="1 of 2 branches missed.">    if (segmentIntervals.size() &lt; 2) {</span>
<span class="nc" id="L370">      return Collections.emptyList();</span>
    }

    // Sort the intervals by ascending starting time
<span class="fc" id="L374">    List&lt;Interval&gt; sortedSegmentIntervals = new ArrayList&lt;Interval&gt;(segmentIntervals);</span>
<span class="fc" id="L375">    Collections.sort(sortedSegmentIntervals, new Comparator&lt;Interval&gt;() {</span>
      @Override
      public int compare(Interval first, Interval second) {
<span class="fc bfc" id="L378" title="All 2 branches covered.">        if (first.getStartMillis() &lt; second.getStartMillis()) {</span>
<span class="fc" id="L379">          return -1;</span>
<span class="pc bpc" id="L380" title="1 of 2 branches missed.">        } else if (second.getStartMillis() &lt; first.getStartMillis()) {</span>
<span class="fc" id="L381">          return 1;</span>
        }
<span class="nc" id="L383">        return 0;</span>
      }
    });

    // Find the minimum starting time and maximum ending time
<span class="fc" id="L388">    final long startTime = sortedSegmentIntervals.get(0).getStartMillis();</span>
<span class="fc" id="L389">    long endTime = Long.MIN_VALUE;</span>
<span class="fc bfc" id="L390" title="All 2 branches covered.">    for (Interval sortedSegmentInterval : sortedSegmentIntervals) {</span>
<span class="pc bpc" id="L391" title="1 of 2 branches missed.">      if (endTime &lt; sortedSegmentInterval.getEndMillis()) {</span>
<span class="fc" id="L392">        endTime = sortedSegmentInterval.getEndMillis();</span>
      }
<span class="fc" id="L394">    }</span>

<span class="fc" id="L396">    final long frequencyMillis = frequency.getMillis();</span>
<span class="fc" id="L397">    int lastEndIntervalCount = 0;</span>
<span class="fc" id="L398">    List&lt;Interval&gt; missingIntervals = new ArrayList&lt;Interval&gt;(10);</span>
<span class="fc bfc" id="L399" title="All 2 branches covered.">    for (Interval segmentInterval : sortedSegmentIntervals) {</span>
<span class="fc" id="L400">      int startIntervalCount = (int) ((segmentInterval.getStartMillis() - startTime) / frequencyMillis);</span>
<span class="fc" id="L401">      int endIntervalCount = (int) ((segmentInterval.getEndMillis() - startTime) / frequencyMillis);</span>

      // If there is at least one complete missing interval between the end of the previous interval and the start of
      // the current interval, then mark the missing interval(s) as missing
<span class="fc bfc" id="L405" title="All 2 branches covered.">      if (lastEndIntervalCount &lt; startIntervalCount - 1) {</span>
<span class="fc bfc" id="L406" title="All 2 branches covered.">        for (int missingIntervalIndex = lastEndIntervalCount + 1; missingIntervalIndex &lt; startIntervalCount;</span>
<span class="fc" id="L407">            ++missingIntervalIndex) {</span>
<span class="fc" id="L408">          missingIntervals.add(new Interval(startTime + frequencyMillis * missingIntervalIndex,</span>
              startTime + frequencyMillis * (missingIntervalIndex + 1) - 1));
        }
      }

<span class="fc" id="L413">      lastEndIntervalCount = Math.max(lastEndIntervalCount, endIntervalCount);</span>
<span class="fc" id="L414">    }</span>

<span class="fc" id="L416">    return missingIntervals;</span>
  }

  /**
   * Counts the number of missing segments, given their start times and their expected frequency.
   *
   * @param sortedStartTimes Start times for the segments, sorted in ascending order.
   * @param frequency The expected segment frequency (ie. daily, hourly, etc.)
   */
  public static int countMissingSegments(long[] sortedStartTimes, TimeUnit frequency) {
    // If there are less than two segments, none can be missing
<span class="fc bfc" id="L427" title="All 2 branches covered.">    if (sortedStartTimes.length &lt; 2) {</span>
<span class="fc" id="L428">      return 0;</span>
    }

<span class="fc" id="L431">    final long frequencyMillis = frequency.toMillis(1);</span>
<span class="fc" id="L432">    final long halfFrequencyMillis = frequencyMillis / 2;</span>
<span class="fc" id="L433">    final long firstStartTime = sortedStartTimes[0];</span>
<span class="fc" id="L434">    final long lastStartTime = sortedStartTimes[sortedStartTimes.length - 1];</span>
<span class="fc" id="L435">    final int expectedSegmentCount = (int) ((lastStartTime + halfFrequencyMillis - firstStartTime) / frequencyMillis);</span>

<span class="fc" id="L437">    int missingSegments = 0;</span>
<span class="fc" id="L438">    int currentIndex = 1;</span>
<span class="fc" id="L439">    int expectedIntervalCount = 1;</span>
<span class="fc bfc" id="L440" title="All 2 branches covered.">    while (expectedIntervalCount &lt;= expectedSegmentCount) {</span>
      // Count the number of complete intervals that are found
<span class="fc" id="L442">      final int intervalCount =</span>
          (int) ((sortedStartTimes[currentIndex] + halfFrequencyMillis - firstStartTime) / frequencyMillis);

      // Does this segment have the expected interval count?
<span class="fc bfc" id="L446" title="All 2 branches covered.">      if (intervalCount == expectedIntervalCount) {</span>
        // Yes, advance both the current index and expected interval count
<span class="fc" id="L448">        ++expectedIntervalCount;</span>
<span class="fc" id="L449">        ++currentIndex;</span>
      } else {
<span class="fc bfc" id="L451" title="All 2 branches covered.">        if (intervalCount &lt; expectedIntervalCount) {</span>
          // Duplicate segment, just advance the index
<span class="fc" id="L453">          ++currentIndex;</span>
        } else {
          // Missing segment(s), advance the index, increment the number of missing segments by the number of missing
          // intervals and set the expected interval to the following one
<span class="fc" id="L457">          missingSegments += intervalCount - expectedIntervalCount;</span>
<span class="fc" id="L458">          expectedIntervalCount = intervalCount + 1;</span>
<span class="fc" id="L459">          ++currentIndex;</span>
        }
      }
<span class="fc" id="L462">    }</span>

<span class="fc" id="L464">    return missingSegments;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>